{"0": {
    "doc": "Upgrade to 1.x.x",
    "title": "Upgrade to 1.x.x",
    "content": "Open Distro for Elasticsearch 1.0.0 uses Elasticsearch 7.0.1, which has numerous breaking changes from 6.x.x. This page includes several important considerations when upgrading from Open Distro for Elasticsearch 0.x.x to 1.x.x. . | Security index | Security YAML format | Discovery | Cluster and index names | Default shard count | Shards per node limit | Search response hits | Mapping types | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/",
    "relUrl": "/docs/upgrade/1-0-0/"
  },"1": {
    "doc": "Upgrade to 1.x.x",
    "title": "Security index",
    "content": "0.x.x versions of the .opendistro_security index do not automatically work with the new version. Instead, you must back up your configuration, upgrade, and then use the -migrate option of the new securityadmin.sh to migrate your configuration YAML files to the new format and reinitialize the index: . # Example backup command for 0.x.x ./securityadmin.sh -r -cd ~/my-backup-dir -icl -nhnv -cacert /etc/elasticsearch/root-ca.pem -cert /etc/elasticsearch/kirk.pem -key /etc/elasticsearch/kirk-key.pem # Example migration command for 1.x.x ./securityadmin.sh -migrate ~/my-backup-dir -nhnv -cacert /etc/elasticsearch/root-ca.pem -cert /etc/elasticsearch/kirk.pem -key /etc/elasticsearch/kirk-key.pem . If you use the Docker installation, create copies of the YAML files outside of the container before and after the migration so that you can pass them to the cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#security-index",
    "relUrl": "/docs/upgrade/1-0-0/#security-index"
  },"2": {
    "doc": "Upgrade to 1.x.x",
    "title": "Security YAML format",
    "content": "1.x.x versions of the Security configuration YAML files use a slightly different file format than 0.x.x versions. The -migrate option of the new securityadmin.sh helps you move from the old format to the new format. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#security-yaml-format",
    "relUrl": "/docs/upgrade/1-0-0/#security-yaml-format"
  },"3": {
    "doc": "Upgrade to 1.x.x",
    "title": "Discovery",
    "content": "Node discovery settings have changed in 1.x.x. Instead of discovery.zen.ping.unicast.hosts and discovery.zen.hosts_provider, use discovery.seed_hosts and discovery.seed_providers. For an example, see Sample Docker Compose file. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#discovery",
    "relUrl": "/docs/upgrade/1-0-0/#discovery"
  },"4": {
    "doc": "Upgrade to 1.x.x",
    "title": "Cluster and index names",
    "content": "Cluster and index names can no longer contain the : character. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#cluster-and-index-names",
    "relUrl": "/docs/upgrade/1-0-0/#cluster-and-index-names"
  },"5": {
    "doc": "Upgrade to 1.x.x",
    "title": "Default shard count",
    "content": "Indices now default to one shard rather than five. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#default-shard-count",
    "relUrl": "/docs/upgrade/1-0-0/#default-shard-count"
  },"6": {
    "doc": "Upgrade to 1.x.x",
    "title": "Shards per node limit",
    "content": "Clusters now default to a limit of 1,000 shards per data node, which you can change using the cluster.max_shards_per_node setting. Primary and replica shards both count towards this limit, but any shards that are part of a closed index do not. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#shards-per-node-limit",
    "relUrl": "/docs/upgrade/1-0-0/#shards-per-node-limit"
  },"7": {
    "doc": "Upgrade to 1.x.x",
    "title": "Search response hits",
    "content": "hits.total, returned as part of search responses, is now an object, not an integer. If you created monitors using the Alerting plugin, you probably need to update them to use the new response format (hits.total.value rather than hits.total). For example, this is the old format: . { \"hits\": { \"total\": 5 } } . This is the new format: . { \"hits\": { \"total\": { \"value\": 5, \"relation\": \"eq\" } } } . Possible values for relation are eq (value is accurate) and gte (value is a lower bound). If you want to use the old behavior, add rest_total_hits_as_int=true as a parameter in the search request: . GET _search?rest_total_hits_as_int=true { \"query\": { \"match\": { \"title\": \"wind\" } } } . To update your monitors: . | Open Kibana. | Choose Alerting, Monitors, and a monitor. | Select a trigger and choose Edit. | Change any occurrences of ctx.results[0].hits.total to ctx.results[0].hits.total.value, and then choose Update. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#search-response-hits",
    "relUrl": "/docs/upgrade/1-0-0/#search-response-hits"
  },"8": {
    "doc": "Upgrade to 1.x.x",
    "title": "Mapping types",
    "content": "Like Elasticsearch 6.x, indices can contain only one mapping type, but that type must now be named _doc. As a result, certain requests that used to require a mapping type no longer do. For example, this is an old call to the bulk API: . POST _bulk { \"index\": { \"_index\" : \"&lt;index&gt;\", \"_type\" : \"_doc\", \"_id\" : \"&lt;id&gt;\" } } { \"A JSON\": \"document\" } . This is a new call: . POST _bulk { \"index\": { \"_index\" : \"&lt;index&gt;\", \"_id\" : \"&lt;id&gt;\" } } { \"A JSON\": \"document\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-0-0/#mapping-types",
    "relUrl": "/docs/upgrade/1-0-0/#mapping-types"
  },"9": {
    "doc": "Upgrade to 1.10.1",
    "title": "Upgrade to 1.10.1 (Kibana)",
    "content": "Open Distro for Elasticsearch 1.10.1 includes a breaking change for the Kibana security plugin, which now uses the new Kibana plugin platform. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-10-1/#upgrade-to-1101-kibana",
    "relUrl": "/docs/upgrade/1-10-1/#upgrade-to-1101-kibana"
  },"10": {
    "doc": "Upgrade to 1.10.1",
    "title": "Kibana security plugin",
    "content": "You must make a manual configuration change if your Kibana install meets these conditions: . | You upgraded Kibana from any of the previous versions to 1.10.1. | You use the Kibana security plugin version 1.10.1.1 or newer. | You use unsecured HTTP for the communication protocol. | . Add this line to kibana.yml, and restart Kibana: . opendistro_security.cookie.secure: false . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-10-1/#kibana-security-plugin",
    "relUrl": "/docs/upgrade/1-10-1/#kibana-security-plugin"
  },"11": {
    "doc": "Upgrade to 1.10.1",
    "title": "Upgrade to 1.10.1",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-10-1/",
    "relUrl": "/docs/upgrade/1-10-1/"
  },"12": {
    "doc": "Upgrade to 1.11.0",
    "title": "Upgrade to 1.11.0 (Kibana)",
    "content": "Open Distro for Elasticsearch 1.11.0 renames the SQL Workbench plugin for Kibana to the Query Workbench. Instead of incrementing the opendistro_sql_workbench version number, remove the plugin and install opendistro-query-workbench instead, as covered in Standalone Kibana plugin install. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-11.0/#upgrade-to-1110-kibana",
    "relUrl": "/docs/upgrade/1-11.0/#upgrade-to-1110-kibana"
  },"13": {
    "doc": "Upgrade to 1.11.0",
    "title": "Upgrade to 1.11.0",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-11.0/",
    "relUrl": "/docs/upgrade/1-11.0/"
  },"14": {
    "doc": "Upgrade to 1.8.0",
    "title": "Upgrade to 1.8.0",
    "content": "Open Distro for Elasticsearch 1.8.0 includes a breaking change from 1.7.0. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-8-0/",
    "relUrl": "/docs/upgrade/1-8-0/"
  },"15": {
    "doc": "Upgrade to 1.8.0",
    "title": "Anomaly detection plugin",
    "content": "If you use the RPM or Debian installs, the name of the anomaly detection plugin in each package manager has changed from opendistro-anomaly-detector to opendistro-anomaly-detection. Prior to upgrading, use your package manager to remove the opendistro-anomaly-detector package: . sudo yum remove opendistro-anomaly-detector sudo apt remove opendistro-anomaly-detector . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/1-8-0/#anomaly-detection-plugin",
    "relUrl": "/docs/upgrade/1-8-0/#anomaly-detection-plugin"
  },"16": {
    "doc": "Amazon Machine Image",
    "title": "Amazon Machine Image",
    "content": "For convenience, Open Distro for Elasticsearch publishes Amazon Machine Images (AMIs) for use with Amazon Elastic Compute Cloud (Amazon EC2). These images use Amazon Linux 2 for their base image and come with Open Distro for Elasticsearch preinstalled. You can find the images in the Community AMIs section of the EC2 console if you search for Open Distro for Elasticsearch. | Choose an instance type with at least 2 GiB of RAM. | Configuration and usage is no different than the standard RPM install. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/ami/",
    "relUrl": "/docs/install/ami/"
  },"17": {
    "doc": "API",
    "title": "API",
    "content": "The security plugin REST API lets you programmatically create and manage users, roles, role mappings, action groups, and tenants. . | Access control for the API | Reserved and hidden resources | Account . | Get account details | Change password | . | Action groups . | Get action group | Get action groups | Delete action group | Create action group | Patch action group | Patch action groups | . | Users . | Get user | Get users | Delete user | Create user | Patch user | Patch users | . | Roles . | Get role | Get roles | Delete role | Create role | Patch role | Patch roles | . | Role mappings . | Get role mapping | Get role mappings | Delete role mapping | Create role mapping | Patch role mapping | Patch role mappings | . | Tenants . | Get tenant | Get tenants | Delete tenant | Create tenant | Patch tenant | Patch tenants | . | Configuration . | Get configuration | Update configuration | Patch configuration | . | Certificates . | Get certificates | Update configuration | Patch configuration | . | Cache . | Flush cache | . | Health . | Health check | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/",
    "relUrl": "/docs/security/access-control/api/"
  },"18": {
    "doc": "API",
    "title": "Access control for the API",
    "content": "Just like Elasticsearch permissions, you control access to the security plugin REST API using roles. Specify roles in elasticsearch.yml: . opendistro_security.restapi.roles_enabled: [\"&lt;role&gt;\", ...] . These roles can now access all APIs. To prevent access to certain APIs: . opendistro_security.restapi.endpoints_disabled.&lt;role&gt;.&lt;endpoint&gt;: [\"&lt;method&gt;\", ...] . Possible values for endpoint are: . | ACTIONGROUPS | ROLES | ROLESMAPPING | INTERNALUSERS | CONFIG | CACHE | LICENSE | SYSTEMINFO | . Possible values for method are: . | GET | PUT | POST | DELETE | PATCH | . For example, the following line grants the my-role role access to the PUT, POST, and DELETE methods of the ROLES URIs. opendistro_security.restapi.endpoints_disabled.my-role.ROLES: [\"PUT\", \"POST\", \"DELETE\"] . To use the PUT and PATCH methods for the configuration APIs, add the following line to elasticsearch.yml: . opendistro_security.unsupported.restapi.allow_securityconfig_modification: true . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#access-control-for-the-api",
    "relUrl": "/docs/security/access-control/api/#access-control-for-the-api"
  },"19": {
    "doc": "API",
    "title": "Reserved and hidden resources",
    "content": "You can mark users, role, role mappings, and action groups as reserved. Resources that have this flag set to true can’t be changed using the REST API or Kibana. To mark a resource as reserved, add the following flag: . kibana_user: reserved: true . Likewise, you can mark users, role, role mappings, and action groups as hidden. Resources that have this flag set to true are not returned by the REST API and not visible in Kibana: . kibana_user: hidden: true . Hidden resources are automatically reserved. To add or remove these flags, you need to modify plugins/opendistro_security/securityconfig/internal_users.yml and run plugins/opendistro_security/tools/securityadmin.sh. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#reserved-and-hidden-resources",
    "relUrl": "/docs/security/access-control/api/#reserved-and-hidden-resources"
  },"20": {
    "doc": "API",
    "title": "Account",
    "content": "Get account details . Returns account details for the current user. For example, if you sign the request as the admin user, the response includes details for that user. Request . GET _opendistro/_security/api/account . Sample response . { \"user_name\": \"admin\", \"is_reserved\": true, \"is_hidden\": false, \"is_internal_user\": true, \"user_requested_tenant\": null, \"backend_roles\": [ \"admin\" ], \"custom_attribute_names\": [], \"tenants\": { \"global_tenant\": true, \"admin_tenant\": true, \"admin\": true }, \"roles\": [ \"all_access\", \"own_index\" ] } . Change password . Changes the password for the current user. Request . PUT _opendistro/_security/api/account { \"current_password\" : \"old-password\", \"password\" : \"new-password\" } . Sample response . { \"status\": \"OK\", \"message\": \"'test-user' updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#account",
    "relUrl": "/docs/security/access-control/api/#account"
  },"21": {
    "doc": "API",
    "title": "Action groups",
    "content": "Get action group . Retrieves one action group. Request . GET _opendistro/_security/api/actiongroups/&lt;action-group&gt; . Sample response . { \"custom_action_group\": { \"reserved\": false, \"hidden\": false, \"allowed_actions\": [ \"kibana_all_read\", \"indices:admin/aliases/get\", \"indices:admin/aliases/exists\" ], \"description\": \"My custom action group\", \"static\": false } } . Get action groups . Retrieves all action groups. Request . GET _opendistro/_security/api/actiongroups/ . Sample response . { \"read\": { \"reserved\": true, \"hidden\": false, \"allowed_actions\": [ \"indices:data/read*\", \"indices:admin/mappings/fields/get*\" ], \"type\": \"index\", \"description\": \"Allow all read operations\", \"static\": true }, ... } . Delete action group . Request . DELETE _opendistro/_security/api/actiongroups/&lt;action-group&gt; . Sample response . { \"status\":\"OK\", \"message\":\"actiongroup SEARCH deleted.\" } . Create action group . Creates or replaces the specified action group. Request . PUT _opendistro/_security/api/actiongroups/&lt;action-group&gt; { \"allowed_actions\": [ \"indices:data/write/index*\", \"indices:data/write/update*\", \"indices:admin/mapping/put\", \"indices:data/write/bulk*\", \"read\", \"write\" ] } . Sample response . { \"status\": \"CREATED\", \"message\": \"'my-action-group' created.\" } . Patch action group . Updates individual attributes of an action group. Request . PATCH _opendistro/_security/api/actiongroups/&lt;action-group&gt; [ { \"op\": \"replace\", \"path\": \"/allowed_actions\", \"value\": [\"indices:admin/create\", \"indices:admin/mapping/put\"] } ] . Sample response . { \"status\":\"OK\", \"message\":\"actiongroup SEARCH deleted.\" } . Patch action groups . Creates, updates, or deletes multiple action groups in a single call. Request . PATCH _opendistro/_security/api/actiongroups [ { \"op\": \"add\", \"path\": \"/CREATE_INDEX\", \"value\": { \"allowed_actions\": [\"indices:admin/create\", \"indices:admin/mapping/put\"] } }, { \"op\": \"remove\", \"path\": \"/CRUD\" } ] . Sample response . { \"status\":\"OK\", \"message\":\"actiongroup SEARCH deleted.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#action-groups",
    "relUrl": "/docs/security/access-control/api/#action-groups"
  },"22": {
    "doc": "API",
    "title": "Users",
    "content": "These calls let you create, update, and delete internal users. If you use an external authentication backend, you probably don’t need to worry about internal users. Get user . Request . GET _opendistro/_security/api/internalusers/&lt;username&gt; . Sample response . { \"kirk\": { \"hash\": \"\", \"roles\": [ \"captains\", \"starfleet\" ], \"attributes\": { \"attribute1\": \"value1\", \"attribute2\": \"value2\", } } } . Get users . Request . GET _opendistro/_security/api/internalusers/ . Sample response . { \"kirk\": { \"hash\": \"\", \"roles\": [ \"captains\", \"starfleet\" ], \"attributes\": { \"attribute1\": \"value1\", \"attribute2\": \"value2\", } } } . Delete user . Request . DELETE _opendistro/_security/api/internalusers/&lt;username&gt; . Sample response . { \"status\":\"OK\", \"message\":\"user kirk deleted.\" } . Create user . Creates or replaces the specified user. You must specify either password (plain text) or hash (the hashed user password). If you specify password, the security plugin automatically hashes the password before storing it. Request . PUT _opendistro/_security/api/internalusers/&lt;username&gt; { \"password\": \"kirkpass\", \"backend_roles\": [\"captains\", \"starfleet\"], \"attributes\": { \"attribute1\": \"value1\", \"attribute2\": \"value2\" } } . Sample response . { \"status\":\"CREATED\", \"message\":\"User kirk created\" } . Patch user . Updates individual attributes of an internal user. Request . PATCH _opendistro/_security/api/internalusers/&lt;username&gt; [ { \"op\": \"replace\", \"path\": \"/backend_roles\", \"value\": [\"klingons\"] }, { \"op\": \"replace\", \"path\": \"/attributes\", \"value\": { \"newattribute\": \"newvalue\" } } ] . Sample response . { \"status\": \"OK\", \"message\": \"'kirk' updated.\" } . Patch users . Creates, updates, or deletes multiple internal users in a single call. Request . PATCH _opendistro/_security/api/internalusers [ { \"op\": \"add\", \"path\": \"/spock\", \"value\": { \"password\": \"testpassword1\", \"backend_roles\": [\"testrole1\"] } }, { \"op\": \"add\", \"path\": \"/worf\", \"value\": { \"password\": \"testpassword2\", \"backend_roles\": [\"testrole2\"] } }, { \"op\": \"remove\", \"path\": \"/riker\" } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#users",
    "relUrl": "/docs/security/access-control/api/#users"
  },"23": {
    "doc": "API",
    "title": "Roles",
    "content": "Get role . Retrieves one role. Request . GET _opendistro/_security/api/roles/&lt;role&gt; . Sample response . { \"test-role\": { \"reserved\": false, \"hidden\": false, \"cluster_permissions\": [ \"cluster_composite_ops\", \"indices_monitor\" ], \"index_permissions\": [{ \"index_patterns\": [ \"movies*\" ], \"dls\": \"\", \"fls\": [], \"masked_fields\": [], \"allowed_actions\": [ \"read\" ] }], \"tenant_permissions\": [{ \"tenant_patterns\": [ \"human_resources\" ], \"allowed_actions\": [ \"kibana_all_read\" ] }], \"static\": false } } . Get roles . Retrieves all roles. Request . GET _opendistro/_security/api/roles/ . Sample response . { \"manage_snapshots\": { \"reserved\": true, \"hidden\": false, \"description\": \"Provide the minimum permissions for managing snapshots\", \"cluster_permissions\": [ \"manage_snapshots\" ], \"index_permissions\": [{ \"index_patterns\": [ \"*\" ], \"fls\": [], \"masked_fields\": [], \"allowed_actions\": [ \"indices:data/write/index\", \"indices:admin/create\" ] }], \"tenant_permissions\": [], \"static\": true }, ... } . Delete role . Request . DELETE _opendistro/_security/api/roles/&lt;role&gt; . Sample response . { \"status\":\"OK\", \"message\":\"role test-role deleted.\" } . Create role . Creates or replaces the specified role. Request . PUT _opendistro/_security/api/roles/&lt;role&gt; { \"cluster_permissions\": [ \"cluster_composite_ops\", \"indices_monitor\" ], \"index_permissions\": [{ \"index_patterns\": [ \"movies*\" ], \"dls\": \"\", \"fls\": [], \"masked_fields\": [], \"allowed_actions\": [ \"read\" ] }], \"tenant_permissions\": [{ \"tenant_patterns\": [ \"human_resources\" ], \"allowed_actions\": [ \"kibana_all_read\" ] }] } . Sample response . { \"status\": \"OK\", \"message\": \"'test-role' updated.\" } . Patch role . Updates individual attributes of a role. Request . PATCH _opendistro/_security/api/roles/&lt;role&gt; [ { \"op\": \"replace\", \"path\": \"/index_permissions/0/fls\", \"value\": [\"myfield1\", \"myfield2\"] }, { \"op\": \"remove\", \"path\": \"/index_permissions/0/dls\" } ] . Sample response . { \"status\": \"OK\", \"message\": \"'&lt;role&gt;' updated.\" } . Patch roles . Creates, updates, or deletes multiple roles in a single call. Request . PATCH _opendistro/_security/api/roles [ { \"op\": \"replace\", \"path\": \"/role1/index_permissions/0/fls\", \"value\": [\"test1\", \"test2\"] }, { \"op\": \"remove\", \"path\": \"/role1/index_permissions/0/dls\" }, { \"op\": \"add\", \"path\": \"/role2/cluster_permissions\", \"value\": [\"manage_snapshots\"] } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#roles",
    "relUrl": "/docs/security/access-control/api/#roles"
  },"24": {
    "doc": "API",
    "title": "Role mappings",
    "content": "Get role mapping . Retrieves one role mapping. Request . GET _opendistro/_security/api/rolesmapping/&lt;role&gt; . Sample response . { \"role_starfleet\" : { \"backend_roles\" : [ \"starfleet\", \"captains\", \"defectors\", \"cn=ldaprole,ou=groups,dc=example,dc=com\" ], \"hosts\" : [ \"*.starfleetintranet.com\" ], \"users\" : [ \"worf\" ] } } . Get role mappings . Retrieves all role mappings. Request . GET _opendistro/_security/api/rolesmapping . Sample response . { \"role_starfleet\" : { \"backend_roles\" : [ \"starfleet\", \"captains\", \"defectors\", \"cn=ldaprole,ou=groups,dc=example,dc=com\" ], \"hosts\" : [ \"*.starfleetintranet.com\" ], \"users\" : [ \"worf\" ] } } . Delete role mapping . Request . DELETE _opendistro/_security/api/rolesmapping/&lt;role&gt; . Sample response . { \"status\": \"OK\", \"message\": \"'my-role' deleted.\" } . Create role mapping . Creates or replaces the specified role mapping. Request . PUT _opendistro/_security/api/rolesmapping/&lt;role&gt; { \"backend_roles\" : [ \"starfleet\", \"captains\", \"defectors\", \"cn=ldaprole,ou=groups,dc=example,dc=com\" ], \"hosts\" : [ \"*.starfleetintranet.com\" ], \"users\" : [ \"worf\" ] } . Sample response . { \"status\": \"CREATED\", \"message\": \"'my-role' created.\" } . Patch role mapping . Updates individual attributes of a role mapping. Request . PATCH _opendistro/_security/api/rolesmapping/&lt;role&gt; [ { \"op\": \"replace\", \"path\": \"/users\", \"value\": [\"myuser\"] }, { \"op\": \"replace\", \"path\": \"/backend_roles\", \"value\": [\"mybackendrole\"] } ] . Sample response . { \"status\": \"OK\", \"message\": \"'my-role' updated.\" } . Patch role mappings . Creates or updates multiple role mappings in a single call. Request . PATCH _opendistro/_security/api/rolesmapping [ { \"op\": \"add\", \"path\": \"/human_resources\", \"value\": { \"users\": [\"user1\"], \"backend_roles\": [\"backendrole2\"] } }, { \"op\": \"add\", \"path\": \"/finance\", \"value\": { \"users\": [\"user2\"], \"backend_roles\": [\"backendrole2\"] } } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#role-mappings",
    "relUrl": "/docs/security/access-control/api/#role-mappings"
  },"25": {
    "doc": "API",
    "title": "Tenants",
    "content": "Get tenant . Retrieves one tenant. Request . GET _opendistro/_security/api/tenants/&lt;tenant&gt; . Sample response . { \"human_resources\": { \"reserved\": false, \"hidden\": false, \"description\": \"A tenant for the human resources team.\", \"static\": false } } . Get tenants . Retrieves all tenants. Request . GET _opendistro/_security/api/tenants/ . Sample response . { \"global_tenant\": { \"reserved\": true, \"hidden\": false, \"description\": \"Global tenant\", \"static\": true }, \"human_resources\": { \"reserved\": false, \"hidden\": false, \"description\": \"A tenant for the human resources team.\", \"static\": false } } . Delete tenant . Request . DELETE _opendistro/_security/api/tenants/&lt;tenant&gt; . Sample response . { \"status\":\"OK\", \"message\":\"tenant human_resources deleted.\" } . Create tenant . Creates or replaces the specified tenant. Request . PUT _opendistro/_security/api/tenants/&lt;tenant&gt; { \"description\": \"A tenant for the human resources team.\" } . Sample response . { \"status\":\"CREATED\", \"message\":\"tenant human_resources created\" } . Patch tenant . Add, delete, or modify a single tenant. Request . PATCH _opendistro/_security/api/tenants/&lt;tenant&gt; [ { \"op\": \"replace\", \"path\": \"/description\", \"value\": \"An updated description\" } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . Patch tenants . Add, delete, or modify multiple tenants in a single call. Request . PATCH _opendistro/_security/api/tenants/ [ { \"op\": \"replace\", \"path\": \"/human_resources/description\", \"value\": \"An updated description\" }, { \"op\": \"add\", \"path\": \"/another_tenant\", \"value\": { \"description\": \"Another description.\" } } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#tenants",
    "relUrl": "/docs/security/access-control/api/#tenants"
  },"26": {
    "doc": "API",
    "title": "Configuration",
    "content": "Get configuration . Retrieves the current security plugin configuration in JSON format. Request . GET _opendistro/_security/api/securityconfig . Update configuration . Creates or updates the existing configuration using the REST API rather than securityadmin.sh. This operation can easily break your existing configuration, so we recommend using securityadmin.sh instead. See Access control for the API for how to enable this operation. Request . PUT _opendistro/_security/api/securityconfig/config { \"dynamic\": { \"filtered_alias_mode\": \"warn\", \"disable_rest_auth\": false, \"disable_intertransport_auth\": false, \"respect_request_indices_options\": false, \"kibana\": { \"multitenancy_enabled\": true, \"server_username\": \"kibanaserver\", \"index\": \".kibana\" }, \"http\": { \"anonymous_auth_enabled\": false }, \"authc\": { \"basic_internal_auth_domain\": { \"http_enabled\": true, \"transport_enabled\": true, \"order\": 0, \"http_authenticator\": { \"challenge\": true, \"type\": \"basic\", \"config\": {} }, \"authentication_backend\": { \"type\": \"intern\", \"config\": {} }, \"description\": \"Authenticate via HTTP Basic against internal users database\" } }, \"auth_failure_listeners\": {}, \"do_not_fail_on_forbidden\": false, \"multi_rolespan_enabled\": true, \"hosts_resolver_mode\": \"ip-only\", \"do_not_fail_on_forbidden_empty\": false } } . Sample response . { \"status\": \"OK\", \"message\": \"'config' updated.\" } . Patch configuration . Updates the existing configuration using the REST API rather than securityadmin.sh. This operation can easily break your existing configuration, so we recommend using securityadmin.sh instead. See Access control for the API for how to enable this operation. Request . PATCH _opendistro/_security/api/securityconfig [ { \"op\": \"replace\", \"path\": \"/config/dynamic/authc/basic_internal_auth_domain/transport_enabled\", \"value\": \"true\" } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#configuration",
    "relUrl": "/docs/security/access-control/api/#configuration"
  },"27": {
    "doc": "API",
    "title": "Certificates",
    "content": "Get certificates . Retrieves the current security plugin configuration in JSON format. Request . GET _opendistro/_security/api/securityconfig . Update configuration . Creates or updates the existing configuration using the REST API rather than securityadmin.sh. This operation can easily break your existing configuration, so we recommend using securityadmin.sh instead. See Access control for the API for how to enable this operation. Request . PUT _opendistro/_security/api/securityconfig/config { \"dynamic\": { \"filtered_alias_mode\": \"warn\", \"disable_rest_auth\": false, \"disable_intertransport_auth\": false, \"respect_request_indices_options\": false, \"kibana\": { \"multitenancy_enabled\": true, \"server_username\": \"kibanaserver\", \"index\": \".kibana\" }, \"http\": { \"anonymous_auth_enabled\": false }, \"authc\": { \"basic_internal_auth_domain\": { \"http_enabled\": true, \"transport_enabled\": true, \"order\": 0, \"http_authenticator\": { \"challenge\": true, \"type\": \"basic\", \"config\": {} }, \"authentication_backend\": { \"type\": \"intern\", \"config\": {} }, \"description\": \"Authenticate via HTTP Basic against internal users database\" } }, \"auth_failure_listeners\": {}, \"do_not_fail_on_forbidden\": false, \"multi_rolespan_enabled\": true, \"hosts_resolver_mode\": \"ip-only\", \"do_not_fail_on_forbidden_empty\": false } } . Sample response . { \"status\": \"OK\", \"message\": \"'config' updated.\" } . Patch configuration . Updates the existing configuration using the REST API rather than securityadmin.sh. This operation can easily break your existing configuration, so we recommend using securityadmin.sh instead. See Access control for the API for how to enable this operation. Request . PATCH _opendistro/_security/api/securityconfig [ { \"op\": \"replace\", \"path\": \"/config/dynamic/authc/basic_internal_auth_domain/transport_enabled\", \"value\": \"true\" } ] . Sample response . { \"status\": \"OK\", \"message\": \"Resource updated.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#certificates",
    "relUrl": "/docs/security/access-control/api/#certificates"
  },"28": {
    "doc": "API",
    "title": "Cache",
    "content": "Flush cache . Flushes the security plugin user, authentication, and authorization cache. Request . DELETE _opendistro/_security/api/cache . Sample response . { \"status\": \"OK\", \"message\": \"Cache flushed successfully.\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#cache",
    "relUrl": "/docs/security/access-control/api/#cache"
  },"29": {
    "doc": "API",
    "title": "Health",
    "content": "Health check . Checks to see if the security plugin is up and running. If you operate your cluster behind a load balancer, this operation is useful for determining node health and doesn’t require a signed request. Request . GET _opendistro/_security/health . Sample response . { \"message\": null, \"mode\": \"strict\", \"status\": \"UP\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/api/#health",
    "relUrl": "/docs/security/access-control/api/#health"
  },"30": {
    "doc": "Anomaly Detection API",
    "title": "Anomaly Detection API",
    "content": "Use these anomaly detection operations to programmatically create and manage detectors. . | Create Anomaly Detector | Preview detector | Start detector job | Stop detector job | Search detector result | Delete detector | Update detector | Get detector | Search detector | Get detector stats | Create monitor | Profile detector | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/",
    "relUrl": "/docs/ad/api/"
  },"31": {
    "doc": "Anomaly Detection API",
    "title": "Create Anomaly Detector",
    "content": "Creates an anomaly detector. This command creates a detector named http_requests that finds anomalies based on the sum and average number of failed HTTP requests: . Request . POST _opendistro/_anomaly_detection/detectors { \"name\": \"test-detector\", \"description\": \"Test detector\", \"time_field\": \"timestamp\", \"indices\": [ \"order*\" ], \"feature_attributes\": [ { \"feature_name\": \"total_order\", \"feature_enabled\": true, \"aggregation_query\": { \"total_order\": { \"sum\": { \"field\": \"value\" } } } } ], \"filter_query\": { \"bool\": { \"filter\": [ { \"exists\": { \"field\": \"value\", \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"detection_interval\": { \"period\": { \"interval\": 1, \"unit\": \"Minutes\" } }, \"window_delay\": { \"period\": { \"interval\": 1, \"unit\": \"Minutes\" } } } . You can specify the following options. | Options | Description | Type | Required | . | name | The name of the detector. | string | Yes | . | description | A description of the detector. | string | Yes | . | time_field | The name of the time field. | string | Yes | . | indices | A list of indices to use as the data source. | list | Yes | . | feature_attributes | Specify a feature_name, set the enabled parameter to true, and specify an aggregation query. | list | Yes | . | filter_query | Provide an optional filter query for your feature. | object | No | . | detection_interval | The time interval for your anomaly detector. | object | Yes | . | window_delay | Add extra processing time for data collection | object | No | . Sample response . { \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 1, \"_seq_no\" : 3, \"_primary_term\" : 1, \"anomaly_detector\" : { \"name\" : \"test-detector\", \"description\" : \"Test detector\", \"time_field\" : \"timestamp\", \"indices\" : [ \"order*\" ], \"filter_query\" : { \"bool\" : { \"filter\" : [ { \"exists\" : { \"field\" : \"value\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"detection_interval\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"window_delay\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"schema_version\" : 0, \"feature_attributes\" : [ { \"feature_id\" : \"mYccEnIBTXsGi3mvMd8_\", \"feature_name\" : \"total_order\", \"feature_enabled\" : true, \"aggregation_query\" : { \"total_order\" : { \"sum\" : { \"field\" : \"value\" } } } } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#create-anomaly-detector",
    "relUrl": "/docs/ad/api/#create-anomaly-detector"
  },"32": {
    "doc": "Anomaly Detection API",
    "title": "Preview detector",
    "content": "Passes a date range to the anomaly detector to return any anomalies within that date range. Request . POST _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_preview { \"period_start\": 1588838250000, \"period_end\": 1589443050000 } . Sample response . { \"anomaly_result\": [ ... { \"detector_id\": \"m4ccEnIBTXsGi3mvMt9p\", \"data_start_time\": 1588843020000, \"data_end_time\": 1588843620000, \"feature_data\": [ { \"feature_id\": \"xxokEnIBcpeWMD987A1X\", \"feature_name\": \"total_order\", \"data\": 489.9929131106 } ], \"anomaly_grade\": 0, \"confidence\": 0.99 } ... ], \"anomaly_detector\": { \"name\": \"test-detector\", \"description\": \"Test detector\", \"time_field\": \"timestamp\", \"indices\": [ \"order*\" ], \"filter_query\": { \"bool\": { \"filter\": [ { \"exists\": { \"field\": \"value\", \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"detection_interval\": { \"period\": { \"interval\": 10, \"unit\": \"Minutes\" } }, \"window_delay\": { \"period\": { \"interval\": 1, \"unit\": \"Minutes\" } }, \"schema_version\": 0, \"feature_attributes\": [ { \"feature_id\": \"xxokEnIBcpeWMD987A1X\", \"feature_name\": \"total_order\", \"feature_enabled\": true, \"aggregation_query\": { \"total_order\": { \"sum\": { \"field\": \"value\" } } } } ], \"last_update_time\": 1589442309241 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#preview-detector",
    "relUrl": "/docs/ad/api/#preview-detector"
  },"33": {
    "doc": "Anomaly Detection API",
    "title": "Start detector job",
    "content": "Starts an anomaly detector job. Request . POST _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_start . Sample response . { \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 1, \"_seq_no\" : 6, \"_primary_term\" : 1 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#start-detector-job",
    "relUrl": "/docs/ad/api/#start-detector-job"
  },"34": {
    "doc": "Anomaly Detection API",
    "title": "Stop detector job",
    "content": "Stops an anomaly detector job. Request . POST _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_stop . Sample response . Stopped detector: m4ccEnIBTXsGi3mvMt9p . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#stop-detector-job",
    "relUrl": "/docs/ad/api/#stop-detector-job"
  },"35": {
    "doc": "Anomaly Detection API",
    "title": "Search detector result",
    "content": "Returns all results for a search query. Request . GET _opendistro/_anomaly_detection/detectors/results/_search POST _opendistro/_anomaly_detection/detectors/results/_search { \"query\": { \"bool\": { \"must\": { \"range\": { \"anomaly_score\": { \"gte\": 0.6, \"lte\": 1 } } } } } } . Sample response . { \"took\": 9, \"timed_out\": false, \"_shards\": { \"total\": 25, \"successful\": 25, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 2, \"relation\": \"eq\" }, \"max_score\": 1, \"hits\": [ { \"_index\": \".opendistro-anomaly-results-history-2020.04.30-1\", \"_type\": \"_doc\", \"_id\": \"_KBrzXEBbpoKkFM5mStm\", \"_version\": 1, \"_seq_no\": 58, \"_primary_term\": 1, \"_score\": 1, \"_source\": { \"detector_id\": \"2KDozHEBbpoKkFM58yr6\", \"anomaly_score\": 0.8995068350366767, \"execution_start_time\": 1588289313114, \"data_end_time\": 1588289313114, \"confidence\": 0.84214852704501, \"data_start_time\": 1588289253114, \"feature_data\": [ { \"feature_id\": \"X0fpzHEB5NGZmIRkXKcy\", \"feature_name\": \"total_error\", \"data\": 20 } ], \"execution_end_time\": 1588289313126, \"anomaly_grade\": 0 } }, { \"_index\": \".opendistro-anomaly-results-history-2020.04.30-1\", \"_type\": \"_doc\", \"_id\": \"EqB1zXEBbpoKkFM5qyyE\", \"_version\": 1, \"_seq_no\": 61, \"_primary_term\": 1, \"_score\": 1, \"_source\": { \"detector_id\": \"2KDozHEBbpoKkFM58yr6\", \"anomaly_score\": 0.7086834513354907, \"execution_start_time\": 1588289973113, \"data_end_time\": 1588289973113, \"confidence\": 0.42162017029510446, \"data_start_time\": 1588289913113, \"feature_data\": [ { \"feature_id\": \"X0fpzHEB5NGZmIRkXKcy\", \"feature_name\": \"memory_usage\", \"data\": 20.0347333108 } ], \"execution_end_time\": 1588289973124, \"anomaly_grade\": 0 } } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#search-detector-result",
    "relUrl": "/docs/ad/api/#search-detector-result"
  },"36": {
    "doc": "Anomaly Detection API",
    "title": "Delete detector",
    "content": "Deletes a detector based on the detector_id. Request . DELETE _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt; . Sample response . { \"_index\" : \".opendistro-anomaly-detectors\", \"_type\" : \"_doc\", \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 2, \"result\" : \"deleted\", \"forced_refresh\" : true, \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 6, \"_primary_term\" : 1 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#delete-detector",
    "relUrl": "/docs/ad/api/#delete-detector"
  },"37": {
    "doc": "Anomaly Detection API",
    "title": "Update detector",
    "content": "Updates a detector with any changes, including the description or adding or removing of features. Request . PUT _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt; { \"name\": \"test-detector\", \"description\": \"Test detector\", \"time_field\": \"timestamp\", \"indices\": [ \"order*\" ], \"feature_attributes\": [ { \"feature_name\": \"total_order\", \"feature_enabled\": true, \"aggregation_query\": { \"total_order\": { \"sum\": { \"field\": \"value\" } } } } ], \"filter_query\": { \"bool\": { \"filter\": [ { \"exists\": { \"field\": \"value\", \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"detection_interval\": { \"period\": { \"interval\": 10, \"unit\": \"Minutes\" } }, \"window_delay\": { \"period\": { \"interval\": 1, \"unit\": \"Minutes\" } } } . Sample response . { \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 2, \"_seq_no\" : 4, \"_primary_term\" : 1, \"anomaly_detector\" : { \"name\" : \"test-detector\", \"description\" : \"Test detector\", \"time_field\" : \"timestamp\", \"indices\" : [ \"order*\" ], \"filter_query\" : { \"bool\" : { \"filter\" : [ { \"exists\" : { \"field\" : \"value\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"detection_interval\" : { \"period\" : { \"interval\" : 10, \"unit\" : \"Minutes\" } }, \"window_delay\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"schema_version\" : 0, \"feature_attributes\" : [ { \"feature_id\" : \"xxokEnIBcpeWMD987A1X\", \"feature_name\" : \"total_order\", \"feature_enabled\" : true, \"aggregation_query\" : { \"total_order\" : { \"sum\" : { \"field\" : \"value\" } } } } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#update-detector",
    "relUrl": "/docs/ad/api/#update-detector"
  },"38": {
    "doc": "Anomaly Detection API",
    "title": "Get detector",
    "content": "Returns all information about a detector based on the detector_id. Request . GET _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt; . Sample response . { \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 1, \"_primary_term\" : 1, \"_seq_no\" : 3, \"anomaly_detector\" : { \"name\" : \"test-detector\", \"description\" : \"Test detector\", \"time_field\" : \"timestamp\", \"indices\" : [ \"order*\" ], \"filter_query\" : { \"bool\" : { \"filter\" : [ { \"exists\" : { \"field\" : \"value\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"detection_interval\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"window_delay\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"schema_version\" : 0, \"feature_attributes\" : [ { \"feature_id\" : \"mYccEnIBTXsGi3mvMd8_\", \"feature_name\" : \"total_order\", \"feature_enabled\" : true, \"aggregation_query\" : { \"total_order\" : { \"sum\" : { \"field\" : \"value\" } } } } ], \"last_update_time\" : 1589441737319 } } . Use job=true to get anomaly detection job information. Request . GET _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;?job=true . Sample response . { \"_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"_version\" : 1, \"_primary_term\" : 1, \"_seq_no\" : 3, \"anomaly_detector\" : { \"name\" : \"test-detector\", \"description\" : \"Test detector\", \"time_field\" : \"timestamp\", \"indices\" : [ \"order*\" ], \"filter_query\" : { \"bool\" : { \"filter\" : [ { \"exists\" : { \"field\" : \"value\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"detection_interval\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"window_delay\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"schema_version\" : 0, \"feature_attributes\" : [ { \"feature_id\" : \"mYccEnIBTXsGi3mvMd8_\", \"feature_name\" : \"total_order\", \"feature_enabled\" : true, \"aggregation_query\" : { \"total_order\" : { \"sum\" : { \"field\" : \"value\" } } } } ], \"last_update_time\" : 1589441737319 }, \"anomaly_detector_job\" : { \"name\" : \"m4ccEnIBTXsGi3mvMt9p\", \"schedule\" : { \"interval\" : { \"start_time\" : 1589442051271, \"period\" : 1, \"unit\" : \"Minutes\" } }, \"window_delay\" : { \"period\" : { \"interval\" : 1, \"unit\" : \"Minutes\" } }, \"enabled\" : true, \"enabled_time\" : 1589442051271, \"last_update_time\" : 1589442051271, \"lock_duration_seconds\" : 60 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#get-detector",
    "relUrl": "/docs/ad/api/#get-detector"
  },"39": {
    "doc": "Anomaly Detection API",
    "title": "Search detector",
    "content": "Returns all anomaly detectors for a search query. Request . GET _opendistro/_anomaly_detection/detectors/_search POST _opendistro/_anomaly_detection/detectors/_search Sample Input: { \"query\": { \"match\": { \"name\": \"test-detector\" } } } . Sample response . { \"took\": 13, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 994, \"relation\": \"eq\" }, \"max_score\": 3.5410638, \"hits\": [ { \"_index\": \".opendistro-anomaly-detectors\", \"_type\": \"_doc\", \"_id\": \"m4ccEnIBTXsGi3mvMt9p\", \"_version\": 2, \"_seq_no\": 221, \"_primary_term\": 1, \"_score\": 3.5410638, \"_source\": { \"name\": \"test-detector\", \"description\": \"Test detector\", \"time_field\": \"timestamp\", \"indices\": [ \"order*\" ], \"filter_query\": { \"bool\": { \"filter\": [ { \"exists\": { \"field\": \"value\", \"boost\": 1 } } ], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"detection_interval\": { \"period\": { \"interval\": 10, \"unit\": \"Minutes\" } }, \"window_delay\": { \"period\": { \"interval\": 1, \"unit\": \"Minutes\" } }, \"schema_version\": 0, \"feature_attributes\": [ { \"feature_id\": \"xxokEnIBcpeWMD987A1X\", \"feature_name\": \"total_order\", \"feature_enabled\": true, \"aggregation_query\": { \"total_order\": { \"sum\": { \"field\": \"value\" } } } } ], \"last_update_time\": 1589442309241 } } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#search-detector",
    "relUrl": "/docs/ad/api/#search-detector"
  },"40": {
    "doc": "Anomaly Detection API",
    "title": "Get detector stats",
    "content": "Provides information about how the plugin is performing. Request . GET _opendistro/_anomaly_detection/stats GET _opendistro/_anomaly_detection/&lt;nodeId&gt;/stats GET _opendistro/_anomaly_detection/&lt;nodeId&gt;/stats/&lt;stat&gt; GET _opendistro/_anomaly_detection/stats/&lt;stat&gt; . Sample response . { \"_nodes\" : { \"total\" : 3, \"successful\" : 3, \"failed\" : 0 }, \"cluster_name\" : \"multi-node-run\", \"anomaly_detectors_index_status\" : \"green\", \"detector_count\" : 1, \"models_checkpoint_index_status\" : \"green\", \"anomaly_results_index_status\" : \"green\", \"nodes\" : { \"IgWDUfzFRzW0FWAXM5FGJw\" : { \"ad_execute_request_count\" : 8, \"ad_execute_failure_count\" : 7, \"models\" : [ { \"detector_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"model_type\" : \"rcf\", \"model_id\" : \"m4ccEnIBTXsGi3mvMt9p_model_rcf_0\" }, { \"detector_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"model_type\" : \"threshold\", \"model_id\" : \"m4ccEnIBTXsGi3mvMt9p_model_threshold\" } ] }, \"y7YUQWukQEWOYbfdEq13hQ\" : { \"ad_execute_request_count\" : 0, \"ad_execute_failure_count\" : 0, \"models\" : [ ] }, \"cDcGNsPoRAyRMlPP1m-vZw\" : { \"ad_execute_request_count\" : 0, \"ad_execute_failure_count\" : 0, \"models\" : [ { \"detector_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"model_type\" : \"rcf\", \"model_id\" : \"m4ccEnIBTXsGi3mvMt9p_model_rcf_2\" }, { \"detector_id\" : \"m4ccEnIBTXsGi3mvMt9p\", \"model_type\" : \"rcf\", \"model_id\" : \"m4ccEnIBTXsGi3mvMt9p_model_rcf_1\" } ] } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#get-detector-stats",
    "relUrl": "/docs/ad/api/#get-detector-stats"
  },"41": {
    "doc": "Anomaly Detection API",
    "title": "Create monitor",
    "content": "Create a monitor to set up alerts for the detector. Request . POST _opendistro/_alerting/monitors { \"type\": \"monitor\", \"name\": \"test-monitor\", \"enabled\": true, \"schedule\": { \"period\": { \"interval\": 20, \"unit\": \"MINUTES\" } }, \"inputs\": [ { \"search\": { \"indices\": [ \".opendistro-anomaly-results*\" ], \"query\": { \"size\": 1, \"query\": { \"bool\": { \"filter\": [ { \"range\": { \"data_end_time\": { \"from\": \"||-20m\", \"to\": \"\", \"include_lower\": true, \"include_upper\": true, \"boost\": 1 } } }, { \"term\": { \"detector_id\": { \"value\": \"m4ccEnIBTXsGi3mvMt9p\", \"boost\": 1 } } } ], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"sort\": [ { \"anomaly_grade\": { \"order\": \"desc\" } }, { \"confidence\": { \"order\": \"desc\" } } ], \"aggregations\": { \"max_anomaly_grade\": { \"max\": { \"field\": \"anomaly_grade\" } } } } } } ], \"triggers\": [ { \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"return ctx.results[0].aggregations.max_anomaly_grade.value != null &amp;&amp; ctx.results[0].aggregations.max_anomaly_grade.value &gt; 0.7 &amp;&amp; ctx.results[0].hits.hits[0]._source.confidence &gt; 0.7\", \"lang\": \"painless\" } }, \"actions\": [ { \"name\": \"test-action\", \"destination_id\": \"ld7912sBlQ5JUWWFThoW\", \"message_template\": { \"source\": \"This is my message body.\" }, \"throttle_enabled\": false, \"subject_template\": { \"source\": \"TheSubject\" } } ] } ] } . Sample response . { \"_id\" : \"OClTEnIBmSf7y6LP11Jz\", \"_version\" : 1, \"_seq_no\" : 10, \"_primary_term\" : 1, \"monitor\" : { \"type\" : \"monitor\", \"schema_version\" : 1, \"name\" : \"test-monitor\", \"enabled\" : true, \"enabled_time\" : 1589445384043, \"schedule\" : { \"period\" : { \"interval\" : 20, \"unit\" : \"MINUTES\" } }, \"inputs\" : [ { \"search\" : { \"indices\" : [ \".opendistro-anomaly-results*\" ], \"query\" : { \"size\" : 1, \"query\" : { \"bool\" : { \"filter\" : [ { \"range\" : { \"data_end_time\" : { \"from\" : \"||-20m\", \"to\" : \"\", \"include_lower\" : true, \"include_upper\" : true, \"boost\" : 1.0 } } }, { \"term\" : { \"detector_id\" : { \"value\" : \"m4ccEnIBTXsGi3mvMt9p\", \"boost\" : 1.0 } } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"sort\" : [ { \"anomaly_grade\" : { \"order\" : \"desc\" } }, { \"confidence\" : { \"order\" : \"desc\" } } ], \"aggregations\" : { \"max_anomaly_grade\" : { \"max\" : { \"field\" : \"anomaly_grade\" } } } } } } ], \"triggers\" : [ { \"id\" : \"NilTEnIBmSf7y6LP11Jr\", \"name\" : \"test-trigger\", \"severity\" : \"1\", \"condition\" : { \"script\" : { \"source\" : \"return ctx.results[0].aggregations.max_anomaly_grade.value != null &amp;&amp; ctx.results[0].aggregations.max_anomaly_grade.value &gt; 0.7 &amp;&amp; ctx.results[0].hits.hits[0]._source.confidence &gt; 0.7\", \"lang\" : \"painless\" } }, \"actions\" : [ { \"id\" : \"NylTEnIBmSf7y6LP11Jr\", \"name\" : \"test-action\", \"destination_id\" : \"ld7912sBlQ5JUWWFThoW\", \"message_template\" : { \"source\" : \"This is my message body.\", \"lang\" : \"mustache\" }, \"throttle_enabled\" : false, \"subject_template\" : { \"source\" : \"TheSubject\", \"lang\" : \"mustache\" } } ] } ], \"last_update_time\" : 1589445384043 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#create-monitor",
    "relUrl": "/docs/ad/api/#create-monitor"
  },"42": {
    "doc": "Anomaly Detection API",
    "title": "Profile detector",
    "content": "Returns information related to the current state of the detector and memory usage, including current errors and shingle size, to help troubleshoot the detector. This command also helps locate logs by identifying the nodes that run the anomaly detector job for each detector. Request . GET _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_profile/ GET _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_profile?_all=true GET _opendistro/_anomaly_detection/detectors/&lt;detectorId&gt;/_profile/&lt;type&gt; . Sample Responses . GET _opendistro/_anomaly_detection/detectors/4j1313EBhPlEUyl3nsX-/_profile { \"state\":\"DISABLED\", \"error\":\"Stopped detector: AD models memory usage exceeds our limit.\" } GET _opendistro/_anomaly_detection/detectors/m4ccEnIBTXsGi3mvMt9p/_profile?_all=true&amp;pretty { \"state\" : \"RUNNING\", \"models\" : [ { \"model_id\" : \"cneh7HEBHPICjJIdXdrR_model_rcf_2\", \"model_size_in_bytes\" : 4456448, \"node_id\" : \"VS29z70PSzOdHiEw4SoV9Q\" }, { \"model_id\" : \"cneh7HEBHPICjJIdXdrR_model_rcf_1\", \"model_size_in_bytes\" : 4456448, \"node_id\" : \"VS29z70PSzOdHiEw4SoV9Q\" }, { \"model_id\" : \"cneh7HEBHPICjJIdXdrR_model_threshold\", \"node_id\" : \"Og23iUroTdKrkwS-y89zLw\" }, { \"model_id\" : \"cneh7HEBHPICjJIdXdrR_model_rcf_0\", \"model_size_in_bytes\" : 4456448, \"node_id\" : \"Og23iUroTdKrkwS-y89zLw\" } ], \"shingle_size\" : 8, \"coordinating_node\" : \"Og23iUroTdKrkwS-y89zLw\", \"total_size_in_bytes\" : 13369344 } GET _opendistro/_anomaly_detection/detectors/m4ccEnIBTXsGi3mvMt9p/_profile/total_size_in_bytes { \"total_size_in_bytes\" : 13369344 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/api/#profile-detector",
    "relUrl": "/docs/ad/api/#profile-detector"
  },"43": {
    "doc": "API",
    "title": "Alerting API",
    "content": "Use the alerting API to programmatically manage monitors and alerts. . | Create monitor | Update monitor | Get monitor | Monitor stats | Delete monitor | Search monitors | Run monitor | Acknowledge alert | Create destination | Update destination | Delete destination | Create email account | Update email account | Get email account | Delete email account | Search email account | Create email group | Update email group | Get email group | Delete email group | Search email group | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#alerting-api",
    "relUrl": "/docs/alerting/api/#alerting-api"
  },"44": {
    "doc": "API",
    "title": "Create monitor",
    "content": "Request . POST _opendistro/_alerting/monitors { \"type\": \"monitor\", \"name\": \"test-monitor\", \"enabled\": true, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [\"movies\"], \"query\": { \"size\": 0, \"aggregations\": {}, \"query\": { \"bool\": { \"filter\": { \"range\": { \"@timestamp\": { \"gte\": \"||-1h\", \"lte\": \"\", \"format\": \"epoch_millis\" } } } } } } } }], \"triggers\": [{ \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"ctx.results[0].hits.total.value &gt; 0\", \"lang\": \"painless\" } }, \"actions\": [{ \"name\": \"test-action\", \"destination_id\": \"ld7912sBlQ5JUWWFThoW\", \"message_template\": { \"source\": \"This is my message body.\" }, \"throttle_enabled\": false, \"subject_template\": { \"source\": \"TheSubject\" } }] }] } . If you use a custom webhook for your destination and need to embed JSON in the message body, be sure to escape your quotes: . { \"message_template\": { \"source\": \"{ \\\"text\\\": \\\"Monitor {{ctx.monitor.name}} just entered alert status. Please investigate the issue. - Trigger: {{ctx.trigger.name}} - Severity: {{ctx.trigger.severity}} - Period start: {{ctx.periodStart}} - Period end: {{ctx.periodEnd}}\\\" }\" } } . Sample response . { \"_id\": \"vd5k2GsBlQ5JUWWFxhsP\", \"_version\": 1, \"_seq_no\": 7, \"_primary_term\": 1, \"monitor\": { \"type\": \"monitor\", \"schema_version\": 1, \"name\": \"test-monitor\", \"enabled\": true, \"enabled_time\": 1562703611363, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [ \"movies\" ], \"query\": { \"size\": 0, \"query\": { \"bool\": { \"filter\": [{ \"range\": { \"@timestamp\": { \"from\": \"||-1h\", \"to\": \"\", \"include_lower\": true, \"include_upper\": true, \"format\": \"epoch_millis\", \"boost\": 1 } } }], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"aggregations\": {} } } }], \"triggers\": [{ \"id\": \"ud5k2GsBlQ5JUWWFxRvi\", \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"ctx.results[0].hits.total.value &gt; 0\", \"lang\": \"painless\" } }, \"actions\": [{ \"id\": \"ut5k2GsBlQ5JUWWFxRvj\", \"name\": \"test-action\", \"destination_id\": \"ld7912sBlQ5JUWWFThoW\", \"message_template\": { \"source\": \"This is my message body.\", \"lang\": \"mustache\" }, \"throttle_enabled\": false, \"subject_template\": { \"source\": \"TheSubject\", \"lang\": \"mustache\" } }] }], \"last_update_time\": 1562703611363 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#create-monitor",
    "relUrl": "/docs/alerting/api/#create-monitor"
  },"45": {
    "doc": "API",
    "title": "Update monitor",
    "content": "When you update a monitor, include the current version number as a parameter. Open Distro for Elasticsearch increments the version number automatically (see the sample response). Request . PUT _opendistro/_alerting/monitors/&lt;monitor_id&gt; { \"type\": \"monitor\", \"name\": \"test-monitor\", \"enabled\": true, \"enabled_time\": 1551466220455, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [ \"*\" ], \"query\": { \"query\": { \"match_all\": { \"boost\": 1 } } } } }], \"triggers\": [{ \"id\": \"StaeOmkBC25HCRGmL_y-\", \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"return true\", \"lang\": \"painless\" } }, \"actions\": [{ \"name\": \"test-action\", \"destination_id\": \"RtaaOmkBC25HCRGm0fxi\", \"subject_template\": { \"source\": \"My Message Subject\", \"lang\": \"mustache\" }, \"message_template\": { \"source\": \"This is my message body.\", \"lang\": \"mustache\" } }] }], \"last_update_time\": 1551466639295 } . Sample response . { \"_id\": \"Q9aXOmkBC25HCRGmzfw-\", \"_version\": 4, \"monitor\": { \"type\": \"monitor\", \"name\": \"test-monitor\", \"enabled\": true, \"enabled_time\": 1551466220455, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [ \"*\" ], \"query\": { \"query\": { \"match_all\": { \"boost\": 1 } } } } }], \"triggers\": [{ \"id\": \"StaeOmkBC25HCRGmL_y-\", \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"return true\", \"lang\": \"painless\" } }, \"actions\": [{ \"name\": \"test-action\", \"destination_id\": \"RtaaOmkBC25HCRGm0fxi\", \"subject_template\": { \"source\": \"My Message Subject\", \"lang\": \"mustache\" }, \"message_template\": { \"source\": \"This is my message body.\", \"lang\": \"mustache\" } }] }], \"last_update_time\": 1551466761596 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#update-monitor",
    "relUrl": "/docs/alerting/api/#update-monitor"
  },"46": {
    "doc": "API",
    "title": "Get monitor",
    "content": "Request . GET _opendistro/_alerting/monitors/&lt;monitor_id&gt; . Sample response . { \"_id\": \"Q9aXOmkBC25HCRGmzfw-\", \"_version\": 3, \"monitor\": { \"type\": \"monitor\", \"name\": \"test-monitor\", \"enabled\": true, \"enabled_time\": 1551466220455, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [ \"*\" ], \"query\": { \"query\": { \"match_all\": { \"boost\": 1 } } } } }], \"triggers\": [{ \"id\": \"StaeOmkBC25HCRGmL_y-\", \"name\": \"test-trigger\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"return true\", \"lang\": \"painless\" } }, \"actions\": [{ \"name\": \"test-action\", \"destination_id\": \"RtaaOmkBC25HCRGm0fxi\", \"subject_template\": { \"source\": \"My Message Subject\", \"lang\": \"mustache\" }, \"message_template\": { \"source\": \"This is my message body.\", \"lang\": \"mustache\" } }] }], \"last_update_time\": 1551466639295 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#get-monitor",
    "relUrl": "/docs/alerting/api/#get-monitor"
  },"47": {
    "doc": "API",
    "title": "Monitor stats",
    "content": "Returns statistics about the alerting feature. Use _opendistro/_alerting/stats to find node IDs and metrics. Then you can drill down using those values. Request . GET _opendistro/_alerting/stats GET _opendistro/_alerting/stats/&lt;metric&gt; GET _opendistro/_alerting/&lt;node-id&gt;/stats GET _opendistro/_alerting/&lt;node-id&gt;/stats/&lt;metric&gt; . Sample response . { \"_nodes\": { \"total\": 9, \"successful\": 9, \"failed\": 0 }, \"cluster_name\": \"475300751431:alerting65-dont-delete\", \"opendistro.scheduled_jobs.enabled\": true, \"scheduled_job_index_exists\": true, \"scheduled_job_index_status\": \"green\", \"nodes_on_schedule\": 9, \"nodes_not_on_schedule\": 0, \"nodes\": { \"qWcbKbb-TVyyI-Q7VSeOqA\": { \"name\": \"qWcbKbb\", \"schedule_status\": \"green\", \"roles\": [ \"MASTER\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 207017, \"full_sweep_on_time\": true }, \"jobs_info\": {} }, \"Do-DX9ZcS06Y9w1XbSJo1A\": { \"name\": \"Do-DX9Z\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 230516, \"full_sweep_on_time\": true }, \"jobs_info\": {} }, \"n5phkBiYQfS5I0FDzcqjZQ\": { \"name\": \"n5phkBi\", \"schedule_status\": \"green\", \"roles\": [ \"MASTER\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 228406, \"full_sweep_on_time\": true }, \"jobs_info\": {} }, \"Tazzo8cQSY-g3vOjgYYLzA\": { \"name\": \"Tazzo8c\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 211722, \"full_sweep_on_time\": true }, \"jobs_info\": { \"i-wsFmkB8NzS6aXjQSk0\": { \"last_execution_time\": 1550864912882, \"running_on_time\": true } } }, \"Nyf7F8brTOSJuFPXw6CnpA\": { \"name\": \"Nyf7F8b\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 223300, \"full_sweep_on_time\": true }, \"jobs_info\": { \"NbpoFmkBeSe-hD59AKgE\": { \"last_execution_time\": 1550864928354, \"running_on_time\": true }, \"-LlLFmkBeSe-hD59Ydtb\": { \"last_execution_time\": 1550864732727, \"running_on_time\": true }, \"pBFxFmkBNXkgNmTBaFj1\": { \"last_execution_time\": 1550863325024, \"running_on_time\": true }, \"hfasEmkBNXkgNmTBrvIW\": { \"last_execution_time\": 1550862000001, \"running_on_time\": true } } }, \"oOdJDIBVT5qbbO3d8VLeEw\": { \"name\": \"oOdJDIB\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 227570, \"full_sweep_on_time\": true }, \"jobs_info\": { \"4hKRFmkBNXkgNmTBKjYX\": { \"last_execution_time\": 1550864806101, \"running_on_time\": true } } }, \"NRDG6JYgR8m0GOZYQ9QGjQ\": { \"name\": \"NRDG6JY\", \"schedule_status\": \"green\", \"roles\": [ \"MASTER\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 227652, \"full_sweep_on_time\": true }, \"jobs_info\": {} }, \"URMrXRz3Tm-CB72hlsl93Q\": { \"name\": \"URMrXRz\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 231048, \"full_sweep_on_time\": true }, \"jobs_info\": { \"m7uKFmkBeSe-hD59jplP\": { \"running_on_time\": true } } }, \"eXgt1k9oTRCLmx2HBGElUw\": { \"name\": \"eXgt1k9\", \"schedule_status\": \"green\", \"roles\": [ \"DATA\", \"INGEST\" ], \"job_scheduling_metrics\": { \"last_full_sweep_time_millis\": 229234, \"full_sweep_on_time\": true }, \"jobs_info\": { \"wWkFFmkBc2NG-PeLntxk\": { \"running_on_time\": true }, \"3usNFmkB8NzS6aXjO1Gs\": { \"last_execution_time\": 1550863959848, \"running_on_time\": true } } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#monitor-stats",
    "relUrl": "/docs/alerting/api/#monitor-stats"
  },"48": {
    "doc": "API",
    "title": "Delete monitor",
    "content": "Request . DELETE _opendistro/_alerting/monitors/&lt;monitor_id&gt; . Sample response . { \"_index\": \".opendistro-scheduled-jobs\", \"_type\": \"_doc\", \"_id\": \"OYAHOmgBl3cmwnqZl_yH\", \"_version\": 2, \"result\": \"deleted\", \"forced_refresh\": true, \"_shards\": { \"total\": 2, \"successful\": 2, \"failed\": 0 }, \"_seq_no\": 11, \"_primary_term\": 1 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#delete-monitor",
    "relUrl": "/docs/alerting/api/#delete-monitor"
  },"49": {
    "doc": "API",
    "title": "Search monitors",
    "content": "Request . GET _opendistro/_alerting/monitors/_search { \"query\": { \"match\" : { \"monitor.name\": \"my-monitor-name\" } } } . Sample response . { \"took\": 17, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.6931472, \"hits\": [{ \"_index\": \".opendistro-scheduled-jobs\", \"_type\": \"_doc\", \"_id\": \"eGQi7GcBRS7-AJEqfAnr\", \"_score\": 0.6931472, \"_source\": { \"type\": \"monitor\", \"name\": \"my-monitor-name\", \"enabled\": true, \"enabled_time\": 1545854942426, \"schedule\": { \"period\": { \"interval\": 1, \"unit\": \"MINUTES\" } }, \"inputs\": [{ \"search\": { \"indices\": [ \"*\" ], \"query\": { \"size\": 0, \"query\": { \"bool\": { \"filter\": [{ \"range\": { \"@timestamp\": { \"from\": \"||-1h\", \"to\": \"\", \"include_lower\": true, \"include_upper\": true, \"format\": \"epoch_millis\", \"boost\": 1 } } }], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"aggregations\": {} } } }], \"triggers\": [{ \"id\": \"Sooi7GcB53a0ewuj_6MH\", \"name\": \"Over\", \"severity\": \"1\", \"condition\": { \"script\": { \"source\": \"_ctx.results[0].hits.total &gt; 400000\", \"lang\": \"painless\" } }, \"actions\": [] }], \"last_update_time\": 1545854975758 } }] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#search-monitors",
    "relUrl": "/docs/alerting/api/#search-monitors"
  },"50": {
    "doc": "API",
    "title": "Run monitor",
    "content": "You can add the optional ?dryrun=true parameter to the URL to show the results of a run without actions sending any message. Request . POST _opendistro/_alerting/monitors/&lt;monitor_id&gt;/_execute . Sample response . { \"monitor_name\": \"logs\", \"period_start\": 1547161872322, \"period_end\": 1547161932322, \"error\": null, \"trigger_results\": { \"Sooi7GcB53a0ewuj_6MH\": { \"name\": \"Over\", \"triggered\": true, \"error\": null, \"action_results\": {} } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#run-monitor",
    "relUrl": "/docs/alerting/api/#run-monitor"
  },"51": {
    "doc": "API",
    "title": "Acknowledge alert",
    "content": "To get the alert ID, query the .opendistro-alerts index. See Alerting indices. You can acknowledge any number of alerts in one call. If the alert is already in an ERROR, COMPLETED, or ACKNOWLEDGED state, it will appear in the failed array. Request . POST _opendistro/_alerting/monitors/&lt;monitor-id&gt;/_acknowledge/alerts { \"alerts\": [\"bn0_PmgBoCvkhulGF2K8\"] } . Sample response . { \"success\": [ \"bn0_PmgBoCvkhulGF2K8\" ], \"failed\": [] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#acknowledge-alert",
    "relUrl": "/docs/alerting/api/#acknowledge-alert"
  },"52": {
    "doc": "API",
    "title": "Create destination",
    "content": "Requests . POST _opendistro/_alerting/destinations { \"name\": \"my-destination\", \"type\": \"slack\", \"slack\": { \"url\": \"http://www.example.com\" } } POST _opendistro/_alerting/destinations { \"type\": \"custom_webhook\", \"name\": \"my-custom-destination\", \"custom_webhook\": { \"path\": \"incomingwebhooks/123456-123456-XXXXXX\", \"header_params\": { \"Content-Type\": \"application/json\" }, \"scheme\": \"HTTPS\", \"port\": 443, \"query_params\": { \"token\": \"R2x1UlN4ZHF8MXxxVFJpelJNVDgzdGNwXXXXXXXXX\" }, \"host\": \"hooks.chime.aws\" } } . Sample response . { \"_id\": \"nO-yFmkB8NzS6aXjJdiI\", \"_version\": 1, \"destination\": { \"type\": \"slack\", \"name\": \"my-destination\", \"last_update_time\": 1550863967624, \"slack\": { \"url\": \"http://www.example.com\" } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#create-destination",
    "relUrl": "/docs/alerting/api/#create-destination"
  },"53": {
    "doc": "API",
    "title": "Update destination",
    "content": "Request . PUT _opendistro/_alerting/destinations/&lt;destination-id&gt; { \"name\": \"my-updated-destination\", \"type\": \"slack\", \"slack\": { \"url\": \"http://www.example.com\" } } . Sample response . { \"_id\": \"pe-1FmkB8NzS6aXjqvVY\", \"_version\": 4, \"destination\": { \"type\": \"slack\", \"name\": \"my-updated-destination\", \"last_update_time\": 1550864289375, \"slack\": { \"url\": \"http://www.example.com\" } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#update-destination",
    "relUrl": "/docs/alerting/api/#update-destination"
  },"54": {
    "doc": "API",
    "title": "Delete destination",
    "content": "Request . DELETE _opendistro/_alerting/destinations/&lt;destination-id&gt; . Sample response . { \"_index\": \".opendistro-alerting-config\", \"_type\": \"_doc\", \"_id\": \"Zu-zFmkB8NzS6aXjLeBI\", \"_version\": 2, \"result\": \"deleted\", \"forced_refresh\": true, \"_shards\": { \"total\": 2, \"successful\": 2, \"failed\": 0 }, \"_seq_no\": 8, \"_primary_term\": 1 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#delete-destination",
    "relUrl": "/docs/alerting/api/#delete-destination"
  },"55": {
    "doc": "API",
    "title": "Create email account",
    "content": "Request . POST _opendistro/_alerting/destinations/email_accounts { \"name\": \"example_account\", \"email\": \"example@email.com\", \"host\": \"smtp.email.com\", \"port\": 465, \"method\": \"ssl\" } . Sample response . { \"_id\" : \"email_account_id\", \"_version\" : 1, \"_seq_no\" : 7, \"_primary_term\" : 2, \"email_account\" : { \"schema_version\" : 2, \"name\" : \"example_account\", \"email\" : \"example@email.com\", \"host\" : \"smtp.email.com\", \"port\" : 465, \"method\" : \"ssl\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#create-email-account",
    "relUrl": "/docs/alerting/api/#create-email-account"
  },"56": {
    "doc": "API",
    "title": "Update email account",
    "content": "Request . PUT _opendistro/_alerting/destinations/email_accounts/&lt;email_account_id&gt; { \"name\": \"example_account\", \"email\": \"example@email.com\", \"host\": \"smtp.email.com\", \"port\": 465, \"method\": \"ssl\" } . Sample response . { \"_id\" : \"email_account_id\", \"_version\" : 3, \"_seq_no\" : 19, \"_primary_term\" : 2, \"email_account\" : { \"schema_version\" : 2, \"name\" : \"example_account\", \"email\" : \"example@email.com\", \"host\" : \"smtp.email.com\", \"port\" : 465, \"method\" : \"ssl\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#update-email-account",
    "relUrl": "/docs/alerting/api/#update-email-account"
  },"57": {
    "doc": "API",
    "title": "Get email account",
    "content": "Request . GET _opendistro/_alerting/destinations/email_accounts/&lt;email_account_id&gt; { \"name\": \"example_account\", \"email\": \"example@email.com\", \"host\": \"smtp.email.com\", \"port\": 465, \"method\": \"ssl\" } . Sample response . { \"_id\" : \"email_account_id\", \"_version\" : 2, \"_seq_no\" : 8, \"_primary_term\" : 2, \"email_account\" : { \"schema_version\" : 2, \"name\" : \"test_account\", \"email\" : \"test@email.com\", \"host\" : \"smtp.test.com\", \"port\" : 465, \"method\" : \"ssl\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#get-email-account",
    "relUrl": "/docs/alerting/api/#get-email-account"
  },"58": {
    "doc": "API",
    "title": "Delete email account",
    "content": "Request . DELETE _opendistro/_alerting/destinations/email_accounts/&lt;email_account_id&gt; . Sample response . { \"_index\" : \".opendistro-alerting-config\", \"_type\" : \"_doc\", \"_id\" : \"email_account_id\", \"_version\" : 1, \"result\" : \"deleted\", \"forced_refresh\" : true, \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 12, \"_primary_term\" : 2 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#delete-email-account",
    "relUrl": "/docs/alerting/api/#delete-email-account"
  },"59": {
    "doc": "API",
    "title": "Search email account",
    "content": "Request . POST _opendistro/_alerting/destinations/email_accounts/_search { \"from\": 0, \"size\": 20, \"sort\": { \"email_account.name.keyword\": \"desc\" }, \"query\": { \"bool\": { \"must\": { \"match_all\": {} } } } } . Sample response . { \"took\" : 8, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 2, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ { \"_index\" : \".opendistro-alerting-config\", \"_type\" : \"_doc\", \"_id\" : \"email_account_id\", \"_seq_no\" : 8, \"_primary_term\" : 2, \"_score\" : null, \"_source\" : { \"schema_version\" : 2, \"name\" : \"example_account\", \"email\" : \"example@email.com\", \"host\" : \"smtp.email.com\", \"port\" : 465, \"method\" : \"ssl\" }, \"sort\" : [ \"example_account\" ] }, ... ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#search-email-account",
    "relUrl": "/docs/alerting/api/#search-email-account"
  },"60": {
    "doc": "API",
    "title": "Create email group",
    "content": "Request . POST _opendistro/_alerting/destinations/email_groups { \"name\": \"example_email_group\", \"emails\": [{ \"email\": \"example@email.com\" }] } . Sample response . { \"_id\" : \"email_group_id\", \"_version\" : 1, \"_seq_no\" : 9, \"_primary_term\" : 2, \"email_group\" : { \"schema_version\" : 2, \"name\" : \"example_email_group\", \"emails\" : [ { \"email\" : \"example@email.com\" } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#create-email-group",
    "relUrl": "/docs/alerting/api/#create-email-group"
  },"61": {
    "doc": "API",
    "title": "Update email group",
    "content": "Request . PUT _opendistro/_alerting/destinations/email_groups/&lt;email_group_id&gt; { \"name\": \"example_email_group\", \"emails\": [{ \"email\": \"example@email.com\" }] } . Sample response . { \"_id\" : \"email_group_id\", \"_version\" : 4, \"_seq_no\" : 17, \"_primary_term\" : 2, \"email_group\" : { \"schema_version\" : 2, \"name\" : \"example_email_group\", \"emails\" : [ { \"email\" : \"example@email.com\" } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#update-email-group",
    "relUrl": "/docs/alerting/api/#update-email-group"
  },"62": {
    "doc": "API",
    "title": "Get email group",
    "content": "Request . GET _opendistro/_alerting/destinations/email_groups/&lt;email_group_id&gt; { \"name\": \"example_email_group\", \"emails\": [{ \"email\": \"example@email.com\" }] } . Sample response . { \"_id\" : \"email_group_id\", \"_version\" : 4, \"_seq_no\" : 17, \"_primary_term\" : 2, \"email_group\" : { \"schema_version\" : 2, \"name\" : \"example_email_group\", \"emails\" : [ { \"email\" : \"example@email.com\" } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#get-email-group",
    "relUrl": "/docs/alerting/api/#get-email-group"
  },"63": {
    "doc": "API",
    "title": "Delete email group",
    "content": "Request . DELETE _opendistro/_alerting/destinations/email_groups/&lt;email_group_id&gt; . Sample response . { \"_index\" : \".opendistro-alerting-config\", \"_type\" : \"_doc\", \"_id\" : \"email_group_id\", \"_version\" : 1, \"result\" : \"deleted\", \"forced_refresh\" : true, \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 11, \"_primary_term\" : 2 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#delete-email-group",
    "relUrl": "/docs/alerting/api/#delete-email-group"
  },"64": {
    "doc": "API",
    "title": "Search email group",
    "content": "Request . POST _opendistro/_alerting/destinations/email_groups/_search { \"from\": 0, \"size\": 20, \"sort\": { \"email_group.name.keyword\": \"desc\" }, \"query\": { \"bool\": { \"must\": { \"match_all\": {} } } } } . Sample response . { \"took\" : 7, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 5, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ { \"_index\" : \".opendistro-alerting-config\", \"_type\" : \"_doc\", \"_id\" : \"email_group_id\", \"_seq_no\" : 10, \"_primary_term\" : 2, \"_score\" : null, \"_source\" : { \"schema_version\" : 2, \"name\" : \"example_email_group\", \"emails\" : [ { \"email\" : \"example@email.com\" } ] }, \"sort\" : [ \"example_email_group\" ] }, ... ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/#search-email-group",
    "relUrl": "/docs/alerting/api/#search-email-group"
  },"65": {
    "doc": "API",
    "title": "API",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/api/",
    "relUrl": "/docs/alerting/api/"
  },"66": {
    "doc": "API",
    "title": "RCA API",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/api/#rca-api",
    "relUrl": "/docs/rca/api/#rca-api"
  },"67": {
    "doc": "API",
    "title": "Sample request",
    "content": "# Request all available RCAs GET localhost:9600/_opendistro/_performanceanalyzer/rca # Request a specific RCA GET localhost:9600/_opendistro/_performanceanalyzer/rca?name=HighHeapUsageClusterRca . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/api/#sample-request",
    "relUrl": "/docs/rca/api/#sample-request"
  },"68": {
    "doc": "API",
    "title": "Sample response",
    "content": "{ \"HighHeapUsageClusterRca\": [{ \"rca_name\": \"HighHeapUsageClusterRca\", \"state\": \"unhealthy\", \"timestamp\": 1587426650942, \"HotClusterSummary\": [{ \"number_of_nodes\": 2, \"number_of_unhealthy_nodes\": 1, \"HotNodeSummary\": [{ \"host_address\": \"192.168.144.2\", \"node_id\": \"JtlEoRowSI6iNpzpjlbp_Q\", \"HotResourceSummary\": [{ \"resource_type\": \"old gen\", \"threshold\": 0.65, \"value\": 0.81827232588145373, \"avg\": NaN, \"max\": NaN, \"min\": NaN, \"unit_type\": \"heap usage in percentage\", \"time_period_seconds\": 600, \"TopConsumerSummary\": [{ \"name\": \"CACHE_FIELDDATA_SIZE\", \"value\": 590702564 }, { \"name\": \"CACHE_REQUEST_SIZE\", \"value\": 28375 }, { \"name\": \"CACHE_QUERY_SIZE\", \"value\": 12687 } ], }] }] }] }] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/api/#sample-response",
    "relUrl": "/docs/rca/api/#sample-response"
  },"69": {
    "doc": "API",
    "title": "API",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/api/",
    "relUrl": "/docs/rca/api/"
  },"70": {
    "doc": "API",
    "title": "Performance Analyzer API",
    "content": "Performance Analyzer uses a single HTTP method and URI for most requests: . GET &lt;endpoint&gt;:9600/_opendistro/_performanceanalyzer/metrics . Note the use of port 9600. Provide parameters for metrics, aggregations, dimensions, and nodes (optional): . ?metrics=&lt;metrics&gt;&amp;agg=&lt;aggregations&gt;&amp;dim=&lt;dimensions&gt;&amp;nodes=all\" . For a full list of metrics, see Metrics reference. Performance Analyzer updates its data every five seconds. If you create a custom client, we recommend using that same interval for calls to the API. Sample request . GET localhost:9600/_opendistro/_performanceanalyzer/metrics?metrics=Latency,CPU_Utilization&amp;agg=avg,max&amp;dim=ShardID&amp;nodes=all . Sample response . { \"keHlhQbbTpm1BYicficEQg\": { \"timestamp\": 1554940530000, \"data\": { \"fields\": [{ \"name\": \"ShardID\", \"type\": \"VARCHAR\" }, { \"name\": \"Latency\", \"type\": \"DOUBLE\" }, { \"name\": \"CPU_Utilization\", \"type\": \"DOUBLE\" } ], \"records\": [ [ null, null, 0.012552206029147535 ], [ \"1\", 4.8, 0.0009780939762972104 ] ] } }, \"bHdpbMJZTs-TKtZro2SmYA\": { \"timestamp\": 1554940530000, \"data\": { \"fields\": [{ \"name\": \"ShardID\", \"type\": \"VARCHAR\" }, { \"name\": \"Latency\", \"type\": \"DOUBLE\" }, { \"name\": \"CPU_Utilization\", \"type\": \"DOUBLE\" } ], \"records\": [ [ null, 18.2, 0.011966493817311527 ], [ \"1\", 14.8, 0.0007670829370071493 ] ] } } } . In this case, each top-level object represents a node. The API returns names and data types for the metrics and dimensions that you specified, along with values from five seconds ago and current values (if different). Null values represent inactivity during that time period. Performance Analyzer has one additional URI that returns the unit for each metric. Sample request . GET localhost:9600/_opendistro/_performanceanalyzer/metrics/units . Sample response . { \"Disk_Utilization\": \"%\", \"Cache_Request_Hit\": \"count\", \"TermVectors_Memory\": \"B\", \"Segments_Memory\": \"B\", \"HTTP_RequestDocs\": \"count\", \"Net_TCP_Lost\": \"segments/flow\", \"Refresh_Time\": \"ms\", \"GC_Collection_Event\": \"count\", \"Merge_Time\": \"ms\", \"Sched_CtxRate\": \"count/s\", \"Cache_Request_Size\": \"B\", \"ThreadPool_QueueSize\": \"count\", \"Sched_Runtime\": \"s/ctxswitch\", \"Disk_ServiceRate\": \"MB/s\", \"Heap_AllocRate\": \"B/s\", \"Heap_Max\": \"B\", \"Sched_Waittime\": \"s/ctxswitch\", \"ShardBulkDocs\": \"count\", \"Thread_Blocked_Time\": \"s/event\", \"VersionMap_Memory\": \"B\", \"Master_Task_Queue_Time\": \"ms\", \"Merge_CurrentEvent\": \"count\", \"Indexing_Buffer\": \"B\", \"Bitset_Memory\": \"B\", \"Norms_Memory\": \"B\", \"Net_PacketDropRate4\": \"packets/s\", \"Heap_Committed\": \"B\", \"Net_PacketDropRate6\": \"packets/s\", \"Thread_Blocked_Event\": \"count\", \"GC_Collection_Time\": \"ms\", \"Cache_Query_Miss\": \"count\", \"IO_TotThroughput\": \"B/s\", \"Latency\": \"ms\", \"Net_PacketRate6\": \"packets/s\", \"Cache_Query_Hit\": \"count\", \"IO_ReadSyscallRate\": \"count/s\", \"Net_PacketRate4\": \"packets/s\", \"Cache_Request_Miss\": \"count\", \"CB_ConfiguredSize\": \"B\", \"CB_TrippedEvents\": \"count\", \"ThreadPool_RejectedReqs\": \"count\", \"Disk_WaitTime\": \"ms\", \"Net_TCP_TxQ\": \"segments/flow\", \"Master_Task_Run_Time\": \"ms\", \"IO_WriteSyscallRate\": \"count/s\", \"IO_WriteThroughput\": \"B/s\", \"Flush_Event\": \"count\", \"Net_TCP_RxQ\": \"segments/flow\", \"Refresh_Event\": \"count\", \"Points_Memory\": \"B\", \"Flush_Time\": \"ms\", \"Heap_Init\": \"B\", \"CPU_Utilization\": \"cores\", \"HTTP_TotalRequests\": \"count\", \"ThreadPool_ActiveThreads\": \"count\", \"Cache_Query_Size\": \"B\", \"Paging_MinfltRate\": \"count/s\", \"Merge_Event\": \"count\", \"Net_TCP_SendCWND\": \"B/flow\", \"Cache_Request_Eviction\": \"count\", \"Segments_Total\": \"count\", \"Terms_Memory\": \"B\", \"DocValues_Memory\": \"B\", \"Heap_Used\": \"B\", \"Cache_FieldData_Eviction\": \"count\", \"IO_TotalSyscallRate\": \"count/s\", \"CB_EstimatedSize\": \"B\", \"Net_Throughput\": \"B/s\", \"Paging_RSS\": \"pages\", \"Indexing_ThrottleTime\": \"ms\", \"StoredFields_Memory\": \"B\", \"IndexWriter_Memory\": \"B\", \"Master_PendingQueueSize\": \"count\", \"Net_TCP_SSThresh\": \"B/flow\", \"Cache_FieldData_Size\": \"B\", \"Paging_MajfltRate\": \"count/s\", \"ThreadPool_TotalThreads\": \"count\", \"IO_ReadThroughput\": \"B/s\", \"ShardEvents\": \"count\", \"Net_TCP_NumFlows\": \"count\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/api/#performance-analyzer-api",
    "relUrl": "/docs/pa/api/#performance-analyzer-api"
  },"71": {
    "doc": "API",
    "title": "API",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/api/",
    "relUrl": "/docs/pa/api/"
  },"72": {
    "doc": "ISM API",
    "title": "ISM API",
    "content": "Use the index state management operations to programmatically work with policies and managed indices. . | Add policy at index creation | Create policy | Add policy | Update policy | Get policy | Remove policy from index | Update managed index policy | Retry failed index | Explain index | Delete policy | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/",
    "relUrl": "/docs/ism/api/"
  },"73": {
    "doc": "ISM API",
    "title": "Add policy at index creation",
    "content": "You can attach a policy to an index at the time you’re creating the index. Request . PUT index_1 { \"settings\": { \"opendistro.index_state_management.policy_id\": \"ingest_policy\", \"opendistro.index_state_management.rollover_alias\": \"some_alias\" }, \"aliases\": { \"some_alias\": { \"is_write_index\": true } } } . In this case, the ingest_policy is applied to index_1 with the rollover action defined in some_alias. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#add-policy-at-index-creation",
    "relUrl": "/docs/ism/api/#add-policy-at-index-creation"
  },"74": {
    "doc": "ISM API",
    "title": "Create policy",
    "content": "Creates a policy. Request . PUT _opendistro/_ism/policies/policy_1 { \"policy\": { \"description\": \"ingesting logs\", \"default_state\": \"ingest\", \"states\": [ { \"name\": \"ingest\", \"actions\": [ { \"rollover\": { \"min_doc_count\": 5 } } ], \"transitions\": [ { \"state_name\": \"search\" } ] }, { \"name\": \"search\", \"actions\": [], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"5m\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"delete\": {} } ], \"transitions\": [] } ] } } . Sample response . { \"_id\": \"policy_1\", \"_version\": 1, \"_primary_term\": 1, \"_seq_no\": 7, \"policy\": { \"policy\": { \"policy_id\": \"policy_1\", \"description\": \"ingesting logs\", \"last_updated_time\": 1577990761311, \"schema_version\": 1, \"error_notification\": null, \"default_state\": \"ingest\", \"states\": [ { \"name\": \"ingest\", \"actions\": [ { \"rollover\": { \"min_doc_count\": 5 } } ], \"transitions\": [ { \"state_name\": \"search\" } ] }, { \"name\": \"search\", \"actions\": [], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"5m\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"delete\": {} } ], \"transitions\": [] } ] } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#create-policy",
    "relUrl": "/docs/ism/api/#create-policy"
  },"75": {
    "doc": "ISM API",
    "title": "Add policy",
    "content": "Adds a policy to an index. This operation does not change the policy if the index already has one. Request . POST _opendistro/_ism/add/index_1 { \"policy_id\": \"policy_1\" } . Sample response . { \"updated_indices\": 1, \"failures\": false, \"failed_indices\": [] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#add-policy",
    "relUrl": "/docs/ism/api/#add-policy"
  },"76": {
    "doc": "ISM API",
    "title": "Update policy",
    "content": "Updates a policy. Use the seq_no and primary_term parameters to update an existing policy. If these numbers don’t match the existing policy or the policy doesn’t exist, ISM throws an error. Request . PUT _opendistro/_ism/policies/policy_1?if_seq_no=7&amp;if_primary_term=1 { \"policy\": { \"description\": \"ingesting logs\", \"default_state\": \"ingest\", \"states\": [ { \"name\": \"ingest\", \"actions\": [ { \"rollover\": { \"min_doc_count\": 5 } } ], \"transitions\": [ { \"state_name\": \"search\" } ] }, { \"name\": \"search\", \"actions\": [], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"5m\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"delete\": {} } ], \"transitions\": [] } ] } } . Sample response . { \"_id\": \"policy_1\", \"_version\": 2, \"_primary_term\": 1, \"_seq_no\": 10, \"policy\": { \"policy\": { \"policy_id\": \"policy_1\", \"description\": \"ingesting logs\", \"last_updated_time\": 1577990934044, \"schema_version\": 1, \"error_notification\": null, \"default_state\": \"ingest\", \"states\": [ { \"name\": \"ingest\", \"actions\": [ { \"rollover\": { \"min_doc_count\": 5 } } ], \"transitions\": [ { \"state_name\": \"search\" } ] }, { \"name\": \"search\", \"actions\": [], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"5m\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"delete\": {} } ], \"transitions\": [] } ] } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#update-policy",
    "relUrl": "/docs/ism/api/#update-policy"
  },"77": {
    "doc": "ISM API",
    "title": "Get policy",
    "content": "Gets the policy by policy_id. Request . GET _opendistro/_ism/policies/policy_1 . Sample response . { \"_id\": \"policy_1\", \"_version\": 2, \"_seq_no\": 10, \"_primary_term\": 1, \"policy\": { \"policy_id\": \"policy_1\", \"description\": \"ingesting logs\", \"last_updated_time\": 1577990934044, \"schema_version\": 1, \"error_notification\": null, \"default_state\": \"ingest\", \"states\": [ { \"name\": \"ingest\", \"actions\": [ { \"rollover\": { \"min_doc_count\": 5 } } ], \"transitions\": [ { \"state_name\": \"search\" } ] }, { \"name\": \"search\", \"actions\": [], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"5m\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"delete\": {} } ], \"transitions\": [] } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#get-policy",
    "relUrl": "/docs/ism/api/#get-policy"
  },"78": {
    "doc": "ISM API",
    "title": "Remove policy from index",
    "content": "Removes any ISM policy from the index. Request . POST _opendistro/_ism/remove/index_1 . Sample response . { \"updated_indices\": 1, \"failures\": false, \"failed_indices\": [] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#remove-policy-from-index",
    "relUrl": "/docs/ism/api/#remove-policy-from-index"
  },"79": {
    "doc": "ISM API",
    "title": "Update managed index policy",
    "content": "Updates the managed index policy to a new policy (or to a new version of the policy). You can use an index pattern to update multiple indices at once. When updating multiple indices, you might want to include a state filter to only affect certain managed indices. Request . POST _opendistro/_ism/change_policy/index_1 { \"policy_id\": \"policy_1\", \"state\": \"delete\", \"include\": [ { \"state\": \"searches\" } ] } . Sample response . { \"updated_indices\": 0, \"failures\": false, \"failed_indices\": [] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#update-managed-index-policy",
    "relUrl": "/docs/ism/api/#update-managed-index-policy"
  },"80": {
    "doc": "ISM API",
    "title": "Retry failed index",
    "content": "Retries the failed action for an index. For the retry call to succeed, ISM must manage the index, and the index must be in a failed state. You can use index patterns (*) to retry multiple failed indices. Request . POST _opendistro/_ism/retry/index_1 { \"state\": \"delete\" } . Sample response . { \"updated_indices\": 0, \"failures\": false, \"failed_indices\": [] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#retry-failed-index",
    "relUrl": "/docs/ism/api/#retry-failed-index"
  },"81": {
    "doc": "ISM API",
    "title": "Explain index",
    "content": "Gets the current state of the index. You can use index patterns to get the status of multiple indices. Request . GET _opendistro/_ism/explain/index_1 . Sample response . { \"index_1\": { \"index.opendistro.index_state_management.policy_id\": \"policy_1\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#explain-index",
    "relUrl": "/docs/ism/api/#explain-index"
  },"82": {
    "doc": "ISM API",
    "title": "Delete policy",
    "content": "Deletes the policy by policy_id. Request . DELETE _opendistro/_ism/policies/policy_1 . Sample response . { \"_index\": \".opendistro-ism-config\", \"_type\": \"_doc\", \"_id\": \"policy_1\", \"_version\": 3, \"result\": \"deleted\", \"forced_refresh\": true, \"_shards\": { \"total\": 2, \"successful\": 2, \"failed\": 0 }, \"_seq_no\": 15, \"_primary_term\": 1 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/api/#delete-policy",
    "relUrl": "/docs/ism/api/#delete-policy"
  },"83": {
    "doc": "Basic Queries",
    "title": "Basic queries",
    "content": "Use the SELECT clause, along with FROM, WHERE, GROUP BY, HAVING, ORDER BY, and LIMIT to search and aggregate data. Among these clauses, SELECT and FROM are required, as they specify which fields to retrieve and which indices to retrieve them from. All other clauses are optional. Use them according to your needs. Syntax . The complete syntax for searching and aggregating data is as follows: . SELECT [DISTINCT] (* | expression) [[AS] alias] [, ...] FROM index_name [WHERE predicates] [GROUP BY expression [, ...] [HAVING predicates]] [ORDER BY expression [IS [NOT] NULL] [ASC | DESC] [, ...]] [LIMIT [offset, ] size] . Fundamentals . Apart from the predefined keywords of SQL, the most basic elements are literal and identifiers. A literal is a numeric, string, date or boolean constant. An identifier is an Elasticsearch index or field name. With arithmetic operators and SQL functions, use literals and identifiers to build complex expressions. Rule expressionAtom: . The expression in turn can be combined into a predicate with logical operator. Use a predicate in the WHERE and HAVING clause to filter out data by specific conditions. Rule expression: . Rule predicate: . Execution Order . These SQL clauses execute in an order different from how they appear: . FROM index WHERE predicates GROUP BY expressions HAVING predicates SELECT expressions ORDER BY expressions LIMIT size . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#basic-queries",
    "relUrl": "/docs/sql/basic/#basic-queries"
  },"84": {
    "doc": "Basic Queries",
    "title": "Select",
    "content": "Specify the fields to be retrieved. Syntax . Rule selectElements: . Rule selectElement: . Example 1: Use * to retrieve all fields in an index: . SELECT * FROM accounts . | id | account_number | firstname | gender | city | balance | employer | state | email | address | lastname | age | . | 0 | 1 | Amber | M | Brogan | 39225 | Pyrami | IL | amberduke@pyrami.com | 880 Holmes Lane | Duke | 32 | . | 1 | 16 | Hattie | M | Dante | 5686 | Netagy | TN | hattiebond@netagy.com | 671 Bristol Street | Bond | 36 | . | 2 | 13 | Nanette | F | Nogal | 32838 | Quility | VA | nanettebates@quility.com | 789 Madison Street | Bates | 28 | . | 3 | 18 | Dale | M | Orick | 4180 |   | MD | daleadams@boink.com | 467 Hutchinson Court | Adams | 33 | . Example 2: Use field name(s) to retrieve only specific fields: . SELECT firstname, lastname FROM accounts . | id | firstname | lastname | . | 0 | Amber | Duke | . | 1 | Hattie | Bond | . | 2 | Nanette | Bates | . | 3 | Dale | Adams | . Example 3: Use field aliases instead of field names. Field aliases are used to make field names more readable: . SELECT account_number AS num FROM accounts . | id | num | . | 0 | 1 | . | 1 | 6 | . | 2 | 13 | . | 3 | 18 | . Example 4: Use the DISTINCT clause to get back only unique field values. You can specify one or more field names: . SELECT DISTINCT age FROM accounts . | id | age | . | 0 | 28 | . | 1 | 32 | . | 2 | 33 | . | 3 | 36 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#select",
    "relUrl": "/docs/sql/basic/#select"
  },"85": {
    "doc": "Basic Queries",
    "title": "From",
    "content": "Specify the index that you want search. You can specify subqueries within the FROM clause. Syntax . Rule tableName: . Example 1: Use index aliases to query across indexes. To learn about index aliases, see Index Alias. In this sample query, acc is an alias for the accounts index: . SELECT account_number, accounts.age FROM accounts . or . SELECT account_number, acc.age FROM accounts acc . | id | account_number | age | . | 0 | 1 | 32 | . | 1 | 6 | 36 | . | 2 | 13 | 28 | . | 3 | 18 | 33 | . Example 2: Use index patterns to query indices that match a specific pattern: . SELECT account_number FROM account* . | id | account_number | . | 0 | 1 | . | 1 | 6 | . | 2 | 13 | . | 3 | 18 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#from",
    "relUrl": "/docs/sql/basic/#from"
  },"86": {
    "doc": "Basic Queries",
    "title": "Where",
    "content": "Specify a condition to filter the results. | Operators | Behavior | . | = | Equal to. | . | &lt;&gt; | Not equal to. | . | &gt; | Greater than. | . | &lt; | Less than. | . | &gt;= | Greater than or equal to. | . | &lt;= | Less than or equal to. | . | IN | Specify multiple OR operators. | . | BETWEEN | Similar to a range query. For more information about range queries, see Range query. | . | LIKE | Use for full text search. For more information about full-text queries, see Full-text queries. | . | IS NULL | Check if the field value is NULL. | . | IS NOT NULL | Check if the field value is NOT NULL. | . Combine comparison operators (=, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=) with boolean operators NOT, AND, or OR to build more complex expressions. Example 1: Use comparison operators for numbers, strings, or dates: . SELECT account_number FROM accounts WHERE account_number = 1 . | id | account_number | . | 0 | 1 | . Example 2: Elasticsearch allows for flexible schema so documents in an index may have different fields. Use IS NULL or IS NOT NULL to retrieve only missing fields or existing fields. We do not differentiate between missing fields and fields explicitly set to NULL: . SELECT account_number, employer FROM accounts WHERE employer IS NULL . | id | account_number | employer | . | 0 | 18 |   | . Example 3: Deletes a document that satisfies the predicates in the WHERE clause: . DELETE FROM accounts WHERE age &gt; 30 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#where",
    "relUrl": "/docs/sql/basic/#where"
  },"87": {
    "doc": "Basic Queries",
    "title": "Group By",
    "content": "Group documents with the same field value into buckets. Example 1: Group by fields: . SELECT age FROM accounts GROUP BY age . | id | age | . | 0 | 28 | . | 1 | 32 | . | 2 | 33 | . | 3 | 36 | . Example 2: Group by field alias: . SELECT account_number AS num FROM accounts GROUP BY num . | id | num | . | 0 | 1 | . | 1 | 6 | . | 2 | 13 | . | 3 | 18 | . Example 4: Use scalar functions in the GROUP BY clause: . SELECT ABS(age) AS a FROM accounts GROUP BY ABS(age) . | id | a | . | 0 | 28.0 | . | 1 | 32.0 | . | 2 | 33.0 | . | 3 | 36.0 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#group-by",
    "relUrl": "/docs/sql/basic/#group-by"
  },"88": {
    "doc": "Basic Queries",
    "title": "Having",
    "content": "Use the HAVING clause to aggregate inside each bucket based on aggregation functions (COUNT, AVG, SUM, MIN, and MAX). The HAVING clause filters results from the GROUP BY clause: . Example 1: . SELECT age, MAX(balance) FROM accounts GROUP BY age HAVING MIN(balance) &gt; 10000 . | id | age | MAX (balance) | . | 0 | 28 | 32838 | . | 1 | 32 | 39225 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#having",
    "relUrl": "/docs/sql/basic/#having"
  },"89": {
    "doc": "Basic Queries",
    "title": "Order By",
    "content": "Use the ORDER BY clause to sort results into your desired order. Example 1: Use ORDER BY to sort by ascending or descending order. Besides regular field names, using ordinal, alias, or scalar functions are supported: . SELECT account_number FROM accounts ORDER BY account_number DESC . | id | account_number | . | 0 | 18 | . | 1 | 13 | . | 2 | 6 | . | 3 | 1 | . Example 2: Specify if documents with missing fields are to be put at the beginning or at the end of the results. The default behavior of Elasticsearch is to return nulls or missing fields at the end. To push them before non-nulls, use the IS NOT NULL operator: . SELECT employer FROM accounts ORDER BY employer IS NOT NULL . | id | employer | . | 0 |   | . | 1 | Netagy | . | 2 | Pyrami | . | 3 | Quility | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#order-by",
    "relUrl": "/docs/sql/basic/#order-by"
  },"90": {
    "doc": "Basic Queries",
    "title": "Limit",
    "content": "Specify the maximum number of documents that you want to retrieve. Used to prevent fetching large amounts of data into memory. Example 1: If you pass in a single argument, it’s mapped to the size parameter in Elasticsearch and the from parameter is set to 0. SELECT account_number FROM accounts ORDER BY account_number LIMIT 1 . | id | account_number | . | 0 | 1 | . Example 2: If you pass in two arguments, the first is mapped to the from parameter and the second to the size parameter in Elasticsearch. You can use this for simple pagination for small indices, as it’s inefficient for large indices. Use ORDER BY to ensure the same order between pages: . SELECT account_number FROM accounts ORDER BY account_number LIMIT 1, 1 . | id | account_number | . | 0 | 6 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/#limit",
    "relUrl": "/docs/sql/basic/#limit"
  },"91": {
    "doc": "Basic Queries",
    "title": "Basic Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/basic/",
    "relUrl": "/docs/sql/basic/"
  },"92": {
    "doc": "Boolean Queries",
    "title": "Boolean queries",
    "content": "The bool query lets you combine multiple search queries with boolean logic. You can use boolean logic between queries to either narrow or broaden your search results. The bool query is a go-to query because it allows you to construct an advanced query by chaining together several simple ones. Use the following clauses (subqueries) within the bool query: . | Clause | Behavior | . | must | The results must match the queries in this clause. If you have multiple queries, every single one must match. Acts as an and operator. | . | must_not | This is the anti-must clause. All matches are excluded from the results. Acts as a not operator. | . | should | The results should, but don’t have to, match the queries. Each matching should clause increases the relevancy score. As an option, you can require one or more queries to match the value of the minimum_number_should_match parameter (default is 1). | . | filter | Filters reduce your dataset before applying the queries. A query within a filter clause is a yes-no option, where if a document matches the query it’s included in the results. Otherwise, it’s not. Filter queries do not affect the relevancy score that the results are sorted by. The results of a filter query are generally cached so they tend to run faster. Use the filter query to filter the results based on exact matches, ranges, dates, numbers, and so on. | . The structure of a bool query is as follows: . GET _search { \"query\": { \"bool\": { \"must\": [ {} ], \"must_not\": [ {} ], \"should\": [ {} ], \"filter\": {} } } } . For example, assume you have the complete works of Shakespeare indexed in an Elasticsearch cluster. You want to construct a single query that meets the following requirements: . | The text_entry field must contain the word love and should contain either life or grace. | The speaker field must not contain ROMEO. | Filter these results to the play Romeo and Juliet without affecting the relevancy score. | . Use the following query: . GET shakespeare/_search { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"text_entry\": \"love\" } } ], \"should\": [ { \"match\": { \"text_entry\": \"life\" } }, { \"match\": { \"text_entry\": \"grace\" } } ], \"minimum_should_match\": 1, \"must_not\": [ { \"match\": { \"speaker\": \"ROMEO\" } } ], \"filter\": { \"term\": { \"play_name\": \"Romeo and Juliet\" } } } } } . Sample output . { \"took\": 12, \"timed_out\": false, \"_shards\": { \"total\": 4, \"successful\": 4, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 1, \"relation\": \"eq\" }, \"max_score\": 11.356054, \"hits\": [ { \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"88020\", \"_score\": 11.356054, \"_source\": { \"type\": \"line\", \"line_id\": 88021, \"play_name\": \"Romeo and Juliet\", \"speech_number\": 19, \"line_number\": \"4.5.61\", \"speaker\": \"PARIS\", \"text_entry\": \"O love! O life! not life, but love in death!\" } } ] } } . If you want to identify which of these clauses actually caused the matching results, name each query with the _name parameter. To add the _name parameter, change the field name in the match query to an object: . GET shakespeare/_search { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"text_entry\": { \"query\": \"love\", \"_name\": \"love-must\" } } } ], \"should\": [ { \"match\": { \"text_entry\": { \"query\": \"life\", \"_name\": \"life-should\" } } }, { \"match\": { \"text_entry\": { \"query\": \"grace\", \"_name\": \"grace-should\" } } } ], \"minimum_should_match\": 1, \"must_not\": [ { \"match\": { \"speaker\": { \"query\": \"ROMEO\", \"_name\": \"ROMEO-must-not\" } } } ], \"filter\": { \"term\": { \"play_name\": \"Romeo and Juliet\" } } } } } . Elasticsearch returns a matched_queries array that lists the queries that matched these results: . \"matched_queries\": [ \"love-must\", \"life-should\" ] . If you remove the queries not in this list, you will still see the exact same result. By examining which should clause matched, you can better understand the relevancy score of the results. You can also construct complex boolean expressions by nesting bool queries. For example, to find a text_entry field that matches (love OR hate) AND (life OR grace) in the play Romeo and Juliet: . GET shakespeare/_search { \"query\": { \"bool\": { \"must\": [ { \"bool\": { \"should\": [ { \"match\": { \"text_entry\": \"love\" } }, { \"match\": { \"text\": \"hate\" } } ] } }, { \"bool\": { \"should\": [ { \"match\": { \"text_entry\": \"life\" } }, { \"match\": { \"text\": \"grace\" } } ] } } ], \"filter\": { \"term\": { \"play_name\": \"Romeo and Juliet\" } } } } } . Sample output . { \"took\": 10, \"timed_out\": false, \"_shards\": { \"total\": 2, \"successful\": 2, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 11.37006, \"hits\": [ { \"_index\": \"shakespeare\", \"_type\": \"doc\", \"_id\": \"88020\", \"_score\": 11.37006, \"_source\": { \"type\": \"line\", \"line_id\": 88021, \"play_name\": \"Romeo and Juliet\", \"speech_number\": 19, \"line_number\": \"4.5.61\", \"speaker\": \"PARIS\", \"text_entry\": \"O love! O life! not life, but love in death!\" } } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/bool/#boolean-queries",
    "relUrl": "/docs/elasticsearch/bool/#boolean-queries"
  },"93": {
    "doc": "Boolean Queries",
    "title": "Boolean Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/bool/",
    "relUrl": "/docs/elasticsearch/bool/"
  },"94": {
    "doc": "CAT API",
    "title": "cat API",
    "content": "You can get essential statistics about your cluster in an easy-to-understand, tabular format using the compact and aligned text (CAT) API. The cat API is a human-readable interface that returns plain text instead of traditional JSON. Using the cat API, you can answer questions like which node is the elected master, what state is the cluster in, how many documents are in each index, and so on. To see the available operations in the cat API, use the following command: . GET _cat . You can also use the following string parameters with your query. | Parameter | Description | . | ?v | Makes the output more verbose by adding headers to the columns. It also adds some formatting to help align each of the columns together. All examples on this page include the v parameter. | . | ?help | Lists the default and other available headers for a given operation. | . | ?h | Limits the output to specific headers. | . | ?format | Outputs the result in JSON, YAML, or CBOR formats. | . | ?sort | Sorts the output by the specified columns. | . To see what each column represents, use the ?v parameter: . GET _cat/&lt;operation_name&gt;?v . To see all the available headers, use the ?help parameter: . GET _cat/&lt;operation_name&gt;?help . To limit the output to a subset of headers, use the ?h parameter: . GET _cat/&lt;operation_name&gt;?h=&lt;header_name_1&gt;,&lt;header_name_2&gt;&amp;v . Typically, for any operation you can find out what headers are available using the ?help parameter, and then use the ?h parameter to limit the output to only the headers that you care about. . | Aliases | Allocation | Count | Field data | Health | Indices | Master | Node attributes | Nodes | Pending tasks | Plugins | Recovery | Repositories | Segments | Shards | Snapshots | Tasks | Templates | Thread pool | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#cat-api",
    "relUrl": "/docs/elasticsearch/catapis/#cat-api"
  },"95": {
    "doc": "CAT API",
    "title": "Aliases",
    "content": "Lists the mapping of aliases to indices, plus routing and filtering information. GET _cat/aliases?v . To limit the information to a specific alias, add the alias name after your query. GET _cat/aliases/&lt;alias&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#aliases",
    "relUrl": "/docs/elasticsearch/catapis/#aliases"
  },"96": {
    "doc": "CAT API",
    "title": "Allocation",
    "content": "Lists the allocation of disk space for indices and the number of shards on each node. Default request: . GET _cat/allocation?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#allocation",
    "relUrl": "/docs/elasticsearch/catapis/#allocation"
  },"97": {
    "doc": "CAT API",
    "title": "Count",
    "content": "Lists the number of documents in your cluster. GET _cat/count?v . To see the number of documents in a specific index, add the index name after your query. GET _cat/count/&lt;index&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#count",
    "relUrl": "/docs/elasticsearch/catapis/#count"
  },"98": {
    "doc": "CAT API",
    "title": "Field data",
    "content": "Lists the memory size used by each field per node. GET _cat/fielddata?v . To limit the information to a specific field, add the field name after your query. GET _cat/fielddata/&lt;fields&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#field-data",
    "relUrl": "/docs/elasticsearch/catapis/#field-data"
  },"99": {
    "doc": "CAT API",
    "title": "Health",
    "content": "Lists the status of the cluster, how long the cluster has been up, the number of nodes, and other useful information that helps you analyze the health of your cluster. GET _cat/health?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#health",
    "relUrl": "/docs/elasticsearch/catapis/#health"
  },"100": {
    "doc": "CAT API",
    "title": "Indices",
    "content": "Lists information related to indices⁠—how much disk space they are using, how many shards they have, their health status, and so on. GET _cat/indices?v . To limit the information to a specific index, add the index name after your query. GET _cat/indices/&lt;index&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#indices",
    "relUrl": "/docs/elasticsearch/catapis/#indices"
  },"101": {
    "doc": "CAT API",
    "title": "Master",
    "content": "Lists information that helps identify the elected master node. GET _cat/master?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#master",
    "relUrl": "/docs/elasticsearch/catapis/#master"
  },"102": {
    "doc": "CAT API",
    "title": "Node attributes",
    "content": "Lists the attributes of custom nodes. GET _cat/nodeattrs?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#node-attributes",
    "relUrl": "/docs/elasticsearch/catapis/#node-attributes"
  },"103": {
    "doc": "CAT API",
    "title": "Nodes",
    "content": "Lists node-level information, including node roles and load metrics. A few important node metrics are pid, name, master, ip, port, version, build, jdk, along with disk, heap, ram, and file_desc. GET _cat/nodes?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#nodes",
    "relUrl": "/docs/elasticsearch/catapis/#nodes"
  },"104": {
    "doc": "CAT API",
    "title": "Pending tasks",
    "content": "Lists the progress of all pending tasks, including task priority and time in queue. GET _cat/pending_tasks?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#pending-tasks",
    "relUrl": "/docs/elasticsearch/catapis/#pending-tasks"
  },"105": {
    "doc": "CAT API",
    "title": "Plugins",
    "content": "Lists the names, components, and versions of the installed plugins. GET _cat/plugins?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#plugins",
    "relUrl": "/docs/elasticsearch/catapis/#plugins"
  },"106": {
    "doc": "CAT API",
    "title": "Recovery",
    "content": "Lists all completed and ongoing index and shard recoveries. GET _cat/recovery?v . To see only the recoveries of a specific index, add the index name after your query. GET _cat/recovery/&lt;index&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#recovery",
    "relUrl": "/docs/elasticsearch/catapis/#recovery"
  },"107": {
    "doc": "CAT API",
    "title": "Repositories",
    "content": "Lists all snapshot repositories and their types. GET _cat/repositories?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#repositories",
    "relUrl": "/docs/elasticsearch/catapis/#repositories"
  },"108": {
    "doc": "CAT API",
    "title": "Segments",
    "content": "Lists Lucene segment-level information for each index. GET _cat/segments?v . To see only the information about segments of a specific index, add the index name after your query. GET _cat/segments/&lt;index&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#segments",
    "relUrl": "/docs/elasticsearch/catapis/#segments"
  },"109": {
    "doc": "CAT API",
    "title": "Shards",
    "content": "Lists the state of all primary and replica shards and how they are distributed. GET _cat/shards?v . To see only the information about shards of a specific index, add the index name after your query. GET _cat/shards/&lt;index&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#shards",
    "relUrl": "/docs/elasticsearch/catapis/#shards"
  },"110": {
    "doc": "CAT API",
    "title": "Snapshots",
    "content": "Lists all snapshots for a repository. GET _cat/snapshots/&lt;repository&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#snapshots",
    "relUrl": "/docs/elasticsearch/catapis/#snapshots"
  },"111": {
    "doc": "CAT API",
    "title": "Tasks",
    "content": "Lists the progress of all tasks currently running on your cluster. GET _cat/tasks?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#tasks",
    "relUrl": "/docs/elasticsearch/catapis/#tasks"
  },"112": {
    "doc": "CAT API",
    "title": "Templates",
    "content": "Lists the names, patterns, order numbers, and version numbers of index templates. GET _cat/templates?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#templates",
    "relUrl": "/docs/elasticsearch/catapis/#templates"
  },"113": {
    "doc": "CAT API",
    "title": "Thread pool",
    "content": "Lists the active, queued, and rejected threads of different thread pools on each node. GET _cat/thread_pool?v . To limit the information to a specific thread pool, add the thread pool name after your query. GET _cat/thread_pool/&lt;thread_pool&gt;?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/#thread-pool",
    "relUrl": "/docs/elasticsearch/catapis/#thread-pool"
  },"114": {
    "doc": "CAT API",
    "title": "CAT API",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/catapis/",
    "relUrl": "/docs/elasticsearch/catapis/"
  },"115": {
    "doc": "Anomaly Detection CLI",
    "title": "Anomaly Detection CLI",
    "content": "Anomaly detection CLI lets you call anomaly detection APIs with the esad command. You can use the CLI to: . | Create detectors | Start, stop, and delete detectors | Create named profiles to connect to your cluster | . Install the anomaly detection plugin to your Elasticsearch instance, run the CLI using macOS or Linux, and connect to any valid Elasticsearch end-point. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/cli/",
    "relUrl": "/docs/ad/cli/"
  },"116": {
    "doc": "Anomaly Detection CLI",
    "title": "Install",
    "content": "Launch your local Elasticsearch instance and make sure you have the anomaly detection plugin installed. To install the anomaly detection CLI: . | Download and extract esad binaries. | Make the esad file executable: chmod +x ./esad . | Move the binaries to your path for root users: sudo mv ./esad /usr/local/bin/esad . Or add it to the current path: . export PATH=$PATH:$(pwd) . | Check if the CLI is installed: esad --version . You should see the command prints of the esad version you installed. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/cli/#install",
    "relUrl": "/docs/ad/cli/#install"
  },"117": {
    "doc": "Anomaly Detection CLI",
    "title": "Configure",
    "content": "Before using the CLI, you must configure your credentials. To quickly get started, run the esad profile create command: . esad profile create Enter profile's name: dev ES Anomaly Detection Endpoint: https://localhost:9200 ES Anomaly Detection User: admin ES Anomaly Detection Password: . Specify a unique profile name. The create command doesn’t allow duplicate profiles. Alternatively, you can also use a configuration file: . profiles: - endpoint: https://localhost:9200 username: admin password: foobar name: default - endpoint: https://odfe-node1:9200 username: admin password: foobar name: dev . Save the file in ~/.esad/config.yaml. If save you file to a different location, set the appropriate environment variable: . export ESAD_CONFIG_FILE=/path/to/config_file . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/cli/#configure",
    "relUrl": "/docs/ad/cli/#configure"
  },"118": {
    "doc": "Anomaly Detection CLI",
    "title": "Using the CLI",
    "content": ". | The complete syntax for an esad command is as follows: esad &lt;command&gt; &lt;subcommand&gt; [flags and parameters] . | To start a detector: esad start [detector-name-pattern] . | To see help documentation: esad --help esad &lt;command&gt; --help esad &lt;command&gt; &lt;subcommand&gt; --help . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/cli/#using-the-cli",
    "relUrl": "/docs/ad/cli/#using-the-cli"
  },"119": {
    "doc": "SQL CLI",
    "title": "SQL CLI",
    "content": "SQL CLI is a stand-alone Python application that you can launch with the odfesql command. Install the SQL plugin to your Elasticsearch instance, run the CLI using MacOS or Linux, and connect to any valid Elasticsearch end-point. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/",
    "relUrl": "/docs/sql/cli/"
  },"120": {
    "doc": "SQL CLI",
    "title": "Features",
    "content": "SQL CLI has the following features: . | Multi-line input | Autocomplete for SQL syntax and index names | Syntax highlighting | Formatted output: . | Tabular format | Field names with color | Enabled horizontal display (by default) and vertical display when output is too wide for your terminal, for better visualization | Pagination for large output | . | Works with or without security enabled | Supports loading configuration files | Supports all SQL plugin queries | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#features",
    "relUrl": "/docs/sql/cli/#features"
  },"121": {
    "doc": "SQL CLI",
    "title": "Install",
    "content": "Launch your local Elasticsearch instance and make sure you have the SQL plugin installed. To install the SQL CLI: . | We suggest you install and activate a python3 virtual environment to avoid changing your local environment: pip install virtualenv virtualenv venv cd venv source ./bin/activate . | Install the CLI: pip3 install odfe-sql-cli . | . The SQL CLI only works with Python 3. | To launch the CLI, run: odfesql https://localhost:9200 --username admin --password admin . By default, the odfesql command connects to http://localhost:9200. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#install",
    "relUrl": "/docs/sql/cli/#install"
  },"122": {
    "doc": "SQL CLI",
    "title": "Configure",
    "content": "When you first launch the SQL CLI, a configuration file is automatically created at ~/.config/odfesql-cli/config (for MacOS and Linux), the configuration is auto-loaded thereafter. You can configure the following connection properties: . | endpoint: You do not need to specify an option, anything that follows the launch command odfesql is considered as the endpoint. If you do not provide an endpoint, by default, the SQL CLI connects to http://localhost:9200. | -u/-w: Supports username and password for HTTP basic authentication, such as with the security plugin or fine-grained access control for Amazon Elasticsearch Service. | --aws-auth: Turns on AWS sigV4 authentication to connect to an Amazon Elasticsearch endpoint. Use with the AWS CLI (aws configure) to retrieve the local AWS configuration to authenticate and connect. | . For a list of all available configurations, see clirc. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#configure",
    "relUrl": "/docs/sql/cli/#configure"
  },"123": {
    "doc": "SQL CLI",
    "title": "Using the CLI",
    "content": ". | Save the sample accounts test data file. | Index the sample data. curl -H \"Content-Type: application/x-ndjson\" -POST https://localhost:9200/data/_bulk -u admin:admin --insecure --data-binary \"@accounts.json\" . | Run a sample SQL command: SELECT * FROM accounts; . | . By default, you see a maximum output of 200 rows. To show more results, add a LIMIT clause with the desired value. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#using-the-cli",
    "relUrl": "/docs/sql/cli/#using-the-cli"
  },"124": {
    "doc": "SQL CLI",
    "title": "Query options",
    "content": "Run a single query with the following options: . | --help: Help page for options | -q: Follow by a single query | -f: Specify JDBC or raw format output | -v: Display data vertically | -e: Translate SQL to DSL | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#query-options",
    "relUrl": "/docs/sql/cli/#query-options"
  },"125": {
    "doc": "SQL CLI",
    "title": "CLI options",
    "content": ". | -p: Always use pager to display output | --clirc: Provide path for the configuration file | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/cli/#cli-options",
    "relUrl": "/docs/sql/cli/#cli-options"
  },"126": {
    "doc": "Cluster Restart Upgrade",
    "title": "Cluster restart upgrade",
    "content": "The steps on this page are most applicable if you installed Open Distro for Elasticsearch using the RPM or Debian packages. If you used a Docker image, see Docker upgrade. | Disable shard allocation to prevent Elasticsearch from replicating shards as you shut down each node: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.enable\": \"primaries\" } } . | Stop Elasticsearch on each node: . sudo systemctl stop elasticsearch.service . | If you use the Debian package, upgrade to the underlying Elasticsearch version of the new Open Distro for Elasticsearch release: . wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-x.y.z-amd64.deb sudo dpkg -i elasticsearch-oss-x.y.z-amd64.deb . | Upgrade packages on each node using yum or apt: . sudo yum install opendistroforelasticsearch sudo apt install opendistroforelasticsearch . Alternately, yum lets you upgrade to a specific version of Open Distro for Elasticsearch: . sudo yum install opendistro-for-elasticsearch-1.11.0 . Unfortunately, apt upgrades dependencies to their latest versions and thus only supports upgrades to the newest version of Open Distro for Elasticsearch. | (Optional) Upgrade any additional plugins that you installed on the cluster. The package manager automatically upgrades Open Distro for Elasticsearch plugins. | Start Elasticsearch on each node: . sudo systemctl start elasticsearch.service . | Wait for the cluster to start, and verify that your cluster returns the new version: . curl -XGET https://localhost:9200 -u admin:admin -k . | Verify cluster health and the expected number of nodes: . curl -XGET https://localhost:9200/_cat/health?v -u admin:admin -k . | Enable shard allocation: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.enable\": \"all\" } } . | Open Kibana, and verify that your data is present. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/cluster-restart/#cluster-restart-upgrade",
    "relUrl": "/docs/upgrade/cluster-restart/#cluster-restart-upgrade"
  },"127": {
    "doc": "Cluster Restart Upgrade",
    "title": "Cluster Restart Upgrade",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/cluster-restart/",
    "relUrl": "/docs/upgrade/cluster-restart/"
  },"128": {
    "doc": "Cluster Formation",
    "title": "Cluster formation",
    "content": "Before diving into Elasticsearch and searching and aggregating data, you first need to create an Elasticsearch cluster. Elasticsearch can operate as a single-node or multi-node cluster. The steps to configure both are, in general, quite similar. This page demonstrates how to create and configure a multi-node cluster, but with only a few minor adjustments, you can follow the same steps to create a single-node cluster. To create and deploy an Elasticsearch cluster according to your requirements, it’s important to understand how node discovery and cluster formation work and what settings govern them. There are many ways that you can design a cluster. The following illustration shows a basic architecture. This is a four-node cluster that has one dedicated master node, one dedicated coordinating node, and two data nodes that are master-eligible and also used for ingesting data. The following table provides brief descriptions of the node types. | Node type | Description | Best practices for production | . | Master | Manages the overall operation of a cluster and keeps track of the cluster state. This includes creating and deleting indices, keeping track of the nodes that join and leave the cluster, checking the health of each node in the cluster (by running ping requests), and allocating shards to nodes. | Three dedicated master nodes in three different zones is the right approach for almost all production use cases. This makes sure your cluster never loses quorum. Two nodes will be idle for most of the time except when one node goes down or needs some maintenance. | . | Master-eligible | Elects one node among them as the master node through a voting process. | For production clusters, make sure you have dedicated master nodes. The way to achieve a dedicated node type is to mark all other node types as false. In this case, you have to mark all the other nodes as not master-eligible. | . | Data | Stores and searches data. Performs all data-related operations (indexing, searching, aggregating) on local shards. These are the worker nodes of your cluster and need more disk space than any other node type. | As you add data nodes, keep them balanced between zones. For example, if you have three zones, add data nodes in multiples of three, one for each zone. We recommend using storage and RAM-heavy nodes. | . | Ingest | Preprocesses data before storing it in the cluster. Runs an ingest pipeline that transforms your data before adding it to an index. | If you plan to ingest a lot of data and run complex ingest pipelines, we recommend you use dedicated ingest nodes. You can also optionally offload your indexing from the data nodes so that your data nodes are used exclusively for searching and aggregating. | . | Coordinating | Delegates client requests to the shards on the data nodes, collects and aggregates the results into one final result, and sends this result back to the client. | A couple of dedicated coordinating-only nodes is appropriate to prevent bottlenecks for search-heavy workloads. We recommend using CPUs with as many cores as you can. | . By default, each node is a master-eligible, data, ingest, and coordinating node. Deciding on the number of nodes, assigning node types, and choosing the hardware for each node type depends on your use case. You must take into account factors like the amount of time you want to hold on to your data, the average size of your documents, your typical workload (indexing, searches, aggregations), your expected price-performance ratio, your risk tolerance, and so on. After you assess all these requirements, we recommend you use a benchmark testing tool like Rally to provision a small sample cluster and run tests with varying workloads and configurations. Compare and analyze the system and query metrics for these tests to design an optimum architecture. To get started with Rally, see the Rally documentation. This page demonstrates how to work with the different node types. It assumes that you have a four-node cluster similar to the preceding illustration. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#cluster-formation",
    "relUrl": "/docs/elasticsearch/cluster/#cluster-formation"
  },"129": {
    "doc": "Cluster Formation",
    "title": "Prerequisites",
    "content": "Before you get started, you must install and configure Elasticsearch on all of your nodes. For information about the available options, see Install and Configure. After you are done, use SSH to connect to each node, and then open the config/elasticsearch.yml file. You can set all configurations for your cluster in this file. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#prerequisites",
    "relUrl": "/docs/elasticsearch/cluster/#prerequisites"
  },"130": {
    "doc": "Cluster Formation",
    "title": "Step 1: Name a cluster",
    "content": "Specify a unique name for the cluster. If you don’t specify a cluster name, it’s set to elasticsearch by default. Setting a descriptive cluster name is important, especially if you want to run multiple clusters inside a single network. To specify the cluster name, change the following line: . #cluster.name: my-application . to . cluster.name: odfe-cluster . Make the same change on all the nodes to make sure that they’ll join to form a cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#step-1-name-a-cluster",
    "relUrl": "/docs/elasticsearch/cluster/#step-1-name-a-cluster"
  },"131": {
    "doc": "Cluster Formation",
    "title": "Step 2: Set node attributes for each node in a cluster",
    "content": "After you name the cluster, set node attributes for each node in your cluster. Master node . Give your master node a name. If you don’t specify a name, Elasticsearch assigns a machine-generated name that makes the node difficult to monitor and troubleshoot. node.name: odfe-master . You can also explicitly specify that this node is a master node. This is already true by default, but adding it makes it easier to identify the master node: . node.master: true . Then make the node a dedicated master that won’t perform double-duty as a data node: . node.data: false . Specify that this node will not be used for ingesting data: . node.ingest: false . Data nodes . Change the name of two nodes to odfe-d1 and odfe-d2, respectively: . node.name: odfe-d1 . node.name: odfe-d2 . You can make them master-eligible data nodes that will also be used for ingesting data: . node.master: true node.data: true node.ingest: true . You can also specify any other attributes that you’d like to set for the data nodes. Coordinating node . Change the name of the coordinating node to odfe-c1: . node.name: odfe-c1 . Every node is a coordinating node by default, so to make this node a dedicated coordinating node, set node.master, node.data, and node.ingest to false: . node.master: false node.data: false node.ingest: false . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#step-2-set-node-attributes-for-each-node-in-a-cluster",
    "relUrl": "/docs/elasticsearch/cluster/#step-2-set-node-attributes-for-each-node-in-a-cluster"
  },"132": {
    "doc": "Cluster Formation",
    "title": "Step 3: Bind a cluster to specific IP addresses",
    "content": "network_host defines the IP address that’s used to bind the node. By default, Elasticsearch listens on a local host, which limits the cluster to a single node. You can also use _local_ and _site_ to bind to any loopback or site-local address, whether IPv4 or IPv6: . network.host: [_local_, _site_] . To form a multi-node cluster, specify the IP address of the node: . network.host: &lt;IP address of the node&gt; . Make sure to configure these settings on all of your nodes. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#step-3-bind-a-cluster-to-specific-ip-addresses",
    "relUrl": "/docs/elasticsearch/cluster/#step-3-bind-a-cluster-to-specific-ip-addresses"
  },"133": {
    "doc": "Cluster Formation",
    "title": "Step 4: Configure discovery hosts for a cluster",
    "content": "Now that you’ve configured the network hosts, you need to configure the discovery hosts. Zen Discovery is the built-in, default mechanism that uses unicast to find other nodes in the cluster. You can generally just add all of your master-eligible nodes to the discovery.seed_hosts array. When a node starts up, it finds the other master-eligible nodes, determines which one is the master, and asks to join the cluster. For example, for odfe-master the line looks something like this: . discovery.seed_hosts: [\"&lt;private IP of odfe-d1&gt;\", \"&lt;private IP of odfe-d2&gt;\", \"&lt;private IP of odfe-c1&gt;\"] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#step-4-configure-discovery-hosts-for-a-cluster",
    "relUrl": "/docs/elasticsearch/cluster/#step-4-configure-discovery-hosts-for-a-cluster"
  },"134": {
    "doc": "Cluster Formation",
    "title": "Step 5: Start the cluster",
    "content": "After you set the configurations, start Elasticsearch on all nodes. sudo systemctl start elasticsearch.service . Then go to the logs file to see the formation of the cluster: . less /var/log/elasticsearch/odfe-cluster.log . Perform the following _cat query on any node to see all the nodes formed as a cluster: . curl -XGET https://&lt;private-ip&gt;:9200/_cat/nodes?v -u admin:admin --insecure . ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name x.x.x.x 13 61 0 0.02 0.04 0.05 mi * odfe-master x.x.x.x 16 60 0 0.06 0.05 0.05 md - odfe-d1 x.x.x.x 34 38 0 0.12 0.07 0.06 md - odfe-d2 x.x.x.x 23 38 0 0.12 0.07 0.06 md - odfe-c1 . To better understand and monitor your cluster, use the cat API. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#step-5-start-the-cluster",
    "relUrl": "/docs/elasticsearch/cluster/#step-5-start-the-cluster"
  },"135": {
    "doc": "Cluster Formation",
    "title": "(Advanced) Step 6: Configure shard allocation awareness or forced awareness",
    "content": "If your nodes are spread across several geographical zones, you can configure shard allocation awareness to allocate all replica shards to a zone that’s different from their primary shard. With shard allocation awareness, if the nodes in one of your zones fail, you can be assured that your replica shards are spread across your other zones. It adds a layer of fault tolerance to ensure your data survives a zone failure beyond just individual node failures. To configure shard allocation awareness, add zone attributes to odfe-d1 and odfe-d2, respectively: . node.attr.zone: zoneA . node.attr.zone: zoneB . Update the cluster settings: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.awareness.attributes\": \"zone\" } } . You can either use persistent or transient settings. We recommend the persistent setting because it persists through a cluster reboot. Transient settings do not persist through a cluster reboot. Shard allocation awareness attempts to separate primary and replica shards across multiple zones. But, if only one zone is available (such as after a zone failure), Elasticsearch allocates replica shards to the only remaining zone. Another option is to require that primary and replica shards are never allocated to the same zone. This is called forced awareness. To configure forced awareness, specify all the possible values for your zone attributes: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.awareness.attributes\": \"zone\", \"cluster.routing.allocation.awareness.force.zone.values\":[\"zoneA\", \"zoneB\"] } } . Now, if a data node fails, forced awareness does not allocate the replicas to a node in the same zone. Instead, the cluster enters a yellow state and only allocates the replicas when nodes in another zone come online. In our two-zone architecture, we can use allocation awareness if odfe-d1 and odfe-d2 are less than 50% utilized, so that each of them have the storage capacity to allocate replicas in the same zone. If that is not the case, and odfe-d1 and odfe-d2 do not have the capacity to contain all primary and replica shards, we can use forced awareness. This approach helps to make sure that, in the event of a failure, Elasticsearch doesn’t overload your last remaining zone and lock up your cluster due to lack of storage. Choosing allocation awareness or forced awareness depends on how much space you might need in each zone to balance your primary and replica shards. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#advanced-step-6-configure-shard-allocation-awareness-or-forced-awareness",
    "relUrl": "/docs/elasticsearch/cluster/#advanced-step-6-configure-shard-allocation-awareness-or-forced-awareness"
  },"136": {
    "doc": "Cluster Formation",
    "title": "(Advanced) Step 7: Set up a hot-warm architecture",
    "content": "You can design a hot-warm architecture where you first index your data to hot nodes—fast and expensive—and after a certain period of time move them to warm nodes—slow and cheap. If you analyze time series data that you rarely update and want the older data to go onto cheaper storage, this architecture can be a good fit. This architecture helps save money on storage costs. Rather than increasing the number of hot nodes and using fast, expensive storage, you can add warm nodes for data that you don’t access as frequently. To configure a hot-warm storage architecture, add temp attributes to odfe-d1 and odfe-d2, respectively: . node.attr.temp: hot . node.attr.temp: warm . You can set the attribute name and value to whatever you want as long as it’s consistent for all your hot and warm nodes. To add an index newindex to the hot node: . PUT newindex { \"settings\": { \"index.routing.allocation.require.temp\": \"hot\" } } . Take a look at the following shard allocation for newindex: . GET _cat/shards/newindex?v index shard prirep state docs store ip node new_index 2 p STARTED 0 230b 10.0.0.225 odfe-d1 new_index 2 r UNASSIGNED new_index 3 p STARTED 0 230b 10.0.0.225 odfe-d1 new_index 3 r UNASSIGNED new_index 4 p STARTED 0 230b 10.0.0.225 odfe-d1 new_index 4 r UNASSIGNED new_index 1 p STARTED 0 230b 10.0.0.225 odfe-d1 new_index 1 r UNASSIGNED new_index 0 p STARTED 0 230b 10.0.0.225 odfe-d1 new_index 0 r UNASSIGNED . In this example, all primary shards are allocated to odfe-d1, which is our hot node. All replica shards are unassigned, because we’re forcing this index to allocate only to hot nodes. To add an index oldindex to the warm node: . PUT oldindex { \"settings\": { \"index.routing.allocation.require.temp\": \"warm\" } } . The shard allocation for oldindex: . GET _cat/shards/oldindex?v index shard prirep state docs store ip node old_index 2 p STARTED 0 230b 10.0.0.74 odfe-d2 old_index 2 r UNASSIGNED old_index 3 p STARTED 0 230b 10.0.0.74 odfe-d2 old_index 3 r UNASSIGNED old_index 4 p STARTED 0 230b 10.0.0.74 odfe-d2 old_index 4 r UNASSIGNED old_index 1 p STARTED 0 230b 10.0.0.74 odfe-d2 old_index 1 r UNASSIGNED old_index 0 p STARTED 0 230b 10.0.0.74 odfe-d2 old_index 0 r UNASSIGNED . In this case, all primary shards are allocated to odfe-d2. Again, all replica shards are unassigned because we only have one warm node. A popular approach is to configure your index templates to set the index.routing.allocation.require.temp value to hot. This way, Elasticsearch stores your most recent data on your hot nodes. You can then use the Index State Management (ISM) plugin to periodically check the age of an index and specify actions to take on it. For example, when the index reaches a specific age, change the index.routing.allocation.require.temp setting to warm to automatically move your data from hot nodes to warm nodes. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#advanced-step-7-set-up-a-hot-warm-architecture",
    "relUrl": "/docs/elasticsearch/cluster/#advanced-step-7-set-up-a-hot-warm-architecture"
  },"137": {
    "doc": "Cluster Formation",
    "title": "Next steps",
    "content": "If you are using the security plugin, the previous request to _cat/nodes?v might have failed with an initialization error. To initialize the plugin, run elasticsearch/plugins/opendistro_security/tools/securityadmin.sh. A sample command that uses the demo certificates might look like this: . sudo ./securityadmin.sh -cd ../securityconfig/ -icl -nhnv -cacert /etc/elasticsearch/root-ca.pem -cert /etc/elasticsearch/kirk.pem -key /etc/elasticsearch/kirk-key.pem -h &lt;private-ip&gt; . For full guidance around configuration options, see Security configuration. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/#next-steps",
    "relUrl": "/docs/elasticsearch/cluster/#next-steps"
  },"138": {
    "doc": "Cluster Formation",
    "title": "Cluster Formation",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/cluster/",
    "relUrl": "/docs/elasticsearch/cluster/"
  },"139": {
    "doc": "Commands",
    "title": "Commands",
    "content": "Start a PPL query with a search command to reference a table to search from. You can have the commands that follow in any order. In the following example, the search command refers to an accounts index as the source, then uses fields and where commands for the conditions: . search source=accounts | where age &gt; 18 | fields firstname, lastname . In the below examples, we represent required arguments in angle brackets &lt; &gt; and optional arguments in square brackets [ ]. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/",
    "relUrl": "/docs/ppl/commands/"
  },"140": {
    "doc": "Commands",
    "title": "search",
    "content": "Use the search command to retrieve a document from an index. You can only use the search command as the first command in the PPL query. Syntax . search source=&lt;index&gt; [boolean-expression] . | Field | Description | Required | . | search | Specify search keywords. | Yes | . | index | Specify which index to query from. | No | . | bool-expression | Specify an expression that evaluates to a boolean value. | No | . Example 1: Get all documents . To get all documents from the accounts index: . search source=accounts; . | account_number | firstname | address | balance | gender | city | employer | state | age | email | lastname | . | 1 | Amber | 880 Holmes Lane | 39225 | M | Brogan | Pyrami | IL | 32 | amberduke@pyrami.com | Duke | . | 6 | Hattie | 671 Bristol Street | 5686 | M | Dante | Netagy | TN | 36 | hattiebond@netagy.com | Bond | . | 13 | Nanette | 789 Madison Street | 32838 | F | Nogal | Quility | VA | 28 | null | Bates | . | 18 | Dale | 467 Hutchinson Court | 4180 | M | Orick | null | MD | 33 | daleadams@boink.com | Adams | . Example 2: Get documents that match a condition . To get all documents from the accounts index that have either account_number equal to 1 or have gender as F: . search source=accounts account_number=1 or gender=\"F\"; . | account_number | firstname | address | balance | gender | city | employer | state | age | email | lastname | . | 1 | Amber | 880 Holmes Lane | 39225 | M | Brogan | Pyrami | IL | 32 | amberduke@pyrami.com | Duke | . | 13 | Nanette | 789 Madison Street | 32838 | F | Nogal | Quility | VA | 28 | null | Bates | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#search",
    "relUrl": "/docs/ppl/commands/#search"
  },"141": {
    "doc": "Commands",
    "title": "dedup",
    "content": "The dedup (data deduplication) command removes duplicate documents defined by a field from the search result. Syntax . dedup [int] &lt;field-list&gt; [keepempty=&lt;bool&gt;] [consecutive=&lt;bool&gt;] . | Field | Description | Type | Required | Default | . | int | Retain the specified number of duplicate events for each combination. The number must be greater than 0. If you do not specify a number, only the first occurring event is kept and all other duplicates are removed from the results. | string | No | 1 | . | keepempty | If true, keep the document if any field in the field list has a null value or a field missing. | nested list of objects | No | False | . | consecutive | If true, remove only consecutive events with duplicate combinations of values. | No | False | - | . | field-list | Specify a comma-delimited field list. At least one field is required. | Yes | - | - | . Example 1: Dedup by one field . To remove duplicate documents with the same gender: . search source=accounts | dedup gender | fields account_number, gender; . | account_number | gender | . | 1 | M | . | 13 | F | . Example 2: Keep two duplicate documents . To keep two duplicate documents with the same gender: . search source=accounts | dedup 2 gender | fields account_number, gender; . | account_number | gender | . | 1 | M | . | 6 | M | . | 13 | F | . Example 3: Keep or ignore an empty field by default . To keep two duplicate documents with a null field value: . search source=accounts | dedup email keepempty=true | fields account_number, email; . | account_number | email | . | 1 | amberduke@pyrami.com | . | 6 | hattiebond@netagy.com | . | 13 | null | . | 18 | daleadams@boink.com | . To remove duplicate documents with the null field value: . search source=accounts | dedup email | fields account_number, email; . | account_number | email | . | 1 | amberduke@pyrami.com | . | 6 | hattiebond@netagy.com | . | 18 | daleadams@boink.com | . Example 4: Dedup of consecutive documents . To remove duplicates of consecutive documents: . search source=accounts | dedup gender consecutive=true | fields account_number, gender; . | account_number | gender | . | 1 | M | . | 13 | F | . | 18 | M | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#dedup",
    "relUrl": "/docs/ppl/commands/#dedup"
  },"142": {
    "doc": "Commands",
    "title": "eval",
    "content": "The eval command evaluates an expression and appends its result to the search result. Syntax . eval &lt;field&gt;=&lt;expression&gt; [\",\" &lt;field&gt;=&lt;expression&gt; ]... | Field | Description | Required | . | field | If a field name does not exist, a new field is added. If the field name already exists, it’s overwritten. | Yes | . | expression | Specify any supported expression. | Yes | . Example 1: Create a new field . To create a new doubleAge field for each document. doubleAge is the result of age multiplied by 2: . search source=accounts | eval doubleAge = age * 2 | fields age, doubleAge; . | age | doubleAge | . | 32 | 64 | . | 36 | 72 | . | 28 | 56 | . | 33 | 66 | . Example 2: Overwrite the existing field . To overwrite the age field with age plus 1: . search source=accounts | eval age = age + 1 | fields age; . | age | . | 33 | . | 37 | . | 29 | . | 34 | . Example 3: Create a new field with a field defined with the eval command . To create a new field ddAge. ddAge is the result of doubleAge multiplied by 2, where doubleAge is defined in the eval command: . search source=accounts | eval doubleAge = age * 2, ddAge = doubleAge * 2 | fields age, doubleAge, ddAge; . | age | doubleAge | ddAge | . | 32 | 64 | 128 | . | 36 | 72 | 144 | . | 28 | 56 | 112 | . | 33 | 66 | 132 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#eval",
    "relUrl": "/docs/ppl/commands/#eval"
  },"143": {
    "doc": "Commands",
    "title": "fields",
    "content": "Use the field command to keep or remove fields from a search result. Syntax . field [+|-] &lt;field-list&gt; . | Field | Description | Required | Default | . | index | Plus (+) keeps only fields specified in the field list. Minus (-) removes all fields specified in the field list. | No | + | . | field list | Specify a comma-delimited list of fields. | Yes | No default | . Example 1: Select specified fields from result . To get account_number, firstname, and lastname fields from a search result: . search source=accounts | fields account_number, firstname, lastname; . | account_number | firstname | lastname | . | 1 | Amber | Duke | . | 6 | Hattie | Bond | . | 13 | Nanette | Bates | . | 18 | Dale | Adams | . Example 2: Remove specified fields from a search result . To remove the account_number field from the search results: . search source=accounts | fields account_number, firstname, lastname | fields - account_number; . | firstname | lastname | . | Amber | Duke | . | Hattie | Bond | . | Nanette | Bates | . | Dale | Adams | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#fields",
    "relUrl": "/docs/ppl/commands/#fields"
  },"144": {
    "doc": "Commands",
    "title": "rename",
    "content": "Use the rename command to rename one or more fields in the search result. Syntax . rename &lt;source-field&gt; AS &lt;target-field&gt;[\",\" &lt;source-field&gt; AS &lt;target-field&gt;]... | Field | Description | Required | . | source-field | The name of the field that you want to rename. | Yes | . | target-field | The name you want to rename to. | Yes | . Example 1: Rename one field . Rename the account_number field as an: . search source=accounts | rename account_number as an | fields an; . | an | . | 1 | . | 6 | . | 13 | . | 18 | . Example 2: Rename multiple fields . Rename the account_number field as an and employer as emp: . search source=accounts | rename account_number as an, employer as emp | fields an, emp; . | an | emp | . | 1 | Pyrami | . | 6 | Netagy | . | 13 | Quility | . | 18 | null | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#rename",
    "relUrl": "/docs/ppl/commands/#rename"
  },"145": {
    "doc": "Commands",
    "title": "sort",
    "content": "Use the sort command to sort search results by a specified field. Syntax . sort [count] &lt;[+|-] sort-field&gt;... | Field | Description | Required | Default | . | count | The maximum number results to return from the sorted result. If count=0, all results are returned. | No | 1000 | . | [+|-] | Use plus [+] to sort by ascending order and minus [-] to sort by descending order. | No | Ascending order | . | sort-field | Specify the field that you want to sort by. | Yes | - | . Example 1: Sort by one field . To sort all documents by the age field in ascending order: . search source=accounts | sort age | fields account_number, age; . | account_number | age | . | 13 | 28 | . | 1 | 32 | . | 18 | 33 | . | 6 | 36 | . Example 2: Sort by one field and return all results . To sort all documents by the age field in ascending order and specify count as 0 to get back all results: . search source=accounts | sort 0 age | fields account_number, age; . | account_number | age | . | 13 | 28 | . | 1 | 32 | . | 18 | 33 | . | 6 | 36 | . Example 3: Sort by one field in descending order . To sort all documents by the age field in descending order: . search source=accounts | sort - age | fields account_number, age; . | account_number | age | . | 6 | 36 | . | 18 | 33 | . | 1 | 32 | . | 13 | 28 | . Example 4: Specify the number of sorted documents to return . To sort all documents by the age field in ascending order and specify count as 2 to get back two results: . search source=accounts | sort 2 age | fields account_number, age; . | account_number | age | . | 13 | 28 | . | 1 | 32 | . Example 5: Sort by multiple fields . To sort all documents by the gender field in ascending order and age field in descending order: . search source=accounts | sort + gender, - age | fields account_number, gender, age; . | account_number | gender | age | . | 13 | F | 28 | . | 6 | M | 36 | . | 18 | M | 33 | . | 1 | M | 32 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#sort",
    "relUrl": "/docs/ppl/commands/#sort"
  },"146": {
    "doc": "Commands",
    "title": "stats",
    "content": "Use the stats command to aggregate from search results. The following table lists the aggregation functions and also indicates how each one handles null or missing values: . | Function | NULL | MISSING | . | COUNT | Not counted | Not counted | . | SUM | Ignore | Ignore | . | AVG | Ignore | Ignore | . | MAX | Ignore | Ignore | . | MIN | Ignore | Ignore | . Syntax . stats &lt;aggregation&gt;... [by-clause]... | Field | Description | Required | Default | . | aggregation | Specify a statistical aggregation function. The argument of this function must be a field. | Yes | 1000 | . | by-clause | Specify one or more fields to group the results by. If not specified, the stats command returns only one row, which is the aggregation over the entire result set. | No | - | . Example 1: Calculate the average value of a field . To calculate the average age of all documents: . search source=accounts | stats avg(age); . | avg(age) | . | 32.25 | . Example 2: Calculate the average value of a field by group . To calculate the average age grouped by gender: . search source=accounts | stats avg(age) by gender; . | gender | avg(age) | . | F | 28.0 | . | M | 33.666666666666664 | . Example 3: Calculate the average and sum of a field by group . To calculate the average and sum of age grouped by gender: . search source=accounts | stats avg(age), sum(age) by gender; . | gender | avg(age) | sum(age) | . | F | 28 | 28 | . | M | 33.666666666666664 | 101 | . Example 4: Calculate the maximum value of a field . To calculate the maximum age: . search source=accounts | stats max(age); . | max(age) | . | 36 | . Example 5: Calculate the maximum and minimum value of a field by group . To calculate the maximum and minimum age values grouped by gender: . search source=accounts | stats max(age), min(age) by gender; . | gender | min(age) | max(age) | . | F | 28 | 28 | . | M | 32 | 36 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#stats",
    "relUrl": "/docs/ppl/commands/#stats"
  },"147": {
    "doc": "Commands",
    "title": "where",
    "content": "Use the where command with a bool expression to filter the search result. The where command only returns the result when the bool expression evaluates to true. Syntax . where &lt;boolean-expression&gt; . | Field | Description | Required | . | bool-expression | An expression that evaluates to a boolean value. | No | . Example 1: Filter result set with a condition . To get all documents from the accounts index where account_number is 1 or gender is F: . search source=accounts | where account_number=1 or gender=\"F\" | fields account_number, gender; . | account_number | gender | . | 1 | M | . | 13 | F | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#where",
    "relUrl": "/docs/ppl/commands/#where"
  },"148": {
    "doc": "Commands",
    "title": "head",
    "content": "Use the head command to return the first N number of results in a specified search order. Syntax . head [keeplast = (true | false)] [while \"(\"&lt;boolean-expression&gt;\")\"] [N] . | Field | Description | Required | Default | . | keeplast | Use along with the while argument to check if the last result in the result set is retained. The last result is what caused the while condition to evaluate to false or NULL. Set keeplast to true to retain the last result and false to discard it. | No | True | . | while | An expression that evaluates to either true or false. You cannot use statistical functions in this expression. | No | False | . | N | Specify the number of results to return. | No | 10 | . Example 1: Get the first 10 results . To get the first 10 results: . search source=accounts | fields firstname, age | head; . | firstname | age | . | Amber | 32 | . | Hattie | 36 | . | Nanette | 28 | . Example 2: Get the first N results . To get the first two results: . search source=accounts | fields firstname, age | head 2; . | firstname | age | . | Amber | 32 | . | Hattie | 36 | . Example 3: Get the first N results that match a while condition . To get the first 3 results from all accounts with age less than 30: . search source=accounts | fields firstname, age | sort age | head while(age &lt; 30) 3; . | firstname | age | . | Nanette | 28 | . | Amber | 32 | . Example 4: Get the first N results with a while condition with the last result that failed the condition . To get the first 3 results from all accounts with age less than 30 and include the last failed condition: . search source=accounts | fields firstname, age | sort age | head keeplast=false while(age &lt; 30) 3; . | firstname | age | . | Nanette | 28 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#head",
    "relUrl": "/docs/ppl/commands/#head"
  },"149": {
    "doc": "Commands",
    "title": "rare",
    "content": "Use the rare command to find the least common values of all fields in a field list. A maximum of 10 results are returned for each distinct set of values of the group-by fields. Syntax . rare &lt;field-list&gt; [by-clause] . | Field | Description | Required | . | field-list | Specify a comma-delimited list of field names. | No | . | by-clause | Specify one or more fields to group the results by. | No | . Example 1: Find the least common values in a field . To find the least common values of gender: . search source=accounts | rare gender; . | gender | . | F | . | M | . Example 2: Find the least common values grouped by gender . To find the least common age grouped by gender: . search source=accounts | rare age by gender; . | gender | age | . | F | 28 | . | M | 32 | . | M | 33 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#rare",
    "relUrl": "/docs/ppl/commands/#rare"
  },"150": {
    "doc": "Commands",
    "title": "top",
    "content": "Use the top command to find the most common values of all fields in the field list. Syntax . top [N] &lt;field-list&gt; [by-clause] . | Field | Description | Default | . | N | Specify the number of results to return. | 10 | . | field-list | Specify a comma-delimited list of field names. | - | . | by-clause | Specify one or more fields to group the results by. | - | . Example 1: Find the most common values in a field . To find the most common genders: . search source=accounts | top gender; . | gender | . | M | . | F | . Example 2: Find the most common value in a field . To find the most common gender: . search source=accounts | top 1 gender; . | gender | . | M | . Example 2: Find the most common values grouped by gender . To find the most common age grouped by gender: . search source=accounts | top 1 age by gender; . | gender | age | . | F | 28 | . | M | 32 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/commands/#top-command",
    "relUrl": "/docs/ppl/commands/#top-command"
  },"151": {
    "doc": "Common REST Parameters",
    "title": "Common REST parameters",
    "content": "Elasticsearch supports the following parameters for all REST operations: . | Option | Description | Example | . | Human-readable output | To convert output units to human-readable values (for example, 1h for 1 hour and 1kb for 1,024 bytes), add ?human=true to the request URL. | GET &lt;index_name&gt;/_search?human=true | . | Pretty result | To get back JSON responses in a readable format, add ?pretty=true to the request URL. | GET &lt;index_name&gt;/_search?pretty=true | . | Content type | To specify the type of content in the request body, use the Content-Type key name in the request header. Most operations support JSON, YAML, and CBOR formats. | POST _scripts/&lt;template_name&gt; -H 'Content-Type: application/json | . | Request body in query string | If the client library does not accept a request body for non-POST requests, use the source query string parameter to pass the request body. Also, specify the source_content_type parameter with a supported media type such as application/json. | GET _search?source_content_type=application/json&amp;source={\"query\":{\"match_all\":{}}} | . | Stack traces | To include the error stack trace in the response when an exception is raised, add error_trace=true to the request URL. | GET &lt;index_name&gt;/_search?error_trace=true | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/common-parameters/#common-rest-parameters",
    "relUrl": "/docs/elasticsearch/common-parameters/#common-rest-parameters"
  },"152": {
    "doc": "Common REST Parameters",
    "title": "Common REST Parameters",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/common-parameters/",
    "relUrl": "/docs/elasticsearch/common-parameters/"
  },"153": {
    "doc": "Complex Queries",
    "title": "Complex queries",
    "content": "Besides simple SFW (SELECT-FROM-WHERE) queries, the SQL plugin supports complex queries such as subquery, join, union, and minus. These queries operate on more than one Elasticsearch index. To examine how these queries execute behind the scenes, use the explain operation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/complex/#complex-queries",
    "relUrl": "/docs/sql/complex/#complex-queries"
  },"154": {
    "doc": "Complex Queries",
    "title": "Joins",
    "content": "Open Distro for Elasticsearch SQL supports inner joins, cross joins, and left outer joins. Constraints . Joins have a number of constraints: . | You can only join two indices. | You must use aliases for indices (e.g. people p). | Within an ON clause, you can only use AND conditions. | In a WHERE statement, don’t combine trees that contain multiple indices. For example, the following statement works: . WHERE (a.type1 &gt; 3 OR a.type1 &lt; 0) AND (b.type2 &gt; 4 OR b.type2 &lt; -1) . The following statement does not: . WHERE (a.type1 &gt; 3 OR b.type2 &lt; 0) AND (a.type1 &gt; 4 OR b.type2 &lt; -1) . | You can’t use GROUP BY or ORDER BY for results. | LIMIT with OFFSET (e.g. LIMIT 25 OFFSET 25) is not supported. | . Description . The JOIN clause combines columns from one or more indices using values common to each. Syntax . Rule tableSource: . Rule joinPart: . Example 1: Inner join . Inner join creates a new result set by combining columns of two indices based on your join predicates. It iterates the two indices and compares each document to find the ones that satisfy the join predicates. You can optionally precede the JOIN clause with an INNER keyword. The join predicate(s) is specified by the ON clause. SQL query: . SELECT a.account_number, a.firstname, a.lastname, e.id, e.name FROM accounts a JOIN employees_nested e ON a.account_number = e.id . Explain: . The explain output is complicated, because a JOIN clause is associated with two Elasticsearch DSL queries that execute in separate query planner frameworks. You can interpret it by examining the Physical Plan and Logical Plan objects. { \"Physical Plan\" : { \"Project [ columns=[a.account_number, a.firstname, a.lastname, e.name, e.id] ]\" : { \"Top [ count=200 ]\" : { \"BlockHashJoin[ conditions=( a.account_number = e.id ), type=JOIN, blockSize=[FixedBlockSize with size=10000] ]\" : { \"Scroll [ employees_nested as e, pageSize=10000 ]\" : { \"request\" : { \"size\" : 200, \"from\" : 0, \"_source\" : { \"excludes\" : [ ], \"includes\" : [ \"id\", \"name\" ] } } }, \"Scroll [ accounts as a, pageSize=10000 ]\" : { \"request\" : { \"size\" : 200, \"from\" : 0, \"_source\" : { \"excludes\" : [ ], \"includes\" : [ \"account_number\", \"firstname\", \"lastname\" ] } } }, \"useTermsFilterOptimization\" : false } } } }, \"description\" : \"Hash Join algorithm builds hash table based on result of first query, and then probes hash table to find matched rows for each row returned by second query\", \"Logical Plan\" : { \"Project [ columns=[a.account_number, a.firstname, a.lastname, e.name, e.id] ]\" : { \"Top [ count=200 ]\" : { \"Join [ conditions=( a.account_number = e.id ) type=JOIN ]\" : { \"Group\" : [ { \"Project [ columns=[a.account_number, a.firstname, a.lastname] ]\" : { \"TableScan\" : { \"tableAlias\" : \"a\", \"tableName\" : \"accounts\" } } }, { \"Project [ columns=[e.name, e.id] ]\" : { \"TableScan\" : { \"tableAlias\" : \"e\", \"tableName\" : \"employees_nested\" } } } ] } } } } } . Result set: . | a.account_number | a.firstname | a.lastname | e.id | e.name | . | 6 | Hattie | Bond | 6 | Jane Smith | . Example 2: Cross join . Cross join, also known as cartesian join, combines each document from the first index with each document from the second. The result set is the the cartesian product of documents of both indices. This operation is similar to the inner join without the ON clause that specifies the join condition. It’s risky to perform cross join on two indices of large or even medium size. It might trigger a circuit breaker that terminates the query to avoid running out of memory. SQL query: . SELECT a.account_number, a.firstname, a.lastname, e.id, e.name FROM accounts a JOIN employees_nested e . Result set: . | a.account_number | a.firstname | a.lastname | e.id | e.name | . | 1 | Amber | Duke | 3 | Bob Smith | . | 1 | Amber | Duke | 4 | Susan Smith | . | 1 | Amber | Duke | 6 | Jane Smith | . | 6 | Hattie | Bond | 3 | Bob Smith | . | 6 | Hattie | Bond | 4 | Susan Smith | . | 6 | Hattie | Bond | 6 | Jane Smith | . | 13 | Nanette | Bates | 3 | Bob Smith | . | 13 | Nanette | Bates | 4 | Susan Smith | . | 13 | Nanette | Bates | 6 | Jane Smith | . | 18 | Dale | Adams | 3 | Bob Smith | . | 18 | Dale | Adams | 4 | Susan Smith | . | 18 | Dale | Adams | 6 | Jane Smith | . Example 3: Left outer join . Use left outer join to retain rows from the first index if it does not satisfy the join predicate. The keyword OUTER is optional. SQL query: . SELECT a.account_number, a.firstname, a.lastname, e.id, e.name FROM accounts a LEFT JOIN employees_nested e ON a.account_number = e.id . Result set: . | a.account_number | a.firstname | a.lastname | e.id | e.name | . | 1 | Amber | Duke | null | null | . | 6 | Hattie | Bond | 6 | Jane Smith | . | 13 | Nanette | Bates | null | null | . | 18 | Dale | Adams | null | null | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/complex/#joins",
    "relUrl": "/docs/sql/complex/#joins"
  },"155": {
    "doc": "Complex Queries",
    "title": "Subquery",
    "content": "A subquery is a complete SELECT statement used within another statement and enclosed in parenthesis. From the explain output, you can see that some subqueries are actually transformed to an equivalent join query to execute. Example 1: Table subquery . SQL query: . SELECT a1.firstname, a1.lastname, a1.balance FROM accounts a1 WHERE a1.account_number IN ( SELECT a2.account_number FROM accounts a2 WHERE a2.balance &gt; 10000 ) . Explain: . { \"Physical Plan\" : { \"Project [ columns=[a1.balance, a1.firstname, a1.lastname] ]\" : { \"Top [ count=200 ]\" : { \"BlockHashJoin[ conditions=( a1.account_number = a2.account_number ), type=JOIN, blockSize=[FixedBlockSize with size=10000] ]\" : { \"Scroll [ accounts as a2, pageSize=10000 ]\" : { \"request\" : { \"size\" : 200, \"query\" : { \"bool\" : { \"filter\" : [ { \"bool\" : { \"adjust_pure_negative\" : true, \"must\" : [ { \"bool\" : { \"adjust_pure_negative\" : true, \"must\" : [ { \"bool\" : { \"adjust_pure_negative\" : true, \"must_not\" : [ { \"bool\" : { \"adjust_pure_negative\" : true, \"must_not\" : [ { \"exists\" : { \"field\" : \"account_number\", \"boost\" : 1 } } ], \"boost\" : 1 } } ], \"boost\" : 1 } }, { \"range\" : { \"balance\" : { \"include_lower\" : false, \"include_upper\" : true, \"from\" : 10000, \"boost\" : 1, \"to\" : null } } } ], \"boost\" : 1 } } ], \"boost\" : 1 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1 } }, \"from\" : 0 } }, \"Scroll [ accounts as a1, pageSize=10000 ]\" : { \"request\" : { \"size\" : 200, \"from\" : 0, \"_source\" : { \"excludes\" : [ ], \"includes\" : [ \"firstname\", \"lastname\", \"balance\", \"account_number\" ] } } }, \"useTermsFilterOptimization\" : false } } } }, \"description\" : \"Hash Join algorithm builds hash table based on result of first query, and then probes hash table to find matched rows for each row returned by second query\", \"Logical Plan\" : { \"Project [ columns=[a1.balance, a1.firstname, a1.lastname] ]\" : { \"Top [ count=200 ]\" : { \"Join [ conditions=( a1.account_number = a2.account_number ) type=JOIN ]\" : { \"Group\" : [ { \"Project [ columns=[a1.balance, a1.firstname, a1.lastname, a1.account_number] ]\" : { \"TableScan\" : { \"tableAlias\" : \"a1\", \"tableName\" : \"accounts\" } } }, { \"Project [ columns=[a2.account_number] ]\" : { \"Filter [ conditions=[AND ( AND account_number ISN null, AND balance GT 10000 ) ] ]\" : { \"TableScan\" : { \"tableAlias\" : \"a2\", \"tableName\" : \"accounts\" } } } } ] } } } } } . Result set: . | a1.firstname | a1.lastname | a1.balance | . | Amber | Duke | 39225 | . | Nanette | Bates | 32838 | . Example 2: From subquery . SQL query: . SELECT a.f, a.l, a.a FROM ( SELECT firstname AS f, lastname AS l, age AS a FROM accounts WHERE age &gt; 30 ) AS a . Explain: . { \"from\" : 0, \"size\" : 200, \"query\" : { \"bool\" : { \"filter\" : [ { \"bool\" : { \"must\" : [ { \"range\" : { \"age\" : { \"from\" : 30, \"to\" : null, \"include_lower\" : false, \"include_upper\" : true, \"boost\" : 1.0 } } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"_source\" : { \"includes\" : [ \"firstname\", \"lastname\", \"age\" ], \"excludes\" : [ ] } } . Result set: . | f | l | a | . | Amber | Duke | 32 | . | Dale | Adams | 33 | . | Hattie | Bond | 36 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/complex/#subquery",
    "relUrl": "/docs/sql/complex/#subquery"
  },"156": {
    "doc": "Complex Queries",
    "title": "Complex Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/complex/",
    "relUrl": "/docs/sql/complex/"
  },"157": {
    "doc": "Authentication flow",
    "title": "Authentication flow",
    "content": "Understanding the authentication flow is a great way to get started with configuring the security plugin. | To identify a user who wants to access the cluster, the security plugin needs the user’s credentials. These credentials differ depending on how you’ve configured the plugin. For example, if you use basic authentication, the credentials are a user name and password. If you use a JSON web token, the credentials are stored within the token itself. If you use TLS certificates, the credentials are the distinguished name (DN) of the certificate. | The security plugin authenticates the user’s credentials against a backend: the internal user database, Lightweight Directory Access Protocol (LDAP), Active Directory, Kerberos, or JSON web tokens. The plugin supports chaining backends in securityconfig/config.yml. If more than one backend is present, the plugin tries to authenticate the user sequentially against each until one succeeds. A common use case is to combine the internal user database of the security plugin with LDAP/Active Directory. | After a backend verifies the user’s credentials, the plugin collects any backend roles. These roles can be arbitrary strings in the internal user database, but in most cases, these backend roles come from LDAP/Active Directory. | After the user is authenticated and any backend roles are retrieved, the security plugin uses the role mapping to assign security roles to the user. If the role mapping doesn’t include the user (or the user’s backend roles), the user is successfully authenticated, but has no permissions. | The user can now perform actions as defined by the mapped security roles. For example, a user might map to the kibana_user role and thus have permissions to access Kibana. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/concepts/",
    "relUrl": "/docs/security/configuration/concepts/"
  },"158": {
    "doc": "Backend Configuration",
    "title": "Backend configuration",
    "content": "One of the first steps to using the security plugin is to decide on an authentication backend, which handles steps 2-3 of the authentication flow. The plugin has an internal user database, but many people prefer to use an existing authentication backend, such as an LDAP server, or some combination of the two. The main configuration file for authentication and authorization backends is plugins/opendistro_security/securityconfig/config.yml. It defines how the security plugin retrieves the user credentials, how it verifies these credentials, and how to fetch additional roles from backend systems (optional). config.yml has three main parts: . opendistro_security: dynamic: http: ... authc: ... authz: ... For a more complete example, see the sample file on GitHub. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#backend-configuration",
    "relUrl": "/docs/security/configuration/configuration/#backend-configuration"
  },"159": {
    "doc": "Backend Configuration",
    "title": "HTTP",
    "content": "The http section has the following format: . anonymous_auth_enabled: &lt;true|false&gt; xff: # optional section enabled: &lt;true|false&gt; internalProxies: &lt;string&gt; # Regex pattern remoteIpHeader: &lt;string&gt; # Name of the header in which to look. Typically: x-forwarded-for proxiesHeader: &lt;string&gt; trustedProxies: &lt;string&gt; # Regex pattern . If you disable anonymous authentication, the security plugin won’t initialize if you have not provided at least one authc. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#http",
    "relUrl": "/docs/security/configuration/configuration/#http"
  },"160": {
    "doc": "Backend Configuration",
    "title": "Authentication",
    "content": "The authc section has the following format: . &lt;name&gt;: http_enabled: &lt;true|false&gt; transport_enabled: &lt;true|false&gt; order: &lt;integer&gt; http_authenticator: ... authentication_backend: ... An entry in the authc section is called an authentication domain. It specifies where to get the user credentials and against which backend they should be authenticated. You can use more than one authentication domain. Each authentication domain has a name (for example, basic_auth_internal), enabled flags, and an order. The order makes it possible to chain authentication domains together. The security plugin uses them in the order that you provide. If the user successfully authenticates with one domain, the security plugin skips the remaining domains. http_authenticator specifies which authentication method that you want to use on the HTTP layer. This is the syntax for defining an authenticator on the HTTP layer: . http_authenticator: type: &lt;type&gt; challenge: &lt;true|false&gt; config: ... These are the allowed values for type: . | basic: HTTP basic authentication. No additional configuration is needed. | kerberos: Kerberos authentication. Additional, Kerberos-specific configuration is needed. | jwt: JSON web token authentication. Additional, JWT-specific configuration is needed. | clientcert: Authentication through a client TLS certificate. This certificate must be trusted by one of the root CAs in the truststore of your nodes. | . After setting an HTTP authenticator, you must specify against which backend system you want to authenticate the user: . authentication_backend: type: &lt;type&gt; config: ... These are the possible values for type: . | noop: No further authentication against any backend system is performed. Use noop if the HTTP authenticator has already authenticated the user completely, as in the case of JWT, Kerberos, or client certificate authentication. | internal: Use the users and roles defined in internal_users.yml for authentication. | ldap: Authenticate users against an LDAP server. This setting requires additional, LDAP-specific configuration settings. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#authentication",
    "relUrl": "/docs/security/configuration/configuration/#authentication"
  },"161": {
    "doc": "Backend Configuration",
    "title": "Authorization",
    "content": "After the user has been authenticated, the security plugin can optionally collect additional roles from backend systems. The authorization configuration has the following format: . authz: &lt;name&gt;: http_enabled: &lt;true|false&gt; transport_enabled: &lt;true|false&gt; authorization_backend: type: &lt;type&gt; config: ... You can define multiple entries in this section the same way as you can for authentication entries. In this case, execution order is not relevant, so there is no order field. These are the possible values for type: . | noop: Skip this step altogether. | ldap: Fetch additional roles from an LDAP server. This setting requires additional, LDAP-specific configuration settings. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#authorization",
    "relUrl": "/docs/security/configuration/configuration/#authorization"
  },"162": {
    "doc": "Backend Configuration",
    "title": "Examples",
    "content": "The default plugins/opendistro_security/securityconfig/config.yml that ships with Open Distro for Elasticsearch contains many configuration examples. Use these examples as a starting point, and customize them to your needs. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#examples",
    "relUrl": "/docs/security/configuration/configuration/#examples"
  },"163": {
    "doc": "Backend Configuration",
    "title": "HTTP basic",
    "content": "To set up HTTP basic authentication, you must enable it in the http_authenticator section of the configuration: . http_authenticator: type: basic challenge: true . In most cases, you set the challenge flag to true. The flag defines the behavior of the security plugin if the Authorization field in the HTTP header is not set. If challenge is set to true, the security plugin sends a response with status UNAUTHORIZED (401) back to the client. If the client is accessing the cluster with a browser, this triggers the authentication dialog box, and the user is prompted to enter a user name and password. If challenge is set to false and no Authorization header field is set, the security plugin does not send a WWW-Authenticate response back to the client, and authentication fails. You might want to use this setting if you have another challenge http_authenticator in your configured authentication domains. One such scenario is when you plan to use basic authentication and Kerberos together. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#http-basic",
    "relUrl": "/docs/security/configuration/configuration/#http-basic"
  },"164": {
    "doc": "Backend Configuration",
    "title": "Kerberos",
    "content": "Due to the nature of Kerberos, you must define some settings in elasticsearch.yml and some in config.yml. In elasticsearch.yml, define the following: . opendistro_security.kerberos.krb5_filepath: '/etc/krb5.conf' opendistro_security.kerberos.acceptor_keytab_filepath: 'eskeytab.tab' . opendistro_security.kerberos.krb5_filepath defines the path to your Kerberos configuration file. This file contains various settings regarding your Kerberos installation, for example, the realm names, hostnames, and ports of the Kerberos key distribution center (KDC). opendistro_security.kerberos.acceptor_keytab_filepath defines the path to the keytab file, which contains the principal that the security plugin uses to issue requests against Kerberos. opendistro_security.kerberos.acceptor_principal: 'HTTP/localhost' defines the principal that the security plugin uses to issue requests against Kerberos. This value must be present in the keytab file. Due to security restrictions, the keytab file must be placed in config or a subdirectory, and the path in elasticsearch.yml must be relative, not absolute. Dynamic configuration . A typical Kerberos authentication domain in config.yml looks like this: . authc: kerberos_auth_domain: enabled: true order: 1 http_authenticator: type: kerberos challenge: true config: krb_debug: false strip_realm_from_principal: true authentication_backend: type: noop . Authentication against Kerberos through a browser on an HTTP level is achieved using SPNEGO. Kerberos/SPNEGO implementations vary, depending on your browser and operating system. This is important when deciding if you need to set the challenge flag to true or false. As with HTTP Basic Authentication, this flag determines how the security plugin should react when no Authorization header is found in the HTTP request or if this header does not equal negotiate. If set to true, the security plugin sends a response with status code 401 and a WWW-Authenticate header set to negotiate. This tells the client (browser) to resend the request with the Authorization header set. If set to false, the security plugin cannot extract the credentials from the request, and authentication fails. Setting challenge to false thus makes sense only if the Kerberos credentials are sent in the initial request. As the name implies, setting krb_debug to true will output Kerberos-specific debugging messages to stdout. Use this setting if you encounter problems with your Kerberos integration. If you set strip_realm_from_principal to true, the security plugin strips the realm from the user name. Authentication backend . Because Kerberos/SPNEGO authenticates users on an HTTP level, no additional authentication_backend is needed. Set this value to noop. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#kerberos",
    "relUrl": "/docs/security/configuration/configuration/#kerberos"
  },"165": {
    "doc": "Backend Configuration",
    "title": "JSON web token",
    "content": "JSON web tokens (JWTs) are JSON-based access tokens that assert one or more claims. They are commonly used to implement single sign-on (SSO) solutions and fall in the category of token-based authentication systems: . | A user logs in to an authentication server by providing credentials (for example, a user name and password). | The authentication server validates the credentials. | The authentication server creates an access token and signs it. | The authentication server returns the token to the user. | The user stores the access token. | The user sends the access token alongside every request to the service that it wants to use. | The service verifies the token and grants or denies access. | . A JSON web token is self-contained in the sense that it carries all necessary information to verify a user within itself. The tokens are base64-encoded, signed JSON objects. JSON web tokens consist of three parts: . | Header | Payload | Signature | . Header . The header contains information about the used signing mechanism, as shown in the following example: . { \"alg\": \"HS256\", \"typ\": \"JWT\" } . In this case, the header states that the message was signed using HMAC-SHA256. Payload . The payload of a JSON web token contains the so-called JWT Claims. A claim can be any piece of information about the user that the application that created the token has verified. The specification defines a set of standard claims with reserved names (“registered claims”). These include, for example, the token issuer, the expiration date, or the creation date. Public claims, on the other hand, can be created freely by the token issuer. They can contain arbitrary information, such as the user name and the roles of the user. Example: . { \"iss\": \"example.com\", \"exp\": 1300819380, \"name\": \"John Doe\", \"roles\": \"admin, devops\" } . Signature . The issuer of the token calculates the signature of the token by applying a cryptographic hash function on the base64-encoded header and payload. These three parts are then concatenated using periods to form a complete JSON web token: . encoded = base64UrlEncode(header) + \".\" + base64UrlEncode(payload) signature = HMACSHA256(encoded, 'secretkey'); jwt = encoded + \".\" + base64UrlEncode(signature) . Example: . eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dnZWRJbkFzIjoiYWRtaW4iLCJpYXQiOjE0MjI3Nzk2Mzh9.gzSraSYS8EXBxLN_oWnFSRgCzcmJmMjLiuyu5CSpyHI . Configure JSON web tokens . If JSON web tokens are the only authentication method that you use, disable the user cache by setting opendistro_security.cache.ttl_minutes: 0. Set up an authentication domain and choose jwt as the HTTP authentication type. Because the tokens already contain all required information to verify the request, challenge must be set to false and authentication_backend to noop. Example: . jwt_auth_domain: enabled: true order: 0 http_authenticator: type: jwt challenge: false config: signing_key: \"base64 encoded key\" jwt_header: \"Authorization\" jwt_url_parameter: null subject_key: null roles_key: null authentication_backend: I type: noop . The following table shows the configuration parameters. | Name | Description | . | signing_key | The signing key to use when verifying the token. If you use a symmetric key algorithm, it is the base64-encoded shared secret. If you use an asymmetric algorithm, it contains the public key. | . | jwt_header | The HTTP header in which the token is transmitted. This typically is the Authorization header with the Bearer schema: Authorization: Bearer &lt;token&gt;. Default is Authorization. | . | jwt_url_parameter | If the token is not transmitted in the HTTP header, but as an URL parameter, define the name of this parameter here. | . | subject_key | The key in the JSON payload that stores the user name. If not set, the subject registered claim is used. | . | roles_key | The key in the JSON payload that stores the user’s roles. The value of this key must be a comma-separated list of roles. | . Because JSON web tokens are self-contained and the user is authenticated on the HTTP level, no additional authentication_backend is needed. Set this value to noop. Symmetric key algorithms: HMAC . Hash-based message authentication codes (HMACs) are a group of algorithms that provide a way of signing messages by means of a shared key. The key is shared between the authentication server and the security plugin. It must be configured as a base64-encoded value in the signing_key setting: . jwt_auth_domain: ... config: signing_key: \"a3M5MjEwamRqOTAxOTJqZDE=\" ... Asymmetric key algorithms: RSA and ECDSA . RSA and ECDSA are asymmetric encryption and digital signature algorithms and use a public/private key pair to sign and verify tokens. This means that they use a private key for signing the token, while the security plugin needs to know only the public key to verify it. Because you cannot issue new tokens with the public key—and because you can make valid assumptions about the creator of the token—RSA and ECDSA are considered more secure than using HMAC. To use RS256, you need to configure only the (non-base64-encoded) public RSA key as signing_key in the JWT configuration: . jwt_auth_domain: ... config: signing_key: |- -----BEGIN PUBLIC KEY----- MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQK... -----END PUBLIC KEY----- ... The security plugin automatically detects the algorithm (RSA/ECDSA), and if necessary you can break the key into multiple lines. Bearer authentication for HTTP requests . The most common way of transmitting a JSON web token in an HTTP request is to add it as an HTTP header with the bearer authentication schema: . Authorization: Bearer &lt;JWT&gt; . The default name of the header is Authorization. If required by your authentication server or proxy, you can also use a different HTTP header name using the jwt_header configuration key. As with HTTP basic authentication, you should use HTTPS instead of HTTP when transmitting JSON web tokens in HTTP requests. URL parameters for HTTP requests . Although the most common way to transmit JWTs in HTTP requests is to use a header field, the security plugin also supports parameters. Configure the name of the GET parameter using the following key: . config: signing_key: ... jwt_url_parameter: \"parameter_name\" subject_key: ... roles_key: ... As with HTTP basic authentication, you should use HTTPS instead of HTTP. Validated registered claims . The following registered claims are validated automatically: . | “iat” (Issued At) Claim | “nbf” (Not Before) Claim | “exp” (Expiration Time) Claim | . Supported formats and algorithms . The security plugin supports digitally signed, compact JSON web tokens with all standard algorithms: . HS256: HMAC using SHA-256 HS384: HMAC using SHA-384 HS512: HMAC using SHA-512 RS256: RSASSA-PKCS-v1_5 using SHA-256 RS384: RSASSA-PKCS-v1_5 using SHA-384 RS512: RSASSA-PKCS-v1_5 using SHA-512 PS256: RSASSA-PSS using SHA-256 and MGF1 with SHA-256 PS384: RSASSA-PSS using SHA-384 and MGF1 with SHA-384 PS512: RSASSA-PSS using SHA-512 and MGF1 with SHA-512 ES256: ECDSA using P-256 and SHA-256 ES384: ECDSA using P-384 and SHA-384 ES512: ECDSA using P-521 and SHA-512 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/#json-web-token",
    "relUrl": "/docs/security/configuration/configuration/#json-web-token"
  },"166": {
    "doc": "Backend Configuration",
    "title": "Backend Configuration",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/configuration/",
    "relUrl": "/docs/security/configuration/configuration/"
  },"167": {
    "doc": "Configuration",
    "title": "Elasticsearch configuration",
    "content": "Most Elasticsearch configuration can take place in the cluster settings API. Certain operations require you to modify elasticsearch.yml and restart the cluster. Whenever possible, use the cluster settings API instead; elasticsearch.yml is local to each node, whereas the API applies the setting to all nodes in the cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/configuration/#elasticsearch-configuration",
    "relUrl": "/docs/elasticsearch/configuration/#elasticsearch-configuration"
  },"168": {
    "doc": "Configuration",
    "title": "Cluster settings API",
    "content": "The first step in changing a setting is to view the current settings: . GET _cluster/settings?include_defaults=true . For a more concise summary of non-default settings: . GET _cluster/settings . Three categories of setting exist in the cluster settings API: persistent, transient, and default. Persistent settings, well, persist after a cluster restart. After a restart, Elasticsearch clears transient settings. If you specify the same setting in multiple places, Elasticsearch uses the following precedence: . | Transient settings | Persistent settings | Settings from elasticsearch.yml | Default settings | . To change a setting, just specify the new one as either persistent or transient. This example shows the flat settings form: . PUT /_cluster/settings { \"persistent\" : { \"action.auto_create_index\" : false } } . You can also use the expanded form, which lets you copy and paste from the GET response and change existing values: . PUT /_cluster/settings { \"persistent\": { \"action\": { \"auto_create_index\": false } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/configuration/#cluster-settings-api",
    "relUrl": "/docs/elasticsearch/configuration/#cluster-settings-api"
  },"169": {
    "doc": "Configuration",
    "title": "Configuration file",
    "content": "You can find elasticsearch.yml in /usr/share/elasticsearch/config/elasticsearch.yml (Docker) or /etc/elasticsearch/elasticsearch.yml (RPM) on each node. Out of the box, it contains a number of demo settings for the security plugin that you should modify before using Open Distro for Elasticsearch for a production workload. To learn more, see Security. Sample configuration file . cluster.name: \"docker-cluster\" network.host: 0.0.0.0 # minimum_master_nodes need to be explicitly set when bound on a public IP # set to 1 to allow single node clusters discovery.zen.minimum_master_nodes: 1 ######## Start OpenDistro for Elasticsearch Security Demo Configuration ######## # WARNING: revise all the lines below before you go into production opendistro_security.ssl.transport.pemcert_filepath: esnode.pem opendistro_security.ssl.transport.pemkey_filepath: esnode-key.pem opendistro_security.ssl.transport.pemtrustedcas_filepath: root-ca.pem opendistro_security.ssl.transport.enforce_hostname_verification: false opendistro_security.ssl.http.enabled: true opendistro_security.ssl.http.pemcert_filepath: esnode.pem opendistro_security.ssl.http.pemkey_filepath: esnode-key.pem opendistro_security.ssl.http.pemtrustedcas_filepath: root-ca.pem opendistro_security.allow_unsafe_democertificates: true opendistro_security.allow_default_init_securityindex: true opendistro_security.authcz.admin_dn: - CN=kirk,OU=client,O=client,L=test, C=de opendistro_security.audit.type: internal_elasticsearch opendistro_security.enable_snapshot_restore_privilege: true opendistro_security.check_snapshot_restore_write_privileges: true opendistro_security.restapi.roles_enabled: [\"all_access\", \"security_rest_api_access\"] cluster.routing.allocation.disk.threshold_enabled: false ######## End OpenDistro for Elasticsearch Security Demo Configuration ######## . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/configuration/#configuration-file",
    "relUrl": "/docs/elasticsearch/configuration/#configuration-file"
  },"170": {
    "doc": "Configuration",
    "title": "Configuration",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/configuration/",
    "relUrl": "/docs/elasticsearch/configuration/"
  },"171": {
    "doc": "Cron",
    "title": "Cron expression reference",
    "content": "Monitors can run at a variety of fixed intervals (e.g. hourly, daily, etc.), but you can also define custom cron expressions for when they should run. Monitors use the Unix cron syntax and support five fields: . | Field | Valid values | . | Minute | 0-59 | . | Hour | 0-23 | . | Day of month | 1-31 | . | Month | 1-12 | . | Day of week | 0-7 (0 and 7 are both Sunday) or SUN, MON, TUE, WED, THU, FRI, SAT | . For example, the following expression translates to “every Monday through Friday at 11:30 AM”: . 30 11 * * 1-5 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/cron/#cron-expression-reference",
    "relUrl": "/docs/alerting/cron/#cron-expression-reference"
  },"172": {
    "doc": "Cron",
    "title": "Features",
    "content": "| Feature | Description | . | * | Wildcard. Specifies all valid values. | . | , | List. Use to specify several values (e.g. 1,15,30). | . | - | Range. Use to specify a range of values (e.g. 1-15). | . | / | Step. Use after a wildcard or range to specify the “step” between values. For example, 0-11/2 is equivalent to 0,2,4,6,8,10. | . Note that you can specify the day using two fields: day of month and day of week. For most situations, we recommend that you use just one of these fields and leave the other as *. If you use a non-wildcard value in both fields, the monitor runs when either field matches the time. For example, 15 2 1,15 * 1 causes the monitor to run at 2:15 AM on the 1st of the month, the 15th of the month, and every Monday. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/cron/#features",
    "relUrl": "/docs/alerting/cron/#features"
  },"173": {
    "doc": "Cron",
    "title": "Sample expressions",
    "content": "Every other day at 1:45 PM: . 45 13 1-31/2 * * . Every 10 minutes on Saturday and Sunday: . 0/10 * * * 6-7 . Every three hours on the first day of every other month: . 0 0-23/3 1 1-12/2 * . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/cron/#sample-expressions",
    "relUrl": "/docs/alerting/cron/#sample-expressions"
  },"174": {
    "doc": "Cron",
    "title": "Cron",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/cron/",
    "relUrl": "/docs/alerting/cron/"
  },"175": {
    "doc": "Cross-Cluster Search",
    "title": "Cross-cluster search",
    "content": "Cross-cluster search is exactly what it sounds like: it lets any node in a cluster execute search requests against other clusters. The security plugin supports cross-cluster search out of the box. . | Authentication flow | Permissions | Walkthrough | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/cross-cluster-search/#cross-cluster-search",
    "relUrl": "/docs/security/access-control/cross-cluster-search/#cross-cluster-search"
  },"176": {
    "doc": "Cross-Cluster Search",
    "title": "Authentication flow",
    "content": "When accessing a remote cluster from a coordinating cluster using cross-cluster search: . | The security plugin authenticates the user on the coordinating cluster. | The security plugin fetches the user’s backend roles on the coordinating cluster. | The call, including the authenticated user, is forwarded to the remote cluster. | The user’s permissions are evaluated on the remote cluster. | . You can have different authentication and authorization configurations on the remote and coordinating cluster, but we recommend using the same settings on both. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/cross-cluster-search/#authentication-flow",
    "relUrl": "/docs/security/access-control/cross-cluster-search/#authentication-flow"
  },"177": {
    "doc": "Cross-Cluster Search",
    "title": "Permissions",
    "content": "To query indices on remote clusters, users need to have the following permissions for the index, in addition to READ or SEARCH permissions: . indices:admin/shards/search_shards . Sample roles.yml configuration . humanresources: cluster: - CLUSTER_COMPOSITE_OPS_RO indices: 'humanresources': '*': - READ - indices:admin/shards/search_shards # needed for CCS . Sample role in Kibana . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/cross-cluster-search/#permissions",
    "relUrl": "/docs/security/access-control/cross-cluster-search/#permissions"
  },"178": {
    "doc": "Cross-Cluster Search",
    "title": "Walkthrough",
    "content": "Save this file as docker-compose.yml and run docker-compose up to start two single-node clusters on the same network: . version: '3' services: odfe-node1: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node1 environment: - cluster.name=odfe-cluster1 - discovery.type=single-node - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM ulimits: memlock: soft: -1 hard: -1 volumes: - odfe-data1:/usr/share/elasticsearch/data ports: - 9200:9200 - 9600:9600 # required for Performance Analyzer networks: - odfe-net odfe-node2: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node2 environment: - cluster.name=odfe-cluster2 - discovery.type=single-node - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM ulimits: memlock: soft: -1 hard: -1 volumes: - odfe-data2:/usr/share/elasticsearch/data ports: - 9250:9200 - 9700:9600 # required for Performance Analyzer networks: - odfe-net volumes: odfe-data1: odfe-data2: networks: odfe-net: . After the clusters start, verify the names of each: . curl -XGET -u admin:admin -k https://localhost:9200 { \"cluster_name\" : \"odfe-cluster1\", ... } curl -XGET -u admin:admin -k https://localhost:9250 { \"cluster_name\" : \"odfe-cluster2\", ... } . Both clusters run on localhost, so the important identifier is the port number. In this case, use port 9200 (odfe-node1) as the remote cluster, and port 9250 (odfe-node2) as the coordinating cluster. To get the IP address for the remote cluster, first identify its container ID: . docker ps CONTAINER ID IMAGE PORTS NAMES 6fe89ebc5a8e amazon/opendistro-for-elasticsearch:1.11.0 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9600-&gt;9600/tcp, 9300/tcp odfe-node1 2da08b6c54d8 amazon/opendistro-for-elasticsearch:1.11.0 9300/tcp, 0.0.0.0:9250-&gt;9200/tcp, 0.0.0.0:9700-&gt;9600/tcp odfe-node2 . Then get that container’s IP address: . docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' 6fe89ebc5a8e 172.31.0.3 . On the coordinating cluster, add the remote cluster name and the IP address (with port 9300) for each “seed node.” In this case, you only have one seed node: . curl -k -XPUT -H 'Content-Type: application/json' -u admin:admin https://localhost:9250/_cluster/settings -d ' { \"persistent\": { \"search.remote\": { \"odfe-cluster1\": { \"seeds\": [\"172.31.0.3:9300\"] } } } }' . On the remote cluster, index a document: . curl -XPUT -k -H 'Content-Type: application/json' -u admin:admin https://localhost:9200/books/_doc/1 -d '{\"Dracula\": \"Bram Stoker\"}' . At this point, cross-cluster search works. You can test it using the admin user: . curl -XGET -k -u admin:admin https://localhost:9250/odfe-cluster1:books/_search?pretty { ... \"hits\": [{ \"_index\": \"odfe-cluster1:books\", \"_type\": \"_doc\", \"_id\": \"1\", \"_score\": 1.0, \"_source\": { \"Dracula\": \"Bram Stoker\" } }] } . To continue testing, create a new user on both clusters: . curl -XPUT -k https://admin:admin@localhost:9200/_opendistro/_security/api/internalusers/booksuser -H 'Content-Type: application/json' -d '{\"password\":\"password\"}' curl -XPUT -k https://admin:admin@localhost:9250/_opendistro/_security/api/internalusers/booksuser -H 'Content-Type: application/json' -d '{\"password\":\"password\"}' . Then run the same search as before with booksuser: . curl -XGET -k -u booksuser:password https://localhost:9250/odfe-cluster1:books/_search?pretty { \"error\" : { \"root_cause\" : [ { \"type\" : \"security_exception\", \"reason\" : \"no permissions for [indices:admin/shards/search_shards, indices:data/read/search] and User [name=booksuser, roles=[], requestedTenant=null]\" } ], \"type\" : \"security_exception\", \"reason\" : \"no permissions for [indices:admin/shards/search_shards, indices:data/read/search] and User [name=booksuser, roles=[], requestedTenant=null]\" }, \"status\" : 403 } . Note the permissions error. On the remote cluster, create a role with the appropriate permissions, and map booksuser to that role: . curl -XPUT -k -u admin:admin -H 'Content-Type: application/json' https://localhost:9200/_opendistro/_security/api/roles/booksrole -d '{\"index_permissions\":[{\"index_patterns\":[\"books\"],\"allowed_actions\":[\"indices:admin/shards/search_shards\",\"indices:data/read/search\"]}]}' curl -XPUT -k -u admin:admin -H 'Content-Type: application/json' https://localhost:9200/_opendistro/_security/api/rolesmapping/booksrole -d '{\"users\" : [\"booksuser\"]}' . Both clusters must have the user, but only the remote cluster needs the role and mapping; in this case, the coordinating cluster handles authentication (i.e. “Does this request include valid user credentials?”), and the remote cluster handles authorization (i.e. “Can this user access this data?”). Finally, repeat the search: . curl -XGET -k -u booksuser:password https://localhost:9250/odfe-cluster1:books/_search?pretty { ... \"hits\": [{ \"_index\": \"odfe-cluster1:books\", \"_type\": \"_doc\", \"_id\": \"1\", \"_score\": 1.0, \"_source\": { \"Dracula\": \"Bram Stoker\" } }] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/cross-cluster-search/#walkthrough",
    "relUrl": "/docs/security/access-control/cross-cluster-search/#walkthrough"
  },"179": {
    "doc": "Cross-Cluster Search",
    "title": "Cross-Cluster Search",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/cross-cluster-search/",
    "relUrl": "/docs/security/access-control/cross-cluster-search/"
  },"180": {
    "doc": "Create Dashboards",
    "title": "PerfTop dashboards",
    "content": "Dashboards are defined in JSON and composed of three main elements: tables, line graphs, and bar graphs. You define a grid of rows and columns and then place elements within that grid, with each element spanning as many rows and columns as you specify. The best way to get started with building custom dashboards is to duplicate and modify one of the existing JSON files in the dashboards directory. . | Summary of elements | Position elements | Add queries | Add options . | All elements | Tables | Bars | Lines | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/#perftop-dashboards",
    "relUrl": "/docs/pa/dashboards/#perftop-dashboards"
  },"181": {
    "doc": "Create Dashboards",
    "title": "Summary of elements",
    "content": ". | Tables show metrics per dimension. For example, if your metric is CPU_Utilization and your dimension ShardID, a PerfTop table shows a row for each shard on each node. | Bar graphs are aggregated for the cluster, unless you add nodeName to the dashboard. See the options for all elements. | Line graphs are aggregated for each node. Each line represents a node. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/#summary-of-elements",
    "relUrl": "/docs/pa/dashboards/#summary-of-elements"
  },"182": {
    "doc": "Create Dashboards",
    "title": "Position elements",
    "content": "PerfTop positions elements within a grid. For example, consider this 12 * 12 grid. The upper-left of the grid represents row 0, column 0, so the starting positions for the three boxes are: . | Orange: row 0, column 0 | Purple: row 2, column 2 | Green: row 1, column 6 | . These boxes span a number of rows and columns. In this case: . | Orange: 2 rows, 4 columns | Purple: 1 row, 4 columns | Green: 3 rows, 2 columns | . In JSON form, we have the following: . { \"gridOptions\": { \"rows\": 12, \"cols\": 12 }, \"graphs\": { \"tables\": [{ \"options\": { \"gridPosition\": { \"row\": 0, \"col\": 0, \"rowSpan\": 2, \"colSpan\": 4 } } }, { \"options\": { \"gridPosition\": { \"row\": 2, \"col\": 2, \"rowSpan\": 1, \"colSpan\": 4 } } }, { \"options\": { \"gridPosition\": { \"row\": 1, \"col\": 6, \"rowSpan\": 3, \"colSpan\": 2 } } } ] } } . At this point, however, all the JSON does is define the size and position of three tables. To fill elements with data, you specify a query. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/#position-elements",
    "relUrl": "/docs/pa/dashboards/#position-elements"
  },"183": {
    "doc": "Create Dashboards",
    "title": "Add queries",
    "content": "Queries use the same elements as the REST API, just in JSON form: . { \"queryParams\": { \"metrics\": \"estimated,limitConfigured\", \"aggregates\": \"avg,avg\", \"dimensions\": \"type\", \"sortBy\": \"estimated\" } } . For details on available metrics, see Metrics reference. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/#add-queries",
    "relUrl": "/docs/pa/dashboards/#add-queries"
  },"184": {
    "doc": "Create Dashboards",
    "title": "Add options",
    "content": "Options include labels, colors, and a refresh interval. Different elements types have different options. Dashboards support the 16 ANSI colors: black, red, green, yellow, blue, magenta, cyan, and white. For the “bright” variants of these colors, use the numbers 8–15. If your terminal supports 256 colors, you can also use hex codes (e.g. #6D40ED). All elements . | Option | Type | Description | . | label | String or integer | The text in the upper-left corner of the box. | . | labelColor | String or integer | The color of the label. | . | refreshInterval | Integer | The number of milliseconds between calls to the Performance Analyzer API for new data. Minimum value is 5000. | . | dimensionFilters | String array | The dimension value to diplay for the graph. For example, if you query for metric=Net_Throughput&amp;agg=sum&amp;dim=Direction and the possible dimension values are in and out, you can define dimensionFilters: [\"in\"] to only display the metric data for in dimension | . | nodeName | String | If non-null, lets you restrict elements to individual nodes. You can specify the node name directly in the dashboard file, but the better approach is to use \"nodeName\": \"#nodeName\" in the dashboard and include the --nodename &lt;node_name&gt; argument when starting PerfTop. | . Tables . | Option | Type | Description | . | bg | String or integer | The background color. | . | fg | String or integer | The text color. | . | selectedFg | String or integer | The text color for focused text. | . | selectedBg | String or integer | The background color for focused text. | . | columnSpacing | Integer | The amount of space (measured in characters) between columns. | . | keys | Boolean | Has no impact at this time. | . Bars . | Option | Type | Description | . | barWidth | Integer | The width of each bar (measured in characters) in the graph. | . | xOffset | Integer | The amount of space (measured in characters) between the y-axis and the first bar in the graph. | . | maxHeight | Integer | The maximum height of each bar (measured in characters) in the graph. | . Lines . | Option | Type | Description | . | showNthLabel | Integer | Which of the xAxis labels to show. For example, \"showNthLabel\": 2 shows every other label. | . | showLegend | Boolean | Whether or not to display a legend for the line graph. | . | legend.width | Integer | The width of the legend (measured in characters) in the graph. | . | xAxis | String array | Array of labels for the x-axis. For example, [\"0:00\", \"0:10\", \"0:20\", \"0:30\", \"0:40\", \"0:50\"]. | . | colors | String array | Array of line colors to choose from. For example, [\"magenta\", \"cyan\"]. If you don’t provide this value, PerfTop chooses random colors for each line. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/#add-options",
    "relUrl": "/docs/pa/dashboards/#add-options"
  },"185": {
    "doc": "Create Dashboards",
    "title": "Create Dashboards",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/dashboards/",
    "relUrl": "/docs/pa/dashboards/"
  },"186": {
    "doc": "Debian Package",
    "title": "Debian package",
    "content": "Installing and running Open Distro for Elasticsearch from an Debian package is a more manual process than the Docker image. We recommend Ubuntu 16.04 or 18.04, but any Debian-based distribution that uses systemd should work. RPM lets you install specific versions of Open Distro for Elasticsearch. You can install specific versions using Apt, but you have to manually install each dependency. These steps assume you’re using Ubuntu 18.04. | Install Java 11: . sudo add-apt-repository ppa:openjdk-r/ppa sudo apt update sudo apt install openjdk-11-jdk . | Install unzip: . sudo apt install unzip . | Download and add signing keys for the repositories: . wget -qO - https://d3g5vo6xdbdb9a.cloudfront.net/GPG-KEY-opendistroforelasticsearch | sudo apt-key add - . | Add the repositories: . echo \"deb https://d3g5vo6xdbdb9a.cloudfront.net/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/opendistroforelasticsearch.list . | Install Elasticsearch OSS: . wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.1-amd64.deb sudo dpkg -i elasticsearch-oss-7.9.1-amd64.deb . | Install the latest version of Open Distro for Elasticsearch: . sudo apt-get update sudo apt install opendistroforelasticsearch . If you don’t want the latest version or encounter dependency errors, install the plugins individually: . # List all available versions of a plugin sudo apt list -a opendistro-alerting # Install a specific version of a plugin sudo apt install opendistro-alerting=1.2.0.0-1 sudo apt install opendistro-performance-analyzer=1.2.0.0-1 sudo apt install opendistro-job-scheduler=1.2.0.0-1 sudo apt install opendistro-security=1.2.0.0-0 sudo apt install opendistro-sql=1.2.0.0-1 . For compatibility by Elasticsearch version, see Plugin compatibility. | To start Open Distro for Elasticsearch: . sudo systemctl start elasticsearch.service . | Send requests to the server to verify that Elasticsearch is up and running: . curl -XGET https://localhost:9200 -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/nodes?v -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/plugins?v -u admin:admin --insecure . | For instructions on installing and running Kibana, see Kibana. | To check the status of the service: . systemctl status elasticsearch.service . | To stop Open Distro for Elasticsearch: . sudo systemctl stop elasticsearch.service . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/deb/#debian-package",
    "relUrl": "/docs/install/deb/#debian-package"
  },"187": {
    "doc": "Debian Package",
    "title": "Configuration",
    "content": "To run Open Distro for Elasticsearch when the system starts: . sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable elasticsearch.service . You can also modify the values in /etc/default/elasticsearch (JAVA_HOME, most notably), /etc/elasticsearch/elasticsearch.yml, and /etc/elasticsearch/jvm.options (to set the heap size, most notably). To learn more, see Elasticsearch configuration and Important Settings on the Docker page. (Optional) Set up Performance Analyzer . By default, Performance Analyzer’s endpoints are not accessible from outside the host machine. To edit this behavior, modify the plugin configuration. First navigate to ES_HOME, which is /usr/share/elasticsearch for a standard installation. cd $ES_HOME # navigate to the Elasticsearch home directory cd plugins/opendistro_performance_analyzer/pa_config/ vi performance-analyzer.properties . Uncomment the line #webservice-bind-host and set it to 0.0.0.0: . # ======================== Elasticsearch performance analyzer plugin config ========================= # NOTE: this is an example for Linux. Please modify the config accordingly if you are using it under other OS. # WebService bind host; default to all interfaces webservice-bind-host = 0.0.0.0 # Metrics data location metrics-location = /dev/shm/performanceanalyzer/ # Metrics deletion interval (minutes) for metrics data. # Interval should be between 1 to 60. metrics-deletion-interval = 1 # If set to true, the system cleans up the files behind it. So at any point, we should expect only 2 # metrics-db-file-prefix-path files. If set to false, no files are cleaned up. This can be useful, if you are archiving # the files and wouldn't like for them to be cleaned up. cleanup-metrics-db-files = true # WebService exposed by App's port webservice-listener-port = 9600 # Metric DB File Prefix Path location metrics-db-file-prefix-path = /tmp/metricsdb_ https-enabled = false #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path # Plugin Stats Metadata file name, expected to be in the same location plugin-stats-metadata = plugin-stats-metadata # Agent Stats Metadata file name, expected to be in the same location agent-stats-metadata = agent-stats-metadata . Finally, restart the Elasticsearch service. After the restart, Performance Analyzer is accessible from outside the machine: . sudo systemctl restart elasticsearch.service . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/deb/#configuration",
    "relUrl": "/docs/install/deb/#configuration"
  },"188": {
    "doc": "Debian Package",
    "title": "Where are the files?",
    "content": "The Debian package installs files to the following locations: . | File type | Location | . | Elasticsearch home, management scripts, and plugins | /usr/share/elasticsearch/ | . | Configuration files | /etc/elasticsearch | . | Environment variables | /etc/default/elasticsearch | . | Logs | /var/log/elasticsearch | . | Shard data | /var/lib/elasticsearch | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/deb/#where-are-the-files",
    "relUrl": "/docs/install/deb/#where-are-the-files"
  },"189": {
    "doc": "Debian Package",
    "title": "Notes on Debian",
    "content": "If you are using Debian 10 (Buster) rather than Ubuntu, skip the sudo add-apt-repository ppa:openjdk-r/ppa step. The openjdk-11-jdk package is available by default for Buster. If you are using Debian 9 (Strech), you likely need to make some modifications to the install process. | When installing Java 11, rather than sudo add-apt-repository ppa:openjdk-r/ppa, run: . sudo echo 'deb http://deb.debian.org/debian stretch-backports main' &gt; /etc/apt/sources.list.d/backports.list . | Before installing Open Distro for Elasticsearch, run: . apt install apt-transport-https . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/deb/#notes-on-debian",
    "relUrl": "/docs/install/deb/#notes-on-debian"
  },"190": {
    "doc": "Debian Package",
    "title": "Debian Package",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/deb/",
    "relUrl": "/docs/install/deb/"
  },"191": {
    "doc": "Default Action Groups",
    "title": "Default action groups",
    "content": "This page catalogs all default action groups. Often, the most coherent way to create new action groups is to use a combination of these default groups and individual permissions. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/default-action-groups/#default-action-groups",
    "relUrl": "/docs/security/access-control/default-action-groups/#default-action-groups"
  },"192": {
    "doc": "Default Action Groups",
    "title": "General",
    "content": "| Name | Description | . | unlimited | Grants complete access. Can be used on an cluster- or index-level. Equates to \"*\". | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/default-action-groups/#general",
    "relUrl": "/docs/security/access-control/default-action-groups/#general"
  },"193": {
    "doc": "Default Action Groups",
    "title": "Cluster-level",
    "content": "| Name | Description | . | cluster_all | Grants all cluster permissions. Equates to cluster:*. | . | cluster_monitor | Grants all cluster monitoring permissions. Equates to cluster:monitor/*. | . | cluster_composite_ops_ro | Grants read-only permissions to execute requests like mget, msearch, or mtv, plus permissions to query for aliases. | . | cluster_composite_ops | Same as CLUSTER_COMPOSITE_OPS_RO, but also grants bulk permissions and all aliases permissions. | . | manage_snapshots | Grants permissions to manage snapshots and repositories. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/default-action-groups/#cluster-level",
    "relUrl": "/docs/security/access-control/default-action-groups/#cluster-level"
  },"194": {
    "doc": "Default Action Groups",
    "title": "Index-level",
    "content": "| Name | Description | . | indices_all | Grants all permissions on the index. Equates to indices:*. | . | get | Grants permissions to use get and mget actions only. | . | read | Grants read permissions such as search, get field mappings, get, and mget. | . | write | Grants permissions to create and update documents within existing indices. To create new indices, see CREATE_INDEX. | . | delete | Grants permissions to delete documents. | . | crud | Combines the READ, WRITE and DELETE action groups. | . | search | Grants permissions to search documents. Includes SUGGEST. | . | suggest | Grants permissions to use the suggest API. Included in the READ action group. | . | create_index | Grants permissions to create indices and mappings. | . | indices_monitor | Grants permissions to execute all index monitoring actions (e.g. recovery, segments info, index stats, and status). | . | manage_aliases | Grants permissions to manage aliases. | . | manage | Grants all monitoring and administration permissions for indices. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/default-action-groups/#index-level",
    "relUrl": "/docs/security/access-control/default-action-groups/#index-level"
  },"195": {
    "doc": "Default Action Groups",
    "title": "Default Action Groups",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/default-action-groups/",
    "relUrl": "/docs/security/access-control/default-action-groups/"
  },"196": {
    "doc": "Delete",
    "title": "Delete",
    "content": "The DELETE statement deletes documents that satisfy the predicates in the WHERE clause. If you don’t specify the WHERE clause, all documents are deleted. Syntax . Rule singleDeleteStatement: . Example . SQL query: . DELETE FROM accounts WHERE age &gt; 30 . Explain: . { \"size\" : 1000, \"query\" : { \"bool\" : { \"must\" : [ { \"range\" : { \"age\" : { \"from\" : 30, \"to\" : null, \"include_lower\" : false, \"include_upper\" : true, \"boost\" : 1.0 } } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"_source\" : false } . Result set: . { \"schema\" : [ { \"name\" : \"deleted_rows\", \"type\" : \"long\" } ], \"total\" : 1, \"datarows\" : [ [ 3 ] ], \"size\" : 1, \"status\" : 200 } . The datarows field shows the number of documents deleted. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/delete/",
    "relUrl": "/docs/sql/delete/"
  },"197": {
    "doc": "Disable Security",
    "title": "Disable security",
    "content": "You might want to temporarily disable the security plugin to make testing or internal usage more straightforward. To disable the plugin, add the following line in elasticsearch.yml: . opendistro_security.disabled: true . A more permanent option is to remove the security plugin entirely. Delete the plugins/opendistro_security folder on all nodes, and delete the opendistro_security configuration entries from elasticsearch.yml. To perform these steps on the Docker image, see Customize the Docker image. Disabling or removing the plugin exposes the configuration index for the security plugin. If the index contains sensitive information, be sure to protect it through some other means. If you no longer need the index, delete it. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/disable/#disable-security",
    "relUrl": "/docs/security/configuration/disable/#disable-security"
  },"198": {
    "doc": "Disable Security",
    "title": "Remove Kibana plugin",
    "content": "The security plugin is actually two plugins: one for Elasticsearch and one for Kibana. You can use the Elasticsearch plugin independently, but the Kibana plugin depends on a secured Elasticsearch cluster. If you disable the security plugin in elasticsearch.yml (or delete the plugin entirely) and still want to use Kibana, you must remove the corresponding Kibana plugin. For more information, see Standalone Kibana plugin install. RPM or DEB . | Remove all opendistro_security lines from kibana.yml. | Change elasticsearch.url in kibana.yml to http:// rather than https://. | Enter sudo /usr/share/kibana/bin/kibana-plugin remove opendistro_security. | Enter sudo systemctl restart kibana.service. | . Docker . | Create a new Dockerfile: . FROM amazon/opendistro-for-elasticsearch-kibana:1.11.0 RUN /usr/share/kibana/bin/kibana-plugin remove opendistro_security COPY --chown=kibana:kibana kibana.yml /usr/share/kibana/config/ . In this case, kibana.yml is a “vanilla” version of the file with no Open Distro for Elasticsearch entries. It might look like this: . --- server.name: kibana server.host: \"0\" elasticsearch.hosts: http://localhost:9200 . | To build the new Docker image, run the following command: . docker build --tag=kibana-no-security . | In docker-compose.yml, change amazon/opendistro-for-elasticsearch-kibana:1.11.0 to kibana-no-security. | Change ELASTICSEARCH_URL (docker-compose.yml) or elasticsearch.url (your custom kibana.yml) to http:// rather than https://. | Change ELASTICSEARCH_HOSTS or elasticsearch.hosts to http:// rather than https://. | Enter docker-compose up. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/disable/#remove-kibana-plugin",
    "relUrl": "/docs/security/configuration/disable/#remove-kibana-plugin"
  },"199": {
    "doc": "Disable Security",
    "title": "Disable Security",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/disable/",
    "relUrl": "/docs/security/configuration/disable/"
  },"200": {
    "doc": "Docker Security Configuration",
    "title": "Docker security configuration",
    "content": "Before deploying to a production environment, you should replace the demo security certificates and configuration YAML files with your own. With the RPM and Debian installations, you have direct access to the file system, but the Docker image requires modifying the Docker Compose file to include the replacement files. Additionally you can set the Docker environment variable DISABLE_INSTALL_DEMO_CONFIG to true. This change completely disables the demo installer. Sample Docker Compose file . version: '3' services: odfe-node1: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node1 environment: - cluster.name=odfe-cluster - node.name=odfe-node1 - discovery.seed_hosts=odfe-node1,odfe-node2 - cluster.initial_master_nodes=odfe-node1,odfe-node2 - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM - network.host=0.0.0.0 # required if not using the demo security configuration ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 # maximum number of open files for the Elasticsearch user, set to at least 65536 on modern systems hard: 65536 volumes: - odfe-data1:/usr/share/elasticsearch/data - ./root-ca.pem:/usr/share/elasticsearch/config/root-ca.pem - ./node.pem:/usr/share/elasticsearch/config/node.pem - ./node-key.pem:/usr/share/elasticsearch/config/node-key.pem - ./admin.pem:/usr/share/elasticsearch/config/admin.pem - ./admin-key.pem:/usr/share/elasticsearch/config/admin-key.pem - ./custom-elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml - ./roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml - ./tenants.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/tenants.yml - ./roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml - ./action_groups.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/action_groups.yml ports: - 9200:9200 - 9600:9600 # required for Performance Analyzer networks: - odfe-net odfe-node2: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node2 environment: - cluster.name=odfe-cluster - node.name=odfe-node2 - discovery.seed_hosts=odfe-node1,odfe-node2 - cluster.initial_master_nodes=odfe-node1,odfe-node2 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - network.host=0.0.0.0 ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - odfe-data2:/usr/share/elasticsearch/data - ./root-ca.pem:/usr/share/elasticsearch/config/root-ca.pem - ./node.pem:/usr/share/elasticsearch/config/node.pem - ./node-key.pem:/usr/share/elasticsearch/config/node-key.pem - ./admin.pem:/usr/share/elasticsearch/config/admin.pem - ./admin-key.pem:/usr/share/elasticsearch/config/admin-key.pem - ./custom-elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./internal_users.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/internal_users.yml - ./roles_mapping.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles_mapping.yml - ./tenants.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/tenants.yml - ./roles.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/roles.yml - ./action_groups.yml:/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/action_groups.yml networks: - odfe-net kibana: image: amazon/opendistro-for-elasticsearch-kibana:1.11.0 container_name: odfe-kibana ports: - 5601:5601 expose: - \"5601\" environment: ELASTICSEARCH_URL: https://odfe-node1:9200 ELASTICSEARCH_HOSTS: https://odfe-node1:9200 volumes: - ./custom-kibana.yml:/usr/share/kibana/config/kibana.yml networks: - odfe-net volumes: odfe-data1: odfe-data2: networks: odfe-net: . Then make your changes to elasticsearch.yml. For a full list of settings, see Security. This example adds (extremely) verbose audit logging: . opendistro_security.ssl.transport.pemcert_filepath: node.pem opendistro_security.ssl.transport.pemkey_filepath: node-key.pem opendistro_security.ssl.transport.pemtrustedcas_filepath: root-ca.pem opendistro_security.ssl.transport.enforce_hostname_verification: false opendistro_security.ssl.http.enabled: true opendistro_security.ssl.http.pemcert_filepath: node.pem opendistro_security.ssl.http.pemkey_filepath: node-key.pem opendistro_security.ssl.http.pemtrustedcas_filepath: root-ca.pem opendistro_security.allow_default_init_securityindex: true opendistro_security.authcz.admin_dn: - CN=A,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA opendistro_security.nodes_dn: - 'CN=N,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA' opendistro_security.audit.type: internal_elasticsearch opendistro_security.enable_snapshot_restore_privilege: true opendistro_security.check_snapshot_restore_write_privileges: true opendistro_security.restapi.roles_enabled: [\"all_access\", \"security_rest_api_access\"] cluster.routing.allocation.disk.threshold_enabled: false opendistro_security.audit.config.disabled_rest_categories: NONE opendistro_security.audit.config.disabled_transport_categories: NONE . Use this same override process to specify new authentication settings in /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/config.yml, as well as new internal users, roles, mappings, action groups, and tenants. To start the cluster, run docker-compose up. If you encounter any File /usr/share/elasticsearch/config/elasticsearch.yml has insecure file permissions (should be 0600) messages, you can use chmod to set file permissions before running docker-compose up. Docker Compose passes files to the container as-is. Finally, you can open Kibana at http://localhost:5601, sign in, and use the Security panel to perform other management tasks. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker-security/#docker-security-configuration",
    "relUrl": "/docs/install/docker-security/#docker-security-configuration"
  },"201": {
    "doc": "Docker Security Configuration",
    "title": "Docker Security Configuration",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker-security/",
    "relUrl": "/docs/install/docker-security/"
  },"202": {
    "doc": "Docker",
    "title": "Docker image",
    "content": "You can pull the Open Distro for Elasticsearch Docker image just like any other image: . docker pull amazon/opendistro-for-elasticsearch:1.11.0 docker pull amazon/opendistro-for-elasticsearch-kibana:1.11.0 . To check available versions, see Docker Hub. Open Distro for Elasticsearch images use centos:7 as the base image. If you run Docker locally, we recommend allowing Docker to use at least 4 GB of RAM in Preferences &gt; Resources. . | Run the image | Start a cluster | Configure Elasticsearch . | (Optional) Set up Performance Analyzer | . | Bash access to containers | Important settings | Customize the Docker image | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#docker-image",
    "relUrl": "/docs/install/docker/#docker-image"
  },"203": {
    "doc": "Docker",
    "title": "Run the image",
    "content": "To run the image for local development: . docker run -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" amazon/opendistro-for-elasticsearch:1.11.0 . Then send requests to the server to verify that Elasticsearch is up and running: . curl -XGET https://localhost:9200 -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/nodes?v -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/plugins?v -u admin:admin --insecure . To find the container ID: . docker ps . Then you can stop the container using: . docker stop &lt;container-id&gt; . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#run-the-image",
    "relUrl": "/docs/install/docker/#run-the-image"
  },"204": {
    "doc": "Docker",
    "title": "Start a cluster",
    "content": "To deploy the image across multiple nodes and simulate a more realistic deployment, create a docker-compose.yml file appropriate for your environment and run: . docker-compose up . To stop the cluster, run: . docker-compose down . To stop the cluster and delete all data volumes, run: . docker-compose down -v . Sample Docker Compose file . This sample file starts two data nodes and Kibana. version: '3' services: odfe-node1: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node1 environment: - cluster.name=odfe-cluster - node.name=odfe-node1 - discovery.seed_hosts=odfe-node1,odfe-node2 - cluster.initial_master_nodes=odfe-node1,odfe-node2 - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 # maximum number of open files for the Elasticsearch user, set to at least 65536 on modern systems hard: 65536 volumes: - odfe-data1:/usr/share/elasticsearch/data ports: - 9200:9200 - 9600:9600 # required for Performance Analyzer networks: - odfe-net odfe-node2: image: amazon/opendistro-for-elasticsearch:1.11.0 container_name: odfe-node2 environment: - cluster.name=odfe-cluster - node.name=odfe-node2 - discovery.seed_hosts=odfe-node1,odfe-node2 - cluster.initial_master_nodes=odfe-node1,odfe-node2 - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 volumes: - odfe-data2:/usr/share/elasticsearch/data networks: - odfe-net kibana: image: amazon/opendistro-for-elasticsearch-kibana:1.11.0 container_name: odfe-kibana ports: - 5601:5601 expose: - \"5601\" environment: ELASTICSEARCH_URL: https://odfe-node1:9200 ELASTICSEARCH_HOSTS: https://odfe-node1:9200 networks: - odfe-net volumes: odfe-data1: odfe-data2: networks: odfe-net: . If you override kibana.yml settings using environment variables, as seen above, use all uppercase letters and periods in place of underscores (e.g. for elasticsearch.url, specify ELASTICSEARCH_URL). ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#start-a-cluster",
    "relUrl": "/docs/install/docker/#start-a-cluster"
  },"205": {
    "doc": "Docker",
    "title": "Configure Elasticsearch",
    "content": "You can pass a custom elasticsearch.yml file to the Docker container using the -v flag for docker run: . docker run \\ -p 9200:9200 -p 9600:9600 \\ -e \"discovery.type=single-node\" \\ -v /&lt;full-path-to&gt;/custom-elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ amazon/opendistro-for-elasticsearch:1.11.0 . You can perform the same operation in docker-compose.yml using a relative path: . services: odfe-node1: volumes: - odfe-data1:/usr/share/elasticsearch/data - ./custom-elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml odfe-node2: volumes: - odfe-data2:/usr/share/elasticsearch/data - ./custom-elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml kibana: volumes: - ./custom-kibana.yml:/usr/share/kibana/config/kibana.yml . You can use this same method to pass your own certificates for use with the Security plugin. (Optional) Set up Performance Analyzer . By default, Performance Analyzer’s endpoints are not accessible from outside the Docker container. To edit this behavior, open a shell session in the container and modify the configuration: . docker ps # Look up the container id docker exec -it &lt;container-id&gt; /bin/bash # Inside container cd plugins/opendistro_performance_analyzer/pa_config/ vi performance-analyzer.properties . Uncomment the line #webservice-bind-host and set it to 0.0.0.0: . # ======================== Elasticsearch performance analyzer plugin config ========================= # NOTE: this is an example for Linux. Please modify the config accordingly if you are using it under other OS. # WebService bind host; default to all interfaces webservice-bind-host = 0.0.0.0 # Metrics data location metrics-location = /dev/shm/performanceanalyzer/ # Metrics deletion interval (minutes) for metrics data. # Interval should be between 1 to 60. metrics-deletion-interval = 1 # If set to true, the system cleans up the files behind it. So at any point, we should expect only 2 # metrics-db-file-prefix-path files. If set to false, no files are cleaned up. This can be useful, if you are archiving # the files and wouldn't like for them to be cleaned up. cleanup-metrics-db-files = true # WebService exposed by App's port webservice-listener-port = 9600 # Metric DB File Prefix Path location metrics-db-file-prefix-path = /tmp/metricsdb_ https-enabled = false #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path # Plugin Stats Metadata file name, expected to be in the same location plugin-stats-metadata = plugin-stats-metadata # Agent Stats Metadata file name, expected to be in the same location agent-stats-metadata = agent-stats-metadata . Then restart the Performance Analyzer agent: . kill $(ps aux | grep -i 'PerformanceAnalyzerApp' | grep -v grep | awk '{print $2}') . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#configure-elasticsearch",
    "relUrl": "/docs/install/docker/#configure-elasticsearch"
  },"206": {
    "doc": "Docker",
    "title": "Bash access to containers",
    "content": "To create an interactive Bash session in a container, run docker ps to find the container ID. Then run: . docker exec -it &lt;container-id&gt; /bin/bash . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#bash-access-to-containers",
    "relUrl": "/docs/install/docker/#bash-access-to-containers"
  },"207": {
    "doc": "Docker",
    "title": "Important settings",
    "content": "For production workloads, make sure the Linux setting vm.max_map_count is set to at least 262144. On the Open Distro for Elasticsearch Docker image, this setting is the default. To verify, start a Bash session in the container and run: . cat /proc/sys/vm/max_map_count . To increase this value, you have to modify the Docker image. On the RPM install, you can add this setting to the host machine’s /etc/sysctl.conf file by adding the following line: . vm.max_map_count=262144 . Then run sudo sysctl -p to reload. The docker-compose.yml file above also contains several key settings: bootstrap.memory_lock=true, ES_JAVA_OPTS=-Xms512m -Xmx512m, nofile 65536 and port 9600. Respectively, these settings disable memory swapping (along with memlock), set the size of the Java heap (we recommend half of system RAM), set a limit of 65536 open files for the Elasticsearch user, and allow you to access Performance Analyzer on port 9600. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#important-settings",
    "relUrl": "/docs/install/docker/#important-settings"
  },"208": {
    "doc": "Docker",
    "title": "Customize the Docker image",
    "content": "To run the image with a custom plugin, first create a Dockerfile: . FROM amazon/opendistro-for-elasticsearch:1.11.0 RUN /usr/share/elasticsearch/bin/elasticsearch-plugin install --batch &lt;plugin-name-or-url&gt; . Then run the following commands: . docker build --tag=odfe-custom-plugin . docker run -p 9200:9200 -p 9600:9600 -v /usr/share/elasticsearch/data odfe-custom-plugin . You can also use a Dockerfile to pass your own certificates for use with the Security plugin, similar to the -v argument in Configure Elasticsearch: . FROM amazon/opendistro-for-elasticsearch:1.11.0 COPY --chown=elasticsearch:elasticsearch elasticsearch.yml /usr/share/elasticsearch/config/ COPY --chown=elasticsearch:elasticsearch my-key-file.pem /usr/share/elasticsearch/config/ COPY --chown=elasticsearch:elasticsearch my-certificate-chain.pem /usr/share/elasticsearch/config/ COPY --chown=elasticsearch:elasticsearch my-root-cas.pem /usr/share/elasticsearch/config/ . Alternately, you might want to remove a plugin. This Dockerfile removes the security plugin: . FROM amazon/opendistro-for-elasticsearch:1.11.0 RUN /usr/share/elasticsearch/bin/elasticsearch-plugin remove opendistro_security COPY --chown=elasticsearch:elasticsearch elasticsearch.yml /usr/share/elasticsearch/config/ . In this case, elasticsearch.yml is a “vanilla” version of the file with no Open Distro for Elasticsearch entries. It might look like this: . cluster.name: \"docker-cluster\" network.host: 0.0.0.0 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/#customize-the-docker-image",
    "relUrl": "/docs/install/docker/#customize-the-docker-image"
  },"209": {
    "doc": "Docker",
    "title": "Docker",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/docker/",
    "relUrl": "/docs/install/docker/"
  },"210": {
    "doc": "Docker Upgrade",
    "title": "Docker upgrade",
    "content": "If you use the Docker image, we highly recommend that you perform what amounts to a cluster restart upgrade. This process requires downtime, but takes very few steps and avoids problems with individual nodes rejoining the cluster and executing commands within containers. The most important step is to leave your data volumes intact. Don’t run docker-compose down -v. | Update the version strings in docker-compose.yml. You can perform this step while the cluster is running. For more information, see Sample Docker Compose file. | Recreate the cluster using the updated file: . docker-compose up . | Wait for the cluster to start, and verify that your cluster returns the new version: . curl -XGET https://localhost:9200 -u admin:admin -k . | Verify cluster health and the expected number of containers and nodes: . curl -XGET https://localhost:9200/_cat/health?v -u admin:admin -k docker ps . | Open Kibana, and verify that your data is present. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/docker/#docker-upgrade",
    "relUrl": "/docs/upgrade/docker/#docker-upgrade"
  },"211": {
    "doc": "Docker Upgrade",
    "title": "Docker Upgrade",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/docker/",
    "relUrl": "/docs/upgrade/docker/"
  },"212": {
    "doc": "Document-Level Security",
    "title": "Document-level security",
    "content": "Document-level security lets you restrict a role to a subset of documents in an index. The easiest way to get started with document- and field-level security is open Kibana and choose Security. Then choose Roles, create a new role, and review the Index permissions section. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/document-level-security/#document-level-security",
    "relUrl": "/docs/security/access-control/document-level-security/#document-level-security"
  },"213": {
    "doc": "Document-Level Security",
    "title": "Simple roles",
    "content": "Document-level security uses the Elasticsearch query DSL to define which documents a role grants access to. In Kibana, choose an index pattern and provide a query in the Document level security section: . { \"bool\": { \"must\": { \"match\": { \"genres\": \"Comedy\" } } } } . This query specifies that for the role to have access to a document, its genres field must include Comedy. A typical request to the _search API includes { \"query\": { ... } } around the query, but in this case, you only need to specify the query itself. In the REST API, you provide the query as a string, so you must escape your quotes. This role allows a user to read any document in any index with the field public set to true: . PUT _opendistro/_security/api/roles/public_data { \"cluster_permissions\": [ \"*\" ], \"index_permissions\": [{ \"index_patterns\": [ \"pub*\" ], \"dls\": \"{\\\"term\\\": { \\\"public\\\": true}}\", \"allowed_actions\": [ \"read\" ] }] } . These queries can be as complex as you want, but we recommend keeping them simple to minimize the performance impact that the document-level security feature has on the cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/document-level-security/#simple-roles",
    "relUrl": "/docs/security/access-control/document-level-security/#simple-roles"
  },"214": {
    "doc": "Document-Level Security",
    "title": "Parameter substitution",
    "content": "A number of variables exist that you can use to enforce rules based on the properties of a user. For example, ${user.name} is replaced with the name of the current user. This rule allows a user to read any document where the username is a value of the readable_by field: . PUT _opendistro/_security/api/roles/user_data { \"cluster_permissions\": [ \"*\" ], \"index_permissions\": [{ \"index_patterns\": [ \"pub*\" ], \"dls\": \"{\\\"term\\\": { \\\"readable_by\\\": \\\"${user.name}\\\"}}\", \"allowed_actions\": [ \"read\" ] }] } . This table lists substitutions. | Term | Replaced with | . | ${user.name} | Username. | . | ${user.roles} | A comma-separated, quoted list of user roles. | . | ${attr.&lt;TYPE&gt;.&lt;NAME&gt;} | An attribute with name &lt;NAME&gt; defined for a user. &lt;TYPE&gt; is internal, jwt, proxy or ldap | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/document-level-security/#parameter-substitution",
    "relUrl": "/docs/security/access-control/document-level-security/#parameter-substitution"
  },"215": {
    "doc": "Document-Level Security",
    "title": "Attribute-based security",
    "content": "You can use roles and parameter substitution with the terms_set query to enable attribute-based security. User definition . PUT _opendistro/_security/api/internalusers/user1 { \"password\": \"asdf\", \"backend_roles\": [\"abac\"], \"attributes\": { \"permissions\": \"\\\"att1\\\", \\\"att2\\\", \\\"att3\\\"\" } } . Role definition . PUT _opendistro/_security/api/roles/abac { \"index_permissions\": [{ \"index_patterns\": [ \"*\" ], \"dls\": \"{\\\"terms_set\\\": {\\\"security_attributes\\\": {\\\"terms\\\": [\\\"${attr.internal.permissions}\\\"], \\\"minimum_should_match_script\\\": {\\\"source\\\": \\\"doc['security_attributes'].values.length\\\"}}}}\", \"allowed_actions\": [ \"read\" ] }] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/document-level-security/#attribute-based-security",
    "relUrl": "/docs/security/access-control/document-level-security/#attribute-based-security"
  },"216": {
    "doc": "Document-Level Security",
    "title": "Document-Level Security",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/document-level-security/",
    "relUrl": "/docs/security/access-control/document-level-security/"
  },"217": {
    "doc": "Encryption at Rest",
    "title": "Encryption at rest",
    "content": "The operating system for each Open Distro for Elasticsearch node handles encryption of data at rest. To enable encryption at rest in most Linux distributions, use the cryptsetup command: . cryptsetup luksFormat --key-file &lt;key&gt; &lt;partition&gt; . For full documentation on the command, see the Linux man page. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/encryption-at-rest/#encryption-at-rest",
    "relUrl": "/docs/install/encryption-at-rest/#encryption-at-rest"
  },"218": {
    "doc": "Encryption at Rest",
    "title": "Encryption at Rest",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/encryption-at-rest/",
    "relUrl": "/docs/install/encryption-at-rest/"
  },"219": {
    "doc": "Endpoint",
    "title": "Endpoint",
    "content": "To send a query request to PPL plugin, use the HTTP POST request. We recommend a POST request because it doesn’t have any length limit and it allows you to pass other parameters to the plugin for other functionality. Use the explain endpoint for query translation and troubleshooting. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/endpoint/",
    "relUrl": "/docs/ppl/endpoint/"
  },"220": {
    "doc": "Endpoint",
    "title": "Request Format",
    "content": "To use the PPL plugin with your own applications, send requests to _opendistro/_ppl, with your query in the request body: . curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_ppl \\ ... -d '{\"query\" : \"source=accounts | fields firstname, lastname\"}' . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/endpoint/#request-format",
    "relUrl": "/docs/ppl/endpoint/#request-format"
  },"221": {
    "doc": "Endpoint",
    "title": "Endpoint",
    "content": "To send query request to SQL plugin, you can either use a request parameter in HTTP GET or request body by HTTP POST request. POST request is recommended because it doesn’t have length limitation and allows for other parameters passed to plugin for other functionality such as prepared statement. And also the explain endpoint is used very often for query translation and troubleshooting. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/endpoints/",
    "relUrl": "/docs/sql/endpoints/"
  },"222": {
    "doc": "Endpoint",
    "title": "GET",
    "content": "Description . You can send HTTP GET request with your query embedded in URL parameter. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X GET localhost:9200/_opendistro/_sql?sql=SELECT * FROM accounts . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/endpoints/#get",
    "relUrl": "/docs/sql/endpoints/#get"
  },"223": {
    "doc": "Endpoint",
    "title": "POST",
    "content": "Description . You can also send HTTP POST request with your query in request body. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"query\" : \"SELECT * FROM accounts\" }' . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/endpoints/#post",
    "relUrl": "/docs/sql/endpoints/#post"
  },"224": {
    "doc": "Endpoint",
    "title": "Explain",
    "content": "Description . To translate your query, send it to explain endpoint. The explain output is Elasticsearch domain specific language (DSL) in JSON format. You can just copy and paste it to your console to run it against Elasticsearch directly. Example . Explain query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql/_explain -d '{ \"query\" : \"SELECT firstname, lastname FROM accounts WHERE age &gt; 20\" }' . Explain: . { \"from\": 0, \"size\": 200, \"query\": { \"bool\": { \"filter\": [{ \"bool\": { \"must\": [{ \"range\": { \"age\": { \"from\": 20, \"to\": null, \"include_lower\": false, \"include_upper\": true, \"boost\": 1.0 } } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } }, \"_source\": { \"includes\": [ \"firstname\", \"lastname\" ], \"excludes\": [] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/endpoints/#explain",
    "relUrl": "/docs/sql/endpoints/#explain"
  },"225": {
    "doc": "Endpoint",
    "title": "Cursor",
    "content": "Description . To get back a paginated response, use the fetch_size parameter. The value of fetch_size should be greater than 0. The default value is 1,000. A value of 0 will fallback to a non-paginated response. The fetch_size parameter is only supported for the JDBC response format. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"fetch_size\" : 5, \"query\" : \"SELECT firstname, lastname FROM accounts WHERE age &gt; 20 ORDER BY state ASC\" }' . Result set: . { \"schema\": [ { \"name\": \"firstname\", \"type\": \"text\" }, { \"name\": \"lastname\", \"type\": \"text\" } ], \"cursor\": \"d:eyJhIjp7fSwicyI6IkRYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQU1XZWpkdFRFRkZUMlpTZEZkeFdsWnJkRlZoYnpaeVVRPT0iLCJjIjpbeyJuYW1lIjoiZmlyc3RuYW1lIiwidHlwZSI6InRleHQifSx7Im5hbWUiOiJsYXN0bmFtZSIsInR5cGUiOiJ0ZXh0In1dLCJmIjo1LCJpIjoiYWNjb3VudHMiLCJsIjo5NTF9\", \"total\": 956, \"datarows\": [ [ \"Cherry\", \"Carey\" ], [ \"Lindsey\", \"Hawkins\" ], [ \"Sargent\", \"Powers\" ], [ \"Campos\", \"Olsen\" ], [ \"Savannah\", \"Kirby\" ] ], \"size\": 5, \"status\": 200 } . To fetch subsequent pages, use the cursor from last response: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"cursor\": \"d:eyJhIjp7fSwicyI6IkRYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQU1XZWpkdFRFRkZUMlpTZEZkeFdsWnJkRlZoYnpaeVVRPT0iLCJjIjpbeyJuYW1lIjoiZmlyc3RuYW1lIiwidHlwZSI6InRleHQifSx7Im5hbWUiOiJsYXN0bmFtZSIsInR5cGUiOiJ0ZXh0In1dLCJmIjo1LCJpIjoiYWNjb3VudHMiLCJsIjo5NTF9\" }' . The result only has the fetch_size number of datarows and cursor. The last page has only datarows and no cursor. The datarows can have more than the fetch_size number of records in case the nested fields are flattened. { \"cursor\": \"d:eyJhIjp7fSwicyI6IkRYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQU1XZWpkdFRFRkZUMlpTZEZkeFdsWnJkRlZoYnpaeVVRPT0iLCJjIjpbeyJuYW1lIjoiZmlyc3RuYW1lIiwidHlwZSI6InRleHQifSx7Im5hbWUiOiJsYXN0bmFtZSIsInR5cGUiOiJ0ZXh0In1dLCJmIjo1LCJpIjoiYWNjb3VudHMabcde12345\", \"datarows\": [ [ \"Abbas\", \"Hussain\" ], [ \"Chen\", \"Dai\" ], [ \"Anirudha\", \"Jadhav\" ], [ \"Peng\", \"Huo\" ], [ \"John\", \"Doe\" ] ] } . The cursor context is automatically cleared on the last page. To explicitly clear cursor context, use the _opendistro/_sql/close endpoint operation. &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql/close -d '{ \"cursor\": \"d:eyJhIjp7fSwicyI6IkRYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFBQU1XZWpkdFRFRkZUMlpTZEZkeFdsWnJkRlZoYnpaeVVRPT0iLCJjIjpbeyJuYW1lIjoiZmlyc3RuYW1lIiwidHlwZSI6InRleHQifSx7Im5hbWUiOiJsYXN0bmFtZSIsInR5cGUiOiJ0ZXh0In1dLCJmIjo1LCJpIjoiYWNjb3VudHMiLCJsIjo5NTF9\" }' . Sample response . {\"succeeded\":true} . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/endpoints/#cursor",
    "relUrl": "/docs/sql/endpoints/#cursor"
  },"226": {
    "doc": "Field-Level Security",
    "title": "Field-level security",
    "content": "Field-level security lets you control which document fields a user can see. Just like document-level security, you control access by index within a role. The easiest way to get started with document- and field-level security is open Kibana and choose Security. Then choose Roles, create a new role, and review the Index permissions section. . | Include or exclude fields . | Kibana | roles.yml | REST API | . | Interaction with multiple roles | Interaction with document-level security | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-level-security/#field-level-security",
    "relUrl": "/docs/security/access-control/field-level-security/#field-level-security"
  },"227": {
    "doc": "Field-Level Security",
    "title": "Include or exclude fields",
    "content": "You have two options when you configure field-level security: include or exclude fields. If you include fields, users see only those fields when they retrieve a document. For example, if you include the actors, title, and year fields, a search result might look like this: . { \"_index\": \"movies\", \"_type\": \"_doc\", \"_source\": { \"year\": 2013, \"title\": \"Rush\", \"actors\": [ \"Daniel Brühl\", \"Chris Hemsworth\", \"Olivia Wilde\" ] } } . If you exclude fields, users see everything but those fields when they retrieve a document. For example, if you exclude those same fields, the same search result might look like this: . { \"_index\": \"movies\", \"_type\": \"_doc\", \"_source\": { \"directors\": [ \"Ron Howard\" ], \"plot\": \"A re-creation of the merciless 1970s rivalry between Formula One rivals James Hunt and Niki Lauda.\", \"genres\": [ \"Action\", \"Biography\", \"Drama\", \"Sport\" ] } } . You can achieve the same outcomes using inclusion or exclusion, so choose whichever makes sense for your use case. Mixing the two doesn’t make sense and is not supported. You can specify field-level security settings using Kibana, roles.yml, and the REST API. | To exclude fields in roles.yml or the REST API, add ~ before the field name. | Field names support wildcards (*). Wildcards are especially useful for excluding subfields. For example, if you index a document that has a string (e.g. {\"title\": \"Thor\"}), Elasticsearch creates a title field of type text, but it also creates a title.keyword subfield of type keyword. In this example, to prevent unauthorized access to data in the title field, you must also exclude the title.keyword subfield. Use title* to match all fields that begin with title. | . Kibana . | Choose a role and Add index permission. | Choose an index pattern. | Under Field level security, use the drop-down to select your preferred option. Then specify one or more fields and press Enter. | . roles.yml . someonerole: cluster: [] indices: movies: '*': - \"READ\" _fls_: - \"~actors\" - \"~title\" - \"~year\" . REST API . See Create role. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-level-security/#include-or-exclude-fields",
    "relUrl": "/docs/security/access-control/field-level-security/#include-or-exclude-fields"
  },"228": {
    "doc": "Field-Level Security",
    "title": "Interaction with multiple roles",
    "content": "If you map a user to multiple roles, we recommend that those roles use either include or exclude statements for each index. The security plugin evaluates field-level security settings using the AND operator, so combining include and exclude statements can lead to neither behavior working properly. For example, in the movies index, if you include actors, title, and year in one role, exclude actors, title, and genres in another role, and then map both roles to the same user, a search result might look like this: . { \"_index\": \"movies\", \"_type\": \"_doc\", \"_source\": { \"year\": 2013, \"directors\": [ \"Ron Howard\" ], \"plot\": \"A re-creation of the merciless 1970s rivalry between Formula One rivals James Hunt and Niki Lauda.\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-level-security/#interaction-with-multiple-roles",
    "relUrl": "/docs/security/access-control/field-level-security/#interaction-with-multiple-roles"
  },"229": {
    "doc": "Field-Level Security",
    "title": "Interaction with document-level security",
    "content": "Document-level security relies on Elasticsearch queries, which means that all fields in the query must be visible in order for it to work properly. If you use field-level security in conjunction with document-level security, make sure you don’t restrict access to the fields that document-level security uses. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-level-security/#interaction-with-document-level-security",
    "relUrl": "/docs/security/access-control/field-level-security/#interaction-with-document-level-security"
  },"230": {
    "doc": "Field-Level Security",
    "title": "Field-Level Security",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-level-security/",
    "relUrl": "/docs/security/access-control/field-level-security/"
  },"231": {
    "doc": "Field Masking",
    "title": "Field masking",
    "content": "If you don’t want to remove fields from a document using field-level security, you can mask their values. Currently, field masking is only available for string-based fields and replaces the field’s value with a cryptographic hash. Field masking works alongside field-level security on the same per-role, per-index basis. You can allow certain roles to see sensitive fields in plain text and mask them for others. A search result with a masked field might look like this: . { \"_index\": \"movies\", \"_type\": \"_doc\", \"_source\": { \"year\": 2013, \"directors\": [ \"Ron Howard\" ], \"title\": \"ca998e768dd2e6cdd84c77015feb29975f9f498a472743f159bec6f1f1db109e\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#field-masking",
    "relUrl": "/docs/security/access-control/field-masking/#field-masking"
  },"232": {
    "doc": "Field Masking",
    "title": "Set the salt",
    "content": "You set the salt (a random string used to hash your data) in elasticsearch.yml: . opendistro_security.compliance.salt: abcdefghijklmnopqrstuvqxyz1234567890 . | Property | Description | . | opendistro_security.compliance.salt | The salt to use when generating the hash value. Must be at least 32 characters. Only ASCII characters are allowed. Optional. | . Setting the salt is optional, but we highly recommend it. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#set-the-salt",
    "relUrl": "/docs/security/access-control/field-masking/#set-the-salt"
  },"233": {
    "doc": "Field Masking",
    "title": "Configure field masking",
    "content": "You configure field masking using Kibana, roles.yml, or the REST API. Kibana . | Choose a role. | Choose an index permission. | For Anonymization, specify one or more fields and press Enter. | . roles.yml . someonerole: cluster: [] indices: movies: _masked_fields_: - \"title\" - \"genres\" '*': - \"READ\" . REST API . See Create role. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#configure-field-masking",
    "relUrl": "/docs/security/access-control/field-masking/#configure-field-masking"
  },"234": {
    "doc": "Field Masking",
    "title": "(Advanced) Use an alternative hash algorithm",
    "content": "By default, the security plugin uses the BLAKE2b algorithm, but you can use any hashing algorithm that your JVM provides. This list typically includes MD5, SHA-1, SHA-384, and SHA-512. To specify a different algorithm, add it after the masked field: . someonerole: cluster: [] indices: movies: _masked_fields_: - \"title::SHA-512\" - \"genres\" '*': - \"READ\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#advanced-use-an-alternative-hash-algorithm",
    "relUrl": "/docs/security/access-control/field-masking/#advanced-use-an-alternative-hash-algorithm"
  },"235": {
    "doc": "Field Masking",
    "title": "(Advanced) Pattern-based field masking",
    "content": "Rather than creating a hash, you can use one or more regular expressions and replacement strings to mask a field. The syntax is &lt;field&gt;::/&lt;regular-expression&gt;/::&lt;replacement-string&gt;. If you use multiple regular expressions, the results are passed from left to right, like piping in a shell: . hr_employee: index_permissions: - index_patterns: - 'humanresources' allowed_actions: - ... masked_fields: - 'lastname::/.*/::*' - '*ip_source::/[0-9]{1,3}$/::XXX::/^[0-9]{1,3}/::***' someonerole: cluster: [] indices: movies: _masked_fields_: - \"title::/./::*\" - \"genres::/^[a-zA-Z]{1,3}/::XXX::/[a-zA-Z]{1,3}$/::YYY\" '*': - \"READ\" . The title statement changes each character in the field to *, so you can still discern the length of the masked string. The genres statement changes the first three characters of the string to XXX and the last three characters to YYY. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#advanced-pattern-based-field-masking",
    "relUrl": "/docs/security/access-control/field-masking/#advanced-pattern-based-field-masking"
  },"236": {
    "doc": "Field Masking",
    "title": "Effect on audit logging",
    "content": "The read history feature lets you track read access to sensitive fields in your documents. For example, you might track access to the email field of your customer records. Access to masked fields are excluded from read history, because the user only saw the hash value, not the clear text value of the field. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/#effect-on-audit-logging",
    "relUrl": "/docs/security/access-control/field-masking/#effect-on-audit-logging"
  },"237": {
    "doc": "Field Masking",
    "title": "Field Masking",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/field-masking/",
    "relUrl": "/docs/security/access-control/field-masking/"
  },"238": {
    "doc": "Audit Log Field Reference",
    "title": "Audit log field reference",
    "content": "This page contains descriptions for all audit log fields. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#audit-log-field-reference",
    "relUrl": "/docs/security/audit-logs/field-reference/#audit-log-field-reference"
  },"239": {
    "doc": "Audit Log Field Reference",
    "title": "Common attributes",
    "content": "The following attributes are logged for all event categories, independent of the layer. | Name | Description | . | audit_format_version | The audit log message format version. | . | audit_category | The audit log category, one of FAILED_LOGIN, MISSING_PRIVILEGES, BAD_HEADERS, SSL_EXCEPTION, OPENDISTRO_SECURITY_INDEX_ATTEMPT, AUTHENTICATED or GRANTED_PRIVILEGES. | . | audit_node_id | The ID of the node where the event was generated. | . | audit_node_name | The name of the node where the event was generated. | . | audit_node_host_address | The host address of the node where the event was generated. | . | audit_node_host_name | The host name of the node where the event was generated. | . | audit_request_layer | The layer on which the event has been generated, either TRANSPORT or REST. | . | audit_request_origin | The layer from which the event originated, either TRANSPORT or REST. | . | audit_request_effective_user_is_admin | True if the request was made with a TLS admin certificate, otherwise false. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#common-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#common-attributes"
  },"240": {
    "doc": "Audit Log Field Reference",
    "title": "REST FAILED_LOGIN attributes",
    "content": "| Name | Description | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_rest_request_path | The REST endpoint URI. | . | audit_rest_request_params | The HTTP request parameters, if any. | . | audit_rest_request_headers | The HTTP headers, if any. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#rest-failed_login-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#rest-failed_login-attributes"
  },"241": {
    "doc": "Audit Log Field Reference",
    "title": "REST AUTHENTICATED attributes",
    "content": "| Name | Description | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_rest_request_path | The REST endpoint URI. | . | audit_rest_request_params | The HTTP request parameters, if any. | . | audit_rest_request_headers | The HTTP headers, if any. | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#rest-authenticated-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#rest-authenticated-attributes"
  },"242": {
    "doc": "Audit Log Field Reference",
    "title": "REST SSL_EXCEPTION attributes",
    "content": "| Name | Description | . | audit_request_exception_stacktrace | The stack trace of the SSL exception. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#rest-ssl_exception-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#rest-ssl_exception-attributes"
  },"243": {
    "doc": "Audit Log Field Reference",
    "title": "REST BAD_HEADERS attributes",
    "content": "| Name | Description | . | audit_rest_request_path | The REST endpoint URI. | . | audit_rest_request_params | The HTTP request parameters, if any. | . | audit_rest_request_headers | The HTTP headers, if any. | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#rest-bad_headers-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#rest-bad_headers-attributes"
  },"244": {
    "doc": "Audit Log Field Reference",
    "title": "Transport FAILED_LOGIN attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-failed_login-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-failed_login-attributes"
  },"245": {
    "doc": "Audit Log Field Reference",
    "title": "Transport AUTHENTICATED attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-authenticated-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-authenticated-attributes"
  },"246": {
    "doc": "Audit Log Field Reference",
    "title": "Transport MISSING_PRIVILEGES attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_trace_task_parent_id | The parent ID of this request, if any. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_privilege | The required privilege of the request (e.g. indices:data/read/search). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-missing_privileges-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-missing_privileges-attributes"
  },"247": {
    "doc": "Audit Log Field Reference",
    "title": "Transport GRANTED_PRIVILEGES attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_trace_task_parent_id | The parent ID of this request, if any. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_privilege | The required privilege of the request (e.g. indices:data/read/search). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-granted_privileges-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-granted_privileges-attributes"
  },"248": {
    "doc": "Audit Log Field Reference",
    "title": "Transport SSL_EXCEPTION attributes",
    "content": "| Name | Description | . | audit_request_exception_stacktrace | The stack trace of the SSL exception. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-ssl_exception-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-ssl_exception-attributes"
  },"249": {
    "doc": "Audit Log Field Reference",
    "title": "Transport BAD_HEADERS attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_trace_task_parent_id | The parent ID of this request, if any. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-bad_headers-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-bad_headers-attributes"
  },"250": {
    "doc": "Audit Log Field Reference",
    "title": "Transport OPENDISTRO_SECURITY_INDEX_ATTEMPT attributes",
    "content": "| Name | Description | . | audit_trace_task_id | The ID of the request. | . | audit_transport_headers | The headers of the request, if any. | . | audit_request_effective_user | The username that failed to authenticate. | . | audit_request_initiating_user | The user that initiated the request. Only logged if it differs from the effective user. | . | audit_transport_request_type | The type of request (e.g. IndexRequest). | . | audit_request_body | The HTTP request body, if any (and if request body logging is enabled). | . | audit_trace_indices | The index name(s) included in the request. Can contain wildcards, date patterns, and aliases. Only logged if resolve_indices is true. | . | audit_trace_resolved_indices | The resolved index name(s) affected by the request. Only logged if resolve_indices is true. | . | audit_trace_doc_types | The document types affected by the request. Only logged if resolve_indices is true. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/#transport-opendistro_security_index_attempt-attributes",
    "relUrl": "/docs/security/audit-logs/field-reference/#transport-opendistro_security_index_attempt-attributes"
  },"251": {
    "doc": "Audit Log Field Reference",
    "title": "Audit Log Field Reference",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/field-reference/",
    "relUrl": "/docs/security/audit-logs/field-reference/"
  },"252": {
    "doc": "Full-Text Queries",
    "title": "Full-text queries",
    "content": "Although you can use HTTP request parameters to perform simple searches, the Elasticsearch query domain-specific language (DSL) lets you specify the full range of search options. The query DSL uses the HTTP request body. Queries specified in this way have the added advantage of being more explicit in their intent and easier to tune over time. This page lists all full-text query types and common options. Given the sheer number of options and subtle behaviors, the best method of ensuring useful search results is to test different queries against representative indices and verify the output. . | Match | Multi match | Match boolean prefix | Match phrase | Match phrase prefix | Common terms | Query string | Simple query string | Match all | Match none | Options | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#full-text-queries",
    "relUrl": "/docs/elasticsearch/full-text/#full-text-queries"
  },"253": {
    "doc": "Full-Text Queries",
    "title": "Match",
    "content": "Creates a boolean query that returns results if the search term is present in the field. The most basic form of the query provides only a field (title) and a term (wind): . GET _search { \"query\": { \"match\": { \"title\": \"wind\" } } } . For an example that uses curl, try: . curl --insecure -XGET -u admin:admin https://&lt;host&gt;:&lt;port&gt;/&lt;index&gt;/_search \\ -H \"content-type: application/json\" \\ -d '{ \"query\": { \"match\": { \"title\": \"wind\" } } }' . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"match\": { \"title\": { \"query\": \"wind\", \"fuzziness\": \"AUTO\", \"fuzzy_transpositions\": true, \"operator\": \"or\", \"minimum_should_match\": 1, \"analyzer\": \"standard\", \"zero_terms_query\": \"none\", \"lenient\": false, \"cutoff_frequency\": 0.01, \"prefix_length\": 0, \"max_expansions\": 50, \"boost\": 1 } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match",
    "relUrl": "/docs/elasticsearch/full-text/#match"
  },"254": {
    "doc": "Full-Text Queries",
    "title": "Multi match",
    "content": "Similar to match, but searches multiple fields. The ^ lets you “boost” certain fields. Boosts are multipliers that weigh matches in one field more heavily than matches in other fields. In the following example, a match for “wind” in the title field influences _score four times as much as a match in the plot field. The result is that films like The Wind Rises and Gone with the Wind are near the top of the search results, and films like Twister and Sharknado, which presumably have “wind” in their plot summaries, are near the bottom. GET _search { \"query\": { \"multi_match\": { \"query\": \"wind\", \"fields\": [\"title^4\", \"plot\"] } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"multi_match\": { \"query\": \"wind\", \"fields\": [\"title^4\", \"description\"], \"type\": \"most_fields\", \"operator\": \"and\", \"minimum_should_match\": 3, \"tie_breaker\": 0.0, \"analyzer\": \"standard\", \"boost\": 1, \"fuzziness\": \"AUTO\", \"fuzzy_transpositions\": true, \"lenient\": false, \"prefix_length\": 0, \"max_expansions\": 50, \"auto_generate_synonyms_phrase_query\": true, \"cutoff_frequency\": 0.01, \"zero_terms_query\": \"none\" } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#multi-match",
    "relUrl": "/docs/elasticsearch/full-text/#multi-match"
  },"255": {
    "doc": "Full-Text Queries",
    "title": "Match boolean prefix",
    "content": "Similar to match, but creates a prefix query out of the last term in the query string. GET _search { \"query\": { \"match_bool_prefix\": { \"title\": \"rises wi\" } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"match_bool_prefix\": { \"title\": { \"query\": \"rises wi\", \"fuzziness\": \"AUTO\", \"fuzzy_transpositions\": true, \"max_expansions\": 50, \"prefix_length\": 0, \"operator\": \"or\", \"minimum_should_match\": 2, \"analyzer\": \"standard\" } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match-boolean-prefix",
    "relUrl": "/docs/elasticsearch/full-text/#match-boolean-prefix"
  },"256": {
    "doc": "Full-Text Queries",
    "title": "Match phrase",
    "content": "Creates a phrase query that matches a sequence of terms. GET _search { \"query\": { \"match_phrase\": { \"title\": \"the wind rises\" } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"match_phrase\": { \"title\": { \"query\": \"wind rises the\", \"slop\": 3, \"analyzer\": \"standard\", \"zero_terms_query\": \"none\" } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match-phrase",
    "relUrl": "/docs/elasticsearch/full-text/#match-phrase"
  },"257": {
    "doc": "Full-Text Queries",
    "title": "Match phrase prefix",
    "content": "Similar to match phrase, but creates a prefix query out of the last term in the query string. GET _search { \"query\": { \"match_phrase_prefix\": { \"title\": \"the wind ri\" } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"match_phrase_prefix\": { \"title\": { \"query\": \"the wind ri\", \"analyzer\": \"standard\", \"max_expansions\": 50, \"slop\": 3 } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match-phrase-prefix",
    "relUrl": "/docs/elasticsearch/full-text/#match-phrase-prefix"
  },"258": {
    "doc": "Full-Text Queries",
    "title": "Common terms",
    "content": "The common terms query separates the query string into high- and low-frequency terms based on number of occurrences on the shard. Low-frequency terms are weighed more heavily in the results, and high-frequency terms are considered only for documents that already matched one or more low-frequency terms. In that sense, you can think of this query as having a built-in, ever-changing list of stop words. GET _search { \"query\": { \"common\": { \"title\": { \"query\": \"the wind rises\" } } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"common\": { \"title\": { \"query\": \"the wind rises\", \"cutoff_frequency\": 0.002, \"low_freq_operator\": \"or\", \"boost\": 1, \"analyzer\": \"standard\", \"minimum_should_match\": { \"low_freq\" : 2, \"high_freq\" : 3 } } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#common-terms",
    "relUrl": "/docs/elasticsearch/full-text/#common-terms"
  },"259": {
    "doc": "Full-Text Queries",
    "title": "Query string",
    "content": "The query string query splits text based on operators and analyzes each individually. If you search using the HTTP request parameters (i.e. _search?q=wind), Elasticsearch creates a query string query. GET _search { \"query\": { \"query_string\": { \"query\": \"the wind AND (rises OR rising)\" } } } . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"query_string\": { \"query\": \"the wind AND (rises OR rising)\", \"default_field\": \"title\", \"type\": \"best_fields\", \"fuzziness\": \"AUTO\", \"fuzzy_transpositions\": true, \"fuzzy_max_expansions\": 50, \"fuzzy_prefix_length\": 0, \"minimum_should_match\": 1, \"default_operator\": \"or\", \"analyzer\": \"standard\", \"lenient\": false, \"boost\": 1, \"allow_leading_wildcard\": true, \"enable_position_increments\": true, \"phrase_slop\": 3, \"max_determinized_states\": 10000, \"time_zone\": \"-08:00\", \"quote_field_suffix\": \"\", \"quote_analyzer\": \"standard\", \"analyze_wildcard\": false, \"auto_generate_synonyms_phrase_query\": true } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#query-string",
    "relUrl": "/docs/elasticsearch/full-text/#query-string"
  },"260": {
    "doc": "Full-Text Queries",
    "title": "Simple query string",
    "content": "The simple query string query is like the query string query, but it lets advanced users specify many arguments directly in the query string. The query discards any invalid portions of the query string. GET _search { \"query\": { \"simple_query_string\": { \"query\": \"\\\"rises wind the\\\"~4 | *ising~2\", \"fields\": [\"title\"] } } } . | Special character | Behavior | . | + | Acts as the and operator. | . | | Acts as the or operator. | . | * | Acts as a wildcard. | . | \"\" | Wraps several terms into a phrase. | . | () | Wraps a clause for precedence. | . | ~n | When used after a term (e.g. wnid~3), sets fuzziness. When used after a phrase, sets slop. See Options. | . | - | Negates the term. | . The query accepts the following options. For descriptions of each, see Options. GET _search { \"query\": { \"simple_query_string\": { \"query\": \"\\\"rises wind the\\\"~4 | *ising~2\", \"fields\": [\"title\"], \"flags\": \"ALL\", \"fuzzy_transpositions\": true, \"fuzzy_max_expansions\": 50, \"fuzzy_prefix_length\": 0, \"minimum_should_match\": 1, \"default_operator\": \"or\", \"analyzer\": \"standard\", \"lenient\": false, \"quote_field_suffix\": \"\", \"analyze_wildcard\": false, \"auto_generate_synonyms_phrase_query\": true } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#simple-query-string",
    "relUrl": "/docs/elasticsearch/full-text/#simple-query-string"
  },"261": {
    "doc": "Full-Text Queries",
    "title": "Match all",
    "content": "Matches all documents. Can be useful for testing. GET _search { \"query\": { \"match_all\": {} } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match-all",
    "relUrl": "/docs/elasticsearch/full-text/#match-all"
  },"262": {
    "doc": "Full-Text Queries",
    "title": "Match none",
    "content": "Matches no documents. Rarely useful. GET _search { \"query\": { \"match_none\": {} } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#match-none",
    "relUrl": "/docs/elasticsearch/full-text/#match-none"
  },"263": {
    "doc": "Full-Text Queries",
    "title": "Options",
    "content": "| Option | Valid values | Description | . | allow_leading_wildcard | Boolean | Whether * and ? are allowed as the first character of a search term. The default is true. | . | analyze_wildcard | Boolean | Whether Elasticsearch should attempt to analyze wildcard terms. Some analyzers do a poor job at this task, so the default is false. | . | analyzer | standard, simple, whitespace, stop, keyword, pattern, &lt;language&gt;, fingerprint | The analyzer you want to use for the query. Different analyzers have different character filters, tokenizers, and token filters. The stop analyzer, for example, removes stop words (e.g. “an,” “but,” “this”) from the query string. | . | auto_generate_synonyms_phrase_query | Boolean | A value of true (default) automatically generates phrase queries for multi-term synonyms. For example, if you have the synonym \"ba, batting average\" and search for “ba,” Elasticsearch searches for ba OR \"batting average\" (if this option is true) or ba OR (batting AND average) (if this option is false). | . | boost | Floating-point | Boosts the clause by the given multiplier. Useful for weighing clauses in compound queries. The default is 1.0. | . | cutoff_frequency | Between 0.0 and 1.0 or a positive integer | This value lets you define high and low frequency terms based on number of occurrences in the index. Numbers between 0 and 1 are treated as a percentage. For example, 0.10 is 10%. This value means that if a word occurs within the search field in more than 10% of the documents on the shard, Elasticsearch considers the word “high frequency” and deemphasizes it when calculating search score.Because this setting is per shard, testing its impact on search results can be challenging unless a cluster has many documents. | . | enable_position_increments | Boolean | When true, result queries are aware of position increments. This setting is useful when the removal of stop words leaves an unwanted “gap” between terms. The default is true. | . | fields | String array | The list of fields to search (e.g. \"fields\": [\"title^4\", \"description\"]). If unspecified, defaults to the index.query.default_field setting, which defaults to [\"*\"]. | . | flags | String | A |-delimited string of flags to enable (e.g. AND|OR|NOT). The default is ALL. | . | fuzziness | AUTO, 0, or a positive integer | The number of character edits (insert, delete, substitute) that it takes to change one word to another when determining whether a term matched a value. For example, the distance between wined and wind is 1. The default, AUTO, chooses a value based on the length of each term and is a good choice for most use cases. | . | fuzzy_transpositions | Boolean | Setting fuzzy_transpositions to true (default) adds swaps of adjacent characters to the insert, delete, and substitute operations of the fuzziness option. For example, the distance between wind and wnid is 1 if fuzzy_transpositions is true (swap “n” and “i”) and 2 if it is false (delete “n”, insert “n”). If fuzzy_transpositions is false, rewind and wnid have the same distance (2) from wind, despite the more human-centric opinion that wnid is an obvious typo. The default is a good choice for most use cases. | . | lenient | Boolean | Setting lenient to true lets you ignore data type mismatches between the query and the document field. For example, a query string of “8.2” could match a field of type float. The default is false. | . | low_freq_operator | and, or | The operator for low-frequency terms. The default is or. See Common Terms queries and operator in this table. | . | max_determinized_states | Positive integer | The maximum number of “states” (a measure of complexity) that Lucene can create for query strings that contain regular expressions (e.g. \"query\": \"/wind.+?/\"). Larger numbers allow for queries that use more memory. The default is 10,000. | . | max_expansions | Positive integer | Fuzzy queries “expand to” a number of matching terms that are within the distance specified in fuzziness. Then Elasticsearch tries to match those terms against its indices. max_expansions specifies the maximum number of terms that the fuzzy query expands to. The default is 50. | . | minimum_should_match | Positive or negative integer, positive or negative percentage, combination | If the query string contains multiple search terms and you used the or operator, the number of terms that need to match for the document to be considered a match. For example, if minimum_should_match is 2, “wind often rising” does not match “The Wind Rises.” If minimum_should_match is 1, it matches. This option also has low_freq and high_freq properties for Common Terms queries. | . | operator | or, and | If the query string contains multiple search terms, whether all terms need to match (and) or only one term needs to match (or) for a document to be considered a match. | . | phrase_slop | 0 (default) or a positive integer | See slop. | . | prefix_length | 0 (default) or a positive integer | The number of leading characters that are not considered in fuzziness. | . | quote_field_suffix | String | This option lets you search different fields depending on whether terms are wrapped in quotes. For example, if quote_field_suffix is \".exact\" and you search for \"lightly\" (in quotes) in the title field, Elasticsearch searches the title.exact field. This second field might use a different type (e.g. keyword rather than text) or a different analyzer. The default is null. | . | rewrite | constant_score, scoring_boolean, constant_score_boolean, top_terms_N, top_terms_boost_N, top_terms_blended_freqs_N | Determines how Elasticsearch rewrites and scores multi-term queries. The default is constant_score. | . | slop | 0 (default) or a positive integer | Controls the degree to which words in a query can be misordered and still be considered a match. From the Lucene documentation: “The number of other words permitted between words in query phrase. For example, to switch the order of two words requires two moves (the first move places the words atop one another), so to permit re-orderings of phrases, the slop must be at least two. A value of zero requires an exact match.” | . | tie_breaker | 0.0 (default) to 1.0 | Changes the way Elasticsearch scores searches. For example, a type of best_fields typically uses the highest score from any one field. If you specify a tie_breaker value between 0.0 and 1.0, the score changes to highest score + tie_breaker * score for all other matching fields. If you specify a value of 1.0, Elasticsearch adds together the scores for all matching fields (effectively defeating the purpose of best_fields). | . | time_zone | UTC offset | The time zone to use (e.g. -08:00) if the query string contains a date range (e.g. \"query\": \"wind rises release_date[2012-01-01 TO 2014-01-01]\"). The default is UTC. | . | type | best_fields, most_fields, cross-fields, phrase, phrase_prefix | Determines how Elasticsearch executes the query and scores the results. The default is best_fields. | . | zero_terms_query | none, all | If the analyzer removes all terms from a query string, whether to match no documents (default) or all documents. For example, the stop analyzer removes all terms from the string “an but this.” | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/#options",
    "relUrl": "/docs/elasticsearch/full-text/#options"
  },"264": {
    "doc": "Full-Text Queries",
    "title": "Full-Text Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/full-text/",
    "relUrl": "/docs/elasticsearch/full-text/"
  },"265": {
    "doc": "Functions",
    "title": "Functions",
    "content": "You must enable fielddata in the document mapping for most string functions to work properly. The specification shows the return type of the function with a generic type T as the argument. For example, abs(number T) -&gt; T means that the function abs accepts a numerical argument of type T, which could be any sub-type of the number type, and it returns the actual type of T as the return type. The SQL plugin supports the following functions. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/",
    "relUrl": "/docs/sql/functions/"
  },"266": {
    "doc": "Functions",
    "title": "Mathematical",
    "content": "| Function | Specification | Example | . | abs | abs(number T) -&gt; T | SELECT abs(0.5) FROM my-index LIMIT 1 | . | add | add(number T, number) -&gt; T | SELECT add(1, 5) FROM my-index LIMIT 1 | . | cbrt | cbrt(number T) -&gt; T | SELECT cbrt(0.5) FROM my-index LIMIT 1 | . | ceil | ceil(number T) -&gt; T | SELECT ceil(0.5) FROM my-index LIMIT 1 | . | conv | conv(string T, int a, int b) -&gt; T | SELECT CONV('12', 10, 16), CONV('2C', 16, 10), CONV(12, 10, 2), CONV(1111, 2, 10) FROM my-index LIMIT 1 | . | crc32 | crc32(string T) -&gt; T | SELECT crc32('MySQL') FROM my-index LIMIT 1 | . | divide | divide(number T, number) -&gt; T | SELECT divide(1, 0.5) FROM my-index LIMIT 1 | . | e | e() -&gt; double | SELECT e() FROM my-index LIMIT 1 | . | exp | exp(number T) -&gt; T | SELECT exp(0.5) FROM my-index LIMIT 1 | . | expm1 | expm1(number T) -&gt; T | SELECT expm1(0.5) FROM my-index LIMIT 1 | . | floor | floor(number T) -&gt; T | SELECT floor(0.5) AS Rounded_Down FROM my-index LIMIT 1 | . | ln | ln(number T) -&gt; double | SELECT ln(10) FROM my-index LIMIT 1 | . | log | log(number T) -&gt; double or log(number T, number) -&gt; double | SELECT log(10) FROM my-index LIMIT 1 | . | log2 | log2(number T) -&gt; double | SELECT log2(10) FROM my-index LIMIT 1 | . | log10 | log10(number T) -&gt; double | SELECT log10(10) FROM my-index LIMIT 1 | . | mod | mod(number T, number) -&gt; T | SELECT modulus(2, 3) FROM my-index LIMIT 1 | . | multiply | multiply(number T, number) -&gt; number | SELECT multiply(2, 3) FROM my-index LIMIT 1 | . | pi | pi() -&gt; double | SELECT pi() FROM my-index LIMIT 1 | . | pow | pow(number T) -&gt; T or pow(number T, number) -&gt; T | SELECT pow(2, 3) FROM my-index LIMIT 1 | . | power | power(number T) -&gt; T or power(number T, number) -&gt; T | SELECT power(2, 3) FROM my-index LIMIT 1 | . | rand | rand() -&gt; number or rand(number T) -&gt; T | SELECT rand(0.5) FROM my-index LIMIT 1 | . | rint | rint(number T) -&gt; T | SELECT rint(1.5) FROM my-index LIMIT 1 | . | round | round(number T) -&gt; T | SELECT round(1.5) FROM my-index LIMIT 1 | . | sign | sign(number T) -&gt; T | SELECT sign(1.5) FROM my-index LIMIT 1 | . | signum | signum(number T) -&gt; T | SELECT signum(0.5) FROM my-index LIMIT 1 | . | sqrt | sqrt(number T) -&gt; T | SELECT sqrt(0.5) FROM my-index LIMIT 1 | . | strcmp | strcmp(string T, string T) -&gt; T | SELECT strcmp('hello', 'hello') FROM my-index LIMIT 1 | . | subtract | subtract(number T, number) -&gt; T | SELECT subtract(3, 2) FROM my-index LIMIT 1 | . | truncate | truncate(number T, number T) -&gt; T | SELECT truncate(56.78, 1) FROM my-index LIMIT 1 | . | / | number [op] number -&gt; number | SELECT 1 / 100 FROM my-index LIMIT 1 | . | % | number [op] number -&gt; number | SELECT 1 % 100 FROM my-index LIMIT 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#mathematical",
    "relUrl": "/docs/sql/functions/#mathematical"
  },"267": {
    "doc": "Functions",
    "title": "Trigonometric",
    "content": "| Function | Specification | Example | . | acos | acos(number T) -&gt; double | SELECT acos(0.5) FROM my-index LIMIT 1 | . | asin | asin(number T) -&gt; double | SELECT asin(0.5) FROM my-index LIMIT 1 | . | atan | atan(number T) -&gt; double | SELECT atan(0.5) FROM my-index LIMIT 1 | . | atan2 | atan2(number T, number) -&gt; double | SELECT atan2(1, 0.5) FROM my-index LIMIT 1 | . | cos | cos(number T) -&gt; double | SELECT cos(0.5) FROM my-index LIMIT 1 | . | cosh | cosh(number T) -&gt; double | SELECT cosh(0.5) FROM my-index LIMIT 1 | . | cot | cot(number T) -&gt; double | SELECT cot(0.5) FROM my-index LIMIT 1 | . | degrees | degrees(number T) -&gt; double | SELECT degrees(0.5) FROM my-index LIMIT 1 | . | radians | radians(number T) -&gt; double | SELECT radians(0.5) FROM my-index LIMIT 1 | . | sin | sin(number T) -&gt; double | SELECT sin(0.5) FROM my-index LIMIT 1 | . | sinh | sinh(number T) -&gt; double | SELECT sinh(0.5) FROM my-index LIMIT 1 | . | tan | tan(number T) -&gt; double | SELECT tan(0.5) FROM my-index LIMIT 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#trigonometric",
    "relUrl": "/docs/sql/functions/#trigonometric"
  },"268": {
    "doc": "Functions",
    "title": "Date and time",
    "content": "| Function | Specification | Example | . | adddate | adddate(date, INTERVAL expr unit) -&gt; date | SELECT adddate(date('2020-08-26'), INTERVAL 1 hour) FROM my-index LIMIT 1 | . | curdate | curdate() -&gt; date | SELECT curdate() FROM my-index LIMIT 1 | . | date | date(date) -&gt; date | SELECT date() FROM my-index LIMIT 1 | . | date_format | date_format(date, string) -&gt; string or date_format(date, string, string) -&gt; string | SELECT date_format(date, 'Y') FROM my-index LIMIT 1 | . | date_sub | date_sub(date, INTERVAL expr unit) -&gt; date | SELECT date_sub(date('2008-01-02'), INTERVAL 31 day) FROM my-index LIMIT 1 | . | dayofmonth | dayofmonth(date) -&gt; integer | SELECT dayofmonth(date) FROM my-index LIMIT 1 | . | dayname | dayname(date) -&gt; string | SELECT dayname(date('2020-08-26')) FROM my-index LIMIT 1 | . | dayofyear | dayofyear(date) -&gt; integer | SELECT dayofyear(date('2020-08-26')) FROM my-index LIMIT 1 | . | dayofweek | dayofweek(date) -&gt; integer | SELECT dayofweek(date('2020-08-26')) FROM my-index LIMIT 1 | . | from_days | from_days(N) -&gt; integer | SELECT from_days(733687) FROM my-index LIMIT 1 | . | hour | hour(time) -&gt; integer | SELECT hour((time '01:02:03')) FROM my-index LIMIT 1 | . | maketime | maketime(integer, integer, integer) -&gt; date | SELECT maketime(1, 2, 3) FROM my-index LIMIT 1 | . | microsecond | microsecond(expr) -&gt; integer | SELECT microsecond((time '01:02:03.123456')) FROM my-index LIMIT 1 | . | minute | minute(expr) -&gt; integer | SELECT minute((time '01:02:03')) FROM my-index LIMIT 1 | . | month | month(date) -&gt; integer | SELECT month(date) FROM my-index | . | monthname | monthname(date) -&gt; string | SELECT monthname(date) FROM my-index | . | now | now() -&gt; date | SELECT now() FROM my-index LIMIT 1 | . | quarter | quarter(date) -&gt; integer | SELECT quarter(date('2020-08-26')) FROM my-index LIMIT 1 | . | second | second(time) -&gt; integer | SELECT second((time '01:02:03')) FROM my-index LIMIT 1 | . | subdate | subdate(date, INTERVAL expr unit) -&gt; date, datetime | SELECT subdate(date('2008-01-02'), INTERVAL 31 day) FROM my-index LIMIT 1 | . | time | time(expr) -&gt; time | SELECT time('13:49:00') FROM my-index LIMIT 1 | . | time_to_sec | time_to_sec(time) -&gt; long | SELECT time_to_sec(time '22:23:00') FROM my-index LIMIT 1 | . | timestamp | timestamp(date) -&gt; date | SELECT timestamp(date) FROM my-index LIMIT 1 | . | to_days | to_days(date) -&gt; long | SELECT to_days(date '2008-10-07') FROM my-index LIMIT 1 | . | week | week(date[mode]) -&gt; integer | SELECT week(date('2008-02-20')) FROM my-index LIMIT 1 | . | year | year(date) -&gt; integer | SELECT year(date) FROM my-index LIMIT 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#date-and-time",
    "relUrl": "/docs/sql/functions/#date-and-time"
  },"269": {
    "doc": "Functions",
    "title": "String",
    "content": "| Function | Specification | Example | . | ascii | ascii(string T) -&gt; integer | SELECT ascii(name.keyword) FROM my-index LIMIT 1 | . | concat | concat(str1, str2) -&gt; string | SELECT concat('hello', 'world') FROM my-index LIMIT 1 | . | concat_ws | concat_ws(separator, string, string…) -&gt; string | SELECT concat_ws(\"-\", \"Tutorial\", \"is\", \"fun!\") FROM my-index LIMIT 1 | . | left | left(string T, integer) -&gt; T | SELECT left('hello', 2) FROM my-index LIMIT 1 | . | length | length(string) -&gt; integer | SELECT length('hello') FROM my-index LIMIT 1 | . | locate | locate(string, string, integer) -&gt; integer or locate(string, string) -&gt; INTEGER | SELECT locate('o', 'hello') FROM my-index LIMIT 1, SELECT locate('l', 'hello', 3) FROM my-index LIMIT 1 | . | replace | replace(string T, string, string) -&gt; T | SELECT replace('hello', 'l', 'x') FROM my-index LIMIT 1 | . | right | right(string T, integer) -&gt; T | SELECT right('hello', 1) FROM my-index LIMIT 1 | . | rtrim | rtrim(string T) -&gt; T | SELECT rtrim(name.keyword) FROM my-index LIMIT 1 | . | substring | substring(string T, integer, integer) -&gt; T | SELECT substring(name.keyword, 2,5) FROM my-index LIMIT 1 | . | trim | trim(string T) -&gt; T | SELECT trim(' hello') FROM my-index LIMIT 1 | . | upper | upper(string T) -&gt; T | SELECT upper('helloworld') FROM my-index LIMIT 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#string",
    "relUrl": "/docs/sql/functions/#string"
  },"270": {
    "doc": "Functions",
    "title": "Aggregate",
    "content": "| Function | Specification | Example | . | avg | avg(number T) -&gt; T | SELECT avg(2, 3) FROM my-index LIMIT 1 | . | count | count(number T) -&gt; T | SELECT count(date) FROM my-index LIMIT 1 | . | min | min(number T, number) -&gt; T | SELECT min(2, 3) FROM my-index LIMIT 1 | . | show | show(string T) -&gt; T | SHOW TABLES LIKE my-index | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#aggregate",
    "relUrl": "/docs/sql/functions/#aggregate"
  },"271": {
    "doc": "Functions",
    "title": "Advanced",
    "content": "| Function | Specification | Example | . | if | if(boolean, es_type, es_type) -&gt; es_type | SELECT if(false, 0, 1) FROM my-index LIMIT 1, SELECT if(true, 0, 1) FROM my-index LIMIT 1 | . | ifnull | ifnull(es_type, es_type) -&gt; es_type | SELECT ifnull('hello', 1) FROM my-index LIMIT 1, SELECT ifnull(null, 1) FROM my-index LIMIT 1 | . | isnull | isnull(es_type) -&gt; integer | SELECT isnull(null) FROM my-index LIMIT 1, SELECT isnull(1) FROM my-index LIMIT 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/functions/#advanced",
    "relUrl": "/docs/sql/functions/#advanced"
  },"272": {
    "doc": "Functions",
    "title": "Functions",
    "content": "The PPL plugin supports all SQL functions. To learn more, see SQL Functions. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/functions/",
    "relUrl": "/docs/ppl/functions/"
  },"273": {
    "doc": "Generate Certificates",
    "title": "Generate certificates",
    "content": "If you don’t have access to a certificate authority (CA) for your organization and want to use Open Distro for Elasticsearch for non-demo purposes, you can generate your own self-signed certificates using OpenSSL. You can probably find OpenSSL in the package manager for your operating system. On CentOS, use Yum: . sudo yum install openssl . On macOS, use Homebrew: . brew install openssl . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#generate-certificates",
    "relUrl": "/docs/security/configuration/generate-certificates/#generate-certificates"
  },"274": {
    "doc": "Generate Certificates",
    "title": "Generate a private key",
    "content": "The first step in this process is to generate a private key using the genrsa command. As the name suggests, you should keep this file private. Private keys must be of sufficient length to be secure, so specify 2048: . openssl genrsa -out root-ca-key.pem 2048 . You can optionally add the -aes256 option to encrypt the key using the AES-256 standard. This option requires a password. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#generate-a-private-key",
    "relUrl": "/docs/security/configuration/generate-certificates/#generate-a-private-key"
  },"275": {
    "doc": "Generate Certificates",
    "title": "Generate a root certificate",
    "content": "Next, use the key to generate a self-signed certificate for the root CA: . openssl req -new -x509 -sha256 -key root-ca-key.pem -out root-ca.pem . | The -x509 option specifies that you want a self-signed certificate rather than a certificate request. | The -sha256 option sets the hash algorithm to SHA-256. SHA-256 is the default in later versions of OpenSSL, but earlier versions might use SHA-1. | Optionally, add -days 3650 (10 years) or some other number of days to set an expiration date. | . Follow the prompts to specify details for your organization. Together, these details form the distinguished name (DN) of your CA. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#generate-a-root-certificate",
    "relUrl": "/docs/security/configuration/generate-certificates/#generate-a-root-certificate"
  },"276": {
    "doc": "Generate Certificates",
    "title": "Generate an admin certificate",
    "content": "To generate an admin certificate, first create a new key: . openssl genrsa -out admin-key-temp.pem 2048 . Then convert that key to PKCS#8 format for use in Java using a PKCS#12-compatible algorithm (3DES): . openssl pkcs8 -inform PEM -outform PEM -in admin-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out admin-key.pem . Next, create a certificate signing request (CSR). This file acts as an application to a CA for a signed certificate: . openssl req -new -key admin-key.pem -out admin.csr . Follow the prompts to fill in the details. You don’t need to specify a challenge password. As noted in the OpenSSL Cookbook, “Having a challenge password does not increase the security of the CSR in any way.” . Finally, generate the certificate itself: . openssl x509 -req -in admin.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out admin.pem . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#generate-an-admin-certificate",
    "relUrl": "/docs/security/configuration/generate-certificates/#generate-an-admin-certificate"
  },"277": {
    "doc": "Generate Certificates",
    "title": "(Optional) Generate node and client certificates",
    "content": "Follow the steps in Generate admin certificates with new file names to generate a new certificate for each node and as many client certificates as you need. Each certificate should use its own private key. If you generate node certificates and have opendistro_security.ssl.transport.enforce_hostname_verification set to true (default), be sure to specify a common name (CN) for the certificate that matches the hostname of the intended node. If you want to use the same node certificate on all nodes (not recommended), set the hostname verification to false. For more information, see Configure TLS certificates. Sample script . # Root CA openssl genrsa -out root-ca-key.pem 2048 openssl req -new -x509 -sha256 -key root-ca-key.pem -out root-ca.pem # Admin cert openssl genrsa -out admin-key-temp.pem 2048 openssl pkcs8 -inform PEM -outform PEM -in admin-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out admin-key.pem openssl req -new -key admin-key.pem -out admin.csr openssl x509 -req -in admin.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out admin.pem # Node cert openssl genrsa -out node-key-temp.pem 2048 openssl pkcs8 -inform PEM -outform PEM -in node-key-temp.pem -topk8 -nocrypt -v1 PBE-SHA1-3DES -out node-key.pem openssl req -new -key node-key.pem -out node.csr openssl x509 -req -in node.csr -CA root-ca.pem -CAkey root-ca-key.pem -CAcreateserial -sha256 -out node.pem # Cleanup rm admin-key-temp.pem rm admin.csr rm node-key-temp.pem rm node.csr . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#optional-generate-node-and-client-certificates",
    "relUrl": "/docs/security/configuration/generate-certificates/#optional-generate-node-and-client-certificates"
  },"278": {
    "doc": "Generate Certificates",
    "title": "Get distinguished names",
    "content": "If you created admin and node certificates, you must specify their distinguished names (DNs) in elasticsearch.yml on all nodes: . opendistro_security.authcz.admin_dn: - 'CN=ADMIN,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA' opendistro_security.nodes_dn: - 'CN=node1.example.com,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA' - 'CN=node2.example.com,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA' . But if you look at the subject of the certificate after creating it, you might see different formatting: . subject=/C=CA/ST=ONTARIO/L=TORONTO/O=ORG/OU=UNIT/CN=node1.example.com . If you compare this string to the ones in elasticsearch.yml above, you can see that you need to invert the order of elements and use commas rather than slashes. Enter this command to get the correct string: . openssl x509 -subject -nameopt RFC2253 -noout -in node.pem . Then you can copy and paste the output into elasticsearch.yml: . subject= CN=node1.example.com,OU=UNIT,O=ORG,L=TORONTO,ST=ONTARIO,C=CA . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#get-distinguished-names",
    "relUrl": "/docs/security/configuration/generate-certificates/#get-distinguished-names"
  },"279": {
    "doc": "Generate Certificates",
    "title": "Configure certificates",
    "content": "This process generates many files, but these are the ones you need to add to your cluster configuration: . | root-ca.pem | admin.pem | admin-key.pem | (Optional) each-node-cert.pem | (Optional) each-node-key.pem | . For information about adding and configuring these certificates, see Docker security configuration and Configure TLS certificates. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#configure-certificates",
    "relUrl": "/docs/security/configuration/generate-certificates/#configure-certificates"
  },"280": {
    "doc": "Generate Certificates",
    "title": "Run securityadmin.sh",
    "content": "After configuring your certificates and starting Elasticsearch, run securityadmin.sh to initialize the security plugin: ./securityadmin.sh -cd ../securityconfig/ -icl -nhnv -cacert ../../../config/root-ca.pem -cert ../../../config/admin.pem -key ../../../config/admin-key.pem . For more information about what this command does, see Apply configuration changes and Change passwords for read-only users. If you use Docker, see Bash access to containers. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#run-securityadminsh",
    "relUrl": "/docs/security/configuration/generate-certificates/#run-securityadminsh"
  },"281": {
    "doc": "Generate Certificates",
    "title": "Kibana",
    "content": "Depending on your settings in kibana.yml, you might need to add root-ca.pem to your Kibana node. You have two options: disable SSL verification or add the root CA. | Disable SSL verification: . elasticsearch.ssl.verificationMode: none . | Add the root CA: . elasticsearch.ssl.certificateAuthorities: [\"/usr/share/kibana/config/root-ca.pem\"] elasticsearch.ssl.verificationMode: full . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/#kibana",
    "relUrl": "/docs/security/configuration/generate-certificates/#kibana"
  },"282": {
    "doc": "Generate Certificates",
    "title": "Generate Certificates",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/generate-certificates/",
    "relUrl": "/docs/security/configuration/generate-certificates/"
  },"283": {
    "doc": "Helm",
    "title": "Helm",
    "content": "Helm is a package manager that allows you to easily install and manage Elasticsearch in a Kubernetes cluster. You can define your Elasticsearch configurations in a YAML file and use Helm to deploy your applications in a version-controlled and reproducible way. The Helm chart contains the resources described in the following table. | Resource | Description | . | Chart.yaml | Information about the chart. | . | values.yaml | Default configuration values for the chart. | . | templates | Templates that combine with values to generate the Kubernetes manifest files. | . The specification in the default Helm chart supports many standard use cases and setups. You can modify the default chart to configure your desired specifications and set Transport Layer Security (TLS) and role-based access control (RBAC). For information about the default configuration, steps to configure security, and configurable parameters, see the README. The instructions here assume you have a Kubernetes cluster with Helm preinstalled. See the Kubernetes documentation for steps to configure a Kubernetes cluster and the Helm documentation to install Helm. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/helm/",
    "relUrl": "/docs/install/helm/"
  },"284": {
    "doc": "Helm",
    "title": "Install using Helm",
    "content": ". | Clone the opendistro-build repository: . git clone https://github.com/opendistro-for-elasticsearch/opendistro-build . You can use the release tag (e.g. v1.7.0 or v1.8.0) to get the specific Open Distro for Elasticsearch version. | Change to the opendistro-es directory: . cd opendistro-build/helm/opendistro-es/ . | Package the Helm chart: . helm package . | Deploy Elasticsearch: . helm install --generate-name opendistro-es-1.11.0.tgz . | . The output shows you the specifications instantiated from the install. To customize the deployment, pass in the values that you want to override with a custom YAML file: . helm install --values=customevalues.yaml opendistro-es-1.11.0.tgz . Sample output . NAME: opendistro-es LAST DEPLOYED: Fri Jan 17 14:44:19 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None . To make sure your Elasticsearch pod is up and running, run the following command: . $ kubectl get pods NAME READY STATUS RESTARTS AGE opendistro-es-client-988fb9fbf-ph8f 1/1 Running 0 3m30s opendistro-es-data-0 1/1 Running 0 3m30s opendistro-es-kibana-786f547486-75gw4 1/1 Running 0 3m31s opendistro-es-master-0 1/1 Running 0 3m30s . To access the Elasticsearch shell: . $ kubectl exec -it opendistro-es-master-1 -- /bin/bash . You can send requests to the pod to verify that Elasticsearch is up and running: . $ curl -XGET https://localhost:9200 -u admin:admin --insecure . To set up port forwarding to access Kibana, exit the Elasticsearch shell and run the following command: . $ kubectl port-forward deployment/opendistro-es-kibana 5601 . You can now access Kibana from your browser at: http://localhost:5601. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/helm/#install-using-helm",
    "relUrl": "/docs/install/helm/#install-using-helm"
  },"285": {
    "doc": "Helm",
    "title": "Uninstall using Helm",
    "content": "To delete or uninstall this deployment, run the following command: . helm delete opendistro-es . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/helm/#uninstall-using-helm",
    "relUrl": "/docs/install/helm/#uninstall-using-helm"
  },"286": {
    "doc": "User Impersonation",
    "title": "User impersonation",
    "content": "User impersonation allows specially privileged users to act as another user without knowledge of nor access to the impersonated user’s credentials. Impersonation can be useful for testing and troubleshooting, or for allowing system services to safely act as a user. Impersonation can occur on either the REST interface or at the transport layer. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/impersonation/#user-impersonation",
    "relUrl": "/docs/security/access-control/impersonation/#user-impersonation"
  },"287": {
    "doc": "User Impersonation",
    "title": "REST interface",
    "content": "To allow one user to impersonate another, add the following to elasticsearch.yml: . opendistro_security.authcz.rest_impersonation_user: &lt;AUTHENTICATED_USER&gt;: - &lt;IMPERSONATED_USER_1&gt; - &lt;IMPERSONATED_USER_2&gt; . The impersonated user field supports wildcards. Setting it to * allows AUTHENTICATED_USER to impersonate any user. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/impersonation/#rest-interface",
    "relUrl": "/docs/security/access-control/impersonation/#rest-interface"
  },"288": {
    "doc": "User Impersonation",
    "title": "Transport interface",
    "content": "In a similar fashion, add the following to enable transport layer impersonation: . opendistro_security.authcz.impersonation_dn: \"CN=spock,OU=client,O=client,L=Test,C=DE\": - worf . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/impersonation/#transport-interface",
    "relUrl": "/docs/security/access-control/impersonation/#transport-interface"
  },"289": {
    "doc": "User Impersonation",
    "title": "Impersonating Users",
    "content": "To impersonate another user, submit a request to the system with the HTTP header opendistro_security_impersonate_as set to the name of the user to be impersonated. A good test is to make a GET request to the _opendistro/_security/authinfo URI: . curl -XGET -u admin:admin -k -H \"opendistro_security_impersonate_as: user_1\" https://localhost:9200/_opendistro/_security/authinfo?pretty . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/impersonation/#impersonating-users",
    "relUrl": "/docs/security/access-control/impersonation/#impersonating-users"
  },"290": {
    "doc": "User Impersonation",
    "title": "User Impersonation",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/impersonation/",
    "relUrl": "/docs/security/access-control/impersonation/"
  },"291": {
    "doc": "Index Aliases",
    "title": "Index alias",
    "content": "An alias is a virtual index name that can point to one or more indices. If your data is spread across multiple indices, rather than keeping track of which indices to query, you can create an alias and query it instead. For example, if you’re storing logs into indices based on the month and you frequently query the logs for the previous two months, you can create a last_2_months alias and update the indices it points to each month. Because you can change the indices an alias points to at any time, referring to indices using aliases in your applications allows you to reindex your data without any downtime. . | Create aliases | Add or remove indices | Manage aliases | Add aliases at index creation | Create filtered aliases | Index alias options | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#index-alias",
    "relUrl": "/docs/elasticsearch/index-alias/#index-alias"
  },"292": {
    "doc": "Index Aliases",
    "title": "Create aliases",
    "content": "To create an alias, use a POST request: . POST _aliases . Use the actions method to specify the list of actions that you want to perform. This command creates an alias named alias1 and adds index-1 to this alias: . POST _aliases { \"actions\": [ { \"add\": { \"index\": \"index-1\", \"alias\": \"alias1\" } } ] } . You should see the following response: . { \"acknowledged\": true } . If this request fails, make sure the index that you’re adding to the alias already exists. To check if alias1 refers to index-1, run the following command: . GET alias1 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#create-aliases",
    "relUrl": "/docs/elasticsearch/index-alias/#create-aliases"
  },"293": {
    "doc": "Index Aliases",
    "title": "Add or remove indices",
    "content": "You can perform multiple actions in the same _aliases operation. For example, the following command removes index-1 and adds index-2 to alias1: . POST _aliases { \"actions\": [ { \"remove\": { \"index\": \"index-1\", \"alias\": \"alias1\" } }, { \"add\": { \"index\": \"index-2\", \"alias\": \"alias1\" } } ] } . The add and remove actions occur atomically, which means that at no point will alias1 point to both index-1 and index-2. You can also add indices based on an index pattern: . POST _aliases { \"actions\": [ { \"add\": { \"index\": \"index*\", \"alias\": \"alias1\" } } ] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#add-or-remove-indices",
    "relUrl": "/docs/elasticsearch/index-alias/#add-or-remove-indices"
  },"294": {
    "doc": "Index Aliases",
    "title": "Manage aliases",
    "content": "To list the mapping of aliases to indices, run the following command: . GET _cat/aliases?v . Sample response . alias index filter routing.index routing.search alias1 index-1 * - - . To check which indices an alias points to, run the following command: . GET _alias/alias1 . Sample response . { \"index-2\": { \"aliases\": { \"alias1\": {} } } } . Conversely, to find which alias points to a specific index, run the following command: . GET /index-2/_alias/* . To check if an alias exists, run the following command: . HEAD /alias1/_alias/ . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#manage-aliases",
    "relUrl": "/docs/elasticsearch/index-alias/#manage-aliases"
  },"295": {
    "doc": "Index Aliases",
    "title": "Add aliases at index creation",
    "content": "You can add an index to an alias as you create the index: . PUT index-1 { \"aliases\": { \"alias1\": {} } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#add-aliases-at-index-creation",
    "relUrl": "/docs/elasticsearch/index-alias/#add-aliases-at-index-creation"
  },"296": {
    "doc": "Index Aliases",
    "title": "Create filtered aliases",
    "content": "You can create a filtered alias to access a subset of documents or fields from the underlying indices. This command adds only a specific timestamp field to alias1: . POST _aliases { \"actions\": [ { \"add\": { \"index\": \"index-1\", \"alias\": \"alias1\", \"filter\": { \"term\": { \"timestamp\": \"1574641891142\" } } } } ] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#create-filtered-aliases",
    "relUrl": "/docs/elasticsearch/index-alias/#create-filtered-aliases"
  },"297": {
    "doc": "Index Aliases",
    "title": "Index alias options",
    "content": "You can specify the options shown in the following table. | Option | Valid values | Description | Required | . | index | String | The name of the index that the alias points to. | Yes | . | alias | String | The name of the alias. | No | . | filter | Object | Add a filter to the alias. | No | . | routing | String | Limit search to an associated shard value. You can specify search_routing and index_routing independently. | No | . | is_write_index | String | Specify the index that accepts any write operations to the alias. If this value is not specified, then no write operations are allowed. | No | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/#index-alias-options",
    "relUrl": "/docs/elasticsearch/index-alias/#index-alias-options"
  },"298": {
    "doc": "Index Aliases",
    "title": "Index Aliases",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-alias/",
    "relUrl": "/docs/elasticsearch/index-alias/"
  },"299": {
    "doc": "Index Data",
    "title": "Index data",
    "content": "You index data using the Elasticsearch REST API. Two APIs exist: the index API and the _bulk API. For situations in which new data arrives incrementally (for example, customer orders from a small business), you might use the index API to add documents individually as they arrive. For situations in which the flow of data is less frequent (for example, weekly updates to a marketing website), you might prefer to generate a file and send it to the _bulk API. For large numbers of documents, lumping requests together and using the _bulk API offers superior performance. If your documents are enormous, however, you might need to index them individually. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#index-data",
    "relUrl": "/docs/elasticsearch/index-data/#index-data"
  },"300": {
    "doc": "Index Data",
    "title": "Introduction to indexing",
    "content": "Before you can search data, you must index it. Indexing is the method by which search engines organize data for fast retrieval. The resulting structure is called, fittingly, an index. In Elasticsearch, the basic unit of data is a JSON document. Within an index, Elasticsearch identifies each document using a unique ID. A request to the index API looks like the following: . PUT &lt;index&gt;/_doc/&lt;id&gt; { \"A JSON\": \"document\" } . A request to the _bulk API looks a little different, because you specify the index and ID in the bulk data: . POST _bulk { \"index\": { \"_index\": \"&lt;index&gt;\", \"_id\": \"&lt;id&gt;\" } } { \"A JSON\": \"document\" } . Bulk data must conform to a specific format, which requires a newline character (\\n) at the end of every line, including the last line. This is the basic format: . Action and metadata\\n Optional document\\n Action and metadata\\n Optional document\\n . The document is optional, because delete actions do not require a document. The other actions (index, create, and update) all require a document. If you specifically want the action to fail if the document already exists, use the create action instead of the index action. To index bulk data using the curl command, navigate to the folder where you have your file saved and run the following command: . curl -H \"Content-Type: application/x-ndjson\" -POST https://localhost:9200/data/_bulk -u admin:admin --insecure --data-binary \"@data.json\" . If any one of the actions in the _bulk API fail, Elasticsearch continues to execute the other actions. Examine the items array in the response to figure out what went wrong. The entries in the items array are in the same order as the actions specified in the request. Elasticsearch features automatic index creation when you add a document to an index that doesn’t already exist. It also features automatic ID generation if you don’t specify an ID in the request. This simple example automatically creates the movies index, indexes the document, and assigns it a unique ID: . POST movies/_doc { \"title\": \"Spirited Away\" } . Automatic ID generation has a clear downside: because the indexing request didn’t specify a document ID, you can’t easily update the document at a later time. Also, if you run this request 10 times, Elasticsearch indexes this document as 10 different documents with unique IDs. To specify an ID of 1, use the following request, and note the use of PUT instead of POST: . PUT movies/_doc/1 { \"title\": \"Spirited Away\" } . Because you must specify an ID, if you run this command 10 times, you still have just one document indexed with the _version field incremented to 10. Indices default to one primary shard and one replica. If you want to specify non-default settings, create the index before adding documents: . PUT more-movies { \"settings\": { \"number_of_shards\": 6, \"number_of_replicas\": 2 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#introduction-to-indexing",
    "relUrl": "/docs/elasticsearch/index-data/#introduction-to-indexing"
  },"301": {
    "doc": "Index Data",
    "title": "Naming restrictions for indices",
    "content": "Elasticsearch indices have the following naming restrictions: . | All letters must be lowercase. | Index names can’t begin with _ (underscore) or - (hyphen). | Index names can’t contain spaces, commas, or the following characters: . :, \", *, +, /, \\, |, ?, #, &gt;, or &lt; . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#naming-restrictions-for-indices",
    "relUrl": "/docs/elasticsearch/index-data/#naming-restrictions-for-indices"
  },"302": {
    "doc": "Index Data",
    "title": "Read data",
    "content": "After you index a document, you can retrieve it by sending a GET request to the same endpoint that you used for indexing: . GET movies/_doc/1 { \"_index\" : \"movies\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 1, \"_seq_no\" : 0, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"title\" : \"Spirited Away\" } } . You can see the document in the _source object. If the document is not found, the found key is false and the _source object is not part of the response. To retrieve multiple documents with a single command, use the _mget operation. The format for retrieving multiple documents is similar to the _bulk operation, where you must specify the index and ID in the request body: . GET _mget { \"docs\": [ { \"_index\": \"&lt;index&gt;\", \"_id\": \"&lt;id&gt;\" }, { \"_index\": \"&lt;index&gt;\", \"_id\": \"&lt;id&gt;\" } ] } . To only return specific fields in a document: . GET _mget { \"docs\": [ { \"_index\": \"&lt;index&gt;\", \"_id\": \"&lt;id&gt;\", \"_source\": \"field1\" }, { \"_index\": \"&lt;index&gt;\", \"_id\": \"&lt;id&gt;\", \"_source\": \"field2\" } ] } . To check if a document exists: . HEAD movies/_doc/&lt;doc-id&gt; . If the document exists, you get back a 200 OK response, and if it doesn’t, you get back a 404 - Not Found error. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#read-data",
    "relUrl": "/docs/elasticsearch/index-data/#read-data"
  },"303": {
    "doc": "Index Data",
    "title": "Update data",
    "content": "To update existing fields or to add new fields, send a POST request to the _update operation with your changes in a doc object: . POST movies/_update/1 { \"doc\": { \"title\": \"Castle in the Sky\", \"genre\": [\"Animation\", \"Fantasy\"] } } . Note the updated title field and new genre field: . GET movies/_doc/1 { \"_index\" : \"movies\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 2, \"_seq_no\" : 1, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"title\" : \"Castle in the Sky\", \"genre\" : [ \"Animation\", \"Fantasy\" ] } } . The document also has an incremented _version field. Use this field to keep track of how many times a document is updated. POST requests make partial updates to documents. To altogether replace a document, use a PUT request: . PUT movies/_doc/1 { \"title\": \"Spirited Away\" } . The document with ID of 1 will contain only the title field, because the entire document will be replaced with the document indexed in this PUT request. Use the upsert object to conditionally update documents based on whether they already exist. Here, if the document exists, its title field changes to Castle in the Sky. If it doesn’t, Elasticsearch indexes the document in the upsert object. POST movies/_update/2 { \"doc\": { \"title\": \"Castle in the Sky\" }, \"upsert\": { \"title\": \"Only Yesterday\", \"genre\": [\"Animation\", \"Fantasy\"], \"date\": 1993 } } . Sample response . { \"_index\" : \"movies\", \"_type\" : \"_doc\", \"_id\" : \"2\", \"_version\" : 2, \"result\" : \"updated\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 3, \"_primary_term\" : 1 } . Each update operation for a document has a unique combination of the _seq_no and _primary_term values. Elasticsearch first writes your updates to the primary shard and then sends this change to all the replica shards. An uncommon issue can occur if multiple users of your Elasticsearch-based application make updates to existing documents in the same index. In this situation, another user can read and update a document from a replica before it receives your update from the primary shard. Your update operation then ends up updating an older version of the document. In the best case, you and the other user make the same changes, and the document remains accurate. In the worst case, the document now contains out-of-date information. To prevent this situation, use the _seq_no and _primary_term values in the request header: . POST movies/_update/2?if_seq_no=3&amp;if_primary_term=1 { \"doc\": { \"title\": \"Castle in the Sky\", \"genre\": [\"Animation\", \"Fantasy\"] } } . If the document is updated after we retrieved it, the _seq_no and _primary_term values are different and our update operation fails with a 409 — Conflict error. When using the _bulk API, specify the _seq_no and _primary_term values within the action metadata. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#update-data",
    "relUrl": "/docs/elasticsearch/index-data/#update-data"
  },"304": {
    "doc": "Index Data",
    "title": "Delete data",
    "content": "To delete a document from an index, use a DELETE request: . DELETE movies/_doc/1 . The DELETE operation increments the _version field. If you add the document back to the same ID, the _version field increments again. This behavior occurs because Elasticsearch deletes the document _source, but retains its metadata. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/#delete-data",
    "relUrl": "/docs/elasticsearch/index-data/#delete-data"
  },"305": {
    "doc": "Index Data",
    "title": "Index Data",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-data/",
    "relUrl": "/docs/elasticsearch/index-data/"
  },"306": {
    "doc": "Index Templates",
    "title": "Index template",
    "content": "Index templates let you initialize new indices with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of these indices have the same number of shards and replicas. . | Create template | Retrieve template | Configure multiple templates | Delete template | Index template options | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#index-template",
    "relUrl": "/docs/elasticsearch/index-templates/#index-template"
  },"307": {
    "doc": "Index Templates",
    "title": "Create template",
    "content": "To create an index template, use a POST request: . POST _index_template . This command creates a template named daily_logs and applies it to any new index whose name matches the regular expression logs-2020-01-* and also adds it to the my_logs alias: . PUT _index_template/daily_logs { \"index_patterns\": [ \"logs-2020-01-*\" ], \"template\": { \"aliases\": { \"my_logs\": {} }, \"settings\": { \"number_of_shards\": 2, \"number_of_replicas\": 1 }, \"mappings\": { \"properties\": { \"timestamp\": { \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" }, \"value\": { \"type\": \"double\" } } } } } . You should see the following response: . { \"acknowledged\": true } . If you create an index named logs-2020-01-01, you can see that it has the mappings and settings from the template: . PUT logs-2020-01-01 GET logs-2020-01-01 . { \"logs-2020-01-01\": { \"aliases\": { \"my_logs\": {} }, \"mappings\": { \"properties\": { \"timestamp\": { \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" }, \"value\": { \"type\": \"double\" } } }, \"settings\": { \"index\": { \"creation_date\": \"1578107970779\", \"number_of_shards\": \"2\", \"number_of_replicas\": \"1\", \"uuid\": \"U1vMDMOHSAuS2IzPcPHpOA\", \"version\": { \"created\": \"7010199\" }, \"provided_name\": \"logs-2020-01-01\" } } } } . Any additional indices that match this pattern—logs-2020-01-02, logs-2020-01-03, and so on—will inherit the same mappings and settings. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#create-template",
    "relUrl": "/docs/elasticsearch/index-templates/#create-template"
  },"308": {
    "doc": "Index Templates",
    "title": "Retrieve template",
    "content": "To list all index templates: . GET _cat/templates . To find a template by its name: . GET _index_template/daily_logs . To get a list of all your templates: . GET _index_template/daily_logs . To get a list of all templates that match a pattern: . GET _index_template/daily* . To check if a specific template exists: . HEAD _index_template/&lt;name&gt; . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#retrieve-template",
    "relUrl": "/docs/elasticsearch/index-templates/#retrieve-template"
  },"309": {
    "doc": "Index Templates",
    "title": "Configure multiple templates",
    "content": "You can create multiple index templates for your indices. If the index name matches more than one template, Elasticsearch merges all mappings and settings from all matching templates and applies them to the index. The settings from the more recently created index templates override the settings of older index templates. So, you can first define a few common settings in a generic template that can act as a catch-all and then add more specialized settings as required. An even better approach is to explicitly specify template priority using the order parameter. Elasticsearch applies templates with lower priority numbers first and then overrides them with templates that have higher priority numbers. For example, say you have the following two templates that both match the logs-2020-01-02 index and there’s a conflict in the number_of_shards field: . Template 1 . PUT _index_template/template-01 { \"index_patterns\": [ \"logs*\" ], \"priority\": 0, \"template\": { \"settings\": { \"number_of_shards\": 2 } } } . Template 2 . PUT _index_template/template-02 { \"index_patterns\": [ \"logs-2020-01-*\" ], \"priority\": 1, \"template\": { \"settings\": { \"number_of_shards\": 3 } } } . Because template-02 has a higher priority value, it takes precedence over template-01 . The logs-2020-01-02 index would have the number_of_shards value as 3. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#configure-multiple-templates",
    "relUrl": "/docs/elasticsearch/index-templates/#configure-multiple-templates"
  },"310": {
    "doc": "Index Templates",
    "title": "Delete template",
    "content": "You can delete an index template using its name, as shown in the following command: . DELETE _index_template/daily_logs . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#delete-template",
    "relUrl": "/docs/elasticsearch/index-templates/#delete-template"
  },"311": {
    "doc": "Index Templates",
    "title": "Index template options",
    "content": "You can specify the options shown in the following table: . | Option | Type | Description | Required | . | priority | Number | Specify the priority of the index template. | No | . | create | Boolean | Specify whether this index template should replace an existing one. | No | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/#index-template-options",
    "relUrl": "/docs/elasticsearch/index-templates/#index-template-options"
  },"312": {
    "doc": "Index Templates",
    "title": "Index Templates",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/index-templates/",
    "relUrl": "/docs/elasticsearch/index-templates/"
  },"313": {
    "doc": "Performance Analyzer",
    "title": "Performance Analyzer",
    "content": "Performance Analyzer is an agent and REST API that allows you to query numerous performance metrics for your cluster, including aggregations of those metrics, independent of the Java Virtual Machine (JVM). PerfTop is the default command line interface (CLI) for displaying those metrics. To download PerfTop, see Download on the Open Distro for Elasticsearch website. You can also install it using npm: . npm install -g @aws/opendistro-for-elasticsearch-perftop . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/",
    "relUrl": "/docs/pa/"
  },"314": {
    "doc": "Performance Analyzer",
    "title": "Get started with PerfTop",
    "content": "The basic syntax is: ./perf-top-&lt;operating_system&gt; --dashboard &lt;dashboard&gt;.json --endpoint &lt;endpoint&gt; . If you’re using npm, the syntax is similar: . perf-top --dashboard &lt;dashboard&gt; --endpoint &lt;endpoint&gt; . If you’re running PerfTop from a node (i.e. locally), specify port 9600: ./perf-top-linux --dashboard dashboards/&lt;dashboard&gt;.json --endpoint localhost:9600 . Otherwise, just specify the Elasticsearch endpoint: ./perf-top-macos --dashboard dashboards/&lt;dashboard&gt;.json --endpoint my-cluster.my-domain.com . PerfTop has four pre-built dashboards in the dashboards directory, but you can also create your own. You can also load the pre-built dashboards (ClusterOverview, ClusterNetworkMemoryAnalysis, ClusterThreadAnalysis, or NodeAnalysis) without the JSON files, such as --dashboard ClusterThreadAnalysis. PerfTop has no interactivity. Start the application, monitor the dashboard, and press esc, q, or Ctrl + C to quit. Other options . | For NodeAnalysis and similar custom dashboards, you can add the --nodename &lt;node_name&gt; argument if you want your dashboard to display metrics for only a single node. | For troubleshooting, add the --logfile &lt;log-file&gt;.txt argument. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/#get-started-with-perftop",
    "relUrl": "/docs/pa/#get-started-with-perftop"
  },"315": {
    "doc": "Performance Analyzer",
    "title": "Performance Analyzer configuration",
    "content": "Storage . Performance Analyzer uses /dev/shm for temporary storage. During heavy workloads on a cluster, Performance Analyzer can use up to 1 GB of space. Docker, however, has a default /dev/shm size of 64 MB. To change this value, you can use the docker run --shm-size 1gb flag or a similar setting in Docker Compose. If you’re not using Docker, check the size of /dev/shm using df -h. The default value is probably plenty, but if you need to change its size, add the following line to /etc/fstab: . tmpfs /dev/shm tmpfs defaults,noexec,nosuid,size=1G 0 0 . Then remount the file system: . mount -o remount /dev/shm . Security . Performance Analyzer supports encryption in transit for requests. It currently does not support client or server authentication for requests. To enable encryption in transit, edit performance-analyzer.properties in your $ES_HOME directory: . vi $ES_HOME/plugins/opendistro_performance_analyzer/pa_config/performance-analyzer.properties . Change the following lines to configure encryption in transit. Note that certificate-file-path must be a certificate for the server, not a root CA: . https-enabled = true #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/#performance-analyzer-configuration",
    "relUrl": "/docs/pa/#performance-analyzer-configuration"
  },"316": {
    "doc": "Alerting",
    "title": "Alerting",
    "content": "Kibana . The alerting feature notifies you when data from one or more Elasticsearch indices meets certain conditions. For example, you might want to notify a Slack channel if your application logs more than five HTTP 503 errors in one hour, or you might want to page a developer if no new documents have been indexed in the past 20 minutes. To get started, choose Alerting in Kibana. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/",
    "relUrl": "/docs/alerting/"
  },"317": {
    "doc": "Upgrade",
    "title": "Upgrade Open Distro for Elasticsearch",
    "content": "New major versions of Elasticsearch generally have breaking changes. Before you upgrade any cluster to 1.0.0, see Upgrade to 1.x.x in this section. Regularly upgrading Open Distro for Elasticsearch gives you access to the latest features, fixes, and improvements. Elasticsearch supports two types of upgrades: rolling and cluster restart. | Rolling upgrades let you shut down one node at a time for minimal disruption of service. Rolling upgrades work between minor versions (for example, 6.5 to 6.8) and also support a single path to the next major version (for example, 6.8 to 7.0). Performing these upgrades can be time-consuming, might require intermediate upgrades to arrive at your desired version, and can affect cluster performance, but the cluster remains available throughout the process. | Cluster restart upgrades require you to shut down all nodes, perform the upgrade, and restart the cluster. Cluster restart upgrades work between minor versions (for example, 6.5 to 6.8) and the next major version (for example, 6.x to 7.0). Cluster restart upgrades are simpler and faster to perform, but require downtime. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/#upgrade-open-distro-for-elasticsearch",
    "relUrl": "/docs/upgrade/#upgrade-open-distro-for-elasticsearch"
  },"318": {
    "doc": "Upgrade",
    "title": "Upgrade",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/",
    "relUrl": "/docs/upgrade/"
  },"319": {
    "doc": "KNN",
    "title": "KNN",
    "content": "Short for its associated k-nearest neighbors algorithm, the KNN plugin lets you search for points in a vector space and find the “nearest neighbors” for those points by Euclidean distance or cosine similarity. Use cases include recommendations (for example, an “other songs you might like” feature in a music application), image recognition, and fraud detection. For background information on the algorithm, see Wikipedia. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/",
    "relUrl": "/docs/knn/"
  },"320": {
    "doc": "KNN",
    "title": "Get started",
    "content": "To use the KNN query type, you must create an index with index.knn: true and add one or more fields of the knn_vector data type. Additionally, you can specify the index.knn.space_type parameter with l2 to use Euclidean distance or cosinesimil to use cosine similarity for calculations. By default, index.knn.space_type is l2. Here is an example that creates an index with two knn_vector fields and uses cosine similarity: . PUT my-knn-index-1 { \"settings\": { \"index\": { \"knn\": true, \"knn.space_type\": \"cosinesimil\" } }, \"mappings\": { \"properties\": { \"my_vector1\": { \"type\": \"knn_vector\", \"dimension\": 2 }, \"my_vector2\": { \"type\": \"knn_vector\", \"dimension\": 4 } } } } . The knn_vector data type supports a single list of up to 10,000 floats, with the number of floats defined by the required dimension parameter. In Elasticsearch, codecs handle the storage and retrieval of indices. The KNN plugin uses a custom codec to write vector data to a graph so that the underlying KNN search library can read it. After you create the index, add some data to it: . POST _bulk { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"1\" } } { \"my_vector1\": [1.5, 2.5], \"price\": 12.2 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"2\" } } { \"my_vector1\": [2.5, 3.5], \"price\": 7.1 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"3\" } } { \"my_vector1\": [3.5, 4.5], \"price\": 12.9 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"4\" } } { \"my_vector1\": [5.5, 6.5], \"price\": 1.2 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"5\" } } { \"my_vector1\": [4.5, 5.5], \"price\": 3.7 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"6\" } } { \"my_vector2\": [1.5, 5.5, 4.5, 6.4], \"price\": 10.3 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"7\" } } { \"my_vector2\": [2.5, 3.5, 5.6, 6.7], \"price\": 5.5 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"8\" } } { \"my_vector2\": [4.5, 5.5, 6.7, 3.7], \"price\": 4.4 } { \"index\": { \"_index\": \"my-knn-index-1\", \"_id\": \"9\" } } { \"my_vector2\": [1.5, 5.5, 4.5, 6.4], \"price\": 8.9 } . Then you can search the data using the knn query type: . GET my-knn-index-1/_search { \"size\": 2, \"query\": { \"knn\": { \"my_vector2\": { \"vector\": [2, 3, 5, 6], \"k\": 2 } } } } . In this case, k is the number of neighbors you want the query to return, but you must also include the size option. Otherwise, you get k results for each shard (and each segment) rather than k results for the entire query. The plugin supports a maximum k value of 10,000. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/#get-started",
    "relUrl": "/docs/knn/#get-started"
  },"321": {
    "doc": "KNN",
    "title": "Compound queries with KNN",
    "content": "If you use the knn query alongside filters or other clauses (e.g. bool, must, match), you might receive fewer than k results. In this example, post_filter reduces the number of results from 2 to 1: . GET my-knn-index-1/_search { \"size\": 2, \"query\": { \"knn\": { \"my_vector2\": { \"vector\": [2, 3, 5, 6], \"k\": 2 } } }, \"post_filter\": { \"range\": { \"price\": { \"gte\": 5, \"lte\": 10 } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/#compound-queries-with-knn",
    "relUrl": "/docs/knn/#compound-queries-with-knn"
  },"322": {
    "doc": "KNN",
    "title": "Custom scoring",
    "content": "The previous example shows a search that returns fewer than k results. If you want to avoid this situation, KNN’s custom scoring option lets you essentially invert the order of events. First, add another index: . PUT my-knn-index-2 { \"settings\": { \"index.knn\": true }, \"mappings\": { \"properties\": { \"my_vector\": { \"type\": \"knn_vector\", \"dimension\": 2 }, \"color\": { \"type\": \"keyword\" } } } } . If you only want to use KNN’s custom scoring, you can omit \"index.knn\": true. The benefit of this approach is faster indexing speed and lower memory usage, but you lose the ability to perform standard KNN queries on the index. Then add some documents: . POST _bulk { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"1\" } } { \"my_vector\": [1, 1], \"color\" : \"RED\" } { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"2\" } } { \"my_vector\": [2, 2], \"color\" : \"RED\" } { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"3\" } } { \"my_vector\": [3, 3], \"color\" : \"RED\" } { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"4\" } } { \"my_vector\": [10, 10], \"color\" : \"BLUE\" } { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"5\" } } { \"my_vector\": [20, 20], \"color\" : \"BLUE\" } { \"index\": { \"_index\": \"my-knn-index-2\", \"_id\": \"6\" } } { \"my_vector\": [30, 30], \"color\" : \"BLUE\" } . Finally, use the script_store query to pre-filter your documents before identifying nearest neighbors: . GET my-knn-index-2/_search { \"size\": 2, \"query\": { \"script_score\": { \"query\": { \"bool\": { \"filter\": { \"term\": { \"color\": \"BLUE\" } } } }, \"script\": { \"lang\": \"knn\", \"source\": \"knn_score\", \"params\": { \"field\": \"my_vector\", \"vector\": [9.9, 9.9], \"space_type\": \"l2\" } } } } } . All parameters are required. | lang is the script type. This value is usually painless, but here you must specify knn. | source is the name of the stored script, knn_store. | field is the field that contains your vector data. | vector is the point you want to find the nearest neighbors for. | space_type is either l2 or cosinesimil. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/#custom-scoring",
    "relUrl": "/docs/knn/#custom-scoring"
  },"323": {
    "doc": "KNN",
    "title": "Performance considerations",
    "content": "The standard KNN query and custom scoring option perform differently. Test using a representative set of documents to see if the search results and latencies match your expectations. Custom scoring works best if the initial filter reduces the number of documents to no more than 20,000. Increasing shard count can improve latencies, but be sure to keep shard size within the recommended guidelines. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/#performance-considerations",
    "relUrl": "/docs/knn/#performance-considerations"
  },"324": {
    "doc": "Install and Configure",
    "title": "Install and configure Open Distro for Elasticsearch",
    "content": "Open Distro for Elasticsearch has many download options: Docker image, RPM package, Debian package, tarball, and Windows executable. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/#install-and-configure-open-distro-for-elasticsearch",
    "relUrl": "/docs/install/#install-and-configure-open-distro-for-elasticsearch"
  },"325": {
    "doc": "Install and Configure",
    "title": "Install and Configure",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/",
    "relUrl": "/docs/install/"
  },"326": {
    "doc": "Anomaly Detection",
    "title": "Anomaly Detection",
    "content": "An anomaly is any unusual change in behavior. Anomalies in your time-series data can lead to valuable insights. For example, for IT infrastructure data, an anomaly in the memory usage metric might help you uncover early signs of a system failure. Discovering anomalies using conventional methods such as creating visualizations and dashboards can be challenging. You can set an alert based on a static threshold, but this requires prior domain knowledge and is not adaptive to data that exhibits organic growth or seasonal behavior. The anomaly detection feature automatically detects anomalies in your Elasticsearch data in near real-time using the Random Cut Forest (RCF) algorithm. RCF is an unsupervised machine learning algorithm that models a sketch of your incoming data stream to compute an anomaly grade and confidence score value for each incoming data point. These values are used to differentiate an anomaly from normal variations. For more information about how RCF works, see Random Cut Forests. You can pair the anomaly detection plugin with the alerting plugin to notify you as soon as an anomaly is detected. To use the anomaly detection plugin, your computer needs to have more than one CPU core. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/",
    "relUrl": "/docs/ad/"
  },"327": {
    "doc": "Anomaly Detection",
    "title": "Get started with Anomaly Detection",
    "content": "To get started, choose Anomaly Detection in Kibana. To first test with sample streaming data, choose Sample Detectors and try out one of the preconfigured detectors. Step 1: Create a detector . A detector is an individual anomaly detection task. You can create multiple detectors, and all the detectors can run simultaneously, with each analyzing data from different sources. | Choose Create Detector. | Enter the Name of the detector and a brief Description. Make sure the name that you enter is unique and descriptive enough to help you to identify the purpose of this detector. | For Data source, choose the index that you want to use as the data source. You can optionally use index patterns to choose multiple indices. | Choose the Timestamp field in your index. | For Data filter, you can optionally filter the index that you chose as the data source. From the Filter type menu, choose Visual filter, and then design your filter query by selecting Fields, Operator, and Value, or choose Custom Expression and add in your own JSON filter query. | For Detector operation settings, define the Detector interval to set the time interval at which the detector collects data. | The detector aggregates the data in this interval, then feeds the aggregated result into the anomaly detection model. The shorter you set this interval, the fewer data points the detector aggregates. The anomaly detection model uses a shingling process, a technique that uses consecutive data points to create a sample for the model. This process needs a certain number of aggregated data points from contiguous intervals. | We recommend you set the detector interval based on your actual data. Too long of an interval might delay the results and too short of an interval might miss some data and also not have a sufficient number of consecutive data points for the shingle process. | . | To add extra processing time for data collection, specify a Window delay value. This is to tell the detector that the data is not ingested into Elasticsearch in real time but with a certain delay. Set the window delay to shift the detector interval to account for this delay. | For example, say the detector interval is 10 minutes and data is ingested into your cluster with a general delay of 1 minute. Assume the detector runs at 2:00, the detector attempts to get the last 10 minutes of data from 1:50 to 2:00, but because of the 1-minute delay, it only gets 9 minutes of data and misses the data from 1:59 to 2:00. Setting the window delay to 1 minute, shifts the interval window to 1:49 - 1:59, so the detector accounts for all 10 minutes of the detector interval time. | . | Choose Create. | . After you create the detector, the next step is to add features to it. Step 2: Add features to your detector . In this case, a feature is the field in your index that you to check for anomalies. A detector can discover anomalies across one or more features. You must choose an aggregation method for each feature: average(), count(), sum(), min(), or max(). The aggregation method determines what constitutes an anomaly. For example, if you choose min(), the detector focuses on finding anomalies based on the minimum values of your feature. If you choose average(), the detector finds anomalies based on the average values of your feature. You can add a maximum of five features for a detector. | On the Model configuration page, enter the Feature name. | For Find anomalies based on, choose the method to find anomalies. For Field Value menu, choose the field and the aggregation method. Or choose Custom expression, and add in your own JSON aggregation query. | . (Optional) Set a category field for high cardinality . You can categorize anomalies based on a keyword or IP field type. The category field categorizes or slices the source time series with a dimension like IP addresses, product IDs, country codes, and so on. This helps to see a granular view of anomalies within each entity of the category field to isolate and debug issues. To set a category field, choose Enable a category field and select a field. Only a certain number of unique entities are supported in the category field. Use the following equation to calculate the recommended total number of entities number supported in a cluster: . (data nodes * heap size * anomaly detection maximum memory percentage) / (entity size of a detector) . This formula provides a good starting point, test with a representative workload and see how it goes. For example, for a cluster with 3 data nodes, each with 8G of JVM heap size, a maximum memory percentage of 10% (default), and the entity size of the detector as 1MB: the total number of unique entities supported is (8.096 * 10^9 * 0.1 / 1M ) * 3 = 2429. Set a window size . Set the number of aggregation intervals from your data stream to consider in a detection window. We recommend you choose this value based on your actual data to see which one leads to the best results for your use case. Based on experiments performed on a wide variety of one-dimensional data streams, we recommend using a window size between 1 and 16. The default window size is 8. If you have set the category field for high cardinality, the default window size is 1. If you expect missing values in your data or if you want the anomalies based on the current interval, choose 1. If your data is continuously ingested and you want the anomalies based on multiple intervals, choose a larger window size. Preview sample anomalies . Preview sample anomalies and adjust the feature settings if needed. For sample previews, the anomaly detection plugin selects a small number of data samples—for example, one data point every 30 minutes—and uses interpolation to estimate the remaining data points to approximate the actual feature data. It loads this sample dataset into the detector. The detector uses this sample dataset to generate a sample preview of anomaly results. Examine the sample preview and use it to fine-tune your feature configurations, for example, enable or disable features, to get more accurate results. | Choose Save and start detector. | Choose between automatically starting the detector (recommended) or manually starting the detector at a later time. | . Step 3: Observe the results . Choose the Anomaly results tab. You will have to wait for some time to see the anomaly results. If the detector interval is 10 minutes, the detector might take more than an hour to start, as it’s waiting for sufficient data to generate anomalies. A shorter interval means the model passes the shingle process more quickly and starts to generate the anomaly results sooner. Use the profile detector operation to make sure you check you have sufficient data points. If you see the detector pending in “initialization” for longer than a day, aggregate your existing data using the detector interval to check if for any missing data points. If you find a lot of missing data points from the aggregated data, consider increasing the detector interval. | The Live anomalies chart displays the live anomaly results for the last 60 intervals. For example, if the interval is set to 10, it shows the results for the last 600 minutes. This chart refreshes every 30 seconds. | The Anomaly history chart plots the anomaly grade with the corresponding measure of confidence. | The Feature breakdown graph plots the features based on the aggregation method. You can vary the date-time range of the detector. | The Anomaly occurrence table shows the Start time, End time, Data confidence, and Anomaly grade for each anomaly detected. | . Anomaly grade is a number between 0 and 1 that indicates the level of severity of how anomalous a data point is. An anomaly grade of 0 represents “not an anomaly,” and a non-zero value represents the relative severity of the anomaly. The confidence score is an estimate of the probability that the reported anomaly grade matches the expected anomaly grade. Confidence increases as the model observes more data and learns the data behavior and trends. Note that confidence is distinct from model accuracy. If you set the category field, you see an additional Heat map chart. The heat map correlates results for anomalous entities. This chart is empty until you select an anomalous entity. You also see the anomaly and feature line chart for the time period of the anomaly (anomaly_grade &gt; 0). Choose a filled rectangle to see a more detailed view of the anomaly. Step 4: Set up alerts . To create a monitor to send you notifications when any anomalies are detected, choose Set up alerts. You’re redirected to the Alerting, Add monitor page. For steps to create a monitor and set notifications based on your anomaly detector, see Monitor. If you stop or delete a detector, make sure to delete any monitors associated with the detector. Step 5: Adjust the model . To see all the configuration settings, choose the Detector configuration tab. | To make any changes to the detector configuration, or fine tune the time interval to minimize any false positives, in the Detector configuration section, choose Edit. | You need to stop the detector to change the detector configuration. In the pop-up box, confirm that you want to stop the detector and proceed. | . | To enable or disable features, in the Features section, choose Edit and adjust the feature settings as needed. After you make your changes, choose Save and start detector. | Choose between automatically starting the detector (recommended) or manually starting the detector at a later time. | . | . Step 6: Manage your detectors . Go to the Detector details page to change or delete your detectors. | To make changes to your detector, choose the detector name to open the detector details page. | Choose Actions, and then choose Edit detector. | You need to stop the detector to change the detector configuration. In the pop-up box, confirm that you want to stop the detector and proceed. | . | After making your changes, choose Save changes. | To delete your detector, choose Actions, and then choose Delete detector. | In the pop-up box, type delete to confirm and choose Delete. | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ad/#get-started-with-anomaly-detection",
    "relUrl": "/docs/ad/#get-started-with-anomaly-detection"
  },"328": {
    "doc": "Troubleshoot",
    "title": "Troubleshoot",
    "content": "This section contains a list of issues and workarounds. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/",
    "relUrl": "/docs/troubleshoot/"
  },"329": {
    "doc": "Troubleshoot",
    "title": "Java error during startup",
    "content": "You might see [ERROR][c.a.o.s.s.t.OpenDistroSecuritySSLNettyTransport] [odfe-node1] SSL Problem Insufficient buffer remaining for AEAD cipher fragment (2). Needs to be more than tag size (16) when starting Open Distro for Elasticsearch. This problem is a known issue with Java and doesn’t affect the operation of the cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#java-error-during-startup",
    "relUrl": "/docs/troubleshoot/#java-error-during-startup"
  },"330": {
    "doc": "Troubleshoot",
    "title": "Kibana fails to start",
    "content": "If you encounter the error FATAL Error: Request Timeout after 30000ms during startup, try running Kibana on a more powerful machine. We recommend four CPU cores and 8 GB of RAM. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#kibana-fails-to-start",
    "relUrl": "/docs/troubleshoot/#kibana-fails-to-start"
  },"331": {
    "doc": "Troubleshoot",
    "title": "Can’t open Kibana on Windows",
    "content": "Kibana doesn’t support Microsoft Edge and many versions of Internet Explorer. We recommend using Firefox or Chrome. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#cant-open-kibana-on-windows",
    "relUrl": "/docs/troubleshoot/#cant-open-kibana-on-windows"
  },"332": {
    "doc": "Troubleshoot",
    "title": "Can’t update by script when FLS, DLS, or field masking is active",
    "content": "The security plugin blocks the update by script operation (POST &lt;index&gt;/_update/&lt;id&gt;) when field-level security, document-level security, or field masking are active. You can still update documents using the standard index operation (PUT &lt;index&gt;/_doc/&lt;id&gt;). ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#cant-update-by-script-when-fls-dls-or-field-masking-is-active",
    "relUrl": "/docs/troubleshoot/#cant-update-by-script-when-fls-dls-or-field-masking-is-active"
  },"333": {
    "doc": "Troubleshoot",
    "title": "Illegal reflective access operation in logs",
    "content": "This is a known issue with Performance Analyzer that shouldn’t affect functionality. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#illegal-reflective-access-operation-in-logs",
    "relUrl": "/docs/troubleshoot/#illegal-reflective-access-operation-in-logs"
  },"334": {
    "doc": "Troubleshoot",
    "title": "Multi-tenancy issues in Kibana",
    "content": "If you’re testing multiple users in Kibana and encounter unexpected changes in tenant, use Google Chrome in an Incognito window or Firefox in a Private window. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#multi-tenancy-issues-in-kibana",
    "relUrl": "/docs/troubleshoot/#multi-tenancy-issues-in-kibana"
  },"335": {
    "doc": "Troubleshoot",
    "title": "Beats",
    "content": "If you encounter compatibility issues when attempting to connect Beats to Open Distro for Elasticsearch, make sure you’re using the Apache 2.0 distribution of Beats, not the default distribution, which uses a proprietary license. As of version 6.7, the default distribution of Beats includes a license check and fails to connect to the Apache 2.0 distribution of Elasticsearch. Try this minimal output configuration for using Beats with the security plugin: . output.elasticsearch: hosts: [\"localhost:9200\"] protocol: https username: \"admin\" password: \"admin\" ssl.certificate_authorities: - /full/path/to/root-ca.pem ssl.certificate: \"/full/path/to/client.pem\" ssl.key: \"/full/path/to/client-key.pem\" . Even if you use the OSS version, Beats might check for a proprietary plugin on the Elasticsearch server and throw an error during setup. To disable the check, try adding these settings: . setup.ilm.enabled: false setup.ilm.check_exists: false . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#beats",
    "relUrl": "/docs/troubleshoot/#beats"
  },"336": {
    "doc": "Troubleshoot",
    "title": "Logstash",
    "content": "If you’re having trouble connecting Logstash to Open Distro for Elasticsearch, try this minimal output configuration, which works with the security plugin: . output { elasticsearch { hosts =&gt; [\"localhost:9200\"] index =&gt; \"logstash-index-test\" user =&gt; \"admin\" password =&gt; \"admin\" ssl =&gt; true cacert =&gt; \"/full/path/to/root-ca.pem\" ilm_enabled =&gt; false } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#logstash",
    "relUrl": "/docs/troubleshoot/#logstash"
  },"337": {
    "doc": "Troubleshoot",
    "title": "Dependency error during upgrade",
    "content": "If you run sudo yum upgrade and receive a dependency error, Elasticsearch likely has a new minor version that the Open Distro for Elasticsearch plugins don’t support yet. You can install a specific, supported version of Elasticsearch to resolve the issue. A temporary solution is to add the --skip-broken option to upgrade the rest of your system: . sudo yum upgrade --skip-broken . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#dependency-error-during-upgrade",
    "relUrl": "/docs/troubleshoot/#dependency-error-during-upgrade"
  },"338": {
    "doc": "Troubleshoot",
    "title": "Elasticsearch fails to start on Java 8 (RPM install)",
    "content": "If Elasticsearch fails to start and you’re using Java 8, verify that you set the symbolic link (symlink) correctly in step 6 of the RPM installation. If Java is installed to a non-standard path, try looking for tools.jar using the following command: . ls /usr/lib/jvm/java-1.8.0-openjdk-*/lib/tools.jar . Then you can delete the old symlink and create a new one to the corrected path: . sudo rm /usr/share/elasticsearch/lib/tools.jar sudo ln -s /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-0.amzn2.x86_64/lib/tools.jar /usr/share/elasticsearch/lib/ . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/#elasticsearch-fails-to-start-on-java-8-rpm-install",
    "relUrl": "/docs/troubleshoot/#elasticsearch-fails-to-start-on-java-8-rpm-install"
  },"339": {
    "doc": "Kibana",
    "title": "Kibana",
    "content": "Kibana is the default visualization tool for data in Elasticsearch. It also serves as a user interface for the Open Distro for Elasticsearch security, alerting, and Index State Management plugins. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/",
    "relUrl": "/docs/kibana/"
  },"340": {
    "doc": "Kibana",
    "title": "Run Kibana using Docker",
    "content": "You can start Kibana using docker run after creating a Docker network and starting Elasticsearch, but the process of connecting Kibana to Elasticsearch is significantly easier with a Docker Compose file. | Run docker pull amazon/opendistro-for-elasticsearch-kibana:1.11.0. | Create a docker-compose.yml file appropriate for your environment. A sample file that includes Kibana is available on the Open Distro for Elasticsearch Docker installation page. Just like elasticsearch.yml, you can pass a custom kibana.yml to the container in the Docker Compose file. | Run docker-compose up. Wait for the containers to start. Then see Get started with Kibana. | When finished, run docker-compose down. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#run-kibana-using-docker",
    "relUrl": "/docs/kibana/#run-kibana-using-docker"
  },"341": {
    "doc": "Kibana",
    "title": "Run Kibana using the RPM or Debian package",
    "content": ". | If you haven’t already, add the yum repositories specified in steps 1–2 in RPM or the apt repositories in steps 2–3 of Debian package. | sudo yum install opendistroforelasticsearch-kibana or sudo apt install opendistroforelasticsearch-kibana | Modify /etc/kibana/kibana.yml to use elasticsearch.hosts rather than elasticsearch.url. | sudo systemctl start kibana.service | To stop Kibana: . sudo systemctl stop kibana.service . | . Configuration . To run Kibana when the system starts: . sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable kibana.service . You can also modify the values in /etc/kibana/kibana.yml. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#run-kibana-using-the-rpm-or-debian-package",
    "relUrl": "/docs/kibana/#run-kibana-using-the-rpm-or-debian-package"
  },"342": {
    "doc": "Kibana",
    "title": "Run Kibana using the tarball",
    "content": ". | Download the tarball: . curl https://d3g5vo6xdbdb9a.cloudfront.net/tarball/opendistroforelasticsearch-kibana/opendistroforelasticsearch-kibana-1.11.0.tar.gz -o opendistroforelasticsearch-kibana-1.11.0.tar.gz . | Download the checksum: . curl https://d3g5vo6xdbdb9a.cloudfront.net/tarball/opendistroforelasticsearch-kibana/opendistroforelasticsearch-kibana-1.11.0.tar.gz.sha512 -o opendistroforelasticsearch-kibana-1.11.0.tar.gz.sha512 . | Verify the tarball against the checksum: . shasum -a 512 -c opendistroforelasticsearch-kibana-1.11.0.tar.gz.sha512 . On CentOS, you might not have shasum. Install this package: . sudo yum install perl-Digest-SHA . | Extract the TAR file to a directory and change to that directory: . tar -zxf opendistroforelasticsearch-kibana-1.11.0.tar.gz cd opendistroforelasticsearch-kibana . | If desired, modify config/kibana.yml. | Run Kibana: ./bin/kibana . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#run-kibana-using-the-tarball",
    "relUrl": "/docs/kibana/#run-kibana-using-the-tarball"
  },"343": {
    "doc": "Kibana",
    "title": "Run Kibana on Windows (ZIP)",
    "content": ". | Download the ZIP. | Extract the ZIP file to a directory and open that directory at the command prompt. | If desired, modify config/kibana.yml. | Run Kibana: .\\bin\\kibana.bat . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#run-kibana-on-windows-zip",
    "relUrl": "/docs/kibana/#run-kibana-on-windows-zip"
  },"344": {
    "doc": "Kibana",
    "title": "Run Kibana on Windows (EXE)",
    "content": ". | Download the EXE file, run it, and click through the steps. | Open the command prompt. | Navigate to the Kibana install directory. | If desired, modify config/kibana.yml. | Run Kibana: .\\bin\\kibana.bat . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#run-kibana-on-windows-exe",
    "relUrl": "/docs/kibana/#run-kibana-on-windows-exe"
  },"345": {
    "doc": "Kibana",
    "title": "Get started with Kibana",
    "content": ". | After starting Kibana, you can access it at port 5601. For example, http://localhost:5601. | Log in with the default username admin and password admin. | Choose Try our sample data and add the sample flight data. | Choose Discover and search for a few flights. | Choose Dashboard, [Flights] Global Flight Dashboard, and wait for the dashboard to load. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/#get-started-with-kibana",
    "relUrl": "/docs/kibana/#get-started-with-kibana"
  },"346": {
    "doc": "Audit Logs",
    "title": "Audit logs",
    "content": "Audit logs let you track access to your Elasticsearch cluster and are useful for compliance purposes or in the aftermath of a security breach. You can configure the categories to be logged, the detail level of the logged messages, and where to store the logs. To enable audit logging: . | Add the following line to elasticsearch.yml on each node: . opendistro_security.audit.type: internal_elasticsearch . This setting stores audit logs on the current cluster. For other storage options, see Audit Log Storage Types. | Restart each node. | . After this initial setup, you can use Kibana to manage your audit log categories and other settings. In Kibana, choose Security, Audit logs. . | Tracked events | Exclude categories | Disable REST or the transport layer | Disable request body logging | Log index names | Configure bulk request handling | Exclude requests | Exclude users | Configure the audit log index name | (Advanced) Tune the thread pool | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#audit-logs",
    "relUrl": "/docs/security/audit-logs/#audit-logs"
  },"347": {
    "doc": "Audit Logs",
    "title": "Tracked events",
    "content": "Audit logging records events in two ways: HTTP requests (REST) and the transport layer. | Event | Logged on REST | Logged on transport | Description | . | FAILED_LOGIN | Yes | Yes | The credentials of a request could not be validated, most likely because the user does not exist or the password is incorrect. | . | AUTHENTICATED | Yes | Yes | A user successfully authenticated. | . | MISSING_PRIVILEGES | No | Yes | The user does not have the required permissions to execute the request. | . | GRANTED_PRIVILEGES | No | Yes | A user made a successful request to Elasticsearch. | . | SSL_EXCEPTION | Yes | Yes | An attempt was made to access Elasticsearch without a valid SSL/TLS certificate. | . | OPENDISTRO_SECURITY_INDEX_ATTEMPT | No | Yes | An attempt was made to modify the security plugin internal user and privileges index without the required permissions or TLS admin certificate. | . | BAD_HEADERS | Yes | Yes | An attempt was made to spoof a request to Elasticsearch with the security plugin internal headers. | . These default log settings work well for most use cases, but you can change settings to save storage space or adapt the information to your exact needs. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#tracked-events",
    "relUrl": "/docs/security/audit-logs/#tracked-events"
  },"348": {
    "doc": "Audit Logs",
    "title": "Exclude categories",
    "content": "To exclude categories, set: . opendistro_security.audit.config.disabled_rest_categories: &lt;disabled categories&gt; opendistro_security.audit.config.disabled_transport_categories: &lt;disabled categories&gt; . For example: . opendistro_security.audit.config.disabled_rest_categories: AUTHENTICATED, OPENDISTRO_SECURITY_INDEX_ATTEMPT opendistro_security.audit.config.disabled_transport_categories: GRANTED_PRIVILEGES . If you want to log events in all categories, use NONE: . opendistro_security.audit.config.disabled_rest_categories: NONE opendistro_security.audit.config.disabled_transport_categories: NONE . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#exclude-categories",
    "relUrl": "/docs/security/audit-logs/#exclude-categories"
  },"349": {
    "doc": "Audit Logs",
    "title": "Disable REST or the transport layer",
    "content": "By default, the security plugin logs events on both REST and the transport layer. You can disable either type: . opendistro_security.audit.enable_rest: false opendistro_security.audit.enable_transport: false . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#disable-rest-or-the-transport-layer",
    "relUrl": "/docs/security/audit-logs/#disable-rest-or-the-transport-layer"
  },"350": {
    "doc": "Audit Logs",
    "title": "Disable request body logging",
    "content": "By default, the security plugin includes the body of the request (if available) for both REST and the transport layer. If you do not want or need the request body, you can disable it: . opendistro_security.audit.log_request_body: false . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#disable-request-body-logging",
    "relUrl": "/docs/security/audit-logs/#disable-request-body-logging"
  },"351": {
    "doc": "Audit Logs",
    "title": "Log index names",
    "content": "By default, the security plugin logs all indices affected by a request. Because index names can be an aliases and contain wildcards/date patterns, the security plugin logs the index name that the user submitted and the actual index name to which it resolves. For example, if you use an alias or a wildcard, the the audit event might look like: . audit_trace_indices: [ \"human*\" ], audit_trace_resolved_indices: [ \"humanresources\" ] . You can disable this feature by setting: . opendistro_security.audit.resolve_indices: false . Disabling this feature only takes effect if opendistro_security.audit.log_request_body is also set to false. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#log-index-names",
    "relUrl": "/docs/security/audit-logs/#log-index-names"
  },"352": {
    "doc": "Audit Logs",
    "title": "Configure bulk request handling",
    "content": "Bulk requests can contain many indexing operations. By default, the security plugin only logs the single bulk request, not each individual operation. The security plugin can be configured to log each indexing operation as a separate event: . opendistro_security.audit.resolve_bulk_requests: true . This change can create a massive number of events in the audit logs, so we don’t recommend enabling this setting if you make heavy use of the _bulk API. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#configure-bulk-request-handling",
    "relUrl": "/docs/security/audit-logs/#configure-bulk-request-handling"
  },"353": {
    "doc": "Audit Logs",
    "title": "Exclude requests",
    "content": "You can exclude certain requests from being logged completely, by either configuring actions (for transport requests) and/or HTTP request paths (REST): . opendistro_security.audit.ignore_requests: [\"indices:data/read/*\", \"SearchRequest\"] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#exclude-requests",
    "relUrl": "/docs/security/audit-logs/#exclude-requests"
  },"354": {
    "doc": "Audit Logs",
    "title": "Exclude users",
    "content": "By default, the security plugin logs events from all users, but excludes the internal Kibana server user kibanaserver. You can exclude other users: . opendistro_security.audit.ignore_users: - kibanaserver - admin . If requests from all users should be logged, use NONE: . opendistro_security.audit.ignore_users: NONE . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#exclude-users",
    "relUrl": "/docs/security/audit-logs/#exclude-users"
  },"355": {
    "doc": "Audit Logs",
    "title": "Configure the audit log index name",
    "content": "By default, the security plugin stores audit events in a daily rolling index named auditlog-YYYY.MM.dd. You can configure the name of the index in elasticsearch.yml: . opendistro_security.audit.config.index: myauditlogindex . Use a date pattern in the index name to configure daily, weekly, or monthly rolling indices: . opendistro_security.audit.config.index: \"'auditlog-'YYYY.MM.dd\" . For a reference on the date pattern format, see the Joda DateTimeFormat documentation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#configure-the-audit-log-index-name",
    "relUrl": "/docs/security/audit-logs/#configure-the-audit-log-index-name"
  },"356": {
    "doc": "Audit Logs",
    "title": "(Advanced) Tune the thread pool",
    "content": "The Search plugin logs events asynchronously, which keeps performance impact on your cluster minimal. The plugin uses a fixed thread pool to log events. You can define the number of threads in the pool in elasticsearch.yml: . opendistro_security.audit.threadpool.size: &lt;integer&gt; . The default setting is 10. Setting this value to 0 disables the thread pool, which means the plugin logs events synchronously. To set the maximum queue length per thread: . opendistro_security.audit.threadpool.max_queue_len: 100000 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/#advanced-tune-the-thread-pool",
    "relUrl": "/docs/security/audit-logs/#advanced-tune-the-thread-pool"
  },"357": {
    "doc": "Audit Logs",
    "title": "Audit Logs",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/",
    "relUrl": "/docs/security/audit-logs/"
  },"358": {
    "doc": "Configuration",
    "title": "Security configuration",
    "content": "The plugin includes demo certificates so that you can get up and running quickly, but before using Open Distro for Elasticsearch in a production environment, you must configure it manually: . | Replace the demo certificates | Reconfigure elasticsearch.yml to use your certificates | Reconfigure config.yml to use your authentication backend (if you don’t plan to use the internal user database) | Modify the configuration YAML files | Apply changes using securityadmin.sh | Start Elasticsearch. | Add users, roles, role mappings, and tenants | . If you don’t want to use the plugin, see Disable security. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/#security-configuration",
    "relUrl": "/docs/security/configuration/#security-configuration"
  },"359": {
    "doc": "Configuration",
    "title": "Configuration",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/",
    "relUrl": "/docs/security/configuration/"
  },"360": {
    "doc": "Access Control",
    "title": "Access control",
    "content": "After you configure the security plugin to use your own certificates and preferred authentication backend, you can start adding users, creating roles, and mapping roles to users. This section of the documentation covers what a user is allowed to see and do after successfully authenticating. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/#access-control",
    "relUrl": "/docs/security/access-control/#access-control"
  },"361": {
    "doc": "Access Control",
    "title": "Concepts",
    "content": "| Term | Description | . | Permission | An individual action, such as creating an index (e.g. indices:admin/create). For a complete list, see Permissions. | . | Action group | A set of permissions. For example, the predefined SEARCH action group authorizes roles to use the _search and _msearch APIs. | . | Role | Security roles define the scope of a permission or action group: cluster, index, document, or field. For example, a role named delivery_analyst might have no cluster permissions, the READ action group for all indices that match the delivery-data-* pattern, access to all document types within those indices, and access to all fields except delivery_driver_name. | . | Backend role | (Optional) Arbitrary strings that you specify or that come from an external authentication system (e.g. LDAP/Active Directory). Backend roles can help simplify the role mapping process. Rather than mapping a role to 100 individual users, you can map the role to a single backend role that all 100 users share. | . | User | Users make requests to Elasticsearch clusters. A user has credentials (e.g. a username and password), zero or more backend roles, and zero or more custom attributes. | . | Role mapping | Users assume roles after they successfully authenticate. Role mappings, well, map roles to users (or backend roles). For example, a mapping of kibana_user (role) to jdoe (user) means that John Doe gains all the permissions of kibana_user after authenticating. Likewise, a mapping of all_access (role) to admin (backend role) means that any user with the backend role of admin gains all the permissions of all_access after authenticating. You can map each role to many users and/or backend roles. | . The security plugin comes with a number of predefined action groups, roles, mappings, and users. These entities serve as sensible defaults and are good examples of how to use the plugin. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/#concepts",
    "relUrl": "/docs/security/access-control/#concepts"
  },"362": {
    "doc": "Access Control",
    "title": "Access Control",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/",
    "relUrl": "/docs/security/access-control/"
  },"363": {
    "doc": "Security",
    "title": "Security",
    "content": "Open Distro for Elasticsearch has its own security plugin for authentication and access control. The plugin provides numerous features to help you secure your cluster. | Feature | Description | . | Node-to-node encryption | Encrypts traffic between nodes in the Elasticsearch cluster. | . | HTTP basic authentication | A simple authentication method that includes a user name and password as part of the HTTP request. | . | Support for Active Directory, LDAP, Kerberos, SAML, and OpenID Connect | Use existing, industry-standard infrastructure to authenticate users, or create new users in the internal user database. | . | Role-based access control | Roles define the actions that users can perform: the data they can read, the cluster settings they can modify, the indices to which they can write, and so on. Roles are reusable across users, and users can have multiple roles. | . | Index-level, document-level, and field-level security | Restrict access to entire indices, certain documents within an index, or certain fields within documents. | . | Audit logging | These logs let you track access to your Elasticsearch cluster and are useful for compliance purposes or after unintended data exposure. | . | Cross-cluster search | Use a coordinating cluster to securely send search requests to remote clusters. | . | Kibana multi-tenancy | Create shared (or private) spaces for visualizations and dashboards. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/",
    "relUrl": "/docs/security/"
  },"364": {
    "doc": "PPL",
    "title": "PPL",
    "content": "Piped Processing Language (PPL) is a query language that lets you use pipe (|) syntax to explore, discover, and query data stored in Elasticsearch. To quickly get up and running with PPL, use Query Workbench in Kibana. To learn more, see Workbench. The PPL syntax consists of commands delimited by the pipe character (|) where data flows from left to right through each pipeline. search command | command 1 | command 2 ... You can only use read-only commands like search, where, fields, rename, dedup, stats, sort, eval, head, top, and rare. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/",
    "relUrl": "/docs/ppl/"
  },"365": {
    "doc": "PPL",
    "title": "Quick start",
    "content": "To get started with PPL, choose Dev Tools in Kibana and use the bulk operation to index some sample data: . PUT accounts/_bulk?refresh {\"index\":{\"_id\":\"1\"}} {\"account_number\":1,\"balance\":39225,\"firstname\":\"Amber\",\"lastname\":\"Duke\",\"age\":32,\"gender\":\"M\",\"address\":\"880 Holmes Lane\",\"employer\":\"Pyrami\",\"email\":\"amberduke@pyrami.com\",\"city\":\"Brogan\",\"state\":\"IL\"} {\"index\":{\"_id\":\"6\"}} {\"account_number\":6,\"balance\":5686,\"firstname\":\"Hattie\",\"lastname\":\"Bond\",\"age\":36,\"gender\":\"M\",\"address\":\"671 Bristol Street\",\"employer\":\"Netagy\",\"email\":\"hattiebond@netagy.com\",\"city\":\"Dante\",\"state\":\"TN\"} {\"index\":{\"_id\":\"13\"}} {\"account_number\":13,\"balance\":32838,\"firstname\":\"Nanette\",\"lastname\":\"Bates\",\"age\":28,\"gender\":\"F\",\"address\":\"789 Madison Street\",\"employer\":\"Quility\",\"city\":\"Nogal\",\"state\":\"VA\"} {\"index\":{\"_id\":\"18\"}} {\"account_number\":18,\"balance\":4180,\"firstname\":\"Dale\",\"lastname\":\"Adams\",\"age\":33,\"gender\":\"M\",\"address\":\"467 Hutchinson Court\",\"email\":\"daleadams@boink.com\",\"city\":\"Orick\",\"state\":\"MD\"} . Go to Query Workbench and select PPL. The following example returns firstname and lastname fields for documents in an accounts index with age greater than 18: . search source=accounts | where age &gt; 18 | fields firstname, lastname . Sample Response . | id | firstname | lastname | . | 0 | Amber | Duke | . | 1 | Hattie | Bond | . | 2 | Nanette | Bates | . | 3 | Dale | Adams | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/#quick-start",
    "relUrl": "/docs/ppl/#quick-start"
  },"366": {
    "doc": "Other Resources",
    "title": "Other resources",
    "content": "This section links to useful Open Distro for Elasticsearch resources. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/other/#other-resources",
    "relUrl": "/docs/other/#other-resources"
  },"367": {
    "doc": "Other Resources",
    "title": "Old documentation versions",
    "content": "We host certain old versions of the documentation—typically the final minor release for a given major release—in case you want to get started with a prior version of Open Distro for Elasticsearch. We do not backport bug fixes to old versions of the documentation, so even if you use a prior version of ODFE, the current version of the documentation might be the most useful, accurate resource. | ODFE 0.9.0 documentation | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/other/#old-documentation-versions",
    "relUrl": "/docs/other/#old-documentation-versions"
  },"368": {
    "doc": "Other Resources",
    "title": "External content",
    "content": ". | Open Distro for Elasticsearch blog – includes release announcements, technical walkthroughs, and case studies. | Ansible playbook – helps with installing a production-ready Open Distro Elasticsearch cluster with Kibana using the standalone plugin installation method. | Ansible role – a reusable Ansible configuration for Open Distro for Elasticsearch (Elasticsearch only, no Kibana). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/other/#external-content",
    "relUrl": "/docs/other/#external-content"
  },"369": {
    "doc": "Other Resources",
    "title": "Other Resources",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/other/",
    "relUrl": "/docs/other/"
  },"370": {
    "doc": "Root Cause Analysis",
    "title": "Root Cause Analysis",
    "content": "The Open Distro for Elasticsearch Performance Analyzer plugin (PA) captures Elasticsearch and JVM activity, plus their lower-level resource usage (e.g. disk, network, CPU, and memory). Based on this instrumentation, Performance Analyzer computes and exposes diagnostic metrics so that administrators can measure and understand the bottlenecks in their Elasticsearch clusters. The Root Cause Analysis framework (RCA) uses the information from PA to alert administrators about the root cause of performance and availability issues that their clusters might be experiencing. In broad strokes, the framework helps you access data streams from Elasticsearch nodes running Performance Analyzer. You write snippets of Java to choose the streams that matter to you and evaluate the streams’ PA metrics against certain thresholds. As RCA runs, you can access the state of each analysis using the REST API. To learn more about Root Cause Analysis, see its repository on GitHub. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/",
    "relUrl": "/docs/rca/"
  },"371": {
    "doc": "Index State Management",
    "title": "Index State Management",
    "content": "Kibana . If you analyze time-series data, you likely prioritize new data over old data. You might periodically perform certain operations on older indices, such as reducing replica count or deleting them. Index State Management (ISM) is a plugin that lets you automate these periodic, administrative operations by triggering them based on changes in the index age, index size, or number of documents. Using the ISM plugin, you can define policies that automatically handle index rollovers or deletions to fit your use case. For example, you can define a policy that moves your index into a read_only state after 30 days and then deletes it after a set period of 90 days. You can also set up the policy to send you a notification message when the index is deleted. You might want to perform an index rollover after a certain amount of time or run a force_merge operation on an index during off-peak hours to improve search performance during peak hours. To use the ISM plugin, your user role needs to be mapped to the all_access role that gives you full access to the cluster. To learn more, see Users and roles. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/",
    "relUrl": "/docs/ism/"
  },"372": {
    "doc": "Index State Management",
    "title": "Get started with ISM",
    "content": "To get started, choose Index Management in Kibana. Step 1: Set up policies . A policy is a set of rules that describes how an index should be managed. For information about creating a policy, see Policies. | Choose the Index Policies tab. | Choose Create policy. | In the Name policy section, enter a policy ID. | In the Define policy section, enter your policy. | Choose Create. | . After you create a policy, your next step is to attach this policy to an index or indices. You can also include the policy_id in an index template so when an index is created that matches the index template pattern, the index will have the policy attached to it: . PUT _index_template/&lt;template_name&gt; { \"index_patterns\": [\"index_name-*\"], \"settings\": { \"opendistro.index_state_management.policy_id\": \"policy_id\" } } . Step 2: Attach policies to indices . | Choose Indices. | Choose the index or indices that you want to attach your policy to. | Choose Apply policy. | From the Policy ID menu, choose the policy that you created. You can see a preview of your policy. | If your policy includes a rollover operation, specify a rollover alias. Make sure that the alias that you enter already exists. For more information about the rollover operation, see rollover. | Choose Apply. | . After you attach a policy to an index, ISM creates a job that runs every 5 minutes by default to perform policy actions, check conditions, and transition the index into different states. To change the default time interval for this job, see Settings. If you want to use an Elasticsearch operation to create an index with a policy already attached to it, see create index. Step 3: Manage indices . | Choose Managed Indices. | To change your policy, see Change Policy. | To attach a rollover alias to your index, select your policy and choose Add rollover alias. Make sure that the alias that you enter already exists. For more information about the rollover operation, see rollover. | To remove a policy, choose your policy, and then choose Remove policy. | To retry a policy, choose your policy, and then choose Retry policy. | . For information about managing your policies, see Managed Indices. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/#get-started-with-ism",
    "relUrl": "/docs/ism/#get-started-with-ism"
  },"373": {
    "doc": "Notebooks",
    "title": "Kibana Notebooks",
    "content": "A Kibana notebook is an interface that lets you easily combine live visualizations and narrative text in a single notebook interface. With Kibana notebooks, you can interactively explore data by running different visualizations and share your work with team members to collaborate on a project. A notebook is a document composed of two elements: Kibana visualizations and paragraphs (Markdown). Choose multiple timelines to compare and contrast visualizations. Common use cases include creating postmortem reports, designing runbooks, building live infrastructure reports, and writing documentation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/notebooks/#kibana-notebooks",
    "relUrl": "/docs/notebooks/#kibana-notebooks"
  },"374": {
    "doc": "Notebooks",
    "title": "Get Started with Notebooks",
    "content": "To get started, choose Kibana Notebooks in Kibana. Step 1: Create a notebook . A notebook is an interface for creating reports. | Choose Create notebook and enter a descriptive name. | Choose Create. | . Choose Notebook actions to rename, duplicate, or delete a notebook. Step 2: Add a paragraph . Paragraphs combine text and visualizations for describing data. Add a markdown paragraph . | To add text, choose Add markdown paragraph. | Add rich text with markdown syntax. | . Add a visualization paragraph . | To add a visualization, choose Add Kibana visualization paragraph. | In Title, select your visualization and choose a date range. | . | You can choose multiple timelines to compare and contrast visualizations. | . To run and save a paragraph, choose Run. You can perform the following actions on paragraphs: . | Add a new paragraph to the top of a report. | Add a new paragraph to the bottom of a report. | Run all the paragraphs at the same time. | Clear the outputs of all paragraphs. | Delete all the paragraphs. | Move paragraphs up and down. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/notebooks/#get-started-with-notebooks",
    "relUrl": "/docs/notebooks/#get-started-with-notebooks"
  },"375": {
    "doc": "Notebooks",
    "title": "Notebooks",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/notebooks/",
    "relUrl": "/docs/notebooks/"
  },"376": {
    "doc": "Elasticsearch",
    "title": "Introduction to Elasticsearch",
    "content": "Elasticsearch is a distributed search and analytics engine based on Apache Lucene. After adding your data to Elasticsearch, you can perform full-text searches on it with all of the features you might expect: search by field, search multiple indices, boost fields, rank results by score, sort results by field, and aggregate results. Unsurprisingly, people often use Elasticsearch as the backend for a search application—think Wikipedia or an online store. It offers excellent performance and can scale up and down as the needs of the application grow or shrink. An equally popular, but less obvious use case is log analytics, in which you take the logs from an application, feed them into Elasticsearch, and use the rich search and visualization functionality to identify issues. For example, a malfunctioning web server might throw a 500 error 0.5% of the time, which can be hard to notice unless you have a real-time graph of all HTTP status codes that the server has thrown in the past four hours. You can use Kibana to build these sorts of visualizations from data in Elasticsearch. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/#introduction-to-elasticsearch",
    "relUrl": "/docs/elasticsearch/#introduction-to-elasticsearch"
  },"377": {
    "doc": "Elasticsearch",
    "title": "Clusters and nodes",
    "content": "Its distributed design means that you interact with Elasticsearch clusters. Each cluster is a collection of one or more nodes, servers that store your data and process search requests. You can run Elasticsearch locally on a laptop—its system requirements are minimal—but you can also scale a single cluster to hundreds of powerful machines in a data center. In a single node cluster, such as a laptop, one machine has to do everything: manage the state of the cluster, index and search data, and perform any preprocessing of data prior to indexing it. As a cluster grows, however, you can subdivide responsibilities. Nodes with fast disks and plenty of RAM might be great at indexing and searching data, whereas a node with plenty of CPU power and a tiny disk could manage cluster state. For more information on setting node types, see Cluster Formation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/#clusters-and-nodes",
    "relUrl": "/docs/elasticsearch/#clusters-and-nodes"
  },"378": {
    "doc": "Elasticsearch",
    "title": "Indices and documents",
    "content": "Elasticsearch organizes data into indices. Each index is a collection of JSON documents. If you have a set of raw encyclopedia articles or log lines that you want to add to Elasticsearch, you must first convert them to JSON. A simple JSON document for a movie might look like this: . { \"title\": \"The Wind Rises\", \"release_date\": \"2013-07-20\" } . When you add the document to an index, Elasticsearch adds some metadata, such as the unique document ID: . { \"_index\": \"&lt;index-name&gt;\", \"_type\": \"_doc\", \"_id\": \"&lt;document-id&gt;\", \"_version\": 1, \"_source\": { \"title\": \"The Wind Rises\", \"release_date\": \"2013-07-20\" } } . Indices also contain mappings and settings: . | A mapping is the collection of fields that documents in the index have. In this case, those fields are title and release_date. | Settings include data like the index name, creation date, and number of shards. | . Older versions of Elasticsearch used arbitrary document types, but indices created in current versions of Elasticsearch should use a single type named _doc. Store different document types in different indices. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/#indices-and-documents",
    "relUrl": "/docs/elasticsearch/#indices-and-documents"
  },"379": {
    "doc": "Elasticsearch",
    "title": "Primary and replica shards",
    "content": "Elasticsearch splits indices into shards for even distribution across nodes in a cluster. For example, a 400 GB index might be too large for any single node in your cluster to handle, but split into ten shards, each one 40 GB, Elasticsearch can distribute the shards across ten nodes and work with each shard individually. By default, Elasticsearch creates a replica shard for each primary shard. If you split your index into ten shards, for example, Elasticsearch also creates ten replica shards. These replica shards act as backups in the event of a node failure—Elasticsearch distributes replica shards to different nodes than their corresponding primary shards—but they also improve the speed and rate at which the cluster can process search requests. You might specify more than one replica per index for a search-heavy workload. Despite being a piece of an Elasticsearch index, each shard is actually a full Lucene index—confusing, we know. This detail is important, though, because each instance of Lucene is a running process that consumes CPU and memory. More shards is not necessarily better. Splitting a 400 GB index into 1,000 shards, for example, would place needless strain on your cluster. A good rule of thumb is to keep shard size between 10–50 GB. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/#primary-and-replica-shards",
    "relUrl": "/docs/elasticsearch/#primary-and-replica-shards"
  },"380": {
    "doc": "Elasticsearch",
    "title": "REST API",
    "content": "You interact with Elasticsearch clusters using the REST API, which offers a lot of flexibility. You can use clients like curl or any programming language that can send HTTP requests. To add a JSON document to an Elasticsearch index (i.e. index a document), you send an HTTP request: . PUT https://&lt;host&gt;:&lt;port&gt;/&lt;index-name&gt;/_doc/&lt;document-id&gt; { \"title\": \"The Wind Rises\", \"release_date\": \"2013-07-20\" } . To run a search for the document: . GET https://&lt;host&gt;:&lt;port&gt;/&lt;index-name&gt;/_search?q=wind . To delete the document: . DELETE https://&lt;host&gt;:&lt;port&gt;/&lt;index-name&gt;/_doc/&lt;document-id&gt; . You can change most Elasticsearch settings using the REST API, modify indices, check the health of the cluster, get statistics—almost everything. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/#rest-api",
    "relUrl": "/docs/elasticsearch/#rest-api"
  },"381": {
    "doc": "Elasticsearch",
    "title": "Elasticsearch",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/",
    "relUrl": "/docs/elasticsearch/"
  },"382": {
    "doc": "SQL",
    "title": "SQL",
    "content": "Open Distro for Elasticsearch SQL lets you write queries in SQL rather than the Elasticsearch query domain-specific language (DSL). If you’re already familiar with SQL and don’t want to learn the query DSL, this feature is a great option. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/",
    "relUrl": "/docs/sql/"
  },"383": {
    "doc": "SQL",
    "title": "Workbench",
    "content": "The easiest way to get familiar with the SQL plugin is to use SQL Workbench in Kibana to test various queries. To learn more, see Workbench. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/#workbench",
    "relUrl": "/docs/sql/#workbench"
  },"384": {
    "doc": "SQL",
    "title": "REST API",
    "content": "To use the SQL plugin with your own applications, send requests to _opendistro/_sql: . POST _opendistro/_sql { \"query\": \"SELECT * FROM my-index LIMIT 50\" } . Here’s how core SQL concepts map to Elasticsearch: . | SQL | Elasticsearch | . | Table | Index | . | Row | Document | . | Column | Field | . You can query multiple indices by listing them or using wildcards: . POST _opendistro/_sql { \"query\": \"SELECT * FROM my-index1,myindex2,myindex3 LIMIT 50\" } POST _opendistro/_sql { \"query\": \"SELECT * FROM my-index* LIMIT 50\" } . For a sample curl command, try: . curl -XPOST https://localhost:9200/_opendistro/_sql -u admin:admin -k -H 'Content-Type: application/json' -d '{\"query\": \"SELECT * FROM kibana_sample_data_flights LIMIT 10\"}' . By default, queries return data in JDBC format, but you can also return data in standard Elasticsearch JSON, CSV, or raw formats: . POST _opendistro/_sql?format=json|csv|raw { \"query\": \"SELECT * FROM my-index LIMIT 50\" } . See the rest of this guide for detailed information on request parameters, settings, supported operations, tools, and more. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/#rest-api",
    "relUrl": "/docs/sql/#rest-api"
  },"385": {
    "doc": "SQL",
    "title": "Contributing",
    "content": "To get involved and help us improve the SQL plugin, see the development guide for instructions on setting up your development environment and building the project. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/#contributing",
    "relUrl": "/docs/sql/#contributing"
  },"386": {
    "doc": "About",
    "title": "Open Distro for Elasticsearch Documentation",
    "content": "This site contains the technical documentation for Open Distro for Elasticsearch, the community-driven, 100% open source distribution of Elasticsearch with advanced security, alerting, SQL support, automated index management, deep performance analysis, and more. Get started . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/#open-distro-for-elasticsearch-documentation",
    "relUrl": "/#open-distro-for-elasticsearch-documentation"
  },"387": {
    "doc": "About",
    "title": "Why use Open Distro for Elasticsearch?",
    "content": "Open Distro for Elasticsearch is well-suited to the following use cases: . | Log analytics | Real-time application monitoring | Clickstream analytics | Search backend | . Compared to the open source distribution of Elasticsearch, Open Distro for Elasticsearch offers many extra features: . | Component | Purpose | . | Elasticsearch | Data store and search engine | . | Kibana | Search frontend and visualizations | . | Security | Authentication and access control for your cluster | . | Alerting | Receive notifications when your data meets certain conditions | . | SQL | Use SQL to query your data | . | Index State Management | Automate index operations | . | KNN | Find “nearest neighbors” in your vector data | . | Performance Analyzer | Monitor and optimize your cluster | . | Anomaly Detection | Identify atypical data and receive automatic notifications | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/#why-use-open-distro-for-elasticsearch",
    "relUrl": "/#why-use-open-distro-for-elasticsearch"
  },"388": {
    "doc": "About",
    "title": "Get started",
    "content": "Docker . | Install and start Docker Desktop. | Run the following commands: . docker pull amazon/opendistro-for-elasticsearch:1.11.0 docker run -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" amazon/opendistro-for-elasticsearch:1.11.0 . | In a new terminal session, run: . curl -XGET --insecure https://localhost:9200 -u admin:admin . | . To learn more, see Install. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/#get-started",
    "relUrl": "/#get-started"
  },"389": {
    "doc": "About",
    "title": "Builds",
    "content": "If you want to modify the Open Distro for Elasticsearch code and build from source, instructions are in elasticsearch/README.md and kibana/README.md of the opendistro-build repository. Likewise, you can find build instructions for the various plugins in their individual repositories. If your changes could benefit others, please consider submitting a pull request. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/#builds",
    "relUrl": "/#builds"
  },"390": {
    "doc": "About",
    "title": "About Open Distro for Elasticsearch",
    "content": "Open Distro for Elasticsearch is supported by Amazon Web Services. All components are available under the Apache License, Version 2.0 on GitHub. The project welcomes GitHub issues, bug fixes, features, plugins, documentation—anything at all. To get involved, see Contribute on the Open Distro for Elasticsearch website. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/#about-open-distro-for-elasticsearch",
    "relUrl": "/#about-open-distro-for-elasticsearch"
  },"391": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/",
    "relUrl": "/"
  },"392": {
    "doc": "JDBC Driver",
    "title": "JDBC driver",
    "content": "The Java Database Connectivity (JDBC) driver lets you integrate Open Distro for Elasticsearch with your favorite business intelligence (BI) applications. For information on downloading and using the JAR file, see the SQL repository on GitHub. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/jdbc/#jdbc-driver",
    "relUrl": "/docs/sql/jdbc/#jdbc-driver"
  },"393": {
    "doc": "JDBC Driver",
    "title": "JDBC Driver",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/jdbc/",
    "relUrl": "/docs/sql/jdbc/"
  },"394": {
    "doc": "Active Directory and LDAP",
    "title": "Active Directory and LDAP",
    "content": "Active Directory and LDAP can be used for both authentication and authorization (the authc and authz sections of the configuration, respectively). Authentication checks whether the user has entered valid credentials. Authorization retrieves any backend roles for the user. In most cases, you want to configure both authentication and authorization. You can also use authentication only and map the users retrieved from LDAP directly to security plugin roles. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/ldap/",
    "relUrl": "/docs/security/configuration/ldap/"
  },"395": {
    "doc": "Active Directory and LDAP",
    "title": "Docker example",
    "content": "We provide a fully functional example that can help you understand how to use an LDAP server for both authentication and authorization. | Download and unzip the example ZIP file. | At the command line, run docker-compose up. | Review the files: . | docker-compose.yml defines a single ODFE node, an LDAP server, and a PHP administration tool for the LDAP server. You can access the administration tool at https://localhost:6443. Acknowledge the security warning and log in using cn=admin,dc=example,dc=org and changethis. | directory.ldif seeds the LDAP server with three users and two groups. psantos is in the Administrator and Developers groups. jroe and jdoe are in the Developers group. The security plugin loads these groups as backend roles. | roles_mapping.yml maps the Administrator and Developers LDAP groups (as backend roles) to security roles so that users gain the appropriate permissions after authenticating. | internal_users.yml removes all default users except administrator and kibanaserver. | config.yml includes all necessary LDAP settings. | . | Index a document as psantos: . curl -XPUT https://localhost:9200/new-index/_doc/1 -H 'Content-Type: application/json' -d '{\"title\": \"Spirited Away\"}' -u psantos:password -k . If you try the same request as jroe, it fails. The Developers group is mapped to the readall, manage_snapshots, and kibana_user roles and has no write permissions. | Search for the document as jroe: . curl -XGET https://localhost:9200/new-index/_search?pretty -u jroe:password -k . This request succeeds, because the Developers group is mapped to the readall role. | If you want to examine the contents of the various containers, run docker ps to find the container ID and then docker exec -it &lt;container-id&gt; /bin/bash. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/ldap/#docker-example",
    "relUrl": "/docs/security/configuration/ldap/#docker-example"
  },"396": {
    "doc": "Active Directory and LDAP",
    "title": "Connection settings",
    "content": "To enable LDAP authentication and authorization, add the following lines to plugins/opendistro_security/securityconfig/config.yml: . authc: ldap: http_enabled: true transport_enabled: true order: 1 http_authenticator: type: basic challenge: false authentication_backend: type: ldap config: ... authz: ldap: http_enabled: true transport_enabled: true authorization_backend: type: ldap config: ... The connection settings are identical for authentication and authorization and are added to the config sections. Hostname and port . To configure the hostname and port of your Active Directory servers, use the following: . config: hosts: - primary.ldap.example.com:389 - secondary.ldap.example.com:389 . You can configure more than one server here. If the security plugin cannot connect to the first server, it tries to connect to the remaining servers sequentially. Timeouts . To configure connection and response timeouts to your Active Directory server, use the following (values are in milliseconds): . config: connect_timeout: 5000 response_timeout: 0 . If your server supports two-factor authentication (2FA), the default timeout settings might result in login errors. You can increase connect_timeout to accommodate the 2FA process. Setting response_timeout to 0 (the default) indicates an indefinite waiting period. Bind DN and password . To configure the bind_dn and password that the security plugin uses when issuing queries to your server, use the following: . config: bind_dn: cn=admin,dc=example,dc=com password: password . If your server supports anonymous authentication, both bind_dn and password can be set to null. TLS settings . Use the following parameters to configure TLS for connecting to your server: . config: enable_ssl: &lt;true|false&gt; enable_start_tls: &lt;true|false&gt; enable_ssl_client_auth: &lt;true|false&gt; verify_hostnames: &lt;true|false&gt; . | Name | Description | . | enable_ssl | Whether to use LDAP over SSL (LDAPS). | . | enable_start_tls | Whether to use STARTTLS. Can’t be used in combination with LDAPS. | . | enable_ssl_client_auth | Whether to send the client certificate to the LDAP server. | . | verify_hostnames | Whether to verify the hostnames of the server’s TLS certificate. | . Certificate validation . By default, the security plugin validates the TLS certificate of the LDAP servers against the root CA configured in elasticsearch.yml, either as a PEM certificate or a truststore: . opendistro_security.ssl.transport.pemtrustedcas_filepath: ... opendistro_security.ssl.http.truststore_filepath: ... If your server uses a certificate signed by a different CA, import this CA into your truststore or add it to your trusted CA file on each node. You can also use a separate root CA in PEM format by setting one of the following configuration options: . config: pemtrustedcas_filepath: /full/path/to/trusted_cas.pem . config: pemtrustedcas_content: |- MIID/jCCAuagAwIBAgIBATANBgkqhkiG9w0BAQUFADCBjzETMBEGCgmSJomT8ixk ARkWA2NvbTEXMBUGCgmSJomT8ixkARkWB2V4YW1wbGUxGTAXBgNVBAoMEEV4YW1w bGUgQ29tIEluYy4xITAfBgNVBAsMGEV4YW1wbGUgQ29tIEluYy4gUm9vdCBDQTEh ... | Name | Description | . | pemtrustedcas_filepath | Absolute path to the PEM file containing the root CAs of your Active Directory/LDAP server. | . | pemtrustedcas_content | The root CA content of your Active Directory/LDAP server. Cannot be used when pemtrustedcas_filepath is set. | . Client authentication . If you use TLS client authentication, the security plugin sends the PEM certificate of the node, as configured in elasticsearch.yml. Set one of the following configuration options: . config: pemkey_filepath: /full/path/to/private.key.pem pemkey_password: private_key_password pemcert_filepath: /full/path/to/certificate.pem . or . config: pemkey_content: |- MIID2jCCAsKgAwIBAgIBBTANBgkqhkiG9w0BAQUFADCBlTETMBEGCgmSJomT8ixk ARkWA2NvbTEXMBUGCgmSJomT8ixkARkWB2V4YW1wbGUxGTAXBgNVBAoMEEV4YW1w bGUgQ29tIEluYy4xJDAiBgNVBAsMG0V4YW1wbGUgQ29tIEluYy4gU2lnbmluZyBD ... pemkey_password: private_key_password pemcert_content: |- MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCHRZwzwGlP2FvL oEzNeDu2XnOF+ram7rWPT6fxI+JJr3SDz1mSzixTeHq82P5A7RLdMULfQFMfQPfr WXgB4qfisuDSt+CPocZRfUqqhGlMG2l8LgJMr58tn0AHvauvNTeiGlyXy0ShxHbD ... | Name | Description | . | pemkey_filepath | Absolute path to the file containing the private key of your certificate. | . | pemkey_content | The content of the private key of your certificate. Cannot be used when pemkey_filepath is set. | . | pemkey_password | The password of your private key, if any. | . | pemcert_filepath | Absolute path to the client certificate. | . | pemcert_content | The content of the client certificate. Cannot be used when pemcert_filepath is set. | . Enabled ciphers and protocols . You can limit the allowed ciphers and TLS protocols for the LDAP connection. For example, you can allow only strong ciphers and limit the TLS versions to the most recent ones: . ldap: http_enabled: true transport_enabled: true ... authentication_backend: type: ldap config: enabled_ssl_ciphers: - \"TLS_DHE_RSA_WITH_AES_256_CBC_SHA\" - \"TLS_DHE_DSS_WITH_AES_128_CBC_SHA256\" enabled_ssl_protocols: - \"TLSv1.1\" - \"TLSv1.2\" . | Name | Description | . | enabled_ssl_ciphers | Array, enabled TLS ciphers. Only the Java format is supported. | . | enabled_ssl_protocols | Array, enabled TLS protocols. Only the Java format is supported. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/ldap/#connection-settings",
    "relUrl": "/docs/security/configuration/ldap/#connection-settings"
  },"397": {
    "doc": "Active Directory and LDAP",
    "title": "Use Active Directory and LDAP for authentication",
    "content": "To use Active Directory/LDAP for authentication, first configure a respective authentication domain in the authc section of plugins/opendistro_security/securityconfig/config.yml: . authc: ldap: http_enabled: true transport_enabled: true order: 1 http_authenticator: type: basic challenge: true authentication_backend: type: ldap config: ... Next, add the connection settings for your Active Directory/LDAP server to the config section of the authentication domain: . config: enable_ssl: true enable_start_tls: false enable_ssl_client_auth: false verify_hostnames: true hosts: - ldap.example.com:8389 bind_dn: cn=admin,dc=example,dc=com password: passw0rd . Authentication works by issuing an LDAP query containing the user name against the user subtree of the LDAP tree. The security plugin first takes the configured LDAP query and replaces the placeholder {0} with the user name from the user’s credentials. usersearch: '(sAMAccountName={0})' . Then it issues this query against the user subtree. Currently, the entire subtree under the configured userbase is searched: . userbase: 'ou=people,dc=example,dc=com' . If the query is successful, the security plugin retrieves the user name from the LDAP entry. You can specify which attribute from the LDAP entry the security plugin should use as the user name: . username_attribute: uid . If this key is not set or null, then the distinguished name (DN) of the LDAP entry is used. Configuration summary . | Name | Description | . | userbase | Specifies the subtree in the directory where user information is stored. | . | usersearch | The actual LDAP query that the security plugin executes when trying to authenticate a user. The variable {0} is substituted with the user name. | . | username_attribute | The security plugin uses this attribute of the directory entry to look for the user name. If set to null, the DN is used (default). | . Complete authentication example . ldap: http_enabled: true transport_enabled: true order: 1 http_authenticator: type: basic challenge: true authentication_backend: type: ldap config: enable_ssl: true enable_start_tls: false enable_ssl_client_auth: false verify_hostnames: true hosts: - ldap.example.com:636 bind_dn: cn=admin,dc=example,dc=com password: password userbase: 'ou=people,dc=example,dc=com' usersearch: '(sAMAccountName={0})' username_attribute: uid . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/ldap/#use-active-directory-and-ldap-for-authentication",
    "relUrl": "/docs/security/configuration/ldap/#use-active-directory-and-ldap-for-authentication"
  },"398": {
    "doc": "Active Directory and LDAP",
    "title": "Use Active Directory and LDAP for authorization",
    "content": "To use Active Directory/LDAP for authorization, first configure a respective authorization domain in the authz section of config.yml: . authz: ldap: http_enabled: true transport_enabled: true authorization_backend: type: ldap config: ... Authorization is the process of retrieving backend roles for an authenticated user from an LDAP server. This is typically the same servers that you use for authentication, but you can also use a different server. The only requirement is that the user to fetch the roles for actually exists on the LDAP server. Because the security plugin always checks if a user exists in the LDAP server, you must also configure userbase, usersearch and username_attribute in the authz section. Authorization works similarly to authentication. The security plugin issues an LDAP query containing the user name against the role subtree of the LDAP tree. As an alternative, the security plugin can also fetch roles that are defined as a direct attribute of the user entry in the user subtree. Approach 1: Query the role subtree . The security plugin first takes the LDAP query for fetching roles (“rolesearch”) and substitutes any variables found in the query. For example, for a standard Active Directory installation, you would use the following role search: . rolesearch: '(member={0})' . You can use the following variables: . | {0} is substituted with the DN of the user. | {1} is substituted with the user name, as defined by the username_attribute setting. | {2} is substituted with an arbitrary attribute value from the authenticated user’s directory entry. | . The variable {2} refers to an attribute from the user’s directory entry. The attribute that you should use is specified by the userroleattribute setting: . userroleattribute: myattribute . The security plugin then issues the substituted query against the configured role subtree. The entire subtree under rolebase is searched: . rolebase: 'ou=groups,dc=example,dc=com' . If you use nested roles (roles that are members of other roles), you can configure the security plugin to resolve them: . resolve_nested_roles: false . After all roles have been fetched, the security plugin extracts the final role names from a configurable attribute of the role entries: . rolename: cn . If this is not set, the DN of the role entry is used. You can now use this role name for mapping it to one or more of the security plugin roles, as defined in roles_mapping.yml. Approach 2: Use a user’s attribute as the role name . If you store the roles as a direct attribute of the user entries in the user subtree, you need to configure only the attribute name: . userrolename: roles . You can configure multiple attribute names: . userrolename: roles, otherroles . This approach can be combined with querying the role subtree. The security plugin fetches the roles from the user’s role attribute and then executes the role search. If you don’t use or have a role subtree, you can disable the role search completely: . rolesearch_enabled: false . (Advanced) Control LDAP user attributes . By default, the security plugin reads all LDAP user attributes and makes them available for index name variable substitution and DLS query variable substitution. If your LDAP entries have a lot of attributes, you might want to control which attributes should be made available. The fewer the attributes, the better the performance. | Name | Description | . | custom_attr_whitelist | String array. Specifies the LDAP attributes that should be made available for variable substitution. | . | custom_attr_maxval_len | Integer. Specifies the maximum allowed length of each attribute. All attributes longer than this value are discarded. A value of 0 disables custom attributes altogether. Default is 36. | . Example: . authz: ldap: http_enabled: true transport_enabled: true authorization_backend: type: ldap config: custom_attr_whitelist: - attribute1 - attribute2 custom_attr_maxval_len: 36 ... (Advanced) Exclude certain users from role lookup . If you are using multiple authentication methods, it can make sense to exclude certain users from the LDAP role lookup. Consider the following scenario for a typical Kibana setup: All Kibana users are stored in an LDAP/Active Directory server. However, you also have a Kibana server user. Kibana uses this user to manage stored objects and perform monitoring and maintenance tasks. You do not want to add this user to your Active Directory installation, but rather store it in the security plugin internal user database. In this case, it makes sense to exclude the Kibana server user from the LDAP authorization because we already know that there is no corresponding entry. You can use the skip_users configuration setting to define which users should be skipped. Wildcards and regular expressions are supported: . skip_users: - kibanaserver - 'cn=Jane Doe,ou*people,o=TEST' - '/\\S*/' . (Advanced) Exclude roles from nested role lookups . If the users in your LDAP installation have a large number of roles, and you have the requirement to resolve nested roles as well, you might run into performance issues. In most cases, however, not all user roles are related to Elasticsearch and Kibana. You might need only a couple of roles. In this case, you can use the nested role filter feature to define a list of roles that are filtered out from the list of the user’s roles. Wildcards and regular expressions are supported. This has an effect only if resolve_nested_roles is true: . nested_role_filter: - 'cn=Jane Doe,ou*people,o=TEST' - ... Configuration summary . | Name | Description | . | rolebase | Specifies the subtree in the directory where role/group information is stored. | . | rolesearch | The actual LDAP query that the security plugin executes when trying to determine the roles of a user. You can use three variables here (see below). | . | userroleattribute | The attribute in a user entry to use for {2} variable substitution. | . | userrolename | If the roles/groups of a user are not stored in the groups subtree, but as an attribute of the user’s directory entry, define this attribute name here. | . | rolename | The attribute of the role entry that should be used as the role name. | . | resolve_nested_roles | Boolean. Whether or not to resolve nested roles. Default is false. | . | skip_users | Array of users that should be skipped when retrieving roles. Wildcards and regular expressions are supported. | . | nested_role_filter | Array of role DNs that should be filtered before resolving nested roles. Wildcards and regular expressions are supported. | . | rolesearch_enabled | Boolean. Enable or disable the role search. Default is true. | . | custom_attr_whitelist | String array. Specifies the LDAP attributes that should be made available for variable substitution. | . | custom_attr_maxval_len | Integer. Specifies the maximum allowed length of each attribute. All attributes longer than this value are discarded. A value of 0 disables custom attributes altogether. Default is 36. | . Complete authorization example . authz: ldap: http_enabled: true transport_enabled: true authorization_backend: type: ldap config: enable_ssl: true enable_start_tls: false enable_ssl_client_auth: false verify_hostnames: true hosts: - ldap.example.com:636 bind_dn: cn=admin,dc=example,dc=com password: password userbase: 'ou=people,dc=example,dc=com' usersearch: '(uid={0})' username_attribute: uid rolebase: 'ou=groups,dc=example,dc=com' rolesearch: '(member={0})' userroleattribute: null userrolename: none rolename: cn resolve_nested_roles: true skip_users: - kibanaserver - 'cn=Jane Doe,ou*people,o=TEST' - '/\\S*/' . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/ldap/#use-active-directory-and-ldap-for-authorization",
    "relUrl": "/docs/security/configuration/ldap/#use-active-directory-and-ldap-for-authorization"
  },"399": {
    "doc": "Limitations",
    "title": "Limitations",
    "content": "The SQL plugin has the following limitations: . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/limitation/",
    "relUrl": "/docs/sql/limitation/"
  },"400": {
    "doc": "Limitations",
    "title": "SELECT FROM WHERE",
    "content": "Select literal is not supported . The select literal expression is not supported. For example, Select 1 is not supported. Here’s a link to the Github issue - Issue #256. Where clause does not support arithmetic operations . The WHERE clause does not support expressions. For example, SELECT FlightNum FROM kibana_sample_data_flights where (AvgTicketPrice + 100) &lt;= 1000 is not supported. Here’s a link to the Github issue - Issue #234. Aggregation over expression is not supported . You can only apply aggregation on fields, aggregations can’t accept an expression as a parameter. For example, avg(log(age)) is not supported. Here’s a link to the Github issue - Issue #288. Conflict type in multiple index query . Queries using wildcard index fail if the index has the field with a conflict type. For example, if you have two indices with field a: . POST conflict_index_1/_doc/ { \"a\": { \"b\": 1 } } POST conflict_index_2/_doc/ { \"a\": { \"b\": 1, \"c\": 2 } } . Then, the query fails because of the field mapping conflict. The query SELECT * FROM conflict_index* also fails for the same reason. Error occurred in Elasticsearch engine: Different mappings are not allowed for the same field[a]: found [{properties:{b:{type:long},c:{type:long}}}] and [{properties:{b:{type:long}}}] \", \"details\": \"com.amazon.opendistroforelasticsearch.sql.rewriter.matchtoterm.VerificationException: Different mappings are not allowed for the same field[a]: found [{properties:{b:{type:long},c:{type:long}}}] and [{properties:{b:{type:long}}}] \\nFor more details, please send request for Json format to see the raw response from elasticsearch engine.\", \"type\": \"VerificationException . Here’s a link to the Github issue - Issue #445. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/limitation/#select-from-where",
    "relUrl": "/docs/sql/limitation/#select-from-where"
  },"401": {
    "doc": "Limitations",
    "title": "Subquery in the FROM clause",
    "content": "Subquery in the FROM clause in this format: SELECT outer FROM (SELECT inner) is supported only when the query is merged into one query. For example, the following query is supported: . SELECT t.f, t.d FROM ( SELECT FlightNum as f, DestCountry as d FROM kibana_sample_data_flights WHERE OriginCountry = 'US') t . But, if the outer query has GROUP BY or ORDER BY, then it’s not supported. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/limitation/#subquery-in-the-from-clause",
    "relUrl": "/docs/sql/limitation/#subquery-in-the-from-clause"
  },"402": {
    "doc": "Limitations",
    "title": "JOIN does not support aggregations on the joined result",
    "content": "The join query does not support aggregations on the joined result. For example, e.g. SELECT depo.name, avg(empo.age) FROM empo JOIN depo WHERE empo.id == depo.id GROUP BY depo.name is not supported. Here’s a link to the Github issue - Issue 110. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/limitation/#join-does-not-support-aggregations-on-the-joined-result",
    "relUrl": "/docs/sql/limitation/#join-does-not-support-aggregations-on-the-joined-result"
  },"403": {
    "doc": "Limitations",
    "title": "Pagination only supports basic queries",
    "content": "The pagination query enables you to get back paginated responses. Currently, the pagination only supports basic queries. For example, the following query returns the data with cursor id. POST _opendistro/_sql/ { \"fetch_size\" : 5, \"query\" : \"SELECT OriginCountry, DestCountry FROM kibana_sample_data_flights ORDER BY OriginCountry ASC\" } . The response in JDBC format with cursor id. { \"schema\": [ { \"name\": \"OriginCountry\", \"type\": \"keyword\" }, { \"name\": \"DestCountry\", \"type\": \"keyword\" } ], \"cursor\": \"d:eyJhIjp7fSwicyI6IkRYRjFaWEo1UVc1a1JtVjBZMmdCQUFBQUFBQUFCSllXVTJKVU4yeExiWEJSUkhsNFVrdDVXVEZSYkVKSmR3PT0iLCJjIjpbeyJuYW1lIjoiT3JpZ2luQ291bnRyeSIsInR5cGUiOiJrZXl3b3JkIn0seyJuYW1lIjoiRGVzdENvdW50cnkiLCJ0eXBlIjoia2V5d29yZCJ9XSwiZiI6MSwiaSI6ImtpYmFuYV9zYW1wbGVfZGF0YV9mbGlnaHRzIiwibCI6MTMwNTh9\", \"total\": 13059, \"datarows\": [[ \"AE\", \"CN\" ]], \"size\": 1, \"status\": 200 } . The query with aggregation and join does not support pagination for now. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/limitation/#pagination-only-supports-basic-queries",
    "relUrl": "/docs/sql/limitation/#pagination-only-supports-basic-queries"
  },"404": {
    "doc": "Logs",
    "title": "Logs",
    "content": "The Elasticsearch logs include valuable information for monitoring cluster operations and troubleshooting issues. The location of the logs differs based on the installation type: . | On Docker, Elasticsearch writes most logs to the console and stores the remainder in elasticsearch/logs/. The tarball installation also uses elasticsearch/logs/. | On the RPM and Debian installations, Elasticsearch writes logs to /var/log/elasticsearch/. | . Logs are available as .log (plain text) and .json files. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/logs/",
    "relUrl": "/docs/elasticsearch/logs/"
  },"405": {
    "doc": "Logs",
    "title": "Application logs",
    "content": "For its application logs, Elasticsearch uses Apache Log4j 2 and its built-in log levels (from least to most severe) of TRACE, DEBUG, INFO, WARN, ERROR, and FATAL. The default Elasticsearch log level is INFO. Rather than changing the default log level (logger.level), you change the log level for individual Elasticsearch modules: . PUT /_cluster/settings { \"persistent\" : { \"logger.org.elasticsearch.index.reindex\" : \"DEBUG\" } } . The easiest way to identify modules is not from the logs, which abbreviate the path (for example, o.e.i.r), but from the Elasticsearch source code. After this sample change, Elasticsearch emits much more detailed logs during reindex operations: . [2019-10-18T16:52:51,184][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: starting [2019-10-18T16:52:51,186][DEBUG][o.e.i.r.TransportReindexAction] [node1] executing initial scroll against [some-index] [2019-10-18T16:52:51,291][DEBUG][o.e.i.r.TransportReindexAction] [node1] scroll returned [3] documents with a scroll id of [DXF1Z==] [2019-10-18T16:52:51,292][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: got scroll response with [3] hits [2019-10-18T16:52:51,294][DEBUG][o.e.i.r.WorkerBulkByScrollTaskState] [node1] [1626]: preparing bulk request for [0s] [2019-10-18T16:52:51,297][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: preparing bulk request [2019-10-18T16:52:51,299][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: sending [3] entry, [222b] bulk request [2019-10-18T16:52:51,310][INFO ][o.e.c.m.MetaDataMappingService] [node1] [some-new-index/R-j3adc6QTmEAEb-eAie9g] create_mapping [_doc] [2019-10-18T16:52:51,383][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: got scroll response with [0] hits [2019-10-18T16:52:51,384][DEBUG][o.e.i.r.WorkerBulkByScrollTaskState] [node1] [1626]: preparing bulk request for [0s] [2019-10-18T16:52:51,385][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: preparing bulk request [2019-10-18T16:52:51,386][DEBUG][o.e.i.r.TransportReindexAction] [node1] [1626]: finishing without any catastrophic failures [2019-10-18T16:52:51,395][DEBUG][o.e.i.r.TransportReindexAction] [node1] Freed [1] contexts . The DEBUG and TRACE levels are extremely verbose. If you enable either one to troubleshoot a problem, disable it after you finish. There are other ways to change log levels: . | Add lines to elasticsearch.yml: . logger.org.elasticsearch.index.reindex: debug . Modifying elasticsearch.yml makes the most sense if you want to reuse your logging configuration across multiple clusters or debug startup issues with a single node. | Modify log4j2.properties: . # Define a new logger with unique ID of reindex logger.reindex.name = org.elasticsearch.index.reindex # Set the log level for that ID logger.reindex.level = debug . This approach is extremely flexible, but requires familiarity with the Log4j 2 property file syntax. In general, the other options offer a simpler configuration experience. If you examine the default log4j2.properties file in the configuration directory, you can see a few Elasticsearch-specific variables: . appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] [%node_name]%marker %m%n appender.rolling_old.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log . | ${sys:es.logs.base_path} is the directory for logs (for example, /var/log/elasticsearch/). | ${sys:es.logs.cluster_name} is the name of the cluster. | [%node_name] is the name of the node. | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/logs/#application-logs",
    "relUrl": "/docs/elasticsearch/logs/#application-logs"
  },"406": {
    "doc": "Logs",
    "title": "Slow logs",
    "content": "Elasticsearch has two slow logs, logs that help you identify performance issues: the search slow log and the indexing slow log. These logs rely on thresholds to define what qualifies as a “slow” search or indexing operation. For example, you might decide that a query is slow if it takes more than 15 seconds to complete. Unlike application logs, which you configure for modules, you configure slow logs for indices. By default, both logs are disabled (all thresholds are set to -1): . GET &lt;some-index&gt;/_settings?include_defaults=true { \"indexing\": { \"slowlog\": { \"reformat\": \"true\", \"threshold\": { \"index\": { \"warn\": \"-1\", \"trace\": \"-1\", \"debug\": \"-1\", \"info\": \"-1\" } }, \"source\": \"1000\", \"level\": \"TRACE\" } }, \"search\": { \"slowlog\": { \"level\": \"TRACE\", \"threshold\": { \"fetch\": { \"warn\": \"-1\", \"trace\": \"-1\", \"debug\": \"-1\", \"info\": \"-1\" }, \"query\": { \"warn\": \"-1\", \"trace\": \"-1\", \"debug\": \"-1\", \"info\": \"-1\" } } } } } . To enable these logs, increase one or more thresholds: . PUT &lt;some-index&gt;/_settings { \"indexing\": { \"slowlog\": { \"threshold\": { \"index\": { \"warn\": \"15s\", \"trace\": \"750ms\", \"debug\": \"3s\", \"info\": \"10s\" } }, \"source\": \"500\", \"level\": \"INFO\" } } } . In this example, Elasticsearch logs indexing operations that take 15 seconds or longer at the WARN level and operations that take between 10 and 14.x seconds at the INFO level. If you set a threshold to 0 seconds, Elasticsearch logs all operations, which can be useful for testing that slow logs are indeed enabled. | reformat specifies whether to log the document _source field as a single line (true) or let it span multiple lines (false). | source is the number of characters of the document _source field to log. | level is the minimum log level to include. | . A line from elasticsearch_index_indexing_slowlog.log might look like this: . node1 | [2019-10-24T19:48:51,012][WARN][i.i.s.index] [node1] [some-index/i86iF5kyTyy-PS8zrdDeAA] took[3.4ms], took_millis[3], type[_doc], id[1], routing[], source[{\"title\":\"Your Name\", \"Director\":\"Makoto Shinkai\"}] . Slow logs can consume considerable disk space if you set thresholds or levels too low. Consider enabling them temporarily for troubleshooting or performance tuning. To disable slow logs, return all thresholds to -1. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/logs/#slow-logs",
    "relUrl": "/docs/elasticsearch/logs/#slow-logs"
  },"407": {
    "doc": "Logs",
    "title": "Deprecation logs",
    "content": "Deprecation logs record when clients make deprecated API calls to your cluster. These logs can help you identify and fix issues prior to upgrading to a new major version. By default, Elasticsearch logs deprecated API calls at the WARN level, which works well for almost all use cases. If desired, configure logger.deprecation.level using _cluster/settings, elasticsearch.yml, or log4j2.properties. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/logs/#deprecation-logs",
    "relUrl": "/docs/elasticsearch/logs/#deprecation-logs"
  },"408": {
    "doc": "Managed Indices",
    "title": "Managed indices",
    "content": "You can change or update a policy using the managed index operations. This table lists the fields of managed index operations. | Parameter | Description | Type | Required | Read Only | . | name | The name of the managed index policy. | string | Yes | No | . | index | The name of the managed index that this policy is managing. | string | Yes | No | . | index_uuid | The uuid of the index. | string | Yes | No | . | enabled | When true, the managed index is scheduled and run by the scheduler. | boolean | Yes | No | . | enabled_time | The time the managed index was last enabled. If the managed index process is disabled, then this is null. | timestamp | Yes | Yes | . | last_updated_time | The time the managed index was last updated. | timestamp | Yes | Yes | . | schedule | The schedule of the managed index job. | object | Yes | No | . | policy_id | The name of the policy used by this managed index. | string | Yes | No | . | policy_seq_no | The sequence number of the policy used by this managed index. | number | Yes | No | . | policy_primary_term | The primary term of the policy used by this managed index. | number | Yes | No | . | policy_version | The version of the policy used by this managed index. | number | Yes | Yes | . | policy | The cached JSON of the policy for the policy_version that’s used during runs. If the policy is null, it means that this is the first execution of the job and the latest policy document is read in/saved. | object | No | No | . | change_policy | The information regarding what policy and state to change to. | object | No | No | . | policy_name | The name of the policy to update to. To update to the latest version, set this to be the same as the current policy_name. | string | No | Yes | . | state | The state of the managed index after it finishes updating. If no state is specified, it’s assumed that the policy structure did not change. | string | No | Yes | . The following example shows a managed index policy: . { \"managed_index\": { \"name\": \"my_index\", \"index\": \"my_index\", \"index_uuid\": \"sOKSOfkdsoSKeofjIS\", \"enabled\": true, \"enabled_time\": 1553112384, \"last_updated_time\": 1553112384, \"schedule\": { \"interval\": { \"period\": 1, \"unit\": \"MINUTES\", \"start_time\": 1553112384 } }, \"policy_id\": \"log_rotation\", \"policy_version\": 1, \"policy\": {...}, \"change_policy\": null } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/managedindices/#managed-indices",
    "relUrl": "/docs/ism/managedindices/#managed-indices"
  },"409": {
    "doc": "Managed Indices",
    "title": "Change policy",
    "content": "You can change any managed index policy, but ISM has a few constraints in place to make sure that policy changes don’t break indices. If an index is stuck in its current state, never proceeding, and you want to update its policy immediately, make sure that the new policy includes the same state—same name, same actions, same order—as the old policy. In this case, even if the policy is in the middle of executing an action, ISM applies the new policy. If you update the policy without including an identical state, ISM updates the policy only after all actions in the current state finish executing. Alternately, you can choose a specific state in your old policy after which you want the new policy to take effect. To change a policy using Kibana, do the following: . | Under Managed indices, choose the indices that you want to attach the new policy to. | To attach the new policy to indices in specific states, choose Choose state filters, and then choose those states. | Under Choose New Policy, choose the new policy. | To start the new policy for indices in the current state, choose Keep indices in their current state after the policy takes effect. | To start the new policy in a specific state, choose Start from a chosen state after changing policies, and then choose the default start state in your new policy. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/managedindices/#change-policy",
    "relUrl": "/docs/ism/managedindices/#change-policy"
  },"410": {
    "doc": "Managed Indices",
    "title": "Managed Indices",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/managedindices/",
    "relUrl": "/docs/ism/managedindices/"
  },"411": {
    "doc": "WMS Map Server",
    "title": "Configure WMS map server",
    "content": "Due to licensing restrictions, the default installation of Kibana does in Open Distro for Elasticsearch doesn’t include a map server for tile map visualizations. To configure Kibana to use a WMS map server: . | Open Kibana at https://&lt;host&gt;:&lt;port&gt;. For example, https://localhost:5601. | If necessary, log in. | Management. | Advanced Settings. | Locate visualization:tileMap:WMSdefaults. | Change enabled to true, and add the URL of a valid WMS map server. { \"enabled\": true, \"url\": \"&lt;wms-map-server-url&gt;\", \"options\": { \"format\": \"image/png\", \"transparent\": true } } . | . Map services often have licensing fees or restrictions. You are responsible for all such considerations on any map server that you specify. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/maptiles/#configure-wms-map-server",
    "relUrl": "/docs/kibana/maptiles/#configure-wms-map-server"
  },"412": {
    "doc": "WMS Map Server",
    "title": "WMS Map Server",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/maptiles/",
    "relUrl": "/docs/kibana/maptiles/"
  },"413": {
    "doc": "Metadata Queries",
    "title": "Metadata queries",
    "content": "To see basic metadata about your indices, use the SHOW and DESCRIBE commands. Syntax . Rule showStatement: . Rule showFilter: . Example 1: See metadata for indices . To see metadata for indices that match a specific pattern, use the SHOW command. Use the wildcard % to match all indices: . SHOW TABLES LIKE % . | TABLE_CAT | TABLE_SCHEM | TABLE_NAME | TABLE_TYPE | REMARKS | TYPE_CAT | TYPE_SCHEM | TYPE_NAME | SELF_REFERENCING_COL_NAME | REF_GENERATION | . | docker-cluster | null | accounts | BASE TABLE | null | null | null | null | null | null | . | docker-cluster | null | employees_nested | BASE TABLE | null | null | null | null | null | null | . Example 2: See metadata for a specific index . To see metadata for an index name with a prefix of acc: . SHOW TABLES LIKE acc% . | TABLE_CAT | TABLE_SCHEM | TABLE_NAME | TABLE_TYPE | REMARKS | TYPE_CAT | TYPE_SCHEM | TYPE_NAME | SELF_REFERENCING_COL_NAME | REF_GENERATION | . | docker-cluster | null | accounts | BASE TABLE | null | null | null | null | null | null | . Example 3: See metadata for fields . To see metadata for field names that match a specific pattern, use the DESCRIBE command: . DESCRIBE TABLES LIKE accounts . | TABLE_CAT | TABLE_SCHEM | TABLE_NAME | COLUMN_NAME | DATA_TYPE | TYPE_NAME | COLUMN_SIZE | BUFFER_LENGTH | DECIMAL_DIGITS | NUM_PREC_RADIX | NULLABLE | REMARKS | COLUMN_DEF | SQL_DATA_TYPE | SQL_DATETIME_SUB | CHAR_OCTET_LENGTH | ORDINAL_POSITION | IS_NULLABLE | SCOPE_CATALOG | SCOPE_SCHEMA | SCOPE_TABLE | SOURCE_DATA_TYPE | IS_AUTOINCREMENT | IS_GENERATEDCOLUMN | . | docker-cluster | null | accounts | account_number | null | long | null | null | null | 10 | 2 | null | null | null | null | null | 1 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | firstname | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 2 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | address | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 3 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | balance | null | long | null | null | null | 10 | 2 | null | null | null | null | null | 4 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | gender | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 5 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | city | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 6 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | employer | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 7 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | state | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 8 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | age | null | long | null | null | null | 10 | 2 | null | null | null | null | null | 9 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | email | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 10 |   | null | null | null | null | NO |   | . | docker-cluster | null | accounts | lastname | null | text | null | null | null | 10 | 2 | null | null | null | null | null | 11 |   | null | null | null | null | NO |   | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/metadata/#metadata-queries",
    "relUrl": "/docs/sql/metadata/#metadata-queries"
  },"414": {
    "doc": "Metadata Queries",
    "title": "Metadata Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/metadata/",
    "relUrl": "/docs/sql/metadata/"
  },"415": {
    "doc": "Monitoring",
    "title": "Monitoring",
    "content": "By a stats endpoint, you are able to collect metrics for the plugin within the interval. Note that only node level statistics collecting is implemented for now. In other words, you only get the metrics for the node you’re accessing. Cluster level statistics have yet to be implemented. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/monitoring/",
    "relUrl": "/docs/sql/monitoring/"
  },"416": {
    "doc": "Monitoring",
    "title": "Node Stats",
    "content": "Description . The meaning of fields in the response is as follows: . | Field name | Description | . | request_total | Total count of request | . | request_count | Total count of request within the interval | . | failed_request_count_syserr | Count of failed request due to system error within the interval | . | failed_request_count_cuserr | Count of failed request due to bad request within the interval | . | failed_request_count_cb | Indicate if plugin is being circuit broken within the interval | . Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X GET localhost:9200/_opendistro/_sql/stats . Result set: . { \"failed_request_count_cb\": 0, \"failed_request_count_cuserr\": 0, \"circuit_breaker\": 0, \"request_total\": 0, \"request_count\": 0, \"failed_request_count_syserr\": 0 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/monitoring/#node-stats",
    "relUrl": "/docs/sql/monitoring/#node-stats"
  },"417": {
    "doc": "Monitors",
    "title": "Monitors",
    "content": ". | Key terms | Create destinations . | Email as a destination | . | Create monitors | Create triggers . | Visual graph | Extraction query | Anomaly detector | . | Add actions | Work with alerts | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/",
    "relUrl": "/docs/alerting/monitors/"
  },"418": {
    "doc": "Monitors",
    "title": "Key terms",
    "content": "| Term | Definition | . | Monitor | A job that runs on a defined schedule and queries Elasticsearch. The results of these queries are then used as input for one or more triggers. | . | Trigger | Conditions that, if met, generate alerts and can perform some action. | . | Alert | A notification that a monitor’s trigger condition has been met. | . | Action | The information that you want the monitor to send out after being triggered. Actions have a destination, a message subject, and a message body. | . | Destination | A reusable location for an action, such as Amazon Chime, Slack, or a webhook URL. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#key-terms",
    "relUrl": "/docs/alerting/monitors/#key-terms"
  },"419": {
    "doc": "Monitors",
    "title": "Create destinations",
    "content": ". | Choose Alerting, Destinations, Add destination. | Specify a name for the destination so that you can identify it later. | For Type, choose Slack, Amazon Chime, custom webhook, or email. | . For Email type, refer to Email as a destination section below. For all other types, specify the webhook URL. For more information about webhooks, see the documentation for Slack and Chime. For custom webhooks, you must specify more information: parameters and headers. For example, if your endpoint requires basic authentication, you might need to add a header with a key of Authorization and a value of Basic &lt;Base64-encoded-credential-string&gt;. You might also need to change Content-Type to whatever your webhook requires. Popular values are application/json, application/xml, and text/plain. This information is stored in plain text in the Elasticsearch cluster. We will improve this design in the future, but for now, the encoded credentials (which are neither encrypted nor hashed) might be visible to other Elasticsearch users. Email as a destination . To send or receive an alert notification as an email, first select Email as the destination Type for the alert. Next, you must add at least one sender and a recipient. We also recommend adding email groups if you want to notify more than a few people of an alert. You can configure senders and recipients using Manage senders and Manage email groups. Manage senders . Manage senders allows you to configure and manage Sender email addresses. Senders are email accounts from where the alert notification is sent to different recipients or email groups. To configure a sender email, do the following: . | Once you choose Email as the destination Type, choose Manage senders, under Settings. You can also do this using the Actions button on the top right of the Destinations page. | In the Manage email senders modal window, choose Add sender, New sender. Multiple senders can be added one at a time. | Enter a unique Sender name. | Enter the Email address, SMTP Host (e.g. smtp.gmail.com for a Gmail account), and the Port number. | You can choose to use an Encryption method or leave it as None. However, most email providers require SSL or TLS and this requires you to add a username and password to the Elasticsearch keystore. Refer to Authenticate sender account to learn more. | Choose Save to save the configuration and create the sender. You can create a sender even before you enter your credentials for SSL or TLS. However, you must authenticate each sender account with credentials before you use the destination to send your alert. | . Once the sender is created, the sender account is available to be selected when creating an email destination. You can reuse senders across many different destinations, but each destination only supports one sender. Manage email groups or recipients . Use email groups to create and manage reusable lists of email addresses. For example, one alert might email the DevOps team, whereas another might email the DevOps team and the engineering team. You can enter individual email addresses, or an email group in the Recipients field. For email groups, you can pre-create a group using Manage email groups. To create and manage email groups, do the following: . | Once you select Email as the destination Type, choose Manage email groups, under Settings. Then choose Add email group, New email group. You can also do this using the Actions button on the top right of the Destinations page. | Enter a unique Email group name. | For recipient emails, enter any number of email addresses. | Choose Save. | . You can view the list of all email destinations you created on the Destinations landing page. The Actions button on the top right of the Destinations page allows you to mange email senders and email groups from this page. Authenticate sender account . You must authenticate each sender account with credentials before you send an alert notification from that account to recipients or email groups. You can enter these credentials in the Elasticsearch keystore using the CLI. Run the following commands (in your Elasticsearch directory) to enter your username and password. The &lt;sender_name&gt; is the name you entered for Sender./bin/elasticsearch-keystore add opendistro.alerting.destination.email.&lt;sender_name&gt;.username ./bin/elasticsearch-keystore add opendistro.alerting.destination.email.&lt;sender_name&gt;.password . Note: The keystore settings are node-specific. You must run these commands on each node. To change or update your credentials (once you’ve added them in the keystore settings for every node), you can call the reload API to ensure that your new changes are automatically updated on every node. Run this command to call the reload API: . POST _nodes/reload_secure_settings { \"secure_settings_password\": \"1234\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#create-destinations",
    "relUrl": "/docs/alerting/monitors/#create-destinations"
  },"420": {
    "doc": "Monitors",
    "title": "Create monitors",
    "content": ". | Choose Alerting, Monitors, Create monitor. | Specify a name and schedule for the monitor. | . The anomaly detection option is for pairing with the anomaly detection plugin. See Anomaly Detection. For anomaly detector, choose an appropriate schedule for the monitor based on the detector interval. Otherwise, the alerting monitor may miss reading the results. For example, assume you set the monitor interval and the detector interval as 5 minutes, and you start the detector at 12:00. If an anomaly is detected at 12:05, it might be available at 12:06 because of the delay between writing the anomaly and it being available for queries. The monitor reads the anomaly results between 12:00 and 12:05, so it does not get the anomaly results available at 12:06. To avoid this issue, make sure the alerting monitor is at least twice the detector interval. When you create a monitor using Kibana, the anomaly detector plugin generates a default monitor schedule that’s twice the detector interval. Whenever you update a detector’s interval, make sure to update the associated monitor interval as well, as the anomaly detection plugin does not do this automatically. | Choose one or more indices. You can also use * as a wildcard to specify an index pattern. | Define the monitor in one of three ways: visually, using a query, or using an anomaly detector. | Visual definition works well for monitors that you can define as “some value is above or below some threshold for some amount of time.” . | Query definition gives you flexibility in terms of what you query for (using the Elasticsearch query DSL) and how you evaluate the results of that query (Painless scripting). This example averages the cpu_usage field: . { \"size\": 0, \"query\": { \"match_all\": {} }, \"aggs\": { \"avg_cpu\": { \"avg\": { \"field\": \"cpu_usage\" } } } } . You can even filter query results using {{period_start}} and {{period_end}}: . { \"size\": 0, \"query\": { \"bool\": { \"filter\": [{ \"range\": { \"timestamp\": { \"from\": \"{{period_end}}||-1h\", \"to\": \"{{period_end}}\", \"include_lower\": true, \"include_upper\": true, \"format\": \"epoch_millis\", \"boost\": 1 } } }], \"adjust_pure_negative\": true, \"boost\": 1 } }, \"aggregations\": {} } . “Start” and “end” refer to the interval at which the monitor runs. See Available variables. | . | To define a monitor visually, choose Define using visual graph. Then choose an aggregation (for example, count() or average()), a set of documents, and a timeframe. Visual definition works well for most monitors. To use a query, choose Define using extraction query, add your query (using the Elasticsearch query DSL), and test it using the Run button. The monitor makes this query to Elasticsearch as often as the schedule dictates; check the Query Performance section and make sure you’re comfortable with the performance implications. To use an anomaly detector, choose Define using Anomaly detector and select your Detector. | Choose Create. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#create-monitors",
    "relUrl": "/docs/alerting/monitors/#create-monitors"
  },"421": {
    "doc": "Monitors",
    "title": "Create triggers",
    "content": "The next step in creating a monitor is to create a trigger. These steps differ depending on whether you chose Define using visual graph or Define using extraction query or Define using Anomaly detector when you created the monitor. Either way, you begin by specifying a name and severity level for the trigger. Severity levels help you manage alerts. A trigger with a high severity level (e.g. 1) might page a specific individual, whereas a trigger with a low severity level might message a chat room. Visual graph . For Trigger condition, specify a threshold for the aggregation and timeframe you chose earlier, such as “is below 1,000” or “is exactly 10.” . The line moves up and down as you increase and decrease the threshold. Once this line is crossed, the trigger evaluates to true. Extraction query . For Trigger condition, specify a Painless script that returns true or false. Painless is the default Elasticsearch scripting language and has a syntax similar to Groovy. Trigger condition scripts revolve around the ctx.results[0] variable, which corresponds to the extraction query response. For example, your script might reference ctx.results[0].hits.total.value or ctx.results[0].hits.hits[i]._source.error_code. A return value of true means the trigger condition has been met, and the trigger should execute its actions. Test your script using the Run button. The Info link next to Trigger condition contains a useful summary of the variables and results available to your query. Anomaly detector . For Trigger type, choose Anomaly detector grade and confidence. Specify the Anomaly grade condition for the aggregation and timeframe you chose earlier, “IS ABOVE 0.7” or “IS EXACTLY 0.5.” The anomaly grade is a number between 0 and 1 that indicates the level of severity of how anomalous a data point is. Specify the Anomaly confidence condition for the aggregation and timeframe you chose earlier, “IS ABOVE 0.7” or “IS EXACTLY 0.5.” The anomaly confidence is an estimate of the probability that the reported anomaly grade matches the expected anomaly grade. The line moves up and down as you increase and decrease the threshold. Once this line is crossed, the trigger evaluates to true. Sample scripts . // Evaluates to true if the query returned any documents ctx.results[0].hits.total.value &gt; 0 . // Returns true if the avg_cpu aggregation exceeds 90 if (ctx.results[0].aggregations.avg_cpu.value &gt; 90) { return true; } . // Performs some crude custom scoring and returns true if that score exceeds a certain value int score = 0; for (int i = 0; i &lt; ctx.results[0].hits.hits.length; i++) { // Weighs 500 errors 10 times as heavily as 503 errors if (ctx.results[0].hits.hits[i]._source.http_status_code == \"500\") { score += 10; } else if (ctx.results[0].hits.hits[i]._source.http_status_code == \"503\") { score += 1; } } if (score &gt; 99) { return true; } else { return false; } . Available variables . | Variable | Description | . | ctx.results | An array with one element (i.e. ctx.results[0]). Contains the query results. This variable is empty if the trigger was unable to retrieve results. See ctx.error. | . | ctx.monitor | Includes ctx.monitor.name, ctx.monitor.type, ctx.monitor.enabled, ctx.monitor.enabled_time, ctx.monitor.schedule, ctx.monitor.inputs, triggers and ctx.monitor.last_update_time. | . | ctx.trigger | Includes ctx.trigger.name, ctx.trigger.severity, ctx.trigger.condition, and ctx.trigger.actions. | . | ctx.periodStart | Unix timestamp for the beginning of the period during which the alert triggered. For example, if a monitor runs every ten minutes, a period might begin at 10:40 and end at 10:50. | . | ctx.periodEnd | The end of the period during which the alert triggered. | . | ctx.error | The error message if the trigger was unable to retrieve results or unable to evaluate the trigger, typically due to a compile error or null pointer exception. Null otherwise. | . | ctx.alert | The current, active alert (if it exists). Includes ctx.alert.id, ctx.alert.version, and ctx.alert.isAcknowledged. Null if no alert is active. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#create-triggers",
    "relUrl": "/docs/alerting/monitors/#create-triggers"
  },"422": {
    "doc": "Monitors",
    "title": "Add actions",
    "content": "The final step in creating a monitor is to add one or more actions. Actions send notifications when trigger conditions are met and support Slack, Amazon Chime, and webhooks. If you don’t want to receive notifications for alerts, you don’t have to add actions to your triggers. Instead, you can periodically check Kibana. | Specify a name for the action. | Choose a destination. | Add a subject and body for the message. You can add variables to your messages using Mustache templates. You have access to ctx.action.name, the name of the current action, as well as all trigger variables. If your destination is a custom webhook that expects a particular data format, you might need to include JSON (or even XML) directly in the message body: . { \"text\": \"Monitor {{ctx.monitor.name}} just entered alert status. Please investigate the issue. - Trigger: {{ctx.trigger.name}} - Severity: {{ctx.trigger.severity}} - Period start: {{ctx.periodStart}} - Period end: {{ctx.periodEnd}}\" } . In this case, the message content must conform to the Content-Type header in the custom webhook. | Choose Create. | . After an action sends a message, the content of that message has left the purview of the security plugin. Securing access to the message (e.g. access to the Slack channel) is your responsibility. Sample message . Monitor {{ctx.monitor.name}} just entered an alert state. Please investigate the issue. - Trigger: {{ctx.trigger.name}} - Severity: {{ctx.trigger.severity}} - Period start: {{ctx.periodStart}} - Period end: {{ctx.periodEnd}} . If you want to use the ctx.results variable in a message, use {{ctx.results.0}} rather than {{ctx.results[0]}}. This difference is due to how Mustache handles bracket notation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#add-actions",
    "relUrl": "/docs/alerting/monitors/#add-actions"
  },"423": {
    "doc": "Monitors",
    "title": "Work with alerts",
    "content": "Alerts persist until you resolve the root cause and have the following states: . | State | Description | . | Active | The alert is ongoing and unacknowledged. Alerts remain in this state until you acknowledge them, delete the trigger associated with the alert, or delete the monitor entirely. | . | Acknowledged | Someone has acknowledged the alert, but not fixed the root cause. | . | Completed | The alert is no longer ongoing. Alerts enter this state after the corresponding trigger evaluates to false. | . | Error | An error occurred while executing the trigger—usually the result of a a bad trigger or destination. | . | Deleted | Someone deleted the monitor or trigger associated with this alert while the alert was ongoing. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/monitors/#work-with-alerts",
    "relUrl": "/docs/alerting/monitors/#work-with-alerts"
  },"424": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Kibana multi-tenancy",
    "content": "Tenants in Kibana are spaces for saving index patterns, visualizations, dashboards, and other Kibana objects. By default, all Kibana users have access to two tenants: Private and Global. The global tenant is shared between every Kibana user. The private tenant is exclusive to each user and can’t be shared. Tenants are useful for safely sharing your work with other Kibana users. You can control which roles have access to a tenant and whether those roles have read or write access. You might use the private tenant for exploratory work, create detailed visualizations with your team in an analysts tenant, and maintain a summary dashboard for corporate leadership in an executive tenant. If you share a visualization or dashboard with someone, you can see that the URL includes the tenant: . http://&lt;kibana_host&gt;:5601/app/kibana?security_tenant=analysts#/visualize/edit/c501fa50-7e52-11e9-ae4e-b5d69947d32e?_g=() . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/#kibana-multi-tenancy",
    "relUrl": "/docs/security/access-control/multi-tenancy/#kibana-multi-tenancy"
  },"425": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Configuration",
    "content": "Multi-tenancy is enabled by default, but you can disable it or change its settings using plugins/opendistro_security/securityconfig/config.yml: . config: dynamic: kibana: multitenancy_enabled: true server_username: kibanaserver index: '.kibana' do_not_fail_on_forbidden: false . | Setting | Description | . | multitenancy_enabled | Enable or disable multi-tenancy. Default is true. | . | server_username | Must match the name of the Kibana server user from kibana.yml. Default is kibanaserver. | . | index | Must match the name of the Kibana index from kibana.yml. Default is .kibana. | . | do_not_fail_on_forbidden | If true, the security plugin removes any content that a user is not allowed to see from search results. If false, the plugin returns a security exception. Default is false. | . kibana.yml has some additional settings: . elasticsearch.username: kibanaserver elasticsearch.password: kibanaserver elasticsearch.requestHeadersWhitelist: [\"securitytenant\",\"Authorization\"] opendistro_security.multitenancy.enabled: true opendistro_security.multitenancy.tenants.enable_global: true opendistro_security.multitenancy.tenants.enable_private: true opendistro_security.multitenancy.tenants.preferred: [\"Private\", \"Global\"] opendistro_security.multitenancy.enable_filter: false . | Setting | Description | . | elasticsearch.requestHeadersWhitelist | Kibana requires that you whitelist all HTTP headers that it passes to Elasticsearch. Multi-tenancy uses a specific header, securitytenant, that must be present with the standard Authorization header. If the securitytenant header is not whitelisted, Kibana starts with a red status. | . | opendistro_security.multitenancy.enabled | Enables or disables multi-tenancy in Kibana. Default is true. | . | opendistro_security.multitenancy.tenants.enable_global | Enables or disables the global tenant. Default is true. | . | opendistro_security.multitenancy.tenants.enable_private | Enables or disables the private tenant. Default is true. | . | opendistro_security.multitenancy.tenants.preferred | Lets you change ordering in the Tenants tab of Kibana. By default, the list starts with global and private (if enabled) and then proceeds alphabetically. You can add tenants here to move them to the top of the list. | . | opendistro_security.multitenancy.enable_filter | If you have many tenants, you can add a search bar to the top of the list. Default is false. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/#configuration",
    "relUrl": "/docs/security/access-control/multi-tenancy/#configuration"
  },"426": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Add tenants",
    "content": "To create tenants, use Kibana, the REST API, or tenants.yml. Kibana . | Open Kibana. | Choose Security, Tenants, and Create tenant. | Give the tenant a name and description. | Choose Create. | . REST API . See Create tenant. tenants.yml . --- _meta: type: \"tenants\" config_version: 2 ## Demo tenants admin_tenant: reserved: false description: \"Demo tenant for admin user\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/#add-tenants",
    "relUrl": "/docs/security/access-control/multi-tenancy/#add-tenants"
  },"427": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Give roles access to tenants",
    "content": "After creating a tenant, give a role access to it using Kibana, the REST API, or roles.yml. | Read-write (kibana_all_write) permissions let the role view and modify objects in the tenant. | Read-only (kibana_all_read) permissions let the role view objects, but not modify them. | . Kibana . | Open Kibana. | Choose Security, Roles, and a role. | For Tenant permissions, add tenants, press Enter, and give the role read and/or write permissions to it. | . REST API . See Create role. roles.yml . --- test-role: reserved: false hidden: false cluster_permissions: - \"cluster_composite_ops\" - \"indices_monitor\" index_permissions: - index_patterns: - \"movies*\" dls: \"\" fls: [] masked_fields: [] allowed_actions: - \"read\" tenant_permissions: - tenant_patterns: - \"human_resources\" allowed_actions: - \"kibana_all_read\" static: false _meta: type: \"roles\" config_version: 2 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/#give-roles-access-to-tenants",
    "relUrl": "/docs/security/access-control/multi-tenancy/#give-roles-access-to-tenants"
  },"428": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Manage Kibana indices",
    "content": "The open source version of Kibana saves all objects to a single index: .kibana. The security plugin uses this index for the global tenant, but separate indices for every other tenant. Each user also has a private tenant, so you might see a large number of indices that follow two patterns: .kibana_&lt;hash&gt;_&lt;tenant_name&gt; .kibana_&lt;hash&gt;_&lt;username&gt; . The security plugin scrubs these index names of special characters, so they might not be a perfect match of tenant names and usernames. To back up your Kibana data, take a snapshot of all tenant indices using an index pattern such as .kibana*. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/#manage-kibana-indices",
    "relUrl": "/docs/security/access-control/multi-tenancy/#manage-kibana-indices"
  },"429": {
    "doc": "Kibana Multi-Tenancy",
    "title": "Kibana Multi-Tenancy",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/multi-tenancy/",
    "relUrl": "/docs/security/access-control/multi-tenancy/"
  },"430": {
    "doc": "ODBC Driver",
    "title": "ODBC driver",
    "content": "The Open Database Connectivity (ODBC) driver is a read-only ODBC driver for Windows and macOS that lets you connect business intelligence (BI) and data visualization applications like Tableau and Microsoft Excel to the SQL plugin. For information on downloading and using the JAR file, see the SQL repository on GitHub. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/odbc/#odbc-driver",
    "relUrl": "/docs/sql/odbc/#odbc-driver"
  },"431": {
    "doc": "ODBC Driver",
    "title": "ODBC Driver",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/odbc/",
    "relUrl": "/docs/sql/odbc/"
  },"432": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "OpenID Connect troubleshooting",
    "content": "This page includes troubleshooting steps for using OpenID Connect with the security plugin. . | Set log level to debug | “Failed when trying to obtain the endpoints from your IdP” | “ValidationError: child ‘opendistro_security’ fails” | “Authentication failed. Please provide a new token.” . | Leftover cookies or cached credentials | Wrong client secret | “Failed to get subject from JWT claims” | “Failed to get roles from JWT claims with roles_key” | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/#openid-connect-troubleshooting",
    "relUrl": "/docs/troubleshoot/openid-connect/#openid-connect-troubleshooting"
  },"433": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "Set log level to debug",
    "content": "To help troubleshoot OpenID Connect, set the log level to debug on Elasticsearch. Add the following lines in config/log4j2.properties and restart the node: . logger.opendistro_security.name = com.amazon.dlic.auth.http.jwt logger.opendistro_security.level = trace . This setting prints a lot of helpful information to your log file. If this information isn’t sufficient, you can also set the log level to trace. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/#set-log-level-to-debug",
    "relUrl": "/docs/troubleshoot/openid-connect/#set-log-level-to-debug"
  },"434": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "“Failed when trying to obtain the endpoints from your IdP”",
    "content": "This error indicates that the security plugin can’t reach the metadata endpoint of your IdP. In kibana.yml, check the following setting: . opendistro_security.openid.connect_url: \"http://keycloak.example.com:8080/auth/realms/master/.well-known/openid-configuration\" . If this error occurs on Elasticsearch, check the following setting in config.yml: . openid_auth_domain: enabled: true order: 1 http_authenticator: type: \"openid\" ... config: openid_connect_url: http://keycloak.examplesss.com:8080/auth/realms/master/.well-known/openid-configuration ... ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/#failed-when-trying-to-obtain-the-endpoints-from-your-idp",
    "relUrl": "/docs/troubleshoot/openid-connect/#failed-when-trying-to-obtain-the-endpoints-from-your-idp"
  },"435": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "“ValidationError: child ‘opendistro_security’ fails”",
    "content": "This indicates that one or more of the Kibana configuration settings are missing. Check kibana.yml and make sure you have set the following minimal configuration: . opendistro_security.openid.connect_url: \"...\" opendistro_security.openid.client_id: \"...\" opendistro_security.openid.client_secret: \"...\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/#validationerror-child-opendistro_security-fails",
    "relUrl": "/docs/troubleshoot/openid-connect/#validationerror-child-opendistro_security-fails"
  },"436": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "“Authentication failed. Please provide a new token.”",
    "content": "This error has several potential root causes. Leftover cookies or cached credentials . Please delete all cached browser data, or try again in a private browser window. Wrong client secret . To trade the access token for an identity token, most IdPs require you to provide a client secret. Check if the client secret in kibana.yml matches the client secret of your IdP configuration: . opendistro_security.openid.client_secret: \"...\" . “Failed to get subject from JWT claims” . This error is logged on Elasticsearch and means that the username could not be extracted from the ID token. Make sure the following setting matches the claims in the JWT your IdP issues: . openid_auth_domain: enabled: true order: 1 http_authenticator: type: \"openid\" ... config: subject_key: &lt;subject key&gt; ... “Failed to get roles from JWT claims with roles_key” . This error indicates that the roles key you configured in config.yml does not exist in the JWT issued by your IdP. Make sure the following setting matches the claims in the JWT your IdP issues: . openid_auth_domain: enabled: true order: 1 http_authenticator: type: \"openid\" ... config: roles_key: &lt;roles key&gt; ... ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/#authentication-failed-please-provide-a-new-token",
    "relUrl": "/docs/troubleshoot/openid-connect/#authentication-failed-please-provide-a-new-token"
  },"437": {
    "doc": "Troubleshoot OpenID Connect",
    "title": "Troubleshoot OpenID Connect",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/openid-connect/",
    "relUrl": "/docs/troubleshoot/openid-connect/"
  },"438": {
    "doc": "OpenID Connect",
    "title": "OpenID Connect",
    "content": "The security plugin can integrate with identify providers that use the OpenID Connect standard. This feature enables the following: . | Automatic configuration . Point the security plugin to the metadata of your identity provider (IdP), and the security plugin uses that data for configuration. | Automatic key fetching . The security plugin automatically retrieves the public key for validating the JSON web tokens (JWTs) from the JSON web key set (JWKS) endpoint of your IdP. You don’t have to configure keys or shared secrets in config.yml. | Key rollover . You can change the keys used for signing the JWTs directly in your IdP. If the security plugin detects an unknown key, it tries to retrieve it from the IdP. This rollover is transparent to the user. | Kibana single sign-on . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/",
    "relUrl": "/docs/security/configuration/openid-connect/"
  },"439": {
    "doc": "OpenID Connect",
    "title": "Configure OpenID Connect integration",
    "content": "To integrate with an OpenID IdP, set up an authentication domain and choose openid as the HTTP authentication type. JSON web tokens already contain all required information to verify the request, so set challenge to false and authentication_backend to noop. This is the minimal configuration: . openid_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: openid challenge: false config: subject_key: preferred_username roles_key: roles openid_connect_url: https://keycloak.example.com:8080/auth/realms/master/.well-known/openid-configuration authentication_backend: type: noop . The following table shows the configuration parameters. | Name | Description | . | openid_connect_url | The URL of your IdP where the security plugin can find the OpenID Connect metadata/configuration settings. This URL differs between IdPs. Required. | . | jwt_header | The HTTP header that stores the token. Typically the Authorization header with the Bearer schema: Authorization: Bearer &lt;token&gt;. Optional. Default is Authorization. | . | jwt_url_parameter | If the token is not transmitted in the HTTP header, but as an URL parameter, define the name of the parameter here. Optional. | . | subject_key | The key in the JSON payload that stores the user’s name. If not defined, the subject registered claim is used. Most IdP providers use the preferred_username claim. Optional. | . | roles_key | The key in the JSON payload that stores the user’s roles. The value of this key must be a comma-separated list of roles. Required only if you want to use roles in the JWT. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#configure-openid-connect-integration",
    "relUrl": "/docs/security/configuration/openid-connect/#configure-openid-connect-integration"
  },"440": {
    "doc": "OpenID Connect",
    "title": "OpenID Connect URL",
    "content": "OpenID Connect specifies various endpoints for integration purposes. The most important endpoint is well-known, which lists endpoints and other configuration options for the security plugin. The URL differs between IdPs, but usually ends in /.well-known/openid-configuration. Keycloak example: . http(s)://&lt;server&gt;:&lt;port&gt;/auth/realms/&lt;realm&gt;/.well-known/openid-configuration . The main information that the security plugin needs is jwks_uri. This URI specifies where the IdP’s public keys in JWKS format can be found. For example: . jwks_uri: \"https://keycloak.example.com:8080/auth/realms/master/protocol/openid-connect/certs\" . { keys:[ { kid:\"V-diposfUJIk5jDBFi_QRouiVinG5PowskcSWy5EuCo\", kty:\"RSA\", alg:\"RS256\", use:\"sig\", n:\"rI8aUrAcI_auAdF10KUopDOmEFa4qlUUaNoTER90XXWADtKne6VsYoD3ZnHGFXvPkRAQLM5d65ScBzWungcbLwZGWtWf5T2NzQj0wDyquMRwwIAsFDFtAZWkXRfXeXrFY0irYUS9rIJDafyMRvBbSz1FwWG7RTQkILkwiC4B8W1KdS5d9EZ8JPhrXvPMvW509g0GhLlkBSbPBeRSUlAS2Kk6nY5i3m6fi1H9CP3Y_X-TzOjOTsxQA_1pdP5uubXPUh5YfJihXcgewO9XXiqGDuQn6wZ3hrF6HTlhNWGcSyQPKh1gEcmXWQlRENZMvYET-BuJEE7eKyM5vRhjNoYR3w\", e:\"AQAB\" } ] } . For more information about IdP endpoints, see the following: . | Okta | Keycloak | Auth0 | Connect2ID | Salesforce | IBM OpenID Connect | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#openid-connect-url",
    "relUrl": "/docs/security/configuration/openid-connect/#openid-connect-url"
  },"441": {
    "doc": "OpenID Connect",
    "title": "Fetching public keys",
    "content": "When an IdP generates and signs a JSON web token, it must add the ID of the key to the JWT header. For example: . { \"alg\": \"RS256\", \"typ\": \"JWT\", \"kid\": \"V-diposfUJIk5jDBFi_QRouiVinG5PowskcSWy5EuCo\" } . As per the OpenID Connect specification, the kid (key ID) is mandatory. Token verification does not work if an IdP fails to add the kid field to the JWT. If the security plugin receives a JWT with an unknown kid, it visits the IdP’s jwks_uri and retrieves all available, valid keys. These keys are used and cached until a refresh is triggered by retrieving another unknown key ID. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#fetching-public-keys",
    "relUrl": "/docs/security/configuration/openid-connect/#fetching-public-keys"
  },"442": {
    "doc": "OpenID Connect",
    "title": "Key rollover and multiple public keys",
    "content": "The security plugin can maintain multiple valid public keys at once. The OpenID specification does not allow for a validity period of public keys, so a key is valid until it has been removed from the list of valid keys in your IdP and the list of valid keys has been refreshed. If you want to roll over a key in your IdP, follow these best practices: . | Create a new key pair in your IdP, and give the new key a higher priority than the currently used key. Your IdP uses this new key over the old key. | Upon first appearance of the new kid in a JWT, the security plugin refreshes the key list. At this point, both the old key and the new key are valid. Tokens signed with the old key are also still valid. | The old key can be removed from your IdP when the last JWT signed with this key has timed out. | . If you have to immediately change your public key, you can also delete the old key first and then create a new one. In this case, all JWTs signed with the old key become invalid immediately. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#key-rollover-and-multiple-public-keys",
    "relUrl": "/docs/security/configuration/openid-connect/#key-rollover-and-multiple-public-keys"
  },"443": {
    "doc": "OpenID Connect",
    "title": "TLS settings",
    "content": "To prevent man-in-the-middle attacks, you should secure the connection between the security plugin and your IdP with TLS. Enabling TLS . Use the following parameters to enable TLS for connecting to your IdP: . config: enable_ssl: &lt;true|false&gt; verify_hostnames: &lt;true|false&gt; . | Name | Description | . | enable_ssl | Whether to use TLS. Default is false. | . | verify_hostnames | Whether to verify the hostnames of the IdP’s TLS certificate. Default is true. | . Certificate validation . To validate the TLS certificate of your IdP, configure either the path to the IdP’s root CA or the root certificate’s content: . config: pemtrustedcas_filepath: /path/to/trusted_cas.pem . config: pemtrustedcas_content: |- MIID/jCCAuagAwIBAgIBATANBgkqhkiG9w0BAQUFADCBjzETMBEGCgmSJomT8ixk ARkWA2NvbTEXMBUGCgmSJomT8ixkARkWB2V4YW1wbGUxGTAXBgNVBAoMEEV4YW1w bGUgQ29tIEluYy4xITAfBgNVBAsMGEV4YW1wbGUgQ29tIEluYy4gUm9vdCBDQTEh ... | Name | Description | . | pemtrustedcas_filepath | Absolute path to the PEM file containing the root CAs of your IdP. | . | pemtrustedcas_content | The root CA content of your IdP. Cannot be used if pemtrustedcas_filepath is set. | . TLS client authentication . To use TLS client authentication, configure the PEM certificate and private key the security plugin should send for TLS client authentication (or its content): . config: pemkey_filepath: /path/to/private.key.pem pemkey_password: private_key_password pemcert_filepath: /path/to/certificate.pem . config: pemkey_content: |- MIID2jCCAsKgAwIBAgIBBTANBgkqhkiG9w0BAQUFADCBlTETMBEGCgmSJomT8ixk ARkWA2NvbTEXMBUGCgmSJomT8ixkARkWB2V4YW1wbGUxGTAXBgNVBAoMEEV4YW1w bGUgQ29tIEluYy4xJDAiBgNVBAsMG0V4YW1wbGUgQ29tIEluYy4gU2lnbmluZyBD ... pemkey_password: private_key_password pemcert_content: |- MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCHRZwzwGlP2FvL oEzNeDu2XnOF+ram7rWPT6fxI+JJr3SDz1mSzixTeHq82P5A7RLdMULfQFMfQPfr WXgB4qfisuDSt+CPocZRfUqqhGlMG2l8LgJMr58tn0AHvauvNTeiGlyXy0ShxHbD ... | Name | Description | . | enable_ssl_client_auth | Whether to send the client certificate to the IdP server. Default is false. | . | pemcert_filepath | Absolute path to the client certificate. | . | pemcert_content | The content of the client certificate. Cannot be used when pemcert_filepath is set. | . | pemkey_filepath | Absolute path to the file containing the private key of the client certificate. | . | pemkey_content | The content of the private key of your client certificate. Cannot be used when pemkey_filepath is set. | . | pemkey_password | The password of your private key, if any. | . Enabled ciphers and protocols . You can limit the allowed ciphers and TLS protocols by using the following keys. | Name | Description | . | enabled_ssl_ciphers | Array. Enabled TLS cipher suites. Only Java format is supported. | . | enabled_ssl_protocols | Array. Enabled TLS protocols. Only Java format is supported. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#tls-settings",
    "relUrl": "/docs/security/configuration/openid-connect/#tls-settings"
  },"444": {
    "doc": "OpenID Connect",
    "title": "(Advanced) DoS protection",
    "content": "To help protect against denial-of-service (DoS) attacks, the security plugin only allows a maximum number of new key IDs in a certain span of time. If the number of new key IDs exceeds this threshold, the security plugin returns HTTP status code 503 (Service Unavailable) and refuses to query the IdP. By default, the security plugin does not allow for more than 10 unknown key IDs within 10 seconds. The following table shows how to modify these settings. | Name | Description | . | refresh_rate_limit_count | The maximum number of unknown key IDs in the time frame. Default is 10. | . | refresh_rate_limit_time_window_ms | The time frame to use when checking the maximum number of unknown key IDs, in milliseconds. Default is 10000 (10 seconds). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#advanced-dos-protection",
    "relUrl": "/docs/security/configuration/openid-connect/#advanced-dos-protection"
  },"445": {
    "doc": "OpenID Connect",
    "title": "Kibana single sign-on",
    "content": "Activate OpenID Connect by adding the following to kibana.yml: . opendistro_security.auth.type: \"openid\" . Configuration . OpenID Connect providers usually publish their configuration in JSON format under the metadata url. Therefore, most settings can be pulled in automatically, so the Kibana configuration becomes minimal. The most important settings are the following: . | Connect URL | Client ID . Every IdP can host multiple clients (sometimes called applications) with different settings and authentication protocols. When enabling OpenID Connect, you should create a new client for Kibana in your IdP. The client ID uniquely identifies Kibana. | Client secret . Beyond the ID, each client also has a client secret assigned. The client secret is usually generated when the client is created. Applications can obtain an identity token only when they provide a client secret. You can find this secret in the settings of the client on your IdP. | . Configuration parameters . | Name | Description | . | opendistro_security.openid.connect_url | The URL where the IdP publishes the OpenID metadata. Required. | . | opendistro_security.openid.client_id | The ID of the OpenID Connect client configured in your IdP. Required. | . | opendistro_security.openid.client_secret | The client secret of the OpenID Connect client configured in your IdP. Required. | . | opendistro_security.openid.scope | The scope of the identity token issued by the IdP. Optional. Default is openid profile email address phone. | . | opendistro_security.openid.header | HTTP header name of the JWT token. Optional. Default is Authorization. | . | opendistro_security.openid.logout_url | The logout URL of your IdP. Optional. Only necessary if your IdP does not publish the logout URL in its metadata. | . | opendistro_security.openid.base_redirect_url | The base of the redirect URL that will be sent to your IdP. Optional. Only necessary when Kibana is behind a reverse proxy, in which case it should be different than server.host and server.port in kibana.yml. | . Configuration example . # Enable OpenID authentication opendistro_security.auth.type: \"openid\" # The IdP metadata endpoint opendistro_security.openid.connect_url: \"http://keycloak.example.com:8080/auth/realms/master/.well-known/openid-configuration\" # The ID of the OpenID Connect client in your IdP opendistro_security.openid.client_id: \"kibana-sso\" # The client secret of the OpenID Connect client opendistro_security.openid.client_secret: \"a59c51f5-f052-4740-a3b0-e14ba355b520\" # Use HTTPS instead of HTTP elasticsearch.url: \"https://&lt;hostname&gt;.com:&lt;http port&gt;\" # Configure the Kibana internal server user elasticsearch.username: \"kibanaserver\" elasticsearch.password: \"kibanaserver\" # Disable SSL verification when using self-signed demo certificates elasticsearch.ssl.verificationMode: none # Whitelist basic headers and multi-tenancy header elasticsearch.requestHeadersWhitelist: [\"Authorization\", \"security_tenant\"] . Elasticsearch security configuration . Because Kibana requires that the internal Kibana server user can authenticate through HTTP basic authentication, you must configure two authentication domains. For OpenID Connect, the HTTP basic domain has to be placed first in the chain. Make sure you set the challenge flag to false. Modify and apply the following example settings in config.yml: . basic_internal_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: basic challenge: false authentication_backend: type: internal openid_auth_domain: http_enabled: true transport_enabled: true order: 1 http_authenticator: type: openid challenge: false config: subject_key: preferred_username roles_key: roles openid_connect_url: https://keycloak.example.com:8080/auth/realms/master/.well-known/openid-configuration authentication_backend: type: noop . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/openid-connect/#kibana-single-sign-on",
    "relUrl": "/docs/security/configuration/openid-connect/#kibana-single-sign-on"
  },"446": {
    "doc": "Other Components",
    "title": "Other components",
    "content": "Open Distro for Elasticsearch has a number of additional components that you might want to use: . | Java Database Connectivity (JDBC) driver | PerfTop client for Performance Analyzer | Alerting CLI, a command line interface that lets you use YAML files to manage your Open Distro for Elasticsearch monitors | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/other-components/#other-components",
    "relUrl": "/docs/install/other-components/#other-components"
  },"447": {
    "doc": "Other Components",
    "title": "Other Components",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/other-components/",
    "relUrl": "/docs/install/other-components/"
  },"448": {
    "doc": "JSON Support",
    "title": "JSON Support",
    "content": "SQL plugin supports JSON by following PartiQL specification, a SQL-compatible query language that lets you query semi-structured and nested data for any data format. The SQL plugin only supports a subset of the PartiQL specification. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/partiql/",
    "relUrl": "/docs/sql/partiql/"
  },"449": {
    "doc": "JSON Support",
    "title": "Querying nested collection",
    "content": "PartiQL extends SQL to allow you to query and unnest nested collections. In Elasticsearch, this is very useful to query a JSON index with nested objects or fields. To follow along, use the bulk operation to index some sample data: . POST employees_nested/_bulk?refresh {\"index\":{\"_id\":\"1\"}} {\"id\":3,\"name\":\"Bob Smith\",\"title\":null,\"projects\":[{\"name\":\"SQL Spectrum querying\",\"started_year\":1990},{\"name\":\"SQL security\",\"started_year\":1999},{\"name\":\"Elasticsearch security\",\"started_year\":2015}]} {\"index\":{\"_id\":\"2\"}} {\"id\":4,\"name\":\"Susan Smith\",\"title\":\"Dev Mgr\",\"projects\":[]} {\"index\":{\"_id\":\"3\"}} {\"id\":6,\"name\":\"Jane Smith\",\"title\":\"Software Eng 2\",\"projects\":[{\"name\":\"SQL security\",\"started_year\":1998},{\"name\":\"Hello security\",\"started_year\":2015,\"address\":[{\"city\":\"Dallas\",\"state\":\"TX\"}]}]} . Example 1: Unnesting a nested collection . This example finds the nested document (projects) with a field value (name) that satisfies the predicate (contains security). Because each parent document can have more than one nested documents, the nested document that matches is flattened. In other words, the final result is the cartesian product between the parent and nested documents. SELECT e.name AS employeeName, p.name AS projectName FROM employees_nested AS e, e.projects AS p WHERE p.name LIKE '%security%' . Explain: . { \"from\" : 0, \"size\" : 200, \"query\" : { \"bool\" : { \"filter\" : [ { \"bool\" : { \"must\" : [ { \"nested\" : { \"query\" : { \"wildcard\" : { \"projects.name\" : { \"wildcard\" : \"*security*\", \"boost\" : 1.0 } } }, \"path\" : \"projects\", \"ignore_unmapped\" : false, \"score_mode\" : \"none\", \"boost\" : 1.0, \"inner_hits\" : { \"ignore_unmapped\" : false, \"from\" : 0, \"size\" : 3, \"version\" : false, \"seq_no_primary_term\" : false, \"explain\" : false, \"track_scores\" : false, \"_source\" : { \"includes\" : [ \"projects.name\" ], \"excludes\" : [ ] } } } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"_source\" : { \"includes\" : [ \"name\" ], \"excludes\" : [ ] } } . Result set: . | employeeName | projectName | . | Bob Smith | Elasticsearch Security | . | Bob Smith | SQL security | . | Jane Smith | Hello security | . | Jane Smith | SQL security | . Example 2: Unnesting in existential subquery . To unnest a nested collection in a subquery to check if it satisfies a condition: . SELECT e.name AS employeeName FROM employees_nested AS e WHERE EXISTS ( SELECT * FROM e.projects AS p WHERE p.name LIKE '%security%' ) . Explain: . { \"from\" : 0, \"size\" : 200, \"query\" : { \"bool\" : { \"filter\" : [ { \"bool\" : { \"must\" : [ { \"nested\" : { \"query\" : { \"bool\" : { \"must\" : [ { \"bool\" : { \"must\" : [ { \"bool\" : { \"must_not\" : [ { \"bool\" : { \"must_not\" : [ { \"exists\" : { \"field\" : \"projects\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, { \"wildcard\" : { \"projects.name\" : { \"wildcard\" : \"*security*\", \"boost\" : 1.0 } } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"path\" : \"projects\", \"ignore_unmapped\" : false, \"score_mode\" : \"none\", \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } } ], \"adjust_pure_negative\" : true, \"boost\" : 1.0 } }, \"_source\" : { \"includes\" : [ \"name\" ], \"excludes\" : [ ] } } . Result set: . | employeeName | . | Bob Smith | . | Jane Smith | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/partiql/#querying-nested-collection",
    "relUrl": "/docs/sql/partiql/#querying-nested-collection"
  },"450": {
    "doc": "Permissions",
    "title": "Permissions",
    "content": "This page is a complete list of available permissions in the security plugin. Each permission controls access to a data type or API. Rather than creating new action groups from individual permissions, you can often achieve your desired security posture using some combination of the default action groups. To learn more, see Default Action Groups. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/permissions/",
    "relUrl": "/docs/security/access-control/permissions/"
  },"451": {
    "doc": "Permissions",
    "title": "Cluster",
    "content": ". | cluster:admin/ingest/pipeline/delete | cluster:admin/ingest/pipeline/get | cluster:admin/ingest/pipeline/put | cluster:admin/ingest/pipeline/simulate | cluster:admin/ingest/processor/grok/get | cluster:admin/reindex/rethrottle | cluster:admin/repository/delete | cluster:admin/repository/get | cluster:admin/repository/put | cluster:admin/repository/verify | cluster:admin/reroute | cluster:admin/script/delete | cluster:admin/script/get | cluster:admin/script/put | cluster:admin/settings/update | cluster:admin/snapshot/create | cluster:admin/snapshot/delete | cluster:admin/snapshot/get | cluster:admin/snapshot/restore | cluster:admin/snapshot/status | cluster:admin/snapshot/status* | cluster:admin/tasks/cancel | cluster:admin/tasks/test | cluster:admin/tasks/testunblock | cluster:monitor/allocation/explain | cluster:monitor/health | cluster:monitor/main | cluster:monitor/nodes/hot_threads | cluster:monitor/nodes/info | cluster:monitor/nodes/liveness | cluster:monitor/nodes/stats | cluster:monitor/nodes/usage | cluster:monitor/remote/info | cluster:monitor/state | cluster:monitor/stats | cluster:monitor/task | cluster:monitor/task/get | cluster:monitor/tasks/list | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/permissions/#cluster",
    "relUrl": "/docs/security/access-control/permissions/#cluster"
  },"452": {
    "doc": "Permissions",
    "title": "Indices",
    "content": ". | indices:admin/aliases | indices:admin/aliases/exists | indices:admin/aliases/get | indices:admin/analyze | indices:admin/cache/clear | indices:admin/close | indices:admin/create | indices:admin/delete | indices:admin/exists | indices:admin/flush | indices:admin/flush* | indices:admin/forcemerge | indices:admin/get | indices:admin/mapping/put | indices:admin/mappings/fields/get | indices:admin/mappings/fields/get* | indices:admin/mappings/get | indices:admin/open | indices:admin/refresh | indices:admin/refresh* | indices:admin/rollover | indices:admin/seq_no/global_checkpoint_sync | indices:admin/settings/update | indices:admin/shards/search_shards | indices:admin/shrink | indices:admin/synced_flush | indices:admin/template/delete | indices:admin/template/get | indices:admin/template/put | indices:admin/types/exists | indices:admin/upgrade | indices:admin/validate/query | indices:data/read/explain | indices:data/read/field_caps | indices:data/read/field_caps* | indices:data/read/get | indices:data/read/mget | indices:data/read/mget* | indices:data/read/msearch | indices:data/read/msearch/template | indices:data/read/mtv | indices:data/read/mtv* | indices:data/read/scroll | indices:data/read/scroll/clear | indices:data/read/search | indices:data/read/search* | indices:data/read/search/template | indices:data/read/tv | indices:data/write/bulk | indices:data/write/bulk* | indices:data/write/delete | indices:data/write/delete/byquery | indices:data/write/index | indices:data/write/reindex | indices:data/write/update | indices:data/write/update/byquery | indices:monitor/recovery | indices:monitor/segments | indices:monitor/settings/get | indices:monitor/shard_stores | indices:monitor/stats | indices:monitor/upgrade | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/permissions/#indices",
    "relUrl": "/docs/security/access-control/permissions/#indices"
  },"453": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Standalone Elasticsearch plugin installation",
    "content": "If you don’t want to use the all-in-one Open Distro for Elasticsearch installation options, you can install the individual plugins on a compatible Elasticsearch cluster, just like any other Elasticsearch plugins. . | Plugin compatibility | Install plugins . | Security | Job Scheduler | Alerting | SQL | Index State Management | KNN | Anomaly Detection | Performance Analyzer | . | List installed plugins | Remove plugins . | (Optional) Clean up Performance Analyzer files | . | Update plugins | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#standalone-elasticsearch-plugin-installation",
    "relUrl": "/docs/install/plugins/#standalone-elasticsearch-plugin-installation"
  },"454": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Plugin compatibility",
    "content": "| Elasticsearch version | Plugin versions | . | 7.9.1 | opendistro-anomaly-detection 1.10.1.0, 1.11.0.0 opendistro-job-scheduler 1.10.1.0, 1.11.0.0 opendistro-knn 1.10.1.0, 1.11.0.0 opendistro_alerting 1.10.1.2, 1.11.0.1 opendistro_index_management 1.10.1.1, 1.11.0.0 opendistro_performance_analyzer 1.10.1.0, 1.11.0.0 opendistro_security 1.10.1.0, 1.11.0.0 opendistro_sql 1.10.1.1, 1.11.0.0 . | . | 7.8.0 | opendistro-anomaly-detection 1.9.0.0 opendistro-job-scheduler 1.9.0.0 opendistro-knn 1.9.0.0 opendistro_alerting 1.9.0.0 opendistro_index_management 1.9.0.0 opendistro_performance_analyzer 1.9.0.1 opendistro_security 1.9.0.0 opendistro_sql 1.9.0.0 . | . | 7.7.0 | opendistro-anomaly-detection 1.8.0.0 opendistro-job-scheduler 1.8.0.0 opendistro-knn 1.8.0.0 opendistro_alerting 1.8.0.0 opendistro_index_management 1.8.0.0 opendistro_performance_analyzer 1.8.0.0 opendistro_security 1.8.0.0 opendistro_sql 1.8.0.0 . | . | 7.6.1 | opendistro-anomaly-detection 1.7.0.0 opendistro-job-scheduler 1.7.0.0 opendistro-knn 1.7.0.0 opendistro_alerting 1.7.0.0 opendistro_index_management 1.7.0.0 opendistro_performance_analyzer 1.7.0.0 opendistro_security 1.7.0.0 opendistro_sql 1.7.0.0 . | . | 7.4.2 | opendistro-job-scheduler 1.4.0.0 opendistro-knn 1.4.0.0 opendistro_alerting 1.4.0.0 opendistro_index_management 1.4.0.0 opendistro_performance_analyzer 1.4.0.0 opendistro_security 1.4.0.0 opendistro_sql 1.4.0.0 . | . | 7.3.2 | opendistro-job-scheduler 1.3.0.0 opendistro_alerting 1.3.0.1 opendistro_index_management 1.3.0.1 opendistro_performance_analyzer 1.3.0.0 opendistro_security 1.3.0.0 opendistro_sql 1.3.0.0 . | . | 7.2.1 | opendistro-job-scheduler 1.2.1 opendistro_alerting 1.2.1.0 opendistro_performance_analyzer 1.2.1.0 opendistro_security 1.2.1.0 opendistro_sql 1.2.1.0 . | . | 7.2.0 | opendistro-job-scheduler 1.2.0 opendistro_alerting 1.2.0.0 opendistro_performance_analyzer 1.2.0.0 opendistro_security 1.2.0.0 opendistro_sql 1.2.0.0 . | . | 7.1.1 | opendistro-job-scheduler 1.1.0 opendistro_alerting 1.1.0.0 opendistro_performance_analyzer 1.1.0.0 opendistro_security 1.1.0.0 opendistro_sql 1.1.0.0 . | . | 7.0.1 | opendistro-job-scheduler 1.0.0 opendistro_alerting 1.0.0.0 opendistro_performance_analyzer 1.0.0.0 opendistro_security 1.0.0.2 opendistro_sql 1.0.0.0 . | . | 6.8.1 | opendistro_alerting 0.10.0.0 opendistro_performance_analyzer 0.10.0.0 opendistro_security 0.10.0.0 opendistro_sql 0.10.0.0 . | . | 6.7.1 | opendistro_alerting 0.9.0.0 opendistro_performance_analyzer 0.9.0.0 opendistro_security 0.9.0.0 opendistro_sql 0.9.0.0 . | . | 6.6.2 | opendistro_alerting 0.8.0.0 opendistro_performance_analyzer 0.8.0.0 opendistro_security 0.8.0.0 opendistro_sql 0.8.0.0 . | . | 6.5.4 | opendistro_alerting 0.7.0.0 opendistro_performance_analyzer 0.7.0.0 opendistro_security 0.7.0.1 opendistro_sql 0.7.0.0 . | . To install plugins manually, you must have the exact OSS version of Elasticsearch installed (for example, 6.6.2 and not 6.6.1). To get a list of available Elasticsearch versions on CentOS 7 and Amazon Linux 2, run the following command: . sudo yum list elasticsearch-oss --showduplicates . Then you can specify the version that you need: . sudo yum install elasticsearch-oss-6.7.1 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#plugin-compatibility",
    "relUrl": "/docs/install/plugins/#plugin-compatibility"
  },"455": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Install plugins",
    "content": "Navigate to the Elasticsearch home directory (most likely, it is /usr/share/elasticsearch), and run the install command for each plugin. Security . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-security/opendistro_security-1.11.0.0.zip . After installing the security plugin, you can run sudo sh /usr/share/elasticsearch/plugins/opendistro_security/tools/install_demo_configuration.sh to quickly get started with demo certificates. Otherwise, you must configure it manually and run securityadmin.sh. The security plugin has a corresponding Kibana plugin that you probably want to install as well. Job Scheduler . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-job-scheduler/opendistro-job-scheduler-1.11.0.0.zip . Alerting . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-alerting/opendistro_alerting-1.11.0.1.zip . To install Alerting, you must first install the Job Scheduler plugin. Alerting has a corresponding Kibana plugin that you probably want to install as well. SQL . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-sql/opendistro_sql-1.11.0.0.zip . Index State Management . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-index-management/opendistro_index_management-1.11.0.0.zip . To install Index State Management, you must first install the Job Scheduler plugin. ISM has a corresponding Kibana plugin that you probably want to install as well. KNN . KNN is only available as part of the all-in-one installs: Docker, RPM, and Debian. Anomaly Detection . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/opendistro-anomaly-detection/opendistro-anomaly-detection-1.11.0.0.zip . Performance Analyzer . sudo bin/elasticsearch-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/elasticsearch-plugins/performance-analyzer/opendistro_performance_analyzer-1.11.0.0.zip . Performance Analyzer requires some manual configuration after installing the plugin: . | Create /usr/lib/systemd/system/opendistro-performance-analyzer.service based on this file. | Make the CLI executable: . sudo chmod +x /usr/share/elasticsearch/bin/performance-analyzer-agent-cli . | Run the appropriate postinst script for your Linux distribution: . # Debian-based distros sudo sh /usr/share/elasticsearch/plugins/opendistro_performance_analyzer/install/deb/postinst.sh 1 # RPM distros sudo sh /usr/share/elasticsearch/plugins/opendistro_performance_analyzer/install/rpm/postinst.sh 1 . | Make Performance Analyzer accessible outside of the host machine . cd /usr/share/elasticsearch # navigate to the Elasticsearch home directory cd plugins/opendistro_performance_analyzer/pa_config/ vi performance-analyzer.properties . Uncomment the line #webservice-bind-host and set it to 0.0.0.0: . # ======================== Elasticsearch performance analyzer plugin config ========================= # NOTE: this is an example for Linux. Please modify the config accordingly if you are using it under other OS. # WebService bind host; default to all interfaces webservice-bind-host = 0.0.0.0 # Metrics data location metrics-location = /dev/shm/performanceanalyzer/ # Metrics deletion interval (minutes) for metrics data. # Interval should be between 1 to 60. metrics-deletion-interval = 1 # If set to true, the system cleans up the files behind it. So at any point, we should expect only 2 # metrics-db-file-prefix-path files. If set to false, no files are cleaned up. This can be useful, if you are archiving # the files and wouldn't like for them to be cleaned up. cleanup-metrics-db-files = true # WebService exposed by App's port webservice-listener-port = 9600 # Metric DB File Prefix Path location metrics-db-file-prefix-path = /tmp/metricsdb_ https-enabled = false #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path # Plugin Stats Metadata file name, expected to be in the same location plugin-stats-metadata = plugin-stats-metadata # Agent Stats Metadata file name, expected to be in the same location agent-stats-metadata = agent-stats-metadata . | Start the Elasticsearch service: . sudo systemctl start elasticsearch.service . | Send a test request: . curl -XGET \"localhost:9600/_opendistro/_performanceanalyzer/metrics?metrics=Latency,CPU_Utilization&amp;agg=avg,max&amp;dim=ShardID&amp;nodes=all\" . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#install-plugins",
    "relUrl": "/docs/install/plugins/#install-plugins"
  },"456": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "List installed plugins",
    "content": "To check your installed plugins: . sudo bin/elasticsearch-plugin list . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#list-installed-plugins",
    "relUrl": "/docs/install/plugins/#list-installed-plugins"
  },"457": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Remove plugins",
    "content": "If you are removing Performance Analyzer, see below. Otherwise, you can remove the plugin with a single command: . sudo bin/elasticsearch-plugin remove &lt;plugin-name&gt; . Then restart Elasticsearch on the node: . sudo systemctl restart elasticsearch.service . (Optional) Clean up Performance Analyzer files . Performance Analyzer requires certain configuration files to run. If you want to delete these files, run one of the scripts we provide based on your Linux distribution before performing the normal plugin removal process. | Make the removal scripts executable: . sudo chmod +x plugins/opendistro_performance_analyer/install/deb/postrm sudo sh plugins/opendistro_performance_analyer/install/rpm/postrm . | Run the appropriate removal script for your distribution: . # Debian-based distros sudo --preserve-env=ES_HOME ./plugins/opendistro_performance_analyer/install/deb/postrm # RPM distros sudo --preserve-env=ES_HOME ./plugins/opendistro_performance_analyer/install/rpm/postrm . | . Then proceed with the normal removal procedure. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#remove-plugins",
    "relUrl": "/docs/install/plugins/#remove-plugins"
  },"458": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Update plugins",
    "content": "Elasticsearch doesn’t update plugins. Instead, you have to remove and reinstall them: . sudo bin/elasticsearch-plugin remove &lt;plugin-name&gt; sudo bin/elasticsearch-plugin install &lt;plugin-name&gt; . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/#update-plugins",
    "relUrl": "/docs/install/plugins/#update-plugins"
  },"459": {
    "doc": "Standalone Elasticsearch Plugin Install",
    "title": "Standalone Elasticsearch Plugin Install",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/plugins/",
    "relUrl": "/docs/install/plugins/"
  },"460": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Standalone Kibana plugin install",
    "content": "If you don’t want to use the all-in-one Open Distro for Elasticsearch installation options, you can install the security, alerting, and Index State Management plugins for Kibana individually. . | Plugin compatibility | Prerequisites | Install | List installed plugins | Remove plugins | Update plugins | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#standalone-kibana-plugin-install",
    "relUrl": "/docs/kibana/plugins/#standalone-kibana-plugin-install"
  },"461": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Plugin compatibility",
    "content": "| Kibana version | Plugin versions | . | 7.9.1 | opendistro-anomaly-detection-kibana 1.10.1.0, 1.11.0.0 opendistro_alerting-kibana 1.10.1.1, 1.11.0.2 opendistro_index_management-kibana 1.10.1.0, 1.11.0.0 opendistro_security_kibana 1.10.1.1, 1.11.0.0 opendistro-query-workbench 1.11.0.0 opendistro-notebooks-kibana 1.11.0.0 . | . | 7.8.0 | opendistro-anomaly-detection-kibana 1.9.0.0 opendistro_alerting-kibana 1.9.0.0 opendistro_index_management-kibana 1.9.0.0 opendistro_security_kibana 1.9.0.0 opendistro_sql_workbench 1.9.0.0 . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#plugin-compatibility",
    "relUrl": "/docs/kibana/plugins/#plugin-compatibility"
  },"462": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Prerequisites",
    "content": ". | An Elasticsearch cluster that uses a compatible version | The corresponding Elasticsearch plugins installed on the cluster | The corresponding version of Kibana (e.g. Kibana 6.7.1 works with Elasticsearch 6.7.1) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#prerequisites",
    "relUrl": "/docs/kibana/plugins/#prerequisites"
  },"463": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Install",
    "content": "Navigate to the Kibana home directory (likely /usr/share/kibana) and run the install command for each plugin. Security Kibana . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-security/opendistro_security_kibana_plugin-1.11.0.0.zip . This plugin provides a user interface for managing users, roles, mappings, action groups, and tenants. Alerting Kibana . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-alerting/opendistro-alerting-1.11.0.2.zip . This plugin provides a user interface for creating monitors and managing alerts. Index State Management Kibana . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-index-management/opendistro_index_management_kibana-1.11.0.0.zip . This plugin provides a user interface for managing policies. Anomaly Detection Kibana . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-anomaly-detection/opendistro-anomaly-detection-kibana-1.11.0.0.zip . This plugin provides a user interface for adding detectors. Query Workbench . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-query-workbench/opendistro-query-workbench-1.11.0.0.zip . This plugin provides a user interface for using SQL queries to explore your data. Kibana Notebooks . sudo bin/kibana-plugin install https://d3g5vo6xdbdb9a.cloudfront.net/downloads/kibana-plugins/opendistro-notebooks/opendistro-notebooks-kibana-1.11.0.0.zip . This plugin lets you combine Kibana visualizations and narrative text in a single interface. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#install",
    "relUrl": "/docs/kibana/plugins/#install"
  },"464": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "List installed plugins",
    "content": "To check your installed plugins: . sudo bin/kibana-plugin list . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#list-installed-plugins",
    "relUrl": "/docs/kibana/plugins/#list-installed-plugins"
  },"465": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Remove plugins",
    "content": "sudo bin/kibana-plugin remove &lt;plugin-name&gt; . For certain plugins, you must also remove the “optimze” bundle. Here is a sample command for the Anomaly Detection plugin: . sudo rm /usr/share/kibana/optimize/bundles/opendistro-anomaly-detection-kibana.* . Then restart Kibana. After the removal of any plugin, Kibana performs an optimize operation the next time you start it. This operation takes several minutes even on fast machines, so be patient. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#remove-plugins",
    "relUrl": "/docs/kibana/plugins/#remove-plugins"
  },"466": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Update plugins",
    "content": "Kibana doesn’t update plugins. Instead, you have to remove the old version and its optimized bundle, reinstall them, and restart Kibana: . | Remove the old version: | . sudo bin/kibana-plugin remove &lt;plugin-name&gt; . | Remove the optimized bundle: | . sudo rm /usr/share/kibana/optimize/bundles/&lt;bundle-name&gt; . | Reinstall the new version: | . sudo bin/kibana-plugin install &lt;plugin-name&gt; . | Restart Kibana. | . For example, to remove and reinstall the anomaly detection plugin: . sudo bin/elasticsearch-plugin remove opendistro-anomaly-detection sudo rm /usr/share/kibana/optimize/bundles/opendistro-anomaly-detection-kibana.* sudo bin/kibana-plugin install &lt;AD Kibana plugin artifact URL&gt; Restart Kibana. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/#update-plugins",
    "relUrl": "/docs/kibana/plugins/#update-plugins"
  },"467": {
    "doc": "Standalone Kibana Plugin Install",
    "title": "Standalone Kibana Plugin Install",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/kibana/plugins/",
    "relUrl": "/docs/kibana/plugins/"
  },"468": {
    "doc": "Policies",
    "title": "Policies",
    "content": "Policies are JSON documents that define the following: . | The states that an index can be in, including the default state for new indices. For example, you might name your states “hot,” “warm,” “delete,” and so on. For more information, see States. | Any actions that you want the plugin to take when an index enters a state, such as performing a rollover. For more information, see Actions. | The conditions that must be met for an index to move into a new state, known as transitions. For example, if an index is more than eight weeks old, you might want to move it to the “delete” state. For more information, see Transitions. | . In other words, a policy defines the states that an index can be in, the actions to perform when in a state, and the conditions that must be met to transition between states. You have complete flexibility in the way you can design your policies. You can create any state, transition to any other state, and specify any number of actions in each state. This table lists the relevant fields of a policy. | Field | Description | Type | Required | Read Only | . | policy_id | The name of the policy. | string | Yes | Yes | . | description | A human-readable description of the policy. | string | Yes | No | . | last_updated_time | The time the policy was last updated. | timestamp | Yes | Yes | . | error_notification | The destination and message template for error notifications. The destination could be Amazon Chime, Slack, or a webhook URL. | object | No | No | . | default_state | The default starting state for each index that uses this policy. | string | Yes | No | . | states | The states that you define in the policy. | nested list of objects | Yes | No | . | States | Actions | ISM supported operations . | force_merge | read_only | read_write | replica_count | close | open | delete | rollover | notification | snapshot | index_priority | allocation | . | Transitions | Error notifications | Example policy | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/",
    "relUrl": "/docs/ism/policies/"
  },"469": {
    "doc": "Policies",
    "title": "States",
    "content": "A state is the description of the status that the managed index is currently in. A managed index can be in only one state at a time. Each state has associated actions that are executed sequentially on entering a state and transitions that are checked after all the actions have been completed. This table lists the parameters that you can define for a state. | Field | Description | Type | Required | . | name | The name of the state. | string | Yes | . | actions | The actions to execute after entering a state. For more information, see Actions. | nested list of objects | Yes | . | transitions | The next states and the conditions required to transition to those states. If no transitions exist, the policy assumes that it’s complete and can now stop managing the index. For more information, see Transitions. | nested list of objects | Yes | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#states",
    "relUrl": "/docs/ism/policies/#states"
  },"470": {
    "doc": "Policies",
    "title": "Actions",
    "content": "Actions are the steps that the policy sequentially executes on entering a specific state. They are executed in the order in which they are defined. This table lists the parameters that you can define for an action. | Parameter | Description | Type | Required | Default | . | timeout | The timeout period for the action. Accepts time units for minutes, hours, and days. | time unit | No | - | . | retry | The retry configuration for the action. | object | No | Specific to action | . The retry operation has the following parameters: . | Parameter | Description | Type | Required | Default | . | count | The number of retry counts. | number | Yes | - | . | backoff | The backoff policy type to use when retrying. | string | No | Exponential | . | delay | The time to wait between retries. Accepts time units for minutes, hours, and days. | time unit | No | 1 minute | . The following example action has a timeout period of one hour. The policy retries this action three times with an exponential backoff policy, with a delay of 10 minutes between each retry: . \"actions\": { \"timeout\": \"1h\", \"retry\": { \"count\": 3, \"backoff\": \"exponential\", \"delay\": \"10m\" } } . For a list of available unit types, see Supported units. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#actions",
    "relUrl": "/docs/ism/policies/#actions"
  },"471": {
    "doc": "Policies",
    "title": "ISM supported operations",
    "content": "ISM supports the following operations: . | force_merge | read_only | read_write | replica_count | close | open | delete | rollover | notification | snapshot | index_priority | allocation | . force_merge . Reduces the number of Lucene segments by merging the segments of individual shards. This operation attempts to set the index to a read-only state before starting the merging process. | Parameter | Description | Type | Required | . | max_num_segments | The number of segments to reduce the shard to. | number | Yes | . { \"force_merge\": { \"max_num_segments\": 1 } } . read_only . Sets a managed index to be read only. { \"read_only\": {} } . read_write . Sets a managed index to be writeable. { \"read_write\": {} } . replica_count . Sets the number of replicas to assign to an index. | Parameter | Description | Type | Required | . | number_of_replicas | Defines the number of replicas to assign to an index. | number | Yes | . { \"replica_count\": { \"number_of_replicas\": 2 } } . For information about setting replicas, see Primary and replica shards. close . Closes the managed index. { \"close\": {} } . Closed indices remain on disk, but consume no CPU or memory. You can’t read from, write to, or search closed indices. Closing an index is a good option if you need to retain data for longer than you need to actively search it and have sufficient disk space on your data nodes. If you need to search the data again, reopening a closed index is simpler than restoring an index from a snapshot. open . Opens a managed index. { \"open\": {} } . delete . Deletes a managed index. { \"delete\": {} } . rollover . Rolls an alias over to a new index when the managed index meets one of the rollover conditions. The index format must match the pattern: ^.*-\\d+$. For example, (logs-000001). Set index.opendistro.index_state_management.rollover_alias as the alias to rollover. | Parameter | Description | Type | Example | Required | . | min_size | The minimum size of the total primary shard storage (not counting replicas) required to roll over the index. For example, if you set min_size to 100 GiB and your index has 5 primary shards and 5 replica shards of 20 GiB each, the total size of the primaries is 100 GiB, so the rollover occurs. ISM doesn’t check indices continually, so it doesn’t roll over indices at exactly 100 GiB. Instead, if an index is continuously growing, ISM might check it at 99 GiB, not perform the rollover, check again when the shards reach 105 GiB, and then perform the operation. | string | 20gb or 5mb | No | . | min_doc_count | The minimum number of documents required to roll over the index. | number | 2000000 | No | . | min_index_age | The minimum age required to roll over the index. Index age is the time between its creation and the present. | string | 5d or 7h | No | . { \"rollover\": { \"min_size\": \"50gb\" } } . { \"rollover\": { \"min_doc_count\": 100000000 } } . { \"rollover\": { \"min_index_age\": \"30d\" } } . notification . Sends you a notification. | Parameter | Description | Type | Required | . | destination | The destination URL. | Slack, Amazon Chime, or webhook URL | Yes | . | message_template | The text of the message. You can add variables to your messages using Mustache templates. | object | Yes | . The destination system must return a response otherwise the notification operation throws an error. Example 1: Chime notification . { \"notification\": { \"destination\": { \"chime\": { \"url\": \"&lt;url&gt;\" } }, \"message_template\": { \"source\": \"the index is {{ctx.index}}\" } } } . Example 2: Custom webhook notification . { \"notification\": { \"destination\": { \"custom_webhook\": { \"url\": \"https://&lt;your_webhook&gt;\" } }, \"message_template\": { \"source\": \"the index is {{ctx.index}}\" } } } . Example 3: Slack notification . { \"notification\": { \"destination\": { \"slack\": { \"url\": \"https://hooks.slack.com/services/xxx/xxxxxx\" } }, \"message_template\": { \"source\": \"the index is {{ctx.index}}\" } } } . You can use ctx variables in your message to represent a number of policy parameters based on the past executions of your policy. For example, if your policy has a rollover action, you can use {{ctx.action.name}} in your message to represent the name of the rollover. The following ctx variable options are available for every policy: . Guaranteed variables . | Parameter | Description | Type | . | index | The name of the index. | string | . | index_uuid | The uuid of the index. | string | . | policy_id | The name of the policy. | string | . snapshot . Backup your cluster’s indices and state. For more information about snapshots, see Take and restore snapshots. The snapshot operation has the following parameters: . | Parameter | Description | Type | Required | Default | . | repository | The repository name that you register through the native snapshot API operations. | string | Yes | - | . | snapshot | The name of the snapshot. | string | Yes | - | . { \"snapshot\": { \"repository\": \"my_backup\", \"snapshot\": \"my_snapshot\" } } . index_priority . Set the priority for the index in a specific state. Unallocated shards of indices are recovered in the order of their priority, whenever possible. The indices with higher priority values are recovered first followed by the indices with lower priority values. The index_priority operation has the following parameter: . | Parameter | Description | Type | Required | Default | . | priority | The priority for the index as soon as it enters a state. | number | Yes | 1 | . \"actions\": [ { \"index_priority\": { \"priority\": 50 } } ] . allocation . Allocate the index to a node with a specific attribute. For example, setting require to warm moves your data only to “warm” nodes. The allocation operation has the following parameters: . | Parameter | Description | Type | Required | . | require | Allocate the index to a node with a specified attribute. | string | Yes | . | include | Allocate the index to a node with any of the specified attributes. | string | Yes | . | exclude | Don’t allocate the index to a node with any of the specified attributes. | string | Yes | . | wait_for | Wait for the policy to execute before allocating the index to a node with a specified attribute. | string | Yes | . \"actions\": [ { \"allocation\": { \"require\": { \"box_type\": \"warm\" } } } ] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#ism-supported-operations",
    "relUrl": "/docs/ism/policies/#ism-supported-operations"
  },"472": {
    "doc": "Policies",
    "title": "Transitions",
    "content": "Transitions define the conditions that need to be met for a state to change. After all actions in the current state are completed, the policy starts checking the conditions for transitions. Transitions are evaluated in the order in which they are defined. For example, if the conditions for the first transition are met, then this transition takes place and the rest of the transitions are dismissed. If you don’t specify any conditions in a transition and leave it empty, then it’s assumed to be the equivalent of always true. This means that the policy transitions the index to this state the moment it checks. This table lists the parameters you can define for transitions. | Parameter | Description | Type | Required | . | state_name | The name of the state to transition to if the conditions are met. | string | Yes | . | conditions | List the conditions for the transition. | list | Yes | . The conditions object has the following parameters: . | Parameter | Description | Type | Required | . | min_index_age | The minimum age of the index required to transition. | string | No | . | min_doc_count | The minimum document count of the index required to transition. | number | No | . | min_size | The minimum size of the index required to transition. | string | No | . | cron | The cron job that triggers the transition if no other transition happens first. | object | No | . | cron.cron.expression | The cron expression that triggers the transition. | string | Yes | . | cron.cron.timezone | The timezone that triggers the transition. | string | Yes | . The following example transitions the index to a cold state after a period of 30 days: . \"transitions\": [ { \"state_name\": \"cold\", \"conditions\": { \"min_index_age\": \"30d\" } } ] . ISM checks the conditions on every execution of the policy based on the set interval. This example uses the cron condition to transition indices every Saturday at 5:00 PT: . \"transitions\": [ { \"state_name\": \"cold\", \"conditions\": { \"cron\": { \"cron\": { \"expression\": \"* 17 * * SAT\", \"timezone\": \"America/Los_Angeles\" } } } } ] . Note that this condition does not execute at exactly 5:00 PM; the job still executes based off the job_interval setting. Due to this variance in start time and the amount of time that it can take for actions to complete prior to checking transition conditions, we recommend against overly narrow cron expressions. For example, don’t use 15 17 * * SAT (5:15 PM on Saturday). A window of an hour, which this example uses, is generally sufficient, but you might increase it to 2–3 hours to avoid missing the window and having to wait a week for the transition to occur. Alternately, you could use a broader expression such as * * * * SAT,SUN to have the transition occur at any time during the weekend. For information on writing cron expressions, see Cron expression reference. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#transitions",
    "relUrl": "/docs/ism/policies/#transitions"
  },"473": {
    "doc": "Policies",
    "title": "Error notifications",
    "content": "The error_notification operation sends you a notification if your managed index fails. It notifies a single destination with a custom message. Set up error notifications at the policy level: . { \"policy\": { \"description\": \"hot warm delete workflow\", \"default_state\": \"hot\", \"schema_version\": 1, \"error_notification\": { }, \"states\": [ ] } } . | Parameter | Description | Type | Required | . | destination | The destination URL. | Slack, Amazon Chime, or webhook URL | Yes | . | message_template | The text of the message. You can add variables to your messages using Mustache templates. | object | Yes | . The destination system must return a response otherwise the error_notification operation throws an error. Example 1: Chime notification . { \"error_notification\": { \"destination\": { \"chime\": { \"url\": \"&lt;url&gt;\" } }, \"message_template\": { \"source\": \"The index {{ctx.index}} failed during policy execution.\" } } } . Example 2: Custom webhook notification . { \"error_notification\": { \"destination\": { \"custom_webhook\": { \"url\": \"https://&lt;your_webhook&gt;\" } }, \"message_template\": { \"source\": \"The index {{ctx.index}} failed during policy execution.\" } } } . Example 3: Slack notification . { \"error_notification\": { \"destination\": { \"slack\": { \"url\": \"https://hooks.slack.com/services/xxx/xxxxxx\" } }, \"message_template\": { \"source\": \"The index {{ctx.index}} failed during policy execution.\" } } } . You can use the same options for ctx variables as the notification operation. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#error-notifications",
    "relUrl": "/docs/ism/policies/#error-notifications"
  },"474": {
    "doc": "Policies",
    "title": "Example policy",
    "content": "The following example policy implements a hot, warm, and delete workflow. You can use this policy as a template to prioritize resources to your indices based on their levels of activity. In this case, an index is initially in a hot state. After a day, it changes to a warm state, where the number of replicas increases to 5 to improve the read performance. After 30 days, the policy moves this index into a delete state. The service sends a notification to a Chime room that the index is being deleted, and then permanently deletes it. { \"policy\": { \"description\": \"hot warm delete workflow\", \"default_state\": \"hot\", \"schema_version\": 1, \"states\": [ { \"name\": \"hot\", \"actions\": [ { \"rollover\": { \"min_index_age\": \"1d\" } } ], \"transitions\": [ { \"state_name\": \"warm\" } ] }, { \"name\": \"warm\", \"actions\": [ { \"replica_count\": { \"number_of_replicas\": 5 } } ], \"transitions\": [ { \"state_name\": \"delete\", \"conditions\": { \"min_index_age\": \"30d\" } } ] }, { \"name\": \"delete\", \"actions\": [ { \"notification\": { \"destination\": { \"chime\": { \"url\": \"&lt;URL&gt;\" } }, \"message_template\": { \"source\": \"The index {{ctx.index}} is being deleted\" } } }, { \"delete\": {} } ] } ] } } . This diagram shows the states, transitions, and actions of the above policy as a finite-state machine. For more information about finite-state machines, see Wikipedia. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/policies/#example-policy",
    "relUrl": "/docs/ism/policies/#example-policy"
  },"475": {
    "doc": "Popular APIs",
    "title": "Popular APIs",
    "content": "This page contains sample requests for popular Elasticsearch APIs. . | Create index with non-default settings | Index a document with a random ID | Index a document with a specific ID | Index several documents at once | List all indices | Open or close all indices that match a pattern | Delete all indices that match a pattern | Create an index alias | List all aliases | Search an index or all indices that match a pattern | Get cluster settings, including defaults | Change disk watermarks (or other cluster settings) | Get cluster health | List nodes in the cluster | Get node statistics | Get snapshots in a repository | Take a snapshot | Restore a snapshot | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/",
    "relUrl": "/docs/elasticsearch/popular-api/"
  },"476": {
    "doc": "Popular APIs",
    "title": "Create index with non-default settings",
    "content": "PUT my-logs { \"settings\": { \"number_of_shards\": 4, \"number_of_replicas\": 2 }, \"mappings\": { \"properties\": { \"title\": { \"type\": \"text\" }, \"year\": { \"type\": \"integer\" } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#create-index-with-non-default-settings",
    "relUrl": "/docs/elasticsearch/popular-api/#create-index-with-non-default-settings"
  },"477": {
    "doc": "Popular APIs",
    "title": "Index a document with a random ID",
    "content": "POST my-logs/_doc { \"title\": \"Your Name\", \"year\": \"2016\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#index-a-document-with-a-random-id",
    "relUrl": "/docs/elasticsearch/popular-api/#index-a-document-with-a-random-id"
  },"478": {
    "doc": "Popular APIs",
    "title": "Index a document with a specific ID",
    "content": "PUT my-logs/_doc/1 { \"title\": \"Weathering with You\", \"year\": \"2019\" } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#index-a-document-with-a-specific-id",
    "relUrl": "/docs/elasticsearch/popular-api/#index-a-document-with-a-specific-id"
  },"479": {
    "doc": "Popular APIs",
    "title": "Index several documents at once",
    "content": "The blank line at the end of the request body is required. If you omit the _id field, Elasticsearch generates a random ID. POST _bulk { \"index\": { \"_index\": \"my-logs\", \"_id\": \"2\" } } { \"title\": \"The Garden of Words\", \"year\": 2013 } { \"index\" : { \"_index\": \"my-logs\", \"_id\" : \"3\" } } { \"title\": \"5 Centimeters Per Second\", \"year\": 2007 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#index-several-documents-at-once",
    "relUrl": "/docs/elasticsearch/popular-api/#index-several-documents-at-once"
  },"480": {
    "doc": "Popular APIs",
    "title": "List all indices",
    "content": "GET _cat/indices?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#list-all-indices",
    "relUrl": "/docs/elasticsearch/popular-api/#list-all-indices"
  },"481": {
    "doc": "Popular APIs",
    "title": "Open or close all indices that match a pattern",
    "content": "POST my-logs*/_open POST my-logs*/_close . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#open-or-close-all-indices-that-match-a-pattern",
    "relUrl": "/docs/elasticsearch/popular-api/#open-or-close-all-indices-that-match-a-pattern"
  },"482": {
    "doc": "Popular APIs",
    "title": "Delete all indices that match a pattern",
    "content": "DELETE my-logs* . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#delete-all-indices-that-match-a-pattern",
    "relUrl": "/docs/elasticsearch/popular-api/#delete-all-indices-that-match-a-pattern"
  },"483": {
    "doc": "Popular APIs",
    "title": "Create an index alias",
    "content": "This request creates the alias my-logs-today for the index my-logs-2019-11-13. PUT my-logs-2019-11-13/_alias/my-logs-today . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#create-an-index-alias",
    "relUrl": "/docs/elasticsearch/popular-api/#create-an-index-alias"
  },"484": {
    "doc": "Popular APIs",
    "title": "List all aliases",
    "content": "GET _cat/aliases?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#list-all-aliases",
    "relUrl": "/docs/elasticsearch/popular-api/#list-all-aliases"
  },"485": {
    "doc": "Popular APIs",
    "title": "Search an index or all indices that match a pattern",
    "content": "GET my-logs/_search?q=test GET my-logs*/_search?q=test . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#search-an-index-or-all-indices-that-match-a-pattern",
    "relUrl": "/docs/elasticsearch/popular-api/#search-an-index-or-all-indices-that-match-a-pattern"
  },"486": {
    "doc": "Popular APIs",
    "title": "Get cluster settings, including defaults",
    "content": "GET _cluster/settings?include_defaults=true . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#get-cluster-settings-including-defaults",
    "relUrl": "/docs/elasticsearch/popular-api/#get-cluster-settings-including-defaults"
  },"487": {
    "doc": "Popular APIs",
    "title": "Change disk watermarks (or other cluster settings)",
    "content": "PUT _cluster/settings { \"transient\": { \"cluster.routing.allocation.disk.watermark.low\": \"80%\", \"cluster.routing.allocation.disk.watermark.high\": \"85%\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#change-disk-watermarks-or-other-cluster-settings",
    "relUrl": "/docs/elasticsearch/popular-api/#change-disk-watermarks-or-other-cluster-settings"
  },"488": {
    "doc": "Popular APIs",
    "title": "Get cluster health",
    "content": "GET _cluster/health . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#get-cluster-health",
    "relUrl": "/docs/elasticsearch/popular-api/#get-cluster-health"
  },"489": {
    "doc": "Popular APIs",
    "title": "List nodes in the cluster",
    "content": "GET _cat/nodes?v . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#list-nodes-in-the-cluster",
    "relUrl": "/docs/elasticsearch/popular-api/#list-nodes-in-the-cluster"
  },"490": {
    "doc": "Popular APIs",
    "title": "Get node statistics",
    "content": "GET _nodes/stats . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#get-node-statistics",
    "relUrl": "/docs/elasticsearch/popular-api/#get-node-statistics"
  },"491": {
    "doc": "Popular APIs",
    "title": "Get snapshots in a repository",
    "content": "GET _snapshot/my-repository/_all . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#get-snapshots-in-a-repository",
    "relUrl": "/docs/elasticsearch/popular-api/#get-snapshots-in-a-repository"
  },"492": {
    "doc": "Popular APIs",
    "title": "Take a snapshot",
    "content": "PUT _snapshot/my-repository/my-snapshot . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#take-a-snapshot",
    "relUrl": "/docs/elasticsearch/popular-api/#take-a-snapshot"
  },"493": {
    "doc": "Popular APIs",
    "title": "Restore a snapshot",
    "content": "POST _snapshot/my-repository/my-snapshot/_restore { \"indices\": \"-.opendistro_security\", \"include_global_state\": false } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/popular-api/#restore-a-snapshot",
    "relUrl": "/docs/elasticsearch/popular-api/#restore-a-snapshot"
  },"494": {
    "doc": "Protocol",
    "title": "Protocol",
    "content": "The PPL plugin provides responses in JDBC format. The JDBC format is widely used because it provides schema information and more functionality such as pagination. Besides JDBC driver, various clients can benefit from the detailed and well formatted response. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/protocol/",
    "relUrl": "/docs/ppl/protocol/"
  },"495": {
    "doc": "Protocol",
    "title": "Response Format",
    "content": "The body of HTTP POST request can take a few more additional fields with the PPL query: . curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_ppl \\ ... -d '{\"query\" : \"source=accounts | fields firstname, lastname\"}' . The following example shows a normal response where the schema includes a field name and its type and datarows includes the result set: . { \"schema\": [ { \"name\": \"firstname\", \"type\": \"string\" }, { \"name\": \"lastname\", \"type\": \"string\" } ], \"datarows\": [ [ \"Amber\", \"Duke\" ], [ \"Hattie\", \"Bond\" ], [ \"Nanette\", \"Bates\" ], [ \"Dale\", \"Adams\" ] ], \"total\": 4, \"size\": 4 } . If any error occurred, error message and the cause will be returned instead: . curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_ppl \\ ... -d '{\"query\" : \"source=unknown | fields firstname, lastname\"}' { \"error\": { \"reason\": \"Error occurred in Elasticsearch engine: no such index [unknown]\", \"details\": \"org.elasticsearch.index.IndexNotFoundException: no such index [unknown]\\nFor more details, please send request for Json format to see the raw response from elasticsearch engine.\", \"type\": \"IndexNotFoundException\" }, \"status\": 404 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/protocol/#response-format",
    "relUrl": "/docs/ppl/protocol/#response-format"
  },"496": {
    "doc": "Protocol",
    "title": "Protocol",
    "content": "For the protocol, SQL plugin provides multiple response formats for different purposes while the request format is same for all. Among them JDBC format is widely used because it provides schema information and more functionality such as pagination. Besides JDBC driver, various clients can benefit from the detailed and well formatted response. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/",
    "relUrl": "/docs/sql/protocol/"
  },"497": {
    "doc": "Protocol",
    "title": "Request Format",
    "content": "Description . The body of HTTP POST request can take a few more other fields with SQL query. Example 1 . Use filter to add more conditions to Elasticsearch DSL directly. SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"query\" : \"SELECT firstname, lastname, balance FROM accounts\", \"filter\" : { \"range\" : { \"balance\" : { \"lt\" : 10000 } } } }' . Explain: . { \"from\": 0, \"size\": 200, \"query\": { \"bool\": { \"filter\": [{ \"bool\": { \"filter\": [{ \"range\": { \"balance\": { \"from\": null, \"to\": 10000, \"include_lower\": true, \"include_upper\": false, \"boost\": 1.0 } } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } }, \"_source\": { \"includes\": [ \"firstname\", \"lastname\", \"balance\" ], \"excludes\": [] } } . Example 2 . Use parameters for actual parameter value in prepared SQL query. SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"query\": \"SELECT * FROM accounts WHERE age = ?\", \"parameters\": [{ \"type\": \"integer\", \"value\": 30 }] }' . Explain: . { \"from\": 0, \"size\": 200, \"query\": { \"bool\": { \"filter\": [{ \"bool\": { \"must\": [{ \"term\": { \"age\": { \"value\": 30, \"boost\": 1.0 } } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } }], \"adjust_pure_negative\": true, \"boost\": 1.0 } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/#request-format",
    "relUrl": "/docs/sql/protocol/#request-format"
  },"498": {
    "doc": "Protocol",
    "title": "Elasticsearch DSL",
    "content": "Description . By default the plugin returns original response from Elasticsearch in JSON. Because this is the native response from Elasticsearch, extra efforts are needed to parse and interpret it. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql -d '{ \"query\" : \"SELECT firstname, lastname, age FROM accounts ORDER BY age LIMIT 2\" }' . Result set: . { \"_shards\": { \"total\": 5, \"failed\": 0, \"successful\": 5, \"skipped\": 0 }, \"hits\": { \"hits\": [{ \"_index\": \"accounts\", \"_type\": \"account\", \"_source\": { \"firstname\": \"Nanette\", \"age\": 28, \"lastname\": \"Bates\" }, \"_id\": \"13\", \"sort\": [ 28 ], \"_score\": null }, { \"_index\": \"accounts\", \"_type\": \"account\", \"_source\": { \"firstname\": \"Amber\", \"age\": 32, \"lastname\": \"Duke\" }, \"_id\": \"1\", \"sort\": [ 32 ], \"_score\": null } ], \"total\": { \"value\": 4, \"relation\": \"eq\" }, \"max_score\": null }, \"took\": 100, \"timed_out\": false } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/#elasticsearch-dsl",
    "relUrl": "/docs/sql/protocol/#elasticsearch-dsl"
  },"499": {
    "doc": "Protocol",
    "title": "JDBC Format",
    "content": "Description . JDBC format is provided for JDBC driver and client side that needs both schema and result set well formatted. Example 1 . Here is an example for normal response. The schema includes field name and its type and datarows includes the result set. SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql?format=jdbc -d '{ \"query\" : \"SELECT firstname, lastname, age FROM accounts ORDER BY age LIMIT 2\" }' . Result set: . { \"schema\": [{ \"name\": \"firstname\", \"type\": \"text\" }, { \"name\": \"lastname\", \"type\": \"text\" }, { \"name\": \"age\", \"type\": \"long\" } ], \"total\": 4, \"datarows\": [ [ \"Nanette\", \"Bates\", 28 ], [ \"Amber\", \"Duke\", 32 ] ], \"size\": 2, \"status\": 200 } . Example 2 . If any error occurred, error message and the cause will be returned instead. SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql?format=jdbc -d '{ \"query\" : \"SELECT unknown FROM accounts\" }' . Result set: . { \"error\": { \"reason\": \"Invalid SQL query\", \"details\": \"Field [unknown] cannot be found or used here.\", \"type\": \"SemanticAnalysisException\" }, \"status\": 400 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/#jdbc-format",
    "relUrl": "/docs/sql/protocol/#jdbc-format"
  },"500": {
    "doc": "Protocol",
    "title": "CSV Format",
    "content": "Description . You can also use CSV format to download result set as CSV. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql?format=csv -d '{ \"query\" : \"SELECT firstname, lastname, age FROM accounts ORDER BY age\" }' . Result set: . firstname,lastname,age Nanette,Bates,28 Amber,Duke,32 Dale,Adams,33 Hattie,Bond,36 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/#csv-format",
    "relUrl": "/docs/sql/protocol/#csv-format"
  },"501": {
    "doc": "Protocol",
    "title": "Raw Format",
    "content": "Description . Additionally raw format can be used to pipe the result to other command line tool for post processing. Example . SQL query: . &gt;&gt; curl -H 'Content-Type: application/json' -X POST localhost:9200/_opendistro/_sql?format=raw -d '{ \"query\" : \"SELECT firstname, lastname, age FROM accounts ORDER BY age\" }' . Result set: . Nanette|Bates|28 Amber|Duke|32 Dale|Adams|33 Hattie|Bond|36 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/protocol/#raw-format",
    "relUrl": "/docs/sql/protocol/#raw-format"
  },"502": {
    "doc": "Proxy-based authentication",
    "title": "Proxy-based authentication",
    "content": "If you already have a single sign-on (SSO) solution in place, you might want to use it as an authentication backend. Most solutions work as a proxy in front of Elasticsearch and the security plugin. If proxy authentication succeeds, the proxy adds the (verified) username and its (verified) roles in HTTP header fields. The names of these fields depend on the SSO solution you have in place. The security plugin then extracts these HTTP header fields from the request and uses the values to determine the user’s permissions. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/",
    "relUrl": "/docs/security/configuration/proxy/"
  },"503": {
    "doc": "Proxy-based authentication",
    "title": "Enable proxy detection",
    "content": "To enable proxy detection for Elasticsearch, configure it in the xff section of config.yml: . --- _meta: type: \"config\" config_version: 2 config: dynamic: http: anonymous_auth_enabled: false xff: enabled: true internalProxies: '192\\.168\\.0\\.10|192\\.168\\.0\\.11' remoteIpHeader: 'x-forwarded-for' . You can configure the following settings: . | Name | Description | . | enabled | Enables or disables proxy support. Default is false. | . | internalProxies | A regular expression containing the IP addresses of all trusted proxies. The pattern .* trusts all internal proxies. | . | remoteIpHeader | Name of the HTTP header field that has the hostname chain. Default is x-forwarded-for. | . To determine whether a request comes from a trusted internal proxy, the security plugin compares the remote address of the HTTP request with the list of configured internal proxies. If the remote address is not in the list, the plugin treats the request like a client request. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/#enable-proxy-detection",
    "relUrl": "/docs/security/configuration/proxy/#enable-proxy-detection"
  },"504": {
    "doc": "Proxy-based authentication",
    "title": "Enable proxy authentication",
    "content": "Configure the names of the HTTP header fields that carry the authenticated username and role(s) in in the proxy HTTP authenticator section: . proxy_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: proxy challenge: false config: user_header: \"x-proxy-user\" roles_header: \"x-proxy-roles\" authentication_backend: type: noop . | Name | Description | . | user_header | The HTTP header field containing the authenticated username. Default is x-proxy-user. | . | roles_header | The HTTP header field containing the comma-separated list of authenticated role names. The security plugin uses the roles found in this header field as backend roles. Default is x-proxy-roles. | . | roles_separator | The separator for roles. Default is ,. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/#enable-proxy-authentication",
    "relUrl": "/docs/security/configuration/proxy/#enable-proxy-authentication"
  },"505": {
    "doc": "Proxy-based authentication",
    "title": "Enable extended proxy authentication",
    "content": "The security plugin has an extended version of the proxy type that lets you pass additional user attributes for use with document-level security. Aside from type: extended-proxy and attr_header_prefix, configuration is identical: . proxy_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: extended-proxy challenge: false config: user_header: \"x-proxy-user\" roles_header: \"x-proxy-roles\" attr_header_prefix: \"x-proxy-ext-\" authentication_backend: type: noop . | Name | Description | . | attr_header_prefix | The header prefix that the proxy uses to provide user attributes. For example, if the proxy provides x-proxy-ext-namespace: my-namespace, use ${attr.proxy.namespace} in document-level security queries. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/#enable-extended-proxy-authentication",
    "relUrl": "/docs/security/configuration/proxy/#enable-extended-proxy-authentication"
  },"506": {
    "doc": "Proxy-based authentication",
    "title": "Example",
    "content": "The following example uses an nginx proxy in front of a three-node Elasticsearch cluster. For simplicity, we use hardcoded values for x-proxy-user and x-proxy-roles. In a real world example you would set these headers dynamically. The example also includes a commented header for use with the extended proxy. events { worker_connections 1024; } http { upstream elasticsearch { server node1.example.com:9200; server node2.example.com:9200; server node3.example.com:9200; keepalive 15; } server { listen 8090; server_name nginx.example.com; location / { proxy_pass https://elasticsearch; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header x-proxy-user test; proxy_set_header x-proxy-roles test; #proxy_set_header x-proxy-ext-namespace my-namespace; } } } . The corresponding minimal config.yml looks like: . --- _meta: type: \"config\" config_version: 2 config: dynamic: http: xff: enabled: true internalProxies: '172.16.0.203' # the nginx proxy authc: proxy_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: proxy #type: extended-proxy challenge: false config: user_header: \"x-proxy-user\" roles_header: \"x-proxy-roles\" #attr_header_prefix: \"x-proxy-ext-\" authentication_backend: type: noop . The important part is to enable the X-Forwarded-For (XFF) resolution and set the IP(s) of the internal proxies correctly: . enabled: true internalProxies: '172.16.0.203' # nginx proxy . In this case, nginx.example.com runs on 172.16.0.203, so add this IP to the list of internal proxies. Be sure to set internalProxies to the minimum number of IP addresses so that the security plugin only accepts requests from trusted IPs. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/#example",
    "relUrl": "/docs/security/configuration/proxy/#example"
  },"507": {
    "doc": "Proxy-based authentication",
    "title": "Kibana proxy authentication",
    "content": "To use proxy authentication with Kibana, the most common configuration is to place the proxy in front of Kibana and let Kibana pass the user and role headers to the security plugin. In this case, the remote address of the HTTP call is the IP of Kibana, because it sits directly in front of Elasticsearch. Add the IP of Kibana to the list of internal proxies: . --- _meta: type: \"config\" config_version: 2 config: dynamic: http: xff: enabled: true remoteIpHeader: \"x-forwarded-for\" internalProxies: '&lt;kibana-ip-address&gt;' . To pass the user and role headers that the authenticating proxy adds from Kibana to the security plugin, add them to the HTTP header whitelist in kibana.yml: . elasticsearch.requestHeadersWhitelist: [\"securitytenant\",\"Authorization\",\"x-forwarded-for\",\"x-proxy-user\",\"x-proxy-roles\"] . You must also enable the authentication type in kibana.yml: . opendistro_security.auth.type: \"proxy\" opendistro_security.proxycache.user_header: \"x-proxy-user\" opendistro_security.proxycache.roles_header: \"x-proxy-roles\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/proxy/#kibana-proxy-authentication",
    "relUrl": "/docs/security/configuration/proxy/#kibana-proxy-authentication"
  },"508": {
    "doc": "RCA Reference",
    "title": "RCA reference",
    "content": "You can find a reference of available RCAs and their purposes on Github. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/reference/#rca-reference",
    "relUrl": "/docs/rca/reference/#rca-reference"
  },"509": {
    "doc": "RCA Reference",
    "title": "RCA Reference",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/rca/reference/",
    "relUrl": "/docs/rca/reference/"
  },"510": {
    "doc": "Metrics Reference",
    "title": "Metrics reference",
    "content": "This page contains all Performance Analyzer metrics. All metrics support the avg, sum, min, and max aggregations, although certain metrics measure only one thing, making the choice of aggregation irrelevant. For information on dimensions, see the dimensions reference. This list is extensive. We recommend Ctrl + F to find what you’re looking for. | Metric | Dimensions | Description | . | CPU_Utilization | ShardID, IndexName, Operation, ShardRole | CPU usage ratio. CPU time (in milliseconds) used by the associated thread(s) in the past five seconds, divided by 5000 milliseconds. | . | Paging_MajfltRate | The number of major faults per second in the past five seconds. A major fault requires the process to load a memory page from disk. | . | Paging_MinfltRate | The number of minor faults per second in the past five seconds. A minor fault does not requires the process to load a memory page from disk. | . | Paging_RSS | The number of pages the process has in real memory---the pages that count towards text, data, or stack space. This number does not include pages that have not been demand-loaded in or swapped out. | . | Sched_Runtime | Time (seconds) spent executing on the CPU per context switch. | . | Sched_Waittime | Time (seconds) spent waiting on a run queue per context switch. | . | Sched_CtxRate | Number of times run on the CPU per second in the past five seconds. | . | Heap_AllocRate | An approximation of the heap memory allocated, in bytes, per second in the past five seconds | . | IO_ReadThroughput | Number of bytes read per second in the last five seconds. | . | IO_WriteThroughput | Number of bytes written per second in the last five seconds. | . | IO_TotThroughput | Number of bytes read or written per second in the last five seconds. | . | IO_ReadSyscallRate | Read system calls per second in the last five seconds. | . | IO_WriteSyscallRate | Write system calls per second in the last five seconds. | . | IO_TotalSyscallRate | Read and write system calls per second in the last five seconds. | . | Thread_Blocked_Time | Average time (seconds) that the associated thread(s) blocked to enter or reenter a monitor. | . | Thread_Blocked_Event | The total number of times that the associated thread(s) blocked to enter or reenter a monitor (i.e. the number of times a thread has been in the blocked state). | . | ShardEvents | The total number of events executed on a shard in the past five seconds. | . | ShardBulkDocs | The total number of documents indexed in the past five seconds. | . | Indexing_ThrottleTime | ShardID, IndexName | Time (milliseconds) that the index has been under merge throttling control in the past five seconds. | . | Cache_Query_Hit | The number of successful lookups in the query cache in the past five seconds. | . | Cache_Query_Miss | The number of lookups in the query cache that failed to retrieve a `DocIdSet` in the past five seconds. `DocIdSet` is a set of document IDs in Lucene. | . | Cache_Query_Size | Query cache memory size in bytes. | . | Cache_FieldData_Eviction | The number of times Elasticsearch has evicted data from the fielddata heap space (occurs when the heap space is full) in the past five seconds. | . | Cache_FieldData_Size | Fielddata memory size in bytes. | . | Cache_Request_Hit | The number of successful lookups in the shard request cache in the past five seconds. | . | Cache_Request_Miss | The number of lookups in the request cache that failed to retrieve the results of search requests in the past five seconds. | . | Cache_Request_Eviction | The number of times Elasticsearch evicts data from shard request cache (occurs when the request cache is full) in the past five seconds. | . | Cache_Request_Size | Shard request cache memory size in bytes. | . | Refresh_Event | The total number of refreshes executed in the past five seconds. | . | Refresh_Time | The total time (milliseconds) spent executing refreshes in the past five seconds | . | Flush_Event | The total number of flushes executed in the past five seconds. | . | Flush_Time | The total time (milliseconds) spent executing flushes in the past five seconds. | . | Merge_Event | The total number of merges executed in the past five seconds. | . | Merge_Time | The total time (milliseconds) spent executing merges in the past five seconds. | . | Merge_CurrentEvent | The current number of merges executing. | . | Indexing_Buffer | Index buffer memory size in bytes. | . | Segments_Total | The number of segments. | . | Segments_Memory | Estimated memory usage of segments in bytes. | . | Terms_Memory | Estimated memory usage of terms dictionaries in bytes. | . | StoredFields_Memory | Estimated memory usage of stored fields in bytes. | . | TermVectors_Memory | Estimated memory usage of term vectors in bytes. | . | Norms_Memory | Estimated memory usage of norms (normalization factors) in bytes. | . | Points_Memory | Estimated memory usage of points in bytes. | . | DocValues_Memory | Estimated memory usage of doc values in bytes. | . | IndexWriter_Memory | Estimated memory usage by the index writer in bytes. | . | Bitset_Memory | Estimated memory usage for the cached bit sets in bytes. | . | VersionMap_Memory | Estimated memory usage of the version map in bytes. | . | Shard_Size_In_Bytes | Estimated disk usage of the shard in bytes. | . | Latency | Operation, Exception, Indices, HTTPRespCode, ShardID, IndexName, ShardRole | Latency (milliseconds) of a request. | . | GC_Collection_Event | MemType | The number of garbage collections that have occurred in the past five seconds. | . | GC_Collection_Time | The approximate accumulated time (milliseconds) of all garbage collections that have occurred in the past five seconds. | . | Heap_Committed | The amount of memory (bytes) that is committed for the JVM to use. | . | Heap_Init | The amount of memory (bytes) that the JVM initially requests from the operating system for memory management. | . | Heap_Max | The maximum amount of memory (bytes) that can be used for memory management. | . | Heap_Used | The amount of used memory in bytes. | . | Disk_Utilization | DiskName | Disk utilization rate: percentage of disk time spent reading and writing by the Elasticsearch process in the past five seconds. | . | Disk_WaitTime | Average duration (milliseconds) of read and write operations in the past five seconds. | . | Disk_ServiceRate | Service rate: MB read or written per second in the past five seconds. This metric assumes that each disk sector stores 512 bytes. | . | Net_TCP_NumFlows | DestAddr | Number of samples collected. Performance Analyzer collects one sample every five seconds. | . | Net_TCP_TxQ | Average number of TCP packets in the send buffer. | . | Net_TCP_RxQ | Average number of TCP packets in the receive buffer. | . | Net_TCP_Lost | Average number of unrecovered recurring timeouts. This number is reset when the recovery finishes or `SND.UNA` is advanced. `SND.UNA` is the sequence number of the first byte of data that has been sent, but not yet acknowledged. | . | Net_TCP_SendCWND | Average size (bytes) of the sending congestion window. | . | Net_TCP_SSThresh | Average size (bytes) of the slow start size threshold. | . | Net_PacketRate4 | Direction | The total number of IPv4 datagrams transmitted/received from/by interfaces per second, including those transmitted or received in error | . | Net_PacketDropRate4 | The total number of IPv4 datagrams transmitted or received in error per second. | . | Net_PacketRate6 | The total number of IPv6 datagrams transmitted or received from or by interfaces per second, including those transmitted or received in error. | . | Net_PacketDropRate6 | The total number of IPv6 datagrams transmitted or received in error per second. | . | Net_Throughput | The number of bits transmitted or received per second by all network interfaces. | . | ThreadPool_QueueSize | ThreadPoolType | The size of the task queue. | . | ThreadPool_RejectedReqs | The number of rejected executions. | . | ThreadPool_TotalThreads | The current number of threads in the pool. | . | ThreadPool_ActiveThreads | The approximate number of threads that are actively executing tasks. | . | Master_PendingQueueSize | N/A | The current number of pending tasks in the cluster state update thread. Each node has a cluster state update thread that submits cluster state update tasks (create index, update mapping, allocate shard, fail shard, etc.). | . | HTTP_RequestDocs | Operation, Exception, Indices, HTTPRespCode | The number of items in the request (only for `_bulk` request type). | . | HTTP_TotalRequests | The number of finished requests in the past five seconds. | . | CB_EstimatedSize | CBType | The current number of estimated bytes. | . | CB_TrippedEvents | The number of times the circuit breaker has tripped. | . | CB_ConfiguredSize | The limit (bytes) for how much memory operations can use. | . | Master_Task_Queue_Time | MasterTaskInsertOrder, MasterTaskPriority, MasterTaskType, MasterTaskMetadata | The time (milliseconds) that a master task spent in the queue. | . | Master_Task_Run_Time | The time (milliseconds) that a master task has been executed. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/reference/#metrics-reference",
    "relUrl": "/docs/pa/reference/#metrics-reference"
  },"511": {
    "doc": "Metrics Reference",
    "title": "Dimensions reference",
    "content": "| Dimension | Return values | . | ShardID | ID for the shard (e.g. 1). | . | IndexName | Name of the index (e.g. my-index). | . | Operation | Type of operation (e.g. shardbulk). | . | ShardRole | primary, replica | . | Exception | Elasticsearch exceptions (e.g. org.elasticsearch.index_not_found_exception). | . | Indices | The list of indices in the request URI. | . | HTTPRespCode | Response code from Elasticsearch (e.g. 200). | . | MemType | totYoungGC, totFullGC, Survivor, PermGen, OldGen, Eden, NonHeap, Heap | . | DiskName | Name of the disk (e.g. sda1). | . | DestAddr | Destination address (e.g. 010015AC). | . | Direction | in, out | . | ThreadPoolType | The Elasticsearch thread pools (e.g. index, search,snapshot). | . | CBType | accounting, fielddata, in_flight_requests, parent, request | . | MasterTaskInsertOrder | The order in which the task was inserted (e.g. 3691). | . | MasterTaskPriority | Priority of the task (e.g. URGENT). Elasticsearch executes higher priority tasks before lower priority ones, regardless of insert_order. | . | MasterTaskType | shard-started, create-index, delete-index, refresh-mapping, put-mapping, CleanupSnapshotRestoreState, Update snapshot state | . | MasterTaskMetadata | Metadata for the task (if any). | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/reference/#dimensions-reference",
    "relUrl": "/docs/pa/reference/#dimensions-reference"
  },"512": {
    "doc": "Metrics Reference",
    "title": "Metrics Reference",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/pa/reference/",
    "relUrl": "/docs/pa/reference/"
  },"513": {
    "doc": "Refresh Search Analyzer",
    "title": "Refresh search analyzer",
    "content": "With ISM installed, you can refresh search analyzers in real time with the following API: . POST /_opendistro/_refresh_search_analyzers/&lt;index or alias or wildcard&gt; . For example, if you change the synonym list in your analyzer, the change takes effect without you needing to close and reopen the index. To work, the token filter must have an updateable flag of true: . { \"analyzer\": { \"my_synonyms\": { \"tokenizer\": \"whitespace\", \"filter\": [ \"synonym\" ] } }, \"filter\": { \"synonym\": { \"type\": \"synonym_graph\", \"synonyms_path\": \"synonyms.txt\", \"updateable\": true } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/refresh-analyzer/#refresh-search-analyzer",
    "relUrl": "/docs/ism/refresh-analyzer/#refresh-search-analyzer"
  },"514": {
    "doc": "Refresh Search Analyzer",
    "title": "Refresh Search Analyzer",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/refresh-analyzer/",
    "relUrl": "/docs/ism/refresh-analyzer/"
  },"515": {
    "doc": "Reindex Data",
    "title": "Reindex data",
    "content": "After creating an index, if you need to make an extensive change such as adding a new field to every document or combining multiple indices to form a new one, rather than deleting your index, making the change offline, and then indexing your data all over again, you can use the reindex operation. With the reindex operation, you can copy all or a subset of documents that you select through a query to another index. Reindex is a POST operation. In its most basic form, you specify a source index and a destination index. Reindexing can be an expensive operation depending on the size of your source index. We recommend you disable replicas in your destination index by setting number_of_replicas to 0 and re-enable them once the reindex process is complete. . | Reindex all documents | Reindex from a remote cluster | Reindex a subset of documents | Combine one or more indices | Reindex only unique documents | Reindex sorted documents | Transform documents during reindexing | Update documents in current index | Source index options | Destination index options | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-data",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-data"
  },"516": {
    "doc": "Reindex Data",
    "title": "Reindex all documents",
    "content": "You can copy all documents from one index to another. You first need to create a destination index with your desired field mappings and settings or you can copy the ones from your source index: . PUT destination { \"mappings\":{ \"Add in your desired mappings\" }, \"settings\":{ \"Add in your desired settings\" } } . This reindex command copies all the documents from a source index to a destination index: . POST _reindex { \"source\":{ \"index\":\"source\" }, \"dest\":{ \"index\":\"destination\" } } . If the destination index is not already created, the reindex operation creates a new destination index with default configurations. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-all-documents",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-all-documents"
  },"517": {
    "doc": "Reindex Data",
    "title": "Reindex from a remote cluster",
    "content": "You can copy documents from an index in a remote cluster. Use the remote option to specify the remote hostname and the required login credentials. This command reaches out to a remote cluster, logs in with the username and password, and copies all the documents from the source index in that remote cluster to the destination index in your local cluster: . POST _reindex { \"source\":{ \"remote\":{ \"host\":\"https://&lt;REST_endpoint_of_remote_cluster&gt;:9200\", \"username\":\"YOUR_USERNAME\", \"password\":\"YOUR_PASSWORD\" } }, \"dest\":{ \"index\":\"destination\" } } . You can specify the following options: . | Options | Valid values | Description | Required | . | host | String | The REST endpoint of the remote cluster. | Yes | . | username | String | The username to login to the remote cluster. | No | . | password | String | The password to login to the remote cluster. | No | . | socket_timeout | Time Unit | The wait time for socket reads (default 30s). | No | . | connect_timeout | Time Unit | The wait time for remote connection timeouts (default 30s). | No | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-from-a-remote-cluster",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-from-a-remote-cluster"
  },"518": {
    "doc": "Reindex Data",
    "title": "Reindex a subset of documents",
    "content": "You can copy only a specific set of documents that match a search query. This command copies only a subset of documents matched by a query operation to the destination index: . POST _reindex { \"source\":{ \"index\":\"source\", \"query\": { \"match\": { \"field_name\": \"text\" } } }, \"dest\":{ \"index\":\"destination\" } } . For a list of all query operations, see Full-text queries. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-a-subset-of-documents",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-a-subset-of-documents"
  },"519": {
    "doc": "Reindex Data",
    "title": "Combine one or more indices",
    "content": "You can combine documents from one or more indices by adding the source indices as a list. This command copies all documents from two source indices to one destination index: . POST _reindex { \"source\":{ \"index\":[ \"source_1\", \"source_2\" ] }, \"dest\":{ \"index\":\"destination\" } } . Make sure the number of shards for your source and destination indices are the same. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#combine-one-or-more-indices",
    "relUrl": "/docs/elasticsearch/reindex-data/#combine-one-or-more-indices"
  },"520": {
    "doc": "Reindex Data",
    "title": "Reindex only unique documents",
    "content": "You can copy only documents missing from a destination index by setting the op_type option to create. In this case, if a document with the same ID already exists, the operation ignores the one from the source index. To ignore all version conflicts of documents, set the conflicts option to proceed. POST _reindex { \"conflicts\":\"proceed\", \"source\":{ \"index\":\"source\" }, \"dest\":{ \"index\":\"destination\", \"op_type\":\"create\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-only-unique-documents",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-only-unique-documents"
  },"521": {
    "doc": "Reindex Data",
    "title": "Reindex sorted documents",
    "content": "You can copy certain documents after sorting specific fields in the document. This command copies the last 10 documents based on the timestamp field: . POST _reindex { \"size\":10, \"source\":{ \"index\":\"source\", \"sort\":{ \"timestamp\":\"desc\" } }, \"dest\":{ \"index\":\"destination\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#reindex-sorted-documents",
    "relUrl": "/docs/elasticsearch/reindex-data/#reindex-sorted-documents"
  },"522": {
    "doc": "Reindex Data",
    "title": "Transform documents during reindexing",
    "content": "You can transform your data during the reindexing process using the script option. We recommend Painless for scripting in Elasticsearch. This command runs the source index through a Painless script that increments a number field inside an account object before copying it to the destination index: . POST _reindex { \"source\":{ \"index\":\"source\" }, \"dest\":{ \"index\":\"destination\" }, \"script\":{ \"lang\":\"painless\", \"source\":\"ctx._account.number++\" } } . You can also specify an ingest pipeline to transform your data during the reindexing process. You would first have to create a pipeline with processors defined. You have a number of different processors available to use in your ingest pipeline. Here’s a sample ingest pipeline that defines a split processor that splits a text field based on a space separator and stores it in a new word field. The script processor is a Painless script that finds the length of the word field and stores it in a new word_count field. The remove processor removes the test field. PUT _ingest/pipeline/pipeline-test { \"description\": \"Splits the text field into a list. Computes the length of the 'word' field and stores it in a new 'word_count' field. Removes the 'test' field.\", \"processors\": [ { \"split\": { \"field\": \"text\", \"separator\": \"\\\\s+\", \"target_field\": \"word\" }, } { \"script\": { \"lang\": \"painless\", \"source\": \"ctx.word_count = ctx.word.length\" } }, { \"remove\": { \"field\": \"test\" } } ] } . After creating a pipeline, you can use the reindex operation: . POST _reindex { \"source\": { \"index\": \"source\", }, \"dest\": { \"index\": \"destination\", \"pipeline\": \"pipeline-test\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#transform-documents-during-reindexing",
    "relUrl": "/docs/elasticsearch/reindex-data/#transform-documents-during-reindexing"
  },"523": {
    "doc": "Reindex Data",
    "title": "Update documents in current index",
    "content": "To update your data in your current index itself without copying it to a different index, use the update_by_query operation. The update_by_query operation is POST operation that you can perform on a single index at a time. POST &lt;index_name&gt;/_update_by_query . If you run this command with no parameters, it increments the version number for all documents in the index. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#update-documents-in-current-index",
    "relUrl": "/docs/elasticsearch/reindex-data/#update-documents-in-current-index"
  },"524": {
    "doc": "Reindex Data",
    "title": "Source index options",
    "content": "You can specify the following options for your source index: . | Option | Valid values | Description | Required | . | index | String | The name of the source index. You can provide multiple source indices as a list. | Yes | . | max_docs | Integer | The maximum number of documents to reindex. | No | . | query | Object | The search query to use for the reindex operation. | No | . | size | Integer | The number of documents to reindex. | No | . | slice | String | Specify manual or automatic slicing to parallelize reindexing. | No | . | sort | List | Sort specific fields in the document before reindexing. | No | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#source-index-options",
    "relUrl": "/docs/elasticsearch/reindex-data/#source-index-options"
  },"525": {
    "doc": "Reindex Data",
    "title": "Destination index options",
    "content": "You can specify the following options for your destination index: . | Option | Valid values | Description | Required | . | index | String | The name of the destination index. | Yes | . | version_type | Enum | The version type for the indexing operation. Valid values: internal, external, external_gt, external_gte. | No | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/#destination-index-options",
    "relUrl": "/docs/elasticsearch/reindex-data/#destination-index-options"
  },"526": {
    "doc": "Reindex Data",
    "title": "Reindex Data",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/reindex-data/",
    "relUrl": "/docs/elasticsearch/reindex-data/"
  },"527": {
    "doc": "REST API Reference",
    "title": "Elasticsearch REST API reference",
    "content": "We generate this reference from the Elasticsearch REST API specification. As such, its usefulness depends on the accuracy of the specification. For language issues, missing information, and inaccuracies, modify the JSON files in rest-api-spec/src/main/resources/rest-api-spec/api and submit pull requests to the upstream Elasticsearch repository. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#elasticsearch-rest-api-reference",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#elasticsearch-rest-api-reference"
  },"528": {
    "doc": "REST API Reference",
    "title": "bulk",
    "content": "Allows to perform multiple index/update/delete operations in a single request. POST _bulk PUT _bulk . POST {index}/_bulk PUT {index}/_bulk . POST {index}/{type}/_bulk PUT {index}/{type}/_bulk . HTTP request body . The operation definition and data (action-data pairs), separated by newlines . Required: True . URL parameters . | Parameter | Type | Description | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the bulk operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) | . | refresh | enum | If true then refresh the affected shards to make this operation visible to search, if wait_for then wait for a refresh to make this operation visible to search, if false (the default) then do nothing with refreshes. | . | routing | string | Specific routing value | . | timeout | time | Explicit operation timeout | . | type | string | Default document type for items which don’t provide one | . | _source | list | True or false to return the _source field or not, or default list of fields to return, can be overridden on each sub-request | . | _source_excludes | list | Default list of fields to exclude from the returned _source field, can be overridden on each sub-request | . | _source_includes | list | Default list of fields to extract and return from the _source field, can be overridden on each sub-request | . | pipeline | string | The pipeline id to preprocess incoming documents with | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#bulk",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#bulk"
  },"529": {
    "doc": "REST API Reference",
    "title": "cat.aliases",
    "content": "Shows information about currently configured aliases to indices including filter and routing infos. GET _cat/aliases . GET _cat/aliases/{name} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#cataliases",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#cataliases"
  },"530": {
    "doc": "REST API Reference",
    "title": "cat.allocation",
    "content": "Provides a snapshot of how many shards are allocated to each data node and how much disk space they are using. GET _cat/allocation . GET _cat/allocation/{node_id} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | bytes | enum | The unit in which to display byte values | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catallocation",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catallocation"
  },"531": {
    "doc": "REST API Reference",
    "title": "cat.count",
    "content": "Provides quick access to the document count of the entire cluster, or individual indices. GET _cat/count . GET _cat/count/{index} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catcount",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catcount"
  },"532": {
    "doc": "REST API Reference",
    "title": "cat.fielddata",
    "content": "Shows how much heap memory is currently being used by fielddata on every data node in the cluster. GET _cat/fielddata . GET _cat/fielddata/{fields} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | bytes | enum | The unit in which to display byte values | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . | fields | list | A comma-separated list of fields to return in the output | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catfielddata",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catfielddata"
  },"533": {
    "doc": "REST API Reference",
    "title": "cat.health",
    "content": "Returns a concise representation of the cluster health. GET _cat/health . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | ts | boolean | Set to false to disable timestamping | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#cathealth",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#cathealth"
  },"534": {
    "doc": "REST API Reference",
    "title": "cat.help",
    "content": "Returns help for the Cat APIs. GET _cat . URL parameters . | Parameter | Type | Description | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#cathelp",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#cathelp"
  },"535": {
    "doc": "REST API Reference",
    "title": "cat.indices",
    "content": "Returns information about indices: number of primaries and replicas, document counts, disk size, … . GET _cat/indices . GET _cat/indices/{index} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | bytes | enum | The unit in which to display byte values | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | health | enum | A health status (“green”, “yellow”, or “red” to filter only indices matching the specified health status | . | help | boolean | Return help information | . | pri | boolean | Set to true to return stats only for primary shards | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . | include_unloaded_segments | boolean | If set to true segment stats will include stats for segments that are not currently loaded into memory | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catindices",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catindices"
  },"536": {
    "doc": "REST API Reference",
    "title": "cat.master",
    "content": "Returns information about the master node. GET _cat/master . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catmaster",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catmaster"
  },"537": {
    "doc": "REST API Reference",
    "title": "cat.nodeattrs",
    "content": "Returns information about custom node attributes. GET _cat/nodeattrs . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catnodeattrs",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catnodeattrs"
  },"538": {
    "doc": "REST API Reference",
    "title": "cat.nodes",
    "content": "Returns basic statistics about performance of cluster nodes. GET _cat/nodes . URL parameters . | Parameter | Type | Description | . | bytes | enum | The unit in which to display byte values | . | format | string | a short version of the Accept header, e.g. json, yaml | . | full_id | boolean | Return the full node ID instead of the shortened version (default: false) | . | local | boolean | Calculate the selected nodes using the local cluster state rather than the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catnodes",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catnodes"
  },"539": {
    "doc": "REST API Reference",
    "title": "cat.pending_tasks",
    "content": "Returns a concise representation of the cluster pending tasks. GET _cat/pending_tasks . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catpending_tasks",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catpending_tasks"
  },"540": {
    "doc": "REST API Reference",
    "title": "cat.plugins",
    "content": "Returns information about installed plugins across nodes node. GET _cat/plugins . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catplugins",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catplugins"
  },"541": {
    "doc": "REST API Reference",
    "title": "cat.recovery",
    "content": "Returns information about index shard recoveries, both on-going completed. GET _cat/recovery . GET _cat/recovery/{index} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | active_only | boolean | If true, the response only includes ongoing shard recoveries | . | bytes | enum | The unit in which to display byte values | . | detailed | boolean | If true, the response includes detailed information about shard recoveries | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | index | list | Comma-separated list or wildcard expression of index names to limit the returned information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catrecovery",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catrecovery"
  },"542": {
    "doc": "REST API Reference",
    "title": "cat.repositories",
    "content": "Returns information about snapshot repositories registered in the cluster. GET _cat/repositories . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catrepositories",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catrepositories"
  },"543": {
    "doc": "REST API Reference",
    "title": "cat.segments",
    "content": "Provides low-level information about the segments in the shards of an index. GET _cat/segments . GET _cat/segments/{index} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | bytes | enum | The unit in which to display byte values | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catsegments",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catsegments"
  },"544": {
    "doc": "REST API Reference",
    "title": "cat.shards",
    "content": "Provides a detailed view of shard allocation on nodes. GET _cat/shards . GET _cat/shards/{index} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | bytes | enum | The unit in which to display byte values | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catshards",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catshards"
  },"545": {
    "doc": "REST API Reference",
    "title": "cat.snapshots",
    "content": "Returns all snapshots in a specific repository. GET _cat/snapshots . GET _cat/snapshots/{repository} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | ignore_unavailable | boolean | Set to true to ignore unavailable snapshots | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catsnapshots",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catsnapshots"
  },"546": {
    "doc": "REST API Reference",
    "title": "cat.tasks",
    "content": "Returns information about the tasks currently executing on one or more nodes in the cluster. GET _cat/tasks . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | node_id | list | A comma-separated list of node IDs or names to limit the returned information; use _local to return information from the node you’re connecting to, leave empty to get information from all nodes | . | actions | list | A comma-separated list of actions that should be returned. Leave empty to return all. | . | detailed | boolean | Return detailed task information (default: false) | . | parent_task | number | Return tasks with specified parent task id. Set to -1 to return all. | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | time | enum | The unit in which to display time values | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#cattasks",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#cattasks"
  },"547": {
    "doc": "REST API Reference",
    "title": "cat.templates",
    "content": "Returns information about existing templates. GET _cat/templates . GET _cat/templates/{name} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#cattemplates",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#cattemplates"
  },"548": {
    "doc": "REST API Reference",
    "title": "cat.thread_pool",
    "content": "Returns cluster-wide thread pool statistics per node. By default the active, queue and rejected statistics are returned for all thread pools. GET _cat/thread_pool . GET _cat/thread_pool/{thread_pool_patterns} . URL parameters . | Parameter | Type | Description | . | format | string | a short version of the Accept header, e.g. json, yaml | . | size | enum | The multiplier in which to display values | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | h | list | Comma-separated list of column names to display | . | help | boolean | Return help information | . | s | list | Comma-separated list of column names or column aliases to sort by | . | v | boolean | Verbose mode. Display column headers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#catthread_pool",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#catthread_pool"
  },"549": {
    "doc": "REST API Reference",
    "title": "clear_scroll",
    "content": "Explicitly clears the search context for a scroll. DELETE _search/scroll . DELETE _search/scroll/{scroll_id} . HTTP request body . A comma-separated list of scroll IDs to clear if none was specified via the scroll_id parameter . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clear_scroll",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clear_scroll"
  },"550": {
    "doc": "REST API Reference",
    "title": "cluster.allocation_explain",
    "content": "Provides explanations for shard allocations in the cluster. GET _cluster/allocation/explain POST _cluster/allocation/explain . HTTP request body . The index, shard, and primary flag to explain. Empty means ‘explain the first unassigned shard’ . URL parameters . | Parameter | Type | Description | . | include_yes_decisions | boolean | Return ‘YES’ decisions in explanation (default: false) | . | include_disk_info | boolean | Return information about disk usage and shard sizes (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterallocation_explain",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterallocation_explain"
  },"551": {
    "doc": "REST API Reference",
    "title": "cluster.delete_component_template",
    "content": "Deletes a component template . DELETE _component_template/{name} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterdelete_component_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterdelete_component_template"
  },"552": {
    "doc": "REST API Reference",
    "title": "cluster.delete_voting_config_exclusions",
    "content": "Clears cluster voting config exclusions. DELETE _cluster/voting_config_exclusions . URL parameters . | Parameter | Type | Description | . | wait_for_removal | boolean | Specifies whether to wait for all excluded nodes to be removed from the cluster before clearing the voting configuration exclusions list. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterdelete_voting_config_exclusions",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterdelete_voting_config_exclusions"
  },"553": {
    "doc": "REST API Reference",
    "title": "cluster.exists_component_template",
    "content": "Returns information about whether a particular component template exist . HEAD _component_template/{name} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterexists_component_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterexists_component_template"
  },"554": {
    "doc": "REST API Reference",
    "title": "cluster.get_component_template",
    "content": "Returns one or more component templates . GET _component_template . GET _component_template/{name} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterget_component_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterget_component_template"
  },"555": {
    "doc": "REST API Reference",
    "title": "cluster.get_settings",
    "content": "Returns cluster settings. GET _cluster/settings . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . | include_defaults | boolean | Whether to return all default clusters setting. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterget_settings",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterget_settings"
  },"556": {
    "doc": "REST API Reference",
    "title": "cluster.health",
    "content": "Returns basic information about the health of the cluster. GET _cluster/health . GET _cluster/health/{index} . URL parameters . | Parameter | Type | Description | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | level | enum | Specify the level of detail for returned information | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . | wait_for_active_shards | string | Wait until the specified number of shards is active | . | wait_for_nodes | string | Wait until the specified number of nodes is available | . | wait_for_events | enum | Wait until all currently queued events with the given priority are processed | . | wait_for_no_relocating_shards | boolean | Whether to wait until there are no relocating shards in the cluster | . | wait_for_no_initializing_shards | boolean | Whether to wait until there are no initializing shards in the cluster | . | wait_for_status | enum | Wait until cluster is in a specific state | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterhealth",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterhealth"
  },"557": {
    "doc": "REST API Reference",
    "title": "cluster.pending_tasks",
    "content": "Returns a list of any cluster-level changes (e.g. create index, update mapping, allocate or fail shard) which have not yet been executed. GET _cluster/pending_tasks . URL parameters . | Parameter | Type | Description | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterpending_tasks",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterpending_tasks"
  },"558": {
    "doc": "REST API Reference",
    "title": "cluster.post_voting_config_exclusions",
    "content": "Updates the cluster voting config exclusions by node ids or node names. POST _cluster/voting_config_exclusions . URL parameters . | Parameter | Type | Description | . | node_ids | string | A comma-separated list of the persistent ids of the nodes to exclude from the voting configuration. If specified, you may not also specify ?node_names. | . | node_names | string | A comma-separated list of the names of the nodes to exclude from the voting configuration. If specified, you may not also specify ?node_ids. | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterpost_voting_config_exclusions",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterpost_voting_config_exclusions"
  },"559": {
    "doc": "REST API Reference",
    "title": "cluster.put_component_template",
    "content": "Creates or updates a component template . PUT _component_template/{name} POST _component_template/{name} . HTTP request body . The template definition . Required: True . URL parameters . | Parameter | Type | Description | . | create | boolean | Whether the index template should only be added if new or can also replace an existing one | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterput_component_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterput_component_template"
  },"560": {
    "doc": "REST API Reference",
    "title": "cluster.put_settings",
    "content": "Updates the cluster settings. PUT _cluster/settings . HTTP request body . The settings to be updated. Can be either transient or persistent (survives cluster restart). Required: True . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterput_settings",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterput_settings"
  },"561": {
    "doc": "REST API Reference",
    "title": "cluster.remote_info",
    "content": "Returns the information about configured remote clusters. GET _remote/info . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterremote_info",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterremote_info"
  },"562": {
    "doc": "REST API Reference",
    "title": "cluster.reroute",
    "content": "Allows to manually change the allocation of individual shards in the cluster. POST _cluster/reroute . HTTP request body . The definition of commands to perform (move, cancel, allocate) . URL parameters . | Parameter | Type | Description | . | dry_run | boolean | Simulate the operation only and return the resulting state | . | explain | boolean | Return an explanation of why the commands can or cannot be executed | . | retry_failed | boolean | Retries allocation of shards that are blocked due to too many subsequent allocation failures | . | metric | list | Limit the information returned to the specified metrics. Defaults to all but metadata | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterreroute",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterreroute"
  },"563": {
    "doc": "REST API Reference",
    "title": "cluster.state",
    "content": "Returns a comprehensive information about the state of the cluster. GET _cluster/state . GET _cluster/state/{metric} . GET _cluster/state/{metric}/{index} . URL parameters . | Parameter | Type | Description | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | master_timeout | time | Specify timeout for connection to master | . | flat_settings | boolean | Return settings in flat format (default: false) | . | wait_for_metadata_version | number | Wait for the metadata version to be equal or greater than the specified metadata version | . | wait_for_timeout | time | The maximum time to wait for wait_for_metadata_version before timing out | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterstate",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterstate"
  },"564": {
    "doc": "REST API Reference",
    "title": "cluster.stats",
    "content": "Returns high-level overview of cluster statistics. GET _cluster/stats . GET _cluster/stats/nodes/{node_id} . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#clusterstats",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#clusterstats"
  },"565": {
    "doc": "REST API Reference",
    "title": "count",
    "content": "Returns number of documents matching a query. POST _count GET _count . POST {index}/_count GET {index}/_count . POST {index}/{type}/_count GET {index}/{type}/_count . HTTP request body . A query to restrict the results specified with the Query DSL (optional) . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | ignore_throttled | boolean | Whether specified concrete, expanded or aliased indices should be ignored when throttled | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | min_score | number | Include only documents with a specific _score value in the result | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | routing | list | A comma-separated list of specific routing values | . | q | string | Query in the Lucene query string syntax | . | analyzer | string | The analyzer to use for the query string | . | analyze_wildcard | boolean | Specify whether wildcard and prefix queries should be analyzed (default: false) | . | default_operator | enum | The default operator for query string query (AND or OR) | . | df | string | The field to use as default where no field prefix is given in the query string | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored | . | terminate_after | number | The maximum count for each shard, upon reaching which the query execution will terminate early | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#count",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#count"
  },"566": {
    "doc": "REST API Reference",
    "title": "create",
    "content": "Creates a new document in the index. Returns a 409 response when a document with a same ID already exists in the index. PUT {index}/_create/{id} POST {index}/_create/{id} . PUT {index}/{type}/{id}/_create POST {index}/{type}/{id}/_create . HTTP request body . The document . Required: True . URL parameters . | Parameter | Type | Description | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the index operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) | . | refresh | enum | If true then refresh the affected shards to make this operation visible to search, if wait_for then wait for a refresh to make this operation visible to search, if false (the default) then do nothing with refreshes. | . | routing | string | Specific routing value | . | timeout | time | Explicit operation timeout | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . | pipeline | string | The pipeline id to preprocess incoming documents with | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#create",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#create"
  },"567": {
    "doc": "REST API Reference",
    "title": "dangling_indices.delete_dangling_index",
    "content": "Deletes the specified dangling index . DELETE _dangling/{index_uuid} . URL parameters . | Parameter | Type | Description | . | accept_data_loss | boolean | Must be set to true in order to delete the dangling index | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#dangling_indicesdelete_dangling_index",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#dangling_indicesdelete_dangling_index"
  },"568": {
    "doc": "REST API Reference",
    "title": "dangling_indices.import_dangling_index",
    "content": "Imports the specified dangling index . POST _dangling/{index_uuid} . URL parameters . | Parameter | Type | Description | . | accept_data_loss | boolean | Must be set to true in order to import the dangling index | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#dangling_indicesimport_dangling_index",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#dangling_indicesimport_dangling_index"
  },"569": {
    "doc": "REST API Reference",
    "title": "dangling_indices.list_dangling_indices",
    "content": "Returns all dangling indices. GET _dangling . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#dangling_indiceslist_dangling_indices",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#dangling_indiceslist_dangling_indices"
  },"570": {
    "doc": "REST API Reference",
    "title": "delete",
    "content": "Removes a document from the index. DELETE {index}/_doc/{id} . DELETE {index}/{type}/{id} . URL parameters . | Parameter | Type | Description | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the delete operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) | . | refresh | enum | If true then refresh the affected shards to make this operation visible to search, if wait_for then wait for a refresh to make this operation visible to search, if false (the default) then do nothing with refreshes. | . | routing | string | Specific routing value | . | timeout | time | Explicit operation timeout | . | if_seq_no | number | only perform the delete operation if the last operation that has changed the document has the specified sequence number | . | if_primary_term | number | only perform the delete operation if the last operation that has changed the document has the specified primary term | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#delete",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#delete"
  },"571": {
    "doc": "REST API Reference",
    "title": "delete_by_query",
    "content": "Deletes documents matching the provided query. POST {index}/_delete_by_query . POST {index}/{type}/_delete_by_query . HTTP request body . The search definition using the Query DSL . Required: True . URL parameters . | Parameter | Type | Description |   | . | analyzer | string | The analyzer to use for the query string |   | . | analyze_wildcard | boolean | Specify whether wildcard and prefix queries should be analyzed (default: false) |   | . | default_operator | enum | The default operator for query string query (AND or OR) |   | . | df | string | The field to use as default where no field prefix is given in the query string |   | . | from | number | Starting offset (default: 0) |   | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) |   | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) |   | . | conflicts | enum | What to do when the delete by query hits version conflicts? |   | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. |   | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored |   | . | preference | string | Specify the node or shard the operation should be performed on (default: random) |   | . | q | string | Query in the Lucene query string syntax |   | . | routing | list | A comma-separated list of specific routing values |   | . | scroll | time | Specify how long a consistent view of the index should be maintained for scrolled search |   | . | search_type | enum | Search operation type |   | . | search_timeout | time | Explicit timeout for each search request. Defaults to no timeout. |   | . | size | number | Deprecated, please use max_docs instead |   | . | max_docs | number | Maximum number of documents to process (default: all documents) |   | . | sort | list | A comma-separated list of : pairs |   | . | _source | list | True or false to return the _source field or not, or a list of fields to return |   | . | _source_excludes | list | A list of fields to exclude from the returned _source field |   | . | _source_includes | list | A list of fields to extract and return from the _source field |   | . | terminate_after | number | The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. |   | . | stats | list | Specific ‘tag’ of the request for logging and statistical purposes |   | . | version | boolean | Specify whether to return document version as part of a hit |   | . | request_cache | boolean | Specify if request cache should be used for this request or not, defaults to index level setting |   | . | refresh | boolean | Should the effected indexes be refreshed? |   | . | timeout | time | Time each individual bulk request should wait for shards that are unavailable. |   | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the delete by query operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) |   | . | scroll_size | number | Size on the scroll request powering the delete by query |   | . | wait_for_completion | boolean | Should the request should block until the delete by query is complete. |   | . | requests_per_second | number | The throttle for this request in sub-requests per second. -1 means no throttle. |   | . | slices | number | string | The number of slices this task should be divided into. Defaults to 1, meaning the task isn’t sliced into subtasks. Can be set to auto. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#delete_by_query",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#delete_by_query"
  },"572": {
    "doc": "REST API Reference",
    "title": "delete_by_query_rethrottle",
    "content": "Changes the number of requests per second for a particular Delete By Query operation. POST _delete_by_query/{task_id}/_rethrottle . URL parameters . | Parameter | Type | Description | . | requests_per_second | number | The throttle to set on this request in floating sub-requests per second. -1 means set no throttle. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#delete_by_query_rethrottle",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#delete_by_query_rethrottle"
  },"573": {
    "doc": "REST API Reference",
    "title": "delete_script",
    "content": "Deletes a script. DELETE _scripts/{id} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#delete_script",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#delete_script"
  },"574": {
    "doc": "REST API Reference",
    "title": "exists",
    "content": "Returns information about whether a document exists in an index. HEAD {index}/_doc/{id} . HEAD {index}/{type}/{id} . URL parameters . | Parameter | Type | Description | . | stored_fields | list | A comma-separated list of stored fields to return in the response | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | realtime | boolean | Specify whether to perform the operation in realtime or search mode | . | refresh | boolean | Refresh the shard containing the document before performing the operation | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#exists",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#exists"
  },"575": {
    "doc": "REST API Reference",
    "title": "exists_source",
    "content": "Returns information about whether a document source exists in an index. HEAD {index}/_source/{id} . HEAD {index}/{type}/{id}/_source . URL parameters . | Parameter | Type | Description | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | realtime | boolean | Specify whether to perform the operation in realtime or search mode | . | refresh | boolean | Refresh the shard containing the document before performing the operation | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#exists_source",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#exists_source"
  },"576": {
    "doc": "REST API Reference",
    "title": "explain",
    "content": "Returns information about why a specific matches (or doesn’t match) a query. GET {index}/_explain/{id} POST {index}/_explain/{id} . GET {index}/{type}/{id}/_explain POST {index}/{type}/{id}/_explain . HTTP request body . The query definition using the Query DSL . URL parameters . | Parameter | Type | Description | . | analyze_wildcard | boolean | Specify whether wildcards and prefix queries in the query string query should be analyzed (default: false) | . | analyzer | string | The analyzer for the query string query | . | default_operator | enum | The default operator for query string query (AND or OR) | . | df | string | The default field for query string query (default: _all) | . | stored_fields | list | A comma-separated list of stored fields to return in the response | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | q | string | Query in the Lucene query string syntax | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#explain",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#explain"
  },"577": {
    "doc": "REST API Reference",
    "title": "field_caps",
    "content": "Returns the information about the capabilities of fields among multiple indices. GET _field_caps POST _field_caps . GET {index}/_field_caps POST {index}/_field_caps . HTTP request body . An index filter specified with the Query DSL . URL parameters . | Parameter | Type | Description | . | fields | list | A comma-separated list of field names | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | include_unmapped | boolean | Indicates whether unmapped fields should be included in the response. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#field_caps",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#field_caps"
  },"578": {
    "doc": "REST API Reference",
    "title": "get",
    "content": "Returns a document. GET {index}/_doc/{id} . GET {index}/{type}/{id} . URL parameters . | Parameter | Type | Description | . | stored_fields | list | A comma-separated list of stored fields to return in the response | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | realtime | boolean | Specify whether to perform the operation in realtime or search mode | . | refresh | boolean | Refresh the shard containing the document before performing the operation | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#get",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#get"
  },"579": {
    "doc": "REST API Reference",
    "title": "get_script",
    "content": "Returns a script. GET _scripts/{id} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#get_script",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#get_script"
  },"580": {
    "doc": "REST API Reference",
    "title": "get_script_context",
    "content": "Returns all script contexts. GET _script_context . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#get_script_context",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#get_script_context"
  },"581": {
    "doc": "REST API Reference",
    "title": "get_script_languages",
    "content": "Returns available script types, languages and contexts . GET _script_language . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#get_script_languages",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#get_script_languages"
  },"582": {
    "doc": "REST API Reference",
    "title": "get_source",
    "content": "Returns the source of a document. GET {index}/_source/{id} . GET {index}/{type}/{id}/_source . URL parameters . | Parameter | Type | Description | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | realtime | boolean | Specify whether to perform the operation in realtime or search mode | . | refresh | boolean | Refresh the shard containing the document before performing the operation | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#get_source",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#get_source"
  },"583": {
    "doc": "REST API Reference",
    "title": "index",
    "content": "Creates or updates a document in an index. PUT {index}/_doc/{id} POST {index}/_doc/{id} . POST {index}/_doc . POST {index}/{type} . PUT {index}/{type}/{id} POST {index}/{type}/{id} . HTTP request body . The document . Required: True . URL parameters . | Parameter | Type | Description | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the index operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) | . | op_type | enum | Explicit operation type. Defaults to index for requests with an explicit document ID, and to createfor requests without an explicit document ID | . | refresh | enum | If true then refresh the affected shards to make this operation visible to search, if wait_for then wait for a refresh to make this operation visible to search, if false (the default) then do nothing with refreshes. | . | routing | string | Specific routing value | . | timeout | time | Explicit operation timeout | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . | if_seq_no | number | only perform the index operation if the last operation that has changed the document has the specified sequence number | . | if_primary_term | number | only perform the index operation if the last operation that has changed the document has the specified primary term | . | pipeline | string | The pipeline id to preprocess incoming documents with | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#index",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#index"
  },"584": {
    "doc": "REST API Reference",
    "title": "indices.add_block",
    "content": "Adds a block to an index. PUT {index}/_block/{block} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesadd_block",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesadd_block"
  },"585": {
    "doc": "REST API Reference",
    "title": "indices.analyze",
    "content": "Performs the analysis process on a text and return the tokens breakdown of the text. GET _analyze POST _analyze . GET {index}/_analyze POST {index}/_analyze . HTTP request body . Define analyzer/tokenizer parameters and the text on which the analysis should be performed . URL parameters . | Parameter | Type | Description | . | index | string | The name of the index to scope the operation | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesanalyze",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesanalyze"
  },"586": {
    "doc": "REST API Reference",
    "title": "indices.clear_cache",
    "content": "Clears all or specific caches for one or more indices. POST _cache/clear . POST {index}/_cache/clear . URL parameters . | Parameter | Type | Description | . | fielddata | boolean | Clear field data | . | fields | list | A comma-separated list of fields to clear when using the fielddata parameter (default: all) | . | query | boolean | Clear query caches | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | index | list | A comma-separated list of index name to limit the operation | . | request | boolean | Clear request cache | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesclear_cache",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesclear_cache"
  },"587": {
    "doc": "REST API Reference",
    "title": "indices.clone",
    "content": "Clones an index . PUT {index}/_clone/{target} POST {index}/_clone/{target} . HTTP request body . The configuration for the target index (settings and aliases) . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | wait_for_active_shards | string | Set the number of active shards to wait for on the cloned index before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesclone",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesclone"
  },"588": {
    "doc": "REST API Reference",
    "title": "indices.close",
    "content": "Closes an index. POST {index}/_close . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | wait_for_active_shards | string | Sets the number of active shards to wait for before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesclose",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesclose"
  },"589": {
    "doc": "REST API Reference",
    "title": "indices.create",
    "content": "Creates an index with optional settings and mappings. PUT {index} . HTTP request body . The configuration for the index (settings and mappings) . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be expected in the body of the mappings. | . | wait_for_active_shards | string | Set the number of active shards to wait for before the operation returns. | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicescreate",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicescreate"
  },"590": {
    "doc": "REST API Reference",
    "title": "indices.delete",
    "content": "Deletes an index. DELETE {index} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Ignore unavailable indexes (default: false) | . | allow_no_indices | boolean | Ignore if a wildcard expression resolves to no concrete indices (default: false) | . | expand_wildcards | enum | Whether wildcard expressions should get expanded to open or closed indices (default: open) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesdelete",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesdelete"
  },"591": {
    "doc": "REST API Reference",
    "title": "indices.delete_alias",
    "content": "Deletes an alias. DELETE {index}/_alias/{name} . DELETE {index}/_aliases/{name} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit timestamp for the document | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesdelete_alias",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesdelete_alias"
  },"592": {
    "doc": "REST API Reference",
    "title": "indices.delete_index_template",
    "content": "Deletes an index template. DELETE _index_template/{name} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesdelete_index_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesdelete_index_template"
  },"593": {
    "doc": "REST API Reference",
    "title": "indices.delete_template",
    "content": "Deletes an index template. DELETE _template/{name} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesdelete_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesdelete_template"
  },"594": {
    "doc": "REST API Reference",
    "title": "indices.exists",
    "content": "Returns information about whether a particular index exists. HEAD {index} . URL parameters . | Parameter | Type | Description | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | ignore_unavailable | boolean | Ignore unavailable indexes (default: false) | . | allow_no_indices | boolean | Ignore if a wildcard expression resolves to no concrete indices (default: false) | . | expand_wildcards | enum | Whether wildcard expressions should get expanded to open or closed indices (default: open) | . | flat_settings | boolean | Return settings in flat format (default: false) | . | include_defaults | boolean | Whether to return all default setting for each of the indices. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesexists",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesexists"
  },"595": {
    "doc": "REST API Reference",
    "title": "indices.exists_alias",
    "content": "Returns information about whether a particular alias exists. HEAD _alias/{name} . HEAD {index}/_alias/{name} . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesexists_alias",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesexists_alias"
  },"596": {
    "doc": "REST API Reference",
    "title": "indices.exists_index_template",
    "content": "Returns information about whether a particular index template exists. HEAD _index_template/{name} . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesexists_index_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesexists_index_template"
  },"597": {
    "doc": "REST API Reference",
    "title": "indices.exists_template",
    "content": "Returns information about whether a particular index template exists. HEAD _template/{name} . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesexists_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesexists_template"
  },"598": {
    "doc": "REST API Reference",
    "title": "indices.exists_type",
    "content": "Returns information about whether a particular document type exists. (DEPRECATED) . HEAD {index}/_mapping/{type} . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesexists_type",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesexists_type"
  },"599": {
    "doc": "REST API Reference",
    "title": "indices.flush",
    "content": "Performs the flush operation on one or more indices. POST _flush GET _flush . POST {index}/_flush GET {index}/_flush . URL parameters . | Parameter | Type | Description | . | force | boolean | Whether a flush should be forced even if it is not necessarily needed ie. if no changes will be committed to the index. This is useful if transaction log IDs should be incremented even if no uncommitted changes are present. (This setting can be considered as internal) | . | wait_if_ongoing | boolean | If set to true the flush operation will block until the flush can be executed if another flush operation is already executing. The default is true. If set to false the flush will be skipped iff if another flush operation is already running. | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesflush",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesflush"
  },"600": {
    "doc": "REST API Reference",
    "title": "indices.flush_synced",
    "content": "Performs a synced flush operation on one or more indices. Synced flush is deprecated and will be removed in 8.0. Use flush instead . POST _flush/synced GET _flush/synced . POST {index}/_flush/synced GET {index}/_flush/synced . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesflush_synced",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesflush_synced"
  },"601": {
    "doc": "REST API Reference",
    "title": "indices.forcemerge",
    "content": "Performs the force merge operation on one or more indices. POST _forcemerge . POST {index}/_forcemerge . URL parameters . | Parameter | Type | Description | . | flush | boolean | Specify whether the index should be flushed after performing the operation (default: true) | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | max_num_segments | number | The number of segments the index should be merged into (default: dynamic) | . | only_expunge_deletes | boolean | Specify whether the operation should only expunge deleted documents | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesforcemerge",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesforcemerge"
  },"602": {
    "doc": "REST API Reference",
    "title": "indices.get",
    "content": "Returns information about one or more indices. GET {index} . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether to add the type name to the response (default: false) | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | ignore_unavailable | boolean | Ignore unavailable indexes (default: false) | . | allow_no_indices | boolean | Ignore if a wildcard expression resolves to no concrete indices (default: false) | . | expand_wildcards | enum | Whether wildcard expressions should get expanded to open or closed indices (default: open) | . | flat_settings | boolean | Return settings in flat format (default: false) | . | include_defaults | boolean | Whether to return all default setting for each of the indices. | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget"
  },"603": {
    "doc": "REST API Reference",
    "title": "indices.get_alias",
    "content": "Returns an alias. GET _alias . GET _alias/{name} . GET {index}/_alias/{name} . GET {index}/_alias . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_alias",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_alias"
  },"604": {
    "doc": "REST API Reference",
    "title": "indices.get_field_mapping",
    "content": "Returns mapping for one or more fields. GET _mapping/field/{fields} . GET {index}/_mapping/field/{fields} . GET _mapping/{type}/field/{fields} . GET {index}/_mapping/{type}/field/{fields} . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be returned in the body of the mappings. | . | include_defaults | boolean | Whether the default mapping values should be returned as well | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_field_mapping",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_field_mapping"
  },"605": {
    "doc": "REST API Reference",
    "title": "indices.get_index_template",
    "content": "Returns an index template. GET _index_template . GET _index_template/{name} . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_index_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_index_template"
  },"606": {
    "doc": "REST API Reference",
    "title": "indices.get_mapping",
    "content": "Returns mappings for one or more indices. GET _mapping . GET {index}/_mapping . GET _mapping/{type} . GET {index}/_mapping/{type} . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether to add the type name to the response (default: false) | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | master_timeout | time | Specify timeout for connection to master | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_mapping",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_mapping"
  },"607": {
    "doc": "REST API Reference",
    "title": "indices.get_settings",
    "content": "Returns settings for one or more indices. GET _settings . GET {index}/_settings . GET {index}/_settings/{name} . GET _settings/{name} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | flat_settings | boolean | Return settings in flat format (default: false) | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | include_defaults | boolean | Whether to return all default setting for each of the indices. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_settings",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_settings"
  },"608": {
    "doc": "REST API Reference",
    "title": "indices.get_template",
    "content": "Returns an index template. GET _template . GET _template/{name} . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be returned in the body of the mappings. | . | flat_settings | boolean | Return settings in flat format (default: false) | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_template"
  },"609": {
    "doc": "REST API Reference",
    "title": "indices.get_upgrade",
    "content": "The _upgrade API is no longer useful and will be removed. GET _upgrade . GET {index}/_upgrade . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesget_upgrade",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesget_upgrade"
  },"610": {
    "doc": "REST API Reference",
    "title": "indices.open",
    "content": "Opens an index. POST {index}/_open . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | wait_for_active_shards | string | Sets the number of active shards to wait for before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesopen",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesopen"
  },"611": {
    "doc": "REST API Reference",
    "title": "indices.put_alias",
    "content": "Creates or updates an alias. PUT {index}/_alias/{name} POST {index}/_alias/{name} . PUT {index}/_aliases/{name} POST {index}/_aliases/{name} . HTTP request body . The settings for the alias, such as routing or filter . Required: False . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit timestamp for the document | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesput_alias",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesput_alias"
  },"612": {
    "doc": "REST API Reference",
    "title": "indices.put_index_template",
    "content": "Creates or updates an index template. PUT _index_template/{name} POST _index_template/{name} . HTTP request body . The template definition . Required: True . URL parameters . | Parameter | Type | Description | . | create | boolean | Whether the index template should only be added if new or can also replace an existing one | . | cause | string | User defined reason for creating/updating the index template | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesput_index_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesput_index_template"
  },"613": {
    "doc": "REST API Reference",
    "title": "indices.put_mapping",
    "content": "Updates the index mappings. PUT {index}/_mapping POST {index}/_mapping . PUT {index}/{type}/_mapping POST {index}/{type}/_mapping . PUT {index}/_mapping/{type} POST {index}/_mapping/{type} . PUT {index}/{type}/_mappings POST {index}/{type}/_mappings . PUT {index}/_mappings/{type} POST {index}/_mappings/{type} . PUT _mappings/{type} POST _mappings/{type} . PUT {index}/_mappings POST {index}/_mappings . PUT _mapping/{type} POST _mapping/{type} . HTTP request body . The mapping definition . Required: True . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be expected in the body of the mappings. | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | write_index_only | boolean | When true, applies mappings only to the write index of an alias or data stream | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesput_mapping",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesput_mapping"
  },"614": {
    "doc": "REST API Reference",
    "title": "indices.put_settings",
    "content": "Updates the index settings. PUT _settings . PUT {index}/_settings . HTTP request body . The index settings to be updated . Required: True . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Specify timeout for connection to master | . | timeout | time | Explicit operation timeout | . | preserve_existing | boolean | Whether to update existing settings. If set to true existing settings on an index remain unchanged, the default is false | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | flat_settings | boolean | Return settings in flat format (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesput_settings",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesput_settings"
  },"615": {
    "doc": "REST API Reference",
    "title": "indices.put_template",
    "content": "Creates or updates an index template. PUT _template/{name} POST _template/{name} . HTTP request body . The template definition . Required: True . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be returned in the body of the mappings. | . | order | number | The order for this template when merging multiple matching ones (higher numbers are merged later, overriding the lower numbers) | . | create | boolean | Whether the index template should only be added if new or can also replace an existing one | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesput_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesput_template"
  },"616": {
    "doc": "REST API Reference",
    "title": "indices.recovery",
    "content": "Returns information about ongoing index shard recoveries. GET _recovery . GET {index}/_recovery . URL parameters . | Parameter | Type | Description | . | detailed | boolean | Whether to display detailed information about shard recovery | . | active_only | boolean | Display only those recoveries that are currently on-going | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesrecovery",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesrecovery"
  },"617": {
    "doc": "REST API Reference",
    "title": "indices.refresh",
    "content": "Performs the refresh operation in one or more indices. POST _refresh GET _refresh . POST {index}/_refresh GET {index}/_refresh . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesrefresh",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesrefresh"
  },"618": {
    "doc": "REST API Reference",
    "title": "indices.resolve_index",
    "content": "Returns information about any matching indices, aliases, and data streams . GET _resolve/index/{name} . URL parameters . | Parameter | Type | Description | . | expand_wildcards | enum | Whether wildcard expressions should get expanded to open or closed indices (default: open) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesresolve_index",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesresolve_index"
  },"619": {
    "doc": "REST API Reference",
    "title": "indices.rollover",
    "content": "Updates an alias to point to a new index when the existing index is considered to be too large or too old. POST {alias}/_rollover . POST {alias}/_rollover/{new_index} . HTTP request body . The conditions that needs to be met for executing rollover . URL parameters . | Parameter | Type | Description | . | include_type_name | boolean | Whether a type should be included in the body of the mappings. | . | timeout | time | Explicit operation timeout | . | dry_run | boolean | If set to true the rollover action will only be validated but not actually performed even if a condition matches. The default is false | . | master_timeout | time | Specify timeout for connection to master | . | wait_for_active_shards | string | Set the number of active shards to wait for on the newly created rollover index before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesrollover",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesrollover"
  },"620": {
    "doc": "REST API Reference",
    "title": "indices.segments",
    "content": "Provides low-level information about segments in a Lucene index. GET _segments . GET {index}/_segments . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | verbose | boolean | Includes detailed memory usage by Lucene. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicessegments",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicessegments"
  },"621": {
    "doc": "REST API Reference",
    "title": "indices.shard_stores",
    "content": "Provides store information for shard copies of indices. GET _shard_stores . GET {index}/_shard_stores . URL parameters . | Parameter | Type | Description | . | status | list | A comma-separated list of statuses used to filter on shards to get store information for | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesshard_stores",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesshard_stores"
  },"622": {
    "doc": "REST API Reference",
    "title": "indices.shrink",
    "content": "Allow to shrink an existing index into a new index with fewer primary shards. PUT {index}/_shrink/{target} POST {index}/_shrink/{target} . HTTP request body . The configuration for the target index (settings and aliases) . URL parameters . | Parameter | Type | Description | . | copy_settings | boolean | whether or not to copy settings from the source index (defaults to false) | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | wait_for_active_shards | string | Set the number of active shards to wait for on the shrunken index before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesshrink",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesshrink"
  },"623": {
    "doc": "REST API Reference",
    "title": "indices.simulate_index_template",
    "content": "Simulate matching the given index name against the index templates in the system . POST _index_template/_simulate_index/{name} . HTTP request body . New index template definition, which will be included in the simulation, as if it already exists in the system . Required: False . URL parameters . | Parameter | Type | Description | . | create | boolean | Whether the index template we optionally defined in the body should only be dry-run added if new or can also replace an existing one | . | cause | string | User defined reason for dry-run creating the new template for simulation purposes | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicessimulate_index_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicessimulate_index_template"
  },"624": {
    "doc": "REST API Reference",
    "title": "indices.simulate_template",
    "content": "Simulate resolving the given template name or body . POST _index_template/_simulate . POST _index_template/_simulate/{name} . HTTP request body . New index template definition to be simulated, if no index template name is specified . Required: False . URL parameters . | Parameter | Type | Description | . | create | boolean | Whether the index template we optionally defined in the body should only be dry-run added if new or can also replace an existing one | . | cause | string | User defined reason for dry-run creating the new template for simulation purposes | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicessimulate_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicessimulate_template"
  },"625": {
    "doc": "REST API Reference",
    "title": "indices.split",
    "content": "Allows you to split an existing index into a new index with more primary shards. PUT {index}/_split/{target} POST {index}/_split/{target} . HTTP request body . The configuration for the target index (settings and aliases) . URL parameters . | Parameter | Type | Description | . | copy_settings | boolean | whether or not to copy settings from the source index (defaults to false) | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | wait_for_active_shards | string | Set the number of active shards to wait for on the shrunken index before the operation returns. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicessplit",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicessplit"
  },"626": {
    "doc": "REST API Reference",
    "title": "indices.stats",
    "content": "Provides statistics on operations happening in an index. GET _stats . GET _stats/{metric} . GET {index}/_stats . GET {index}/_stats/{metric} . URL parameters . | Parameter | Type | Description | . | completion_fields | list | A comma-separated list of fields for fielddata and suggest index metric (supports wildcards) | . | fielddata_fields | list | A comma-separated list of fields for fielddata index metric (supports wildcards) | . | fields | list | A comma-separated list of fields for fielddata and completion index metric (supports wildcards) | . | groups | list | A comma-separated list of search groups for search index metric | . | level | enum | Return stats aggregated at cluster, index or shard level | . | types | list | A comma-separated list of document types for the indexing index metric | . | include_segment_file_sizes | boolean | Whether to report the aggregated disk usage of each one of the Lucene index files (only applies if segment stats are requested) | . | include_unloaded_segments | boolean | If set to true segment stats will include stats for segments that are not currently loaded into memory | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | forbid_closed_indices | boolean | If set to false stats will also collected from closed indices if explicitly specified or if expand_wildcards expands to closed indices | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesstats",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesstats"
  },"627": {
    "doc": "REST API Reference",
    "title": "indices.update_aliases",
    "content": "Updates index aliases. POST _aliases . HTTP request body . The definition of actions to perform . Required: True . URL parameters . | Parameter | Type | Description | . | timeout | time | Request timeout | . | master_timeout | time | Specify timeout for connection to master | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesupdate_aliases",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesupdate_aliases"
  },"628": {
    "doc": "REST API Reference",
    "title": "indices.upgrade",
    "content": "The _upgrade API is no longer useful and will be removed. POST _upgrade . POST {index}/_upgrade . URL parameters . | Parameter | Type | Description | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | wait_for_completion | boolean | Specify whether the request should block until the all segments are upgraded (default: false) | . | only_ancient_segments | boolean | If true, only ancient (an older Lucene major release) segments will be upgraded | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesupgrade",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesupgrade"
  },"629": {
    "doc": "REST API Reference",
    "title": "indices.validate_query",
    "content": "Allows a user to validate a potentially expensive query without executing it. GET _validate/query POST _validate/query . GET {index}/_validate/query POST {index}/_validate/query . GET {index}/{type}/_validate/query POST {index}/{type}/_validate/query . HTTP request body . The query definition specified with the Query DSL . URL parameters . | Parameter | Type | Description | . | explain | boolean | Return detailed information about the error | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | q | string | Query in the Lucene query string syntax | . | analyzer | string | The analyzer to use for the query string | . | analyze_wildcard | boolean | Specify whether wildcard and prefix queries should be analyzed (default: false) | . | default_operator | enum | The default operator for query string query (AND or OR) | . | df | string | The field to use as default where no field prefix is given in the query string | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored | . | rewrite | boolean | Provide a more detailed explanation showing the actual Lucene query that will be executed. | . | all_shards | boolean | Execute validation on all shards instead of one random shard per index | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#indicesvalidate_query",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#indicesvalidate_query"
  },"630": {
    "doc": "REST API Reference",
    "title": "info",
    "content": "Returns basic information about the cluster. GET . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#info",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#info"
  },"631": {
    "doc": "REST API Reference",
    "title": "ingest.delete_pipeline",
    "content": "Deletes a pipeline. DELETE _ingest/pipeline/{id} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ingestdelete_pipeline",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ingestdelete_pipeline"
  },"632": {
    "doc": "REST API Reference",
    "title": "ingest.get_pipeline",
    "content": "Returns a pipeline. GET _ingest/pipeline . GET _ingest/pipeline/{id} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ingestget_pipeline",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ingestget_pipeline"
  },"633": {
    "doc": "REST API Reference",
    "title": "ingest.processor_grok",
    "content": "Returns a list of the built-in patterns. GET _ingest/processor/grok . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ingestprocessor_grok",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ingestprocessor_grok"
  },"634": {
    "doc": "REST API Reference",
    "title": "ingest.put_pipeline",
    "content": "Creates or updates a pipeline. PUT _ingest/pipeline/{id} . HTTP request body . The ingest definition . Required: True . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ingestput_pipeline",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ingestput_pipeline"
  },"635": {
    "doc": "REST API Reference",
    "title": "ingest.simulate",
    "content": "Allows to simulate a pipeline with example documents. GET _ingest/pipeline/_simulate POST _ingest/pipeline/_simulate . GET _ingest/pipeline/{id}/_simulate POST _ingest/pipeline/{id}/_simulate . HTTP request body . The simulate definition . Required: True . URL parameters . | Parameter | Type | Description | . | verbose | boolean | Verbose mode. Display data output for each processor in executed pipeline | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ingestsimulate",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ingestsimulate"
  },"636": {
    "doc": "REST API Reference",
    "title": "mget",
    "content": "Allows to get multiple documents in one request. GET _mget POST _mget . GET {index}/_mget POST {index}/_mget . GET {index}/{type}/_mget POST {index}/{type}/_mget . HTTP request body . Document identifiers; can be either docs (containing full document information) or ids (when index and type is provided in the URL. Required: True . URL parameters . | Parameter | Type | Description | . | stored_fields | list | A comma-separated list of stored fields to return in the response | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | realtime | boolean | Specify whether to perform the operation in realtime or search mode | . | refresh | boolean | Refresh the shard containing the document before performing the operation | . | routing | string | Specific routing value | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#mget",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#mget"
  },"637": {
    "doc": "REST API Reference",
    "title": "msearch",
    "content": "Allows to execute several search operations in one request. GET _msearch POST _msearch . GET {index}/_msearch POST {index}/_msearch . GET {index}/{type}/_msearch POST {index}/{type}/_msearch . HTTP request body . The request definitions (metadata-search request definition pairs), separated by newlines . Required: True . URL parameters . | Parameter | Type | Description | . | search_type | enum | Search operation type | . | max_concurrent_searches | number | Controls the maximum number of concurrent searches the multi search api will execute | . | typed_keys | boolean | Specify whether aggregation and suggester names should be prefixed by their respective types in the response | . | pre_filter_shard_size | number | A threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method ie. if date filters are mandatory to match but the shard bounds and the query are disjoint. | . | max_concurrent_shard_requests | number | The number of concurrent shard requests each sub search executes concurrently per node. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests | . | rest_total_hits_as_int | boolean | Indicates whether hits.total should be rendered as an integer or an object in the rest search response | . | ccs_minimize_roundtrips | boolean | Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#msearch",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#msearch"
  },"638": {
    "doc": "REST API Reference",
    "title": "msearch_template",
    "content": "Allows to execute several search template operations in one request. GET _msearch/template POST _msearch/template . GET {index}/_msearch/template POST {index}/_msearch/template . GET {index}/{type}/_msearch/template POST {index}/{type}/_msearch/template . HTTP request body . The request definitions (metadata-search request definition pairs), separated by newlines . Required: True . URL parameters . | Parameter | Type | Description | . | search_type | enum | Search operation type | . | typed_keys | boolean | Specify whether aggregation and suggester names should be prefixed by their respective types in the response | . | max_concurrent_searches | number | Controls the maximum number of concurrent searches the multi search api will execute | . | rest_total_hits_as_int | boolean | Indicates whether hits.total should be rendered as an integer or an object in the rest search response | . | ccs_minimize_roundtrips | boolean | Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#msearch_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#msearch_template"
  },"639": {
    "doc": "REST API Reference",
    "title": "mtermvectors",
    "content": "Returns multiple termvectors in one request. GET _mtermvectors POST _mtermvectors . GET {index}/_mtermvectors POST {index}/_mtermvectors . GET {index}/{type}/_mtermvectors POST {index}/{type}/_mtermvectors . HTTP request body . Define ids, documents, parameters or a list of parameters per document here. You must at least provide a list of document ids. See documentation. Required: False . URL parameters . | Parameter | Type | Description | . | ids | list | A comma-separated list of documents ids. You must define ids as parameter or set “ids” or “docs” in the request body | . | term_statistics | boolean | Specifies if total term frequency and document frequency should be returned. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | field_statistics | boolean | Specifies if document count, sum of document frequencies and sum of total term frequencies should be returned. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | fields | list | A comma-separated list of fields to return. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | offsets | boolean | Specifies if term offsets should be returned. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | positions | boolean | Specifies if term positions should be returned. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | payloads | boolean | Specifies if term payloads should be returned. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | preference | string | Specify the node or shard the operation should be performed on (default: random) .Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | routing | string | Specific routing value. Applies to all returned documents unless otherwise specified in body “params” or “docs”. | . | realtime | boolean | Specifies if requests are real-time as opposed to near-real-time (default: true). | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#mtermvectors",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#mtermvectors"
  },"640": {
    "doc": "REST API Reference",
    "title": "nodes.hot_threads",
    "content": "Returns information about hot threads on each node in the cluster. GET _nodes/hot_threads . GET _nodes/{node_id}/hot_threads . GET _cluster/nodes/hotthreads . GET _cluster/nodes/{node_id}/hotthreads . GET _nodes/hotthreads . GET _nodes/{node_id}/hotthreads . GET _cluster/nodes/hot_threads . GET _cluster/nodes/{node_id}/hot_threads . URL parameters . | Parameter | Type | Description | . | interval | time | The interval for the second sampling of threads | . | snapshots | number | Number of samples of thread stacktrace (default: 10) | . | threads | number | Specify the number of threads to provide information for (default: 3) | . | ignore_idle_threads | boolean | Don’t show threads that are in known-idle places, such as waiting on a socket select or pulling from an empty task queue (default: true) | . | type | enum | The type to sample (default: cpu) | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#nodeshot_threads",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#nodeshot_threads"
  },"641": {
    "doc": "REST API Reference",
    "title": "nodes.info",
    "content": "Returns information about nodes in the cluster. GET _nodes . GET _nodes/{node_id} . GET _nodes/{metric} . GET _nodes/{node_id}/{metric} . URL parameters . | Parameter | Type | Description | . | flat_settings | boolean | Return settings in flat format (default: false) | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#nodesinfo",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#nodesinfo"
  },"642": {
    "doc": "REST API Reference",
    "title": "nodes.reload_secure_settings",
    "content": "Reloads secure settings. POST _nodes/reload_secure_settings . POST _nodes/{node_id}/reload_secure_settings . HTTP request body . An object containing the password for the elasticsearch keystore . Required: False . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#nodesreload_secure_settings",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#nodesreload_secure_settings"
  },"643": {
    "doc": "REST API Reference",
    "title": "nodes.stats",
    "content": "Returns statistical information about nodes in the cluster. GET _nodes/stats . GET _nodes/{node_id}/stats . GET _nodes/stats/{metric} . GET _nodes/{node_id}/stats/{metric} . GET _nodes/stats/{metric}/{index_metric} . GET _nodes/{node_id}/stats/{metric}/{index_metric} . URL parameters . | Parameter | Type | Description | . | completion_fields | list | A comma-separated list of fields for fielddata and suggest index metric (supports wildcards) | . | fielddata_fields | list | A comma-separated list of fields for fielddata index metric (supports wildcards) | . | fields | list | A comma-separated list of fields for fielddata and completion index metric (supports wildcards) | . | groups | boolean | A comma-separated list of search groups for search index metric | . | level | enum | Return indices stats aggregated at index, node or shard level | . | types | list | A comma-separated list of document types for the indexing index metric | . | timeout | time | Explicit operation timeout | . | include_segment_file_sizes | boolean | Whether to report the aggregated disk usage of each one of the Lucene index files (only applies if segment stats are requested) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#nodesstats",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#nodesstats"
  },"644": {
    "doc": "REST API Reference",
    "title": "nodes.usage",
    "content": "Returns low-level information about REST actions usage on nodes. GET _nodes/usage . GET _nodes/{node_id}/usage . GET _nodes/usage/{metric} . GET _nodes/{node_id}/usage/{metric} . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#nodesusage",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#nodesusage"
  },"645": {
    "doc": "REST API Reference",
    "title": "ping",
    "content": "Returns whether the cluster is running. HEAD . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#ping",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#ping"
  },"646": {
    "doc": "REST API Reference",
    "title": "put_script",
    "content": "Creates or updates a script. PUT _scripts/{id} POST _scripts/{id} . PUT _scripts/{id}/{context} POST _scripts/{id}/{context} . HTTP request body . The document . Required: True . URL parameters . | Parameter | Type | Description | . | timeout | time | Explicit operation timeout | . | master_timeout | time | Specify timeout for connection to master | . | context | string | Context name to compile script against | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#put_script",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#put_script"
  },"647": {
    "doc": "REST API Reference",
    "title": "rank_eval",
    "content": "Allows to evaluate the quality of ranked search results over a set of typical search queries . GET _rank_eval POST _rank_eval . GET {index}/_rank_eval POST {index}/_rank_eval . HTTP request body . The ranking evaluation search definition, including search requests, document ratings and ranking metric definition. Required: True . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | search_type | enum | Search operation type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#rank_eval",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#rank_eval"
  },"648": {
    "doc": "REST API Reference",
    "title": "reindex",
    "content": "Allows to copy documents from one index to another, optionally filtering the source documents by a query, changing the destination index settings, or fetching the documents from a remote cluster. POST _reindex . HTTP request body . The search definition using the Query DSL and the prototype for the index request. Required: True . URL parameters . | Parameter | Type | Description |   | . | refresh | boolean | Should the affected indexes be refreshed? |   | . | timeout | time | Time each individual bulk request should wait for shards that are unavailable. |   | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the reindex operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) |   | . | wait_for_completion | boolean | Should the request should block until the reindex is complete. |   | . | requests_per_second | number | The throttle to set on this request in sub-requests per second. -1 means no throttle. |   | . | scroll | time | Control how long to keep the search context alive |   | . | slices | number | string | The number of slices this task should be divided into. Defaults to 1, meaning the task isn’t sliced into subtasks. Can be set to auto. | . | max_docs | number | Maximum number of documents to process (default: all documents) |   | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#reindex",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#reindex"
  },"649": {
    "doc": "REST API Reference",
    "title": "reindex_rethrottle",
    "content": "Changes the number of requests per second for a particular Reindex operation. POST _reindex/{task_id}/_rethrottle . URL parameters . | Parameter | Type | Description | . | requests_per_second | number | The throttle to set on this request in floating sub-requests per second. -1 means set no throttle. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#reindex_rethrottle",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#reindex_rethrottle"
  },"650": {
    "doc": "REST API Reference",
    "title": "render_search_template",
    "content": "Allows to use the Mustache language to pre-render a search definition. GET _render/template POST _render/template . GET _render/template/{id} POST _render/template/{id} . HTTP request body . The search definition template and its params . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#render_search_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#render_search_template"
  },"651": {
    "doc": "REST API Reference",
    "title": "scripts_painless_execute",
    "content": "Allows an arbitrary script to be executed and a result to be returned . GET _scripts/painless/_execute POST _scripts/painless/_execute . HTTP request body . The script to execute . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#scripts_painless_execute",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#scripts_painless_execute"
  },"652": {
    "doc": "REST API Reference",
    "title": "scroll",
    "content": "Allows to retrieve a large numbers of results from a single search request. GET _search/scroll POST _search/scroll . GET _search/scroll/{scroll_id} POST _search/scroll/{scroll_id} . HTTP request body . The scroll ID if not passed by URL or query parameter. URL parameters . | Parameter | Type | Description | . | scroll | time | Specify how long a consistent view of the index should be maintained for scrolled search | . | scroll_id | string | The scroll ID for scrolled search | . | rest_total_hits_as_int | boolean | Indicates whether hits.total should be rendered as an integer or an object in the rest search response | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#scroll",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#scroll"
  },"653": {
    "doc": "REST API Reference",
    "title": "search",
    "content": "Returns results matching a query. GET _search POST _search . GET {index}/_search POST {index}/_search . GET {index}/{type}/_search POST {index}/{type}/_search . HTTP request body . The search definition using the Query DSL . URL parameters . | Parameter | Type | Description | . | analyzer | string | The analyzer to use for the query string | . | analyze_wildcard | boolean | Specify whether wildcard and prefix queries should be analyzed (default: false) | . | ccs_minimize_roundtrips | boolean | Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution | . | default_operator | enum | The default operator for query string query (AND or OR) | . | df | string | The field to use as default where no field prefix is given in the query string | . | explain | boolean | Specify whether to return detailed information about score computation as part of a hit | . | stored_fields | list | A comma-separated list of stored fields to return as part of a hit | . | docvalue_fields | list | A comma-separated list of fields to return as the docvalue representation of a field for each hit | . | from | number | Starting offset (default: 0) | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | ignore_throttled | boolean | Whether specified concrete, expanded or aliased indices should be ignored when throttled | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | q | string | Query in the Lucene query string syntax | . | routing | list | A comma-separated list of specific routing values | . | scroll | time | Specify how long a consistent view of the index should be maintained for scrolled search | . | search_type | enum | Search operation type | . | size | number | Number of hits to return (default: 10) | . | sort | list | A comma-separated list of : pairs | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | terminate_after | number | The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. | . | stats | list | Specific ‘tag’ of the request for logging and statistical purposes | . | suggest_field | string | Specify which field to use for suggestions | . | suggest_mode | enum | Specify suggest mode | . | suggest_size | number | How many suggestions to return in response | . | suggest_text | string | The source text for which the suggestions should be returned | . | timeout | time | Explicit operation timeout | . | track_scores | boolean | Whether to calculate and return scores even if they are not used for sorting | . | track_total_hits | boolean | Indicate if the number of documents that match the query should be tracked | . | allow_partial_search_results | boolean | Indicate if an error should be returned if there is a partial search failure or timeout | . | typed_keys | boolean | Specify whether aggregation and suggester names should be prefixed by their respective types in the response | . | version | boolean | Specify whether to return document version as part of a hit | . | seq_no_primary_term | boolean | Specify whether to return sequence number and primary term of the last modification of each hit | . | request_cache | boolean | Specify if request cache should be used for this request or not, defaults to index level setting | . | batched_reduce_size | number | The number of shard results that should be reduced at once on the coordinating node. This value should be used as a protection mechanism to reduce the memory overhead per search request if the potential number of shards in the request can be large. | . | max_concurrent_shard_requests | number | The number of concurrent shard requests per node this search executes concurrently. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests | . | pre_filter_shard_size | number | A threshold that enforces a pre-filter roundtrip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter roundtrip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method ie. if date filters are mandatory to match but the shard bounds and the query are disjoint. | . | rest_total_hits_as_int | boolean | Indicates whether hits.total should be rendered as an integer or an object in the rest search response | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#search",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#search"
  },"654": {
    "doc": "REST API Reference",
    "title": "search_shards",
    "content": "Returns information about the indices and shards that a search request would be executed against. GET _search_shards POST _search_shards . GET {index}/_search_shards POST {index}/_search_shards . URL parameters . | Parameter | Type | Description | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | routing | string | Specific routing value | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#search_shards",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#search_shards"
  },"655": {
    "doc": "REST API Reference",
    "title": "search_template",
    "content": "Allows to use the Mustache language to pre-render a search definition. GET _search/template POST _search/template . GET {index}/_search/template POST {index}/_search/template . GET {index}/{type}/_search/template POST {index}/{type}/_search/template . HTTP request body . The search definition template and its params . Required: True . URL parameters . | Parameter | Type | Description | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) | . | ignore_throttled | boolean | Whether specified concrete, expanded or aliased indices should be ignored when throttled | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. | . | preference | string | Specify the node or shard the operation should be performed on (default: random) | . | routing | list | A comma-separated list of specific routing values | . | scroll | time | Specify how long a consistent view of the index should be maintained for scrolled search | . | search_type | enum | Search operation type | . | explain | boolean | Specify whether to return detailed information about score computation as part of a hit | . | profile | boolean | Specify whether to profile the query execution | . | typed_keys | boolean | Specify whether aggregation and suggester names should be prefixed by their respective types in the response | . | rest_total_hits_as_int | boolean | Indicates whether hits.total should be rendered as an integer or an object in the rest search response | . | ccs_minimize_roundtrips | boolean | Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#search_template",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#search_template"
  },"656": {
    "doc": "REST API Reference",
    "title": "snapshot.cleanup_repository",
    "content": "Removes stale data from repository. POST _snapshot/{repository}/_cleanup . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotcleanup_repository",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotcleanup_repository"
  },"657": {
    "doc": "REST API Reference",
    "title": "snapshot.create",
    "content": "Creates a snapshot in a repository. PUT _snapshot/{repository}/{snapshot} POST _snapshot/{repository}/{snapshot} . HTTP request body . The snapshot definition . Required: False . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | wait_for_completion | boolean | Should this request wait until the operation has completed before returning | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotcreate",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotcreate"
  },"658": {
    "doc": "REST API Reference",
    "title": "snapshot.create_repository",
    "content": "Creates a repository. PUT _snapshot/{repository} POST _snapshot/{repository} . HTTP request body . The repository definition . Required: True . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . | verify | boolean | Whether to verify the repository after creation | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotcreate_repository",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotcreate_repository"
  },"659": {
    "doc": "REST API Reference",
    "title": "snapshot.delete",
    "content": "Deletes a snapshot. DELETE _snapshot/{repository}/{snapshot} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotdelete",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotdelete"
  },"660": {
    "doc": "REST API Reference",
    "title": "snapshot.delete_repository",
    "content": "Deletes a repository. DELETE _snapshot/{repository} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotdelete_repository",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotdelete_repository"
  },"661": {
    "doc": "REST API Reference",
    "title": "snapshot.get",
    "content": "Returns information about a snapshot. GET _snapshot/{repository}/{snapshot} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | ignore_unavailable | boolean | Whether to ignore unavailable snapshots, defaults to false which means a SnapshotMissingException is thrown | . | verbose | boolean | Whether to show verbose snapshot info or only show the basic info found in the repository index blob | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotget",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotget"
  },"662": {
    "doc": "REST API Reference",
    "title": "snapshot.get_repository",
    "content": "Returns information about a repository. GET _snapshot . GET _snapshot/{repository} . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | local | boolean | Return local information, do not retrieve the state from master node (default: false) | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotget_repository",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotget_repository"
  },"663": {
    "doc": "REST API Reference",
    "title": "snapshot.restore",
    "content": "Restores a snapshot. POST _snapshot/{repository}/{snapshot}/_restore . HTTP request body . Details of what to restore . Required: False . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | wait_for_completion | boolean | Should this request wait until the operation has completed before returning | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotrestore",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotrestore"
  },"664": {
    "doc": "REST API Reference",
    "title": "snapshot.status",
    "content": "Returns information about the status of a snapshot. GET _snapshot/_status . GET _snapshot/{repository}/_status . GET _snapshot/{repository}/{snapshot}/_status . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | ignore_unavailable | boolean | Whether to ignore unavailable snapshots, defaults to false which means a SnapshotMissingException is thrown | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotstatus",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotstatus"
  },"665": {
    "doc": "REST API Reference",
    "title": "snapshot.verify_repository",
    "content": "Verifies a repository. POST _snapshot/{repository}/_verify . URL parameters . | Parameter | Type | Description | . | master_timeout | time | Explicit operation timeout for connection to master node | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#snapshotverify_repository",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#snapshotverify_repository"
  },"666": {
    "doc": "REST API Reference",
    "title": "tasks.cancel",
    "content": "Cancels a task, if it can be cancelled through an API. POST _tasks/_cancel . POST _tasks/{task_id}/_cancel . URL parameters . | Parameter | Type | Description | . | nodes | list | A comma-separated list of node IDs or names to limit the returned information; use _local to return information from the node you’re connecting to, leave empty to get information from all nodes | . | actions | list | A comma-separated list of actions that should be cancelled. Leave empty to cancel all. | . | parent_task_id | string | Cancel tasks with specified parent task id (node_id:task_number). Set to -1 to cancel all. | . | wait_for_completion | boolean | Should the request block until the cancellation of the task and its descendant tasks is completed. Defaults to false | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#taskscancel",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#taskscancel"
  },"667": {
    "doc": "REST API Reference",
    "title": "tasks.get",
    "content": "Returns information about a task. GET _tasks/{task_id} . URL parameters . | Parameter | Type | Description | . | wait_for_completion | boolean | Wait for the matching tasks to complete (default: false) | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#tasksget",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#tasksget"
  },"668": {
    "doc": "REST API Reference",
    "title": "tasks.list",
    "content": "Returns a list of tasks. GET _tasks . URL parameters . | Parameter | Type | Description | . | nodes | list | A comma-separated list of node IDs or names to limit the returned information; use _local to return information from the node you’re connecting to, leave empty to get information from all nodes | . | actions | list | A comma-separated list of actions that should be returned. Leave empty to return all. | . | detailed | boolean | Return detailed task information (default: false) | . | parent_task_id | string | Return tasks with specified parent task id (node_id:task_number). Set to -1 to return all. | . | wait_for_completion | boolean | Wait for the matching tasks to complete (default: false) | . | group_by | enum | Group tasks by nodes or parent/child relationships | . | timeout | time | Explicit operation timeout | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#taskslist",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#taskslist"
  },"669": {
    "doc": "REST API Reference",
    "title": "termvectors",
    "content": "Returns information and statistics about terms in the fields of a particular document. GET {index}/_termvectors/{id} POST {index}/_termvectors/{id} . GET {index}/_termvectors POST {index}/_termvectors . GET {index}/{type}/{id}/_termvectors POST {index}/{type}/{id}/_termvectors . GET {index}/{type}/_termvectors POST {index}/{type}/_termvectors . HTTP request body . Define parameters and or supply a document to get termvectors for. See documentation. Required: False . URL parameters . | Parameter | Type | Description | . | term_statistics | boolean | Specifies if total term frequency and document frequency should be returned. | . | field_statistics | boolean | Specifies if document count, sum of document frequencies and sum of total term frequencies should be returned. | . | fields | list | A comma-separated list of fields to return. | . | offsets | boolean | Specifies if term offsets should be returned. | . | positions | boolean | Specifies if term positions should be returned. | . | payloads | boolean | Specifies if term payloads should be returned. | . | preference | string | Specify the node or shard the operation should be performed on (default: random). | . | routing | string | Specific routing value. | . | realtime | boolean | Specifies if request is real-time as opposed to near-real-time (default: true). | . | version | number | Explicit version number for concurrency control | . | version_type | enum | Specific version type | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#termvectors",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#termvectors"
  },"670": {
    "doc": "REST API Reference",
    "title": "update",
    "content": "Updates a document with a script or partial document. POST {index}/_update/{id} . POST {index}/{type}/{id}/_update . HTTP request body . The request definition requires either script or partial doc . Required: True . URL parameters . | Parameter | Type | Description | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the update operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) | . | _source | list | True or false to return the _source field or not, or a list of fields to return | . | _source_excludes | list | A list of fields to exclude from the returned _source field | . | _source_includes | list | A list of fields to extract and return from the _source field | . | lang | string | The script language (default: painless) | . | refresh | enum | If true then refresh the affected shards to make this operation visible to search, if wait_for then wait for a refresh to make this operation visible to search, if false (the default) then do nothing with refreshes. | . | retry_on_conflict | number | Specify how many times should the operation be retried when a conflict occurs (default: 0) | . | routing | string | Specific routing value | . | timeout | time | Explicit operation timeout | . | if_seq_no | number | only perform the update operation if the last operation that has changed the document has the specified sequence number | . | if_primary_term | number | only perform the update operation if the last operation that has changed the document has the specified primary term | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#update",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#update"
  },"671": {
    "doc": "REST API Reference",
    "title": "update_by_query",
    "content": "Performs an update on every document in the index without changing the source, for example to pick up a mapping change. POST {index}/_update_by_query . POST {index}/{type}/_update_by_query . HTTP request body . The search definition using the Query DSL . URL parameters . | Parameter | Type | Description |   | . | analyzer | string | The analyzer to use for the query string |   | . | analyze_wildcard | boolean | Specify whether wildcard and prefix queries should be analyzed (default: false) |   | . | default_operator | enum | The default operator for query string query (AND or OR) |   | . | df | string | The field to use as default where no field prefix is given in the query string |   | . | from | number | Starting offset (default: 0) |   | . | ignore_unavailable | boolean | Whether specified concrete indices should be ignored when unavailable (missing or closed) |   | . | allow_no_indices | boolean | Whether to ignore if a wildcard indices expression resolves into no concrete indices. (This includes _all string or when no indices have been specified) |   | . | conflicts | enum | What to do when the update by query hits version conflicts? |   | . | expand_wildcards | enum | Whether to expand wildcard expression to concrete indices that are open, closed or both. |   | . | lenient | boolean | Specify whether format-based query failures (such as providing text to a numeric field) should be ignored |   | . | pipeline | string | Ingest pipeline to set on index requests made by this action. (default: none) |   | . | preference | string | Specify the node or shard the operation should be performed on (default: random) |   | . | q | string | Query in the Lucene query string syntax |   | . | routing | list | A comma-separated list of specific routing values |   | . | scroll | time | Specify how long a consistent view of the index should be maintained for scrolled search |   | . | search_type | enum | Search operation type |   | . | search_timeout | time | Explicit timeout for each search request. Defaults to no timeout. |   | . | size | number | Deprecated, please use max_docs instead |   | . | max_docs | number | Maximum number of documents to process (default: all documents) |   | . | sort | list | A comma-separated list of : pairs |   | . | _source | list | True or false to return the _source field or not, or a list of fields to return |   | . | _source_excludes | list | A list of fields to exclude from the returned _source field |   | . | _source_includes | list | A list of fields to extract and return from the _source field |   | . | terminate_after | number | The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. |   | . | stats | list | Specific ‘tag’ of the request for logging and statistical purposes |   | . | version | boolean | Specify whether to return document version as part of a hit |   | . | version_type | boolean | Should the document increment the version number (internal) on hit or not (reindex) |   | . | request_cache | boolean | Specify if request cache should be used for this request or not, defaults to index level setting |   | . | refresh | boolean | Should the affected indexes be refreshed? |   | . | timeout | time | Time each individual bulk request should wait for shards that are unavailable. |   | . | wait_for_active_shards | string | Sets the number of shard copies that must be active before proceeding with the update by query operation. Defaults to 1, meaning the primary shard only. Set to all for all shard copies, otherwise set to any non-negative value less than or equal to the total number of copies for the shard (number of replicas + 1) |   | . | scroll_size | number | Size on the scroll request powering the update by query |   | . | wait_for_completion | boolean | Should the request should block until the update by query operation is complete. |   | . | requests_per_second | number | The throttle to set on this request in sub-requests per second. -1 means no throttle. |   | . | slices | number | string | The number of slices this task should be divided into. Defaults to 1, meaning the task isn’t sliced into subtasks. Can be set to auto. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#update_by_query",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#update_by_query"
  },"672": {
    "doc": "REST API Reference",
    "title": "update_by_query_rethrottle",
    "content": "Changes the number of requests per second for a particular Update By Query operation. POST _update_by_query/{task_id}/_rethrottle . URL parameters . | Parameter | Type | Description | . | requests_per_second | number | The throttle to set on this request in floating sub-requests per second. -1 means set no throttle. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/#update_by_query_rethrottle",
    "relUrl": "/docs/elasticsearch/rest-api-reference/#update_by_query_rethrottle"
  },"673": {
    "doc": "REST API Reference",
    "title": "REST API Reference",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/rest-api-reference/",
    "relUrl": "/docs/elasticsearch/rest-api-reference/"
  },"674": {
    "doc": "Rolling Upgrade",
    "title": "Rolling upgrade",
    "content": "The steps on this page are most applicable if you installed Open Distro for Elasticsearch using the RPM or Debian packages. If you used a Docker image, see Docker upgrade. | Disable shard allocation to prevent Elasticsearch from replicating shards as you shut down each node: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.enable\": \"primaries\" } } . | Stop Elasticsearch on one node: . sudo systemctl stop elasticsearch.service . | If you use the Debian package, upgrade to the underlying Elasticsearch version of the new Open Distro for Elasticsearch release: . wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-x.y.z-amd64.deb sudo dpkg -i elasticsearch-oss-x.y.z-amd64.deb . | Upgrade packages on the node using yum or apt: . sudo yum install opendistroforelasticsearch sudo apt install opendistroforelasticsearch . Alternately, yum lets you upgrade to a specific version of Open Distro for Elasticsearch: . sudo yum install opendistro-for-elasticsearch-1.11.0 . Unfortunately, apt upgrades dependencies to their latest versions and thus only supports upgrades to the newest version of Open Distro for Elasticsearch. | (Optional) Upgrade any additional plugins that you installed on the node. The package manager automatically upgrades Open Distro for Elasticsearch plugins. | Start Elasticsearch on the node: . sudo systemctl start elasticsearch.service . | Wait for the node to join your cluster, and verify that the node is using the new version: . curl -XGET https://localhost:9200/_nodes/_all?pretty=true -u admin:admin -k . | Enable shard allocation: . PUT _cluster/settings { \"persistent\": { \"cluster.routing.allocation.enable\": \"all\" } } . | Wait for cluster health to return to green: . curl -XGET https://localhost:9200/_cat/health?v -u admin:admin -k . | Repeat steps 1-8 for each node. | Open Kibana, and verify that your data is present. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/rolling/#rolling-upgrade",
    "relUrl": "/docs/upgrade/rolling/#rolling-upgrade"
  },"675": {
    "doc": "Rolling Upgrade",
    "title": "Rolling Upgrade",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/upgrade/rolling/",
    "relUrl": "/docs/upgrade/rolling/"
  },"676": {
    "doc": "RPM",
    "title": "RPM package",
    "content": "Installing and running Open Distro for Elasticsearch from an RPM package is a more manual process than the Docker image. We recommend CentOS 7 and Amazon Linux 2, but any RPM-based distribution that uses systemd should work. These steps assume you’re using CentOS 7. | Create the repository file: . sudo curl https://d3g5vo6xdbdb9a.cloudfront.net/yum/opendistroforelasticsearch-artifacts.repo -o /etc/yum.repos.d/opendistroforelasticsearch-artifacts.repo . | Open Distro for Elasticseach requires the full Java Development Kit (JDK), not just the Java Runtime Environment (JRE). If you don’t have the JDK installed, install either version 8 or version 11: . # Java 11 sudo yum install java-11-openjdk-devel # Java 8 sudo yum install java-1.8.0-openjdk-devel . If you’re using Amazon Linux 2, you might need to use Java 8. | Install wget and unzip: . sudo yum install wget unzip . | List all available Open Distro for Elasticsearch versions: . sudo yum list opendistroforelasticsearch --showduplicates . | Choose the version you’d like and install it: . sudo yum install opendistroforelasticsearch-1.11.0 . | If you installed Java 8, run the following command: . sudo ln -s /usr/lib/jvm/java-1.8.0/lib/tools.jar /usr/share/elasticsearch/lib/ . | To start Open Distro for Elasticsearch: . sudo systemctl start elasticsearch.service . | Send requests to the server to verify that Elasticsearch is up and running: . curl -XGET https://localhost:9200 -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/nodes?v -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/plugins?v -u admin:admin --insecure . | For instructions on installing and running Kibana, see Kibana. | To check the status of the service: . systemctl status elasticsearch.service . You might notice some errors if you are using Java 8. If the service is still active (running), you can safely ignore them: . elasticsearch[3969]: java.security.policy: error adding Entry: elasticsearch[3969]: java.net.MalformedURLException: unknown protocol: jrt elasticsearch[3969]: java.security.policy: error adding Entry: elasticsearch[3969]: java.net.MalformedURLException: unknown protocol: jrt . | To stop Open Distro for Elasticsearch: . sudo systemctl stop elasticsearch.service . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/rpm/#rpm-package",
    "relUrl": "/docs/install/rpm/#rpm-package"
  },"677": {
    "doc": "RPM",
    "title": "Configuration",
    "content": "To run Open Distro for Elasticsearch when the system starts: . sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable elasticsearch.service . You can also modify the values in /etc/sysconfig/elasticsearch (JAVA_HOME, most notably), /etc/elasticsearch/elasticsearch.yml, and /etc/elasticsearch/jvm.options (to set the heap size, most notably). To learn more, see Elasticsearch configuration and Important Settings on the Docker page. (Optional) Set up Performance Analyzer . By default, Performance Analyzer’s endpoints are not accessible from outside the host machine. To edit this behavior, modify the plugin configuration. First navigate to ES_HOME, which is /usr/share/elasticsearch for a standard installation. cd $ES_HOME # navigate to the Elasticsearch home directory cd plugins/opendistro_performance_analyzer/pa_config/ vi performance-analyzer.properties . Uncomment the line #webservice-bind-host and set it to 0.0.0.0: . # ======================== Elasticsearch performance analyzer plugin config ========================= # NOTE: this is an example for Linux. Please modify the config accordingly if you are using it under other OS. # WebService bind host; default to all interfaces webservice-bind-host = 0.0.0.0 # Metrics data location metrics-location = /dev/shm/performanceanalyzer/ # Metrics deletion interval (minutes) for metrics data. # Interval should be between 1 to 60. metrics-deletion-interval = 1 # If set to true, the system cleans up the files behind it. So at any point, we should expect only 2 # metrics-db-file-prefix-path files. If set to false, no files are cleaned up. This can be useful, if you are archiving # the files and wouldn't like for them to be cleaned up. cleanup-metrics-db-files = true # WebService exposed by App's port webservice-listener-port = 9600 # Metric DB File Prefix Path location metrics-db-file-prefix-path = /tmp/metricsdb_ https-enabled = false #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path # Plugin Stats Metadata file name, expected to be in the same location plugin-stats-metadata = plugin-stats-metadata # Agent Stats Metadata file name, expected to be in the same location agent-stats-metadata = agent-stats-metadata . Finally, restart the Elasticsearch service. After the restart, Performance Analyzer is accessible from outside the machine: . sudo systemctl restart elasticsearch.service . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/rpm/#configuration",
    "relUrl": "/docs/install/rpm/#configuration"
  },"678": {
    "doc": "RPM",
    "title": "Where are the files?",
    "content": "The RPM package installs files to the following locations: . | File type | Location | . | Elasticsearch home, management scripts, and plugins | /usr/share/elasticsearch/ | . | Configuration files | /etc/elasticsearch | . | Environment variables | /etc/sysconfig/elasticsearch | . | Logs | /var/log/elasticsearch | . | Shard data | /var/lib/elasticsearch | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/rpm/#where-are-the-files",
    "relUrl": "/docs/install/rpm/#where-are-the-files"
  },"679": {
    "doc": "RPM",
    "title": "RPM",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/rpm/",
    "relUrl": "/docs/install/rpm/"
  },"680": {
    "doc": "Troubleshoot SAML",
    "title": "SAML troubleshooting",
    "content": "This page includes troubleshooting steps for using SAML for Kibana authentication. . | Check sp.entity_id | Check the SAML assertion consumer service URL | Sign all documents | Role settings | Inspect the SAML response | Check role mapping | Inspect the JWT token | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#saml-troubleshooting",
    "relUrl": "/docs/troubleshoot/saml/#saml-troubleshooting"
  },"681": {
    "doc": "Troubleshoot SAML",
    "title": "Check sp.entity_id",
    "content": "Most identity providers (IdPs) allow you to configure multiple authentication methods for different applications. For example, in Okta, these clients are called “Applications.” In Keycloak, they are called “Clients.” Each one has its own entity ID. Make sure to configure sp.entity_id to match those settings: . saml: ... http_authenticator: type: 'saml' challenge: true config: ... sp: entity_id: kibana-saml . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#check-spentity_id",
    "relUrl": "/docs/troubleshoot/saml/#check-spentity_id"
  },"682": {
    "doc": "Troubleshoot SAML",
    "title": "Check the SAML assertion consumer service URL",
    "content": "After a successful login, your IdP sends a SAML response using HTTP POST to Kibana’s “assertion consumer service URL” (ACS). The endpoint the Kibana security plugin provides is: . /_opendistro/_security/saml/acs . Make sure that you have configured this endpoint correctly in your IdP. Some IdPs also require you to whitelist all endpoints that they send requests to. Ensure that the ACS endpoint is listed. Kibana also requires you to whitelist this endpoint. Make sure you have the following entry in kibana.yml: . server.xsrf.whitelist: [/_opendistro/_security/saml/acs] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#check-the-saml-assertion-consumer-service-url",
    "relUrl": "/docs/troubleshoot/saml/#check-the-saml-assertion-consumer-service-url"
  },"683": {
    "doc": "Troubleshoot SAML",
    "title": "Sign all documents",
    "content": "Some IdPs do not sign the SAML documents by default. Make sure the IdP signs all documents. Keycloak . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#sign-all-documents",
    "relUrl": "/docs/troubleshoot/saml/#sign-all-documents"
  },"684": {
    "doc": "Troubleshoot SAML",
    "title": "Role settings",
    "content": "Including user roles in the SAML response is dependent on your IdP. For example, in Keycloak, this setting is in the Mappers section of your client. In Okta, you have to set group attribute statements. Make sure this is configured correctly and that the roles_key in the SAML configuration matches the role name in the SAML response: . saml: ... http_authenticator: type: 'saml' challenge: true config: ... roles_key: Role . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#role-settings",
    "relUrl": "/docs/troubleshoot/saml/#role-settings"
  },"685": {
    "doc": "Troubleshoot SAML",
    "title": "Inspect the SAML response",
    "content": "If you are not sure what the SAML response of your IdP contains and where it places the username and roles, you can enable debug mode in the log4j2.properties: . logger.token.name = com.amazon.dlic.auth.http.saml.Token logger.token.level = debug . This setting prints the SAML response to the Elasticsearch log file so that you can inspect and debug it. Setting this logger to debug generates many statements, so we don’t recommend using it in production. Another way of inspecting the SAML response is to monitor network traffic while logging in to Kibana. The IdP uses HTTP POST requests to send Base64-encoded SAML responses to: . /_opendistro/_security/saml/acs . Inspect the payload of this POST request, and use a tool like base64decode.org to decode it. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#inspect-the-saml-response",
    "relUrl": "/docs/troubleshoot/saml/#inspect-the-saml-response"
  },"686": {
    "doc": "Troubleshoot SAML",
    "title": "Check role mapping",
    "content": "The security plugin uses a standard role mapping to map a user or backend role to one or more Security roles. For username, the security plugin uses the NameID attribute of the SAML response by default. For some IdPs, this attribute does not contain the expected username, but some internal user ID. Check the content of the SAML response to locate the element you want to use as username, and configure it by setting the subject_key: . saml: ... http_authenticator: type: 'saml' challenge: true config: ... subject_key: preferred_username . For checking that the correct backend roles are contained in the SAML response, inspect the contents, and set the correct attribute name: . saml: ... http_authenticator: type: 'saml' challenge: true config: ... roles_key: Role . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#check-role-mapping",
    "relUrl": "/docs/troubleshoot/saml/#check-role-mapping"
  },"687": {
    "doc": "Troubleshoot SAML",
    "title": "Inspect the JWT token",
    "content": "The security plugin trades the SAML response for a more lightweight JSON web token. The username and backend roles in the JWT are ultimately mapped to roles in the security plugin. If there is a problem with the mapping, you can enable the token debug mode using the same setting as Inspect the SAML response. This setting prints the JWT to the Elasticsearch log file so that you can inspect and debug it using a tool like JWT.io. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/#inspect-the-jwt-token",
    "relUrl": "/docs/troubleshoot/saml/#inspect-the-jwt-token"
  },"688": {
    "doc": "Troubleshoot SAML",
    "title": "Troubleshoot SAML",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/saml/",
    "relUrl": "/docs/troubleshoot/saml/"
  },"689": {
    "doc": "SAML",
    "title": "SAML",
    "content": "The security plugin supports user authentication through SAML single sign-on. The security plugin implements the web browser SSO profile of the SAML 2.0 protocol. This profile is meant for use with web browsers. It is not a general-purpose way of authenticating users against the security plugin, so its primary use case is to support Kibana single sign-on. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/",
    "relUrl": "/docs/security/configuration/saml/"
  },"690": {
    "doc": "SAML",
    "title": "Docker example",
    "content": "We provide a fully functional example that can help you understand how to use SAML with Kibana. | Download and unzip the example ZIP file. | At the command line, run docker-compose up. | Review the files: . | docker-compose.yml defines two ODFE nodes, a Kibana server, and a SAML server. | custom-kibana.yml add a few SAML settings to the default kibana.yml file. | config.yml configures SAML for authentication. | . | Access Kibana at http://localhost:5601. Note that Kibana immediately redirects you to the SAML login page. | Log in as admin with a password of admin. | After logging in, note that your user in the upper-right is SAMLAdmin, as defined in /var/www/simplesamlphp/config/authsources.php of the SAML server. | If you want to examine the SAML server, run docker ps to find its container ID and then docker exec -it &lt;container-id&gt; /bin/bash. In particular, you might find it helpful to review the contents of the /var/www/simplesamlphp/config/ and /var/www/simplesamlphp/metadata/ directories. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#docker-example",
    "relUrl": "/docs/security/configuration/saml/#docker-example"
  },"691": {
    "doc": "SAML",
    "title": "Activating SAML",
    "content": "To use SAML for authentication, you need to configure a respective authentication domain in the authc section of plugins/opendistro_security/securityconfig/config.yml. Because SAML works solely on the HTTP layer, you do not need any authentication_backend and can set it to noop. Place all SAML-specific configuration options in this chapter in the config section of the SAML HTTP authenticator: . authc: saml_auth_domain: http_enabled: true transport_enabled: false order: 1 http_authenticator: type: saml challenge: true config: idp: metadata_file: okta.xml ... authentication_backend: type: noop . After you have configured SAML in config.yml, you must also activate it in Kibana. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#activating-saml",
    "relUrl": "/docs/security/configuration/saml/#activating-saml"
  },"692": {
    "doc": "SAML",
    "title": "Running multiple authentication domains",
    "content": "We recommend adding at least one other authentication domain, such as LDAP or the internal user database, to support API access to Elasticsearch without SAML. For Kibana and the internal Kibana server user, you also must add another authentication domain that supports basic authentication. This authentication domain should be placed first in the chain, and the challenge flag must be set to false: . authc: basic_internal_auth_domain: http_enabled: true transport_enabled: true order: 0 http_authenticator: type: basic challenge: false authentication_backend: type: internal saml_auth_domain: http_enabled: true transport_enabled: false order: 1 http_authenticator: type: saml challenge: true config: ... authentication_backend: type: noop . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#running-multiple-authentication-domains",
    "relUrl": "/docs/security/configuration/saml/#running-multiple-authentication-domains"
  },"693": {
    "doc": "SAML",
    "title": "Identity provider metadata",
    "content": "A SAML identity provider (IdP) provides a SAML 2.0 metadata file describing the IdP’s capabilities and configuration. The security plugin can read IdP metadata either from a URL or a file. The choice that you make depends on your IdP and your preferences. The SAML 2.0 metadata file is required. | Name | Description | . | idp.metadata_file | The path to the SAML 2.0 metadata file of your IdP. Place the metadata file in the config directory of Open Distro for Elasticsearch. The path has to be specified relative to the config directory. Required if idp.metadata_url is not set. | . | idp.metadata_url | The SAML 2.0 metadata URL of your IdP. Required if idp.metadata_file is not set. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#identity-provider-metadata",
    "relUrl": "/docs/security/configuration/saml/#identity-provider-metadata"
  },"694": {
    "doc": "SAML",
    "title": "IdP and service provider entity ID",
    "content": "An entity ID is a globally unique name for a SAML entity, either an IdP or a service provider (SP). The IdP entity ID is usually provided by your IdP. The SP entity ID is the name of the configured application or client in your IdP. We recommend adding a new application for Kibana and using the URL of your Kibana installation as the SP entity ID. | Name | Description | . | idp.entity_id | The entity ID of your IdP. Required. | . | sp.entity_id | The entity ID of the service provider. Required. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#idp-and-service-provider-entity-id",
    "relUrl": "/docs/security/configuration/saml/#idp-and-service-provider-entity-id"
  },"695": {
    "doc": "SAML",
    "title": "Kibana settings",
    "content": "The Web Browser SSO Profile exchanges information through HTTP GET or POST. For example, after you log in to your IdP, it sends an HTTP POST back to Kibana containing the SAML response. You must configure the base URL of your Kibana installation where the HTTP requests are being sent to. | Name | Description | . | kibana_url | The Kibana base URL. Required. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#kibana-settings",
    "relUrl": "/docs/security/configuration/saml/#kibana-settings"
  },"696": {
    "doc": "SAML",
    "title": "Username and Role attributes",
    "content": "Subjects (for example, user names) are usually stored in the NameID element of a SAML response: . &lt;saml2:Subject&gt; &lt;saml2:NameID&gt;admin&lt;/saml2:NameID&gt; ... &lt;/saml2:Subject&gt; . If your IdP is compliant with the SAML 2.0 specification, you do not need to set anything special. If your IdP uses a different element name, you can also specify its name explicitly. Role attributes are optional. However, most IdPs can be configured to add roles in the SAML assertions as well. If present, you can use these roles in your role mappings: . &lt;saml2:Attribute Name='Role'&gt; &lt;saml2:AttributeValue &gt;Everyone&lt;/saml2:AttributeValue&gt; &lt;saml2:AttributeValue &gt;Admins&lt;/saml2:AttributeValue&gt; &lt;/saml2:Attribute&gt; . If you want to extract roles from the SAML response, you need to specify the element name that contains the roles. | Name | Description | . | subject_key | The attribute in the SAML response where the subject is stored. Optional. If not configured, the NameID attribute is used. | . | roles_key | The attribute in the SAML response where the roles are stored. Optional. If not configured, no roles are used. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#username-and-role-attributes",
    "relUrl": "/docs/security/configuration/saml/#username-and-role-attributes"
  },"697": {
    "doc": "SAML",
    "title": "Request signing",
    "content": "Requests from the security plugin to the IdP can optionally be signed. Use the following settings to configure request signing. | Name | Description | . | sp.signature_private_key | The private key used to sign the requests or to decode encrypted assertions. Optional. Cannot be used when private_key_filepath is set. | . | sp.signature_private_key_password | The password of the private key, if any. | . | sp.signature_private_key_filepath | Path to the private key. The file must be placed under the Open Distro for Elasticsearch config directory, and the path must be specified relative to that same directory. | . | sp.signature_algorithm | The algorithm used to sign the requests. See the next table for possible values. | . The security plugin supports the following signature algorithms. | Algorithm | Value | . | DSA_SHA1 | http://www.w3.org/2000/09/xmldsig#dsa-sha1; | . | RSA_SHA1 | http://www.w3.org/2000/09/xmldsig#rsa-sha1; | . | RSA_SHA256 | http://www.w3.org/2001/04/xmldsig-more#rsa-sha256; | . | RSA_SHA384 | http://www.w3.org/2001/04/xmldsig-more#rsa-sha384; | . | RSA_SHA512 | http://www.w3.org/2001/04/xmldsig-more#rsa-sha512; | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#request-signing",
    "relUrl": "/docs/security/configuration/saml/#request-signing"
  },"698": {
    "doc": "SAML",
    "title": "Logout",
    "content": "Usually, IdPs provide information about their individual logout URL in their SAML 2.0 metadata. If this is the case, the security plugin uses them to render the correct logout link in Kibana. If your IdP does not support an explicit logout, you can force a re-login when the user visits Kibana again. | Name | Description | . | sp.forceAuthn | Force a re-login even if the user has an active session with the IdP. | . Currently, the security plugin supports only the HTTP-Redirect logout binding. Make sure this is configured correctly in your IdP. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#logout",
    "relUrl": "/docs/security/configuration/saml/#logout"
  },"699": {
    "doc": "SAML",
    "title": "Exchange key settings",
    "content": "SAML, unlike other protocols, is not meant to be used for exchanging user credentials with each request. The security plugin trades the SAML response for a lightweight JSON web token that stores the validated user attributes. This token is signed by an exchange key that you can choose freely. Note that when you change this key, all tokens signed with it become invalid immediately. | Name | Description | . | exchange_key | The key to sign the token. The algorithm is HMAC256, so it should have at least 32 characters. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#exchange-key-settings",
    "relUrl": "/docs/security/configuration/saml/#exchange-key-settings"
  },"700": {
    "doc": "SAML",
    "title": "TLS settings",
    "content": "If you are loading the IdP metadata from a URL, we recommend that you use SSL/TLS. If you use an external IdP like Okta or Auth0 that uses a trusted certificate, you usually do not need to configure anything. If you host the IdP yourself and use your own root CA, you can customize the TLS settings as follows. These settings are used only for loading SAML metadata over HTTPS. | Name | Description | . | idp.enable_ssl | Whether to enable the custom TLS configuration. Default is false (JDK settings are used). | . | idp.verify_hostnames | Whether to verify the hostnames of the server’s TLS certificate. | . Example: . authc: saml_auth_domain: http_enabled: true transport_enabled: false order: 1 http_authenticator: type: saml challenge: true config: idp: enable_ssl: true verify_hostnames: true ... authentication_backend: type: noop . Certificate validation . Configure the root CA used for validating the IdP TLS certificate by setting one of the following configuration options: . config: idp: pemtrustedcas_filepath: path/to/trusted_cas.pem . config: idp: pemtrustedcas_content: |- MIID/jCCAuagAwIBAgIBATANBgkqhkiG9w0BAQUFADCBjzETMBEGCgmSJomT8ixk ARkWA2NvbTEXMBUGCgmSJomT8ixkARkWB2V4YW1wbGUxGTAXBgNVBAoMEEV4YW1w bGUgQ29tIEluYy4xITAfBgNVBAsMGEV4YW1wbGUgQ29tIEluYy4gUm9vdCBDQTEh ... | Name | Description | . | idp.pemtrustedcas_filepath | Path to the PEM file containing the root CAs of your IdP. The files must be placed under the Open Distro for Elasticsearch config directory, and you must specify the path relative to that same directory. | . | idp.pemtrustedcas_content | The root CA content of your IdP server. Cannot be used when pemtrustedcas_filepath is set. | . Client authentication . The security plugin can use TLS client authentication when fetching the IdP metadata. If enabled, the security plugin sends a TLS client certificate to the IdP for each metadata request. Use the following keys to configure client authentication. | Name | Description | . | idp.enable_ssl_client_auth | Whether to send a client certificate to the IdP server. Default is false. | . | idp.pemcert_filepath | Path to the PEM file containing the client certificate. The file must be placed under the Open Distro for Elasticsearch config directory, and the path must be specified relative to the config directory. | . | idp.pemcert_content | The content of the client certificate. Cannot be used when pemcert_filepath is set. | . | idp.pemkey_filepath | Path to the private key of the client certificate. The file must be placed under the Open Distro for Elasticsearch config directory, and the path must be specified relative to the config directory. | . | idp.pemkey_content | The content of the private key of your certificate. Cannot be used when pemkey_filepath is set. | . | idp.pemkey_password | The password of your private key, if any. | . Enabled ciphers and protocols . You can limit the allowed ciphers and TLS protocols for the IdP connection. For example, you can only enable strong ciphers and limit the TLS versions to the most recent ones. | Name | Description | . | idp.enabled_ssl_ciphers | Array of enabled TLS ciphers. Only the Java format is supported. | . | idp.enabled_ssl_protocols | Array of enabled TLS protocols. Only the Java format is supported. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#tls-settings",
    "relUrl": "/docs/security/configuration/saml/#tls-settings"
  },"701": {
    "doc": "SAML",
    "title": "Minimal configuration example",
    "content": "The following example shows the minimal configuration: . authc: saml_auth_domain: http_enabled: true transport_enabled: false order: 1 http_authenticator: type: saml challenge: true config: idp: metadata_file: metadata.xml entity_id: http://idp.example.com/ sp: entity_id: https://kibana.example.com kibana_url: https://kibana.example.com:5601/ roles_key: Role exchange_key: 'peuvgOLrjzuhXf ...' authentication_backend: type: noop . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#minimal-configuration-example",
    "relUrl": "/docs/security/configuration/saml/#minimal-configuration-example"
  },"702": {
    "doc": "SAML",
    "title": "Kibana configuration",
    "content": "Because most of the SAML-specific configuration is done in the security plugin, just activate SAML in your kibana.yml by adding the following: . opendistro_security.auth.type: \"saml\" . In addition, the Kibana endpoint for validating the SAML assertions must be whitelisted: . server.xsrf.whitelist: [\"/_opendistro/_security/saml/acs\"] . If you use the logout POST binding, you also need to whitelist the logout endpoint: . server.xsrf.whitelist: [\"/_opendistro/_security/saml/acs\", \"/_opendistro/_security/saml/logout\"] . IdP-initiated SSO . To use IdP-initiated SSO, set the Assertion Consumer Service endpoint of your IdP to this: . /_opendistro/_security/saml/acs/idpinitiated . Then add this endpoint to server.xsrf.whitelist in kibana.yml: . server.xsrf.whitelist: [\"/_opendistro/_security/saml/acs/idpinitiated\", \"/_opendistro/_security/saml/acs\", \"/_opendistro/_security/saml/logout\"] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/saml/#kibana-configuration",
    "relUrl": "/docs/security/configuration/saml/#kibana-configuration"
  },"703": {
    "doc": "Search Templates",
    "title": "Search templates",
    "content": "You can convert your full-text queries into a search template to accept user input and dynamically insert it into your query. For example, if you use Elasticsearch as a backend search engine for your application or website, you can take in user queries from a search bar or a form field and pass them as parameters into a search template. That way, the syntax to create Elasticsearch queries is abstracted from your end users. When you’re writing code to convert user input into Elasticsearch queries, you can simplify your code with search templates. If you need to add fields to your search query, you can just modify the template without making changes to your code. Search templates use the Mustache language. For a list of all syntax options, see the Mustache manual. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#search-templates"
  },"704": {
    "doc": "Search Templates",
    "title": "Create search templates",
    "content": "A search template has two components: the query and the parameters. Parameters are user-inputted values that get placed into variables. Variables are represented with double braces in Mustache notation. When encountering a variable like {{var}} in the query, Elasticsearch goes to the params section, looks for a parameter called var, and replaces it with the specified value. You can code your application to ask your user what they want to search for and then plug in that value in the params object at runtime. This command defines a search template to find a play by its name. The {{play_name}} in the query is replaced by the value Henry IV: . GET _search/template { \"source\": { \"query\": { \"match\": { \"play_name\": \"{{play_name}}\" } } }, \"params\": { \"play_name\": \"Henry IV\" } } . This template runs the search on your entire cluster. To run this search on a specific index, add the index name to the request: . GET shakespeare/_search/template . Specify the from and size parameters: . GET _search/template { \"source\": { \"from\": \"{{from}}\", \"size\": \"{{size}}\", \"query\": { \"match\": { \"play_name\": \"{{play_name}}\" } } }, \"params\": { \"play_name\": \"Henry IV\", \"from\": 10, \"size\": 10 } } . To improve the search experience, you can define defaults so that the user doesn’t have to specify every possible parameter. If the parameter is not defined in the params section, Elasticsearch uses the default value. The syntax for defining the default value for a variable var is as follows: . {{var}}{{^var}}default value{{/var}} . This command sets the defaults for from as 10 and size as 10: . GET _search/template { \"source\": { \"from\": \"{{from}}{{^from}}10{{/from}}\", \"size\": \"{{size}}{{^size}}10{{/size}}\", \"query\": { \"match\": { \"play_name\": \"{{play_name}}\" } } }, \"params\": { \"play_name\": \"Henry IV\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#create-search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#create-search-templates"
  },"705": {
    "doc": "Search Templates",
    "title": "Save and execute search templates",
    "content": "After the search template works the way you want it to, you can save the source of that template as a script, making it reusable for different input parameters. When saving the search template as a script, you need to specify the lang parameter as mustache: . POST _scripts/play_search_template { \"script\": { \"lang\": \"mustache\", \"source\": { \"from\": \"{{from}}{{^from}}0{{/from}}\", \"size\": \"{{size}}{{^size}}10{{/size}}\", \"query\": { \"match\": { \"play_name\": \"\" } } }, \"params\": { \"play_name\": \"Henry IV\" } } } . Now you can reuse the template by referring to its id parameter. You can reuse this source template for different input values. GET _search/template { \"id\": \"play_search_template\", \"params\": { \"play_name\": \"Henry IV\", \"from\": 0, \"size\": 1 } } . Sample output . { \"took\": 7, \"timed_out\": false, \"_shards\": { \"total\": 6, \"successful\": 6, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 3205, \"relation\": \"eq\" }, \"max_score\": 3.641852, \"hits\": [ { \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"4\", \"_score\": 3.641852, \"_source\": { \"type\": \"line\", \"line_id\": 5, \"play_name\": \"Henry IV\", \"speech_number\": 1, \"line_number\": \"1.1.2\", \"speaker\": \"KING HENRY IV\", \"text_entry\": \"Find we a time for frighted peace to pant,\" } } ] } } . If you have a stored template and want to validate it, use the render operation: . POST _render/template { \"id\": \"play_search_template\", \"params\": { \"play_name\": \"Henry IV\" } } . Sample output . { \"template_output\": { \"from\": \"0\", \"size\": \"10\", \"query\": { \"match\": { \"play_name\": \"Henry IV\" } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#save-and-execute-search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#save-and-execute-search-templates"
  },"706": {
    "doc": "Search Templates",
    "title": "Advanced parameter conversion with search templates",
    "content": "You have a lot of different syntax options in Mustache to transpose the input parameters into a query. You can specify conditions, run loops, join arrays, convert arrays to JSON, and so on. Conditions . Use the section tag in Mustache to represent conditions: . {{#var}}var{{/var}} . When var is a boolean value, this syntax acts as an if condition. The {{#var}} and {{/var}} tags insert the values placed between them only if var evaluates to true. Using section tags would make your JSON invalid, so you must write your query in a string format instead. This command includes the size parameter in the query only when the limit parameter is set to true. In the following example, the limit parameter is true, so the size parameter is activated. As a result, you would get back only two documents. GET _search/template { \"source\": \"{ {{#limit}} \\\"size\\\": \\\"{{size}}\\\", {{/limit}} \\\"query\\\":{\\\"match\\\":{\\\"play_name\\\": \\\"{{play_name}}\\\"}}}\", \"params\": { \"play_name\": \"Henry IV\", \"limit\": true, \"size\": 2 } } . You can also design an if-else condition. This command sets size to 2 if limit is true. Otherwise, it sets size to 10. GET _search/template { \"source\": \"{ {{#limit}} \\\"size\\\": \\\"2\\\", {{/limit}} {{^limit}} \\\"size\\\": \\\"10\\\", {{/limit}} \\\"query\\\":{\\\"match\\\":{\\\"play_name\\\": \\\"{{play_name}}\\\"}}}\", \"params\": { \"play_name\": \"Henry IV\", \"limit\": true } } . Loops . You can also use the section tag to implement a foreach loop: . {{#var}}{{.}}}{{/var}} . When var is an array, the search template iterates through it and creates a terms query. GET _search/template { \"source\": \"{\\\"query\\\":{\\\"terms\\\":{\\\"play_name\\\":[\\\"{{#play_name}}\\\",\\\"{{.}}\\\",\\\"{{/play_name}}\\\"]}}}\", \"params\": { \"play_name\": [ \"Henry IV\", \"Othello\" ] } } . This template is rendered as: . GET _search/template { \"source\": { \"query\": { \"terms\": { \"play_name\": [ \"Henry IV\", \"Othello\" ] } } } } . Join . You can use the join tag to concatenate values of an array (separated by commas): . GET _search/template { \"source\": { \"query\": { \"match\": { \"text_entry\": \"{{#join}}{{text_entry}}{{/join}}\" } } }, \"params\": { \"text_entry\": [ \"To be\", \"or not to be\" ] } } . Renders as: . GET _search/template { \"source\": { \"query\": { \"match\": { \"text_entry\": \"{0=To be, 1=or not to be}\" } } } } . Convert to JSON . You can use the toJson tag to convert parameters to their JSON representation: . GET _search/template { \"source\": \"{\\\"query\\\":{\\\"bool\\\":{\\\"must\\\":[{\\\"terms\\\": {\\\"text_entries\\\": {{#toJson}}text_entries{{/toJson}} }}] }}}\", \"params\": { \"text_entries\": [ { \"term\": { \"text_entry\" : \"love\" } }, { \"term\": { \"text_entry\" : \"soldier\" } } ] } } . Renders as: . GET _search/template { \"source\": { \"query\": { \"bool\": { \"must\": [ { \"terms\": { \"text_entries\": [ { \"term\": { \"text_entry\": \"love\" } }, { \"term\": { \"text_entry\": \"soldier\" } } ] } } ] } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#advanced-parameter-conversion-with-search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#advanced-parameter-conversion-with-search-templates"
  },"707": {
    "doc": "Search Templates",
    "title": "Multiple search templates",
    "content": "You can bundle multiple search templates and send them to your Elasticsearch cluster in a single request using the msearch operation. This saves network round trip time, so you get back the response more quickly as compared to independent requests. GET _msearch/template {\"index\":\"shakespeare\"} {\"id\":\"if_search_template\",\"params\":{\"play_name\":\"Henry IV\",\"limit\":false,\"size\":2}} {\"index\":\"shakespeare\"} {\"id\":\"play_search_template\",\"params\":{\"play_name\":\"Henry IV\"}} . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#multiple-search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#multiple-search-templates"
  },"708": {
    "doc": "Search Templates",
    "title": "Manage search templates",
    "content": "To list all scripts, run the following command: . GET _cluster/state/metadata?pretty&amp;filter_path=**.stored_scripts . To retrieve a specific search template, run the following command: . GET _scripts/&lt;name_of_search_template&gt; . To delete a search template, run the following command: . DELETE _scripts/&lt;name_of_search_template&gt; . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/#manage-search-templates",
    "relUrl": "/docs/elasticsearch/search-template/#manage-search-templates"
  },"709": {
    "doc": "Search Templates",
    "title": "Search Templates",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/search-template/",
    "relUrl": "/docs/elasticsearch/search-template/"
  },"710": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Apply configuration changes using securityadmin.sh",
    "content": "The security plugin stores its configuration—including users, roles, and permissions—in an index on the Elasticsearch cluster (.opendistro_security). Storing these settings in an index lets you change settings without restarting the cluster and eliminates the need to edit configuration files on every single node. After changing any of the configuration files in plugins/opendistro_security/securityconfig, however, you must run plugins/opendistro_security/tools/securityadmin.sh to load these new settings into the index. You must also run this script at least once to initialize the .opendistro_security index and configure your authentication and authorization methods. After the .opendistro_security index is initialized, you can use Kibana to manage your users, roles, and permissions. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/#apply-configuration-changes-using-securityadminsh",
    "relUrl": "/docs/security/configuration/security-admin/#apply-configuration-changes-using-securityadminsh"
  },"711": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Configure the admin certificate",
    "content": "You can configure all certificates that should have admin privileges in elasticsearch.yml stating their respective distinguished names (DNs). If you use the demo certificates, for example, you can use the kirk certificate: . opendistro_security.authcz.admin_dn: - CN=kirk,OU=client,O=client,L=test,C=DE . You can’t use node certificates as admin certificates. The two must be separate. Also, do not use any whitespace between the parts of the DN. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/#configure-the-admin-certificate",
    "relUrl": "/docs/security/configuration/security-admin/#configure-the-admin-certificate"
  },"712": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Basic usage",
    "content": "The securityadmin.sh tool can be run from any machine that has access to the transport port of your Elasticsearch cluster (the default is 9300). You can change the security plugin configuration without having to access your nodes through SSH. Each node also includes the tool at plugins/opendistro_security/tools/securityadmin.sh. You might need to make the script executable before running it: . chmod +x plugins/opendistro_security/tools/securityadmin.sh . To print all available command line options, run the script with no arguments: ./plugins/opendistro_security/tools/securityadmin.sh . To load configuration changes to the security plugin, you must provide your admin certificate to the tool: ./securityadmin.sh -cd ../securityconfig/ -icl -nhnv -cacert ../../../config/root-ca.pem -cert ../../../config/kirk.pem -key ../../../config/kirk-key.pem . | The -cd option specifies where the security plugin configuration files to upload to the cluster can be found. | The -icl (--ignore-clustername) option tells the security plugin to upload the configuration regardless of the cluster name. As an alternative, you can also specify the cluster name with the -cn (--clustername) option. | Because the demo certificates are self-signed, we also disable hostname verification with the -nhnv (--disable-host-name-verification) option. | The -cacert, -cert and -key options define the location of your root CA certificate, the admin certificate, and the private key for the admin certificate. If the private key has a password, specify it with the -keypass option. | . The following table shows the PEM options. | Name | Description | . | -cert | The location of the PEM file containing the admin certificate and all intermediate certificates, if any. You can use an absolute or relative path. Relative paths are resolved relative to the execution directory of securityadmin.sh. | . | -key | The location of the PEM file containing the private key of the admin certificate. You can use an absolute or relative path. Relative paths are resolved relative to the execution directory of securityadmin.sh. The key must be in PKCS#8 format. | . | -keypass | The password of the private key of the admin certificate, if any. | . | -cacert | The location of the PEM file containing the root certificate. You can use an absolute or relative path. Relative paths are resolved relative to the execution directory of securityadmin.sh. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/#basic-usage",
    "relUrl": "/docs/security/configuration/security-admin/#basic-usage"
  },"713": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Sample commands",
    "content": "Apply configuration in securityconfig using PEM certificates: . /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh -cacert /etc/elasticsearch/root-ca.pem -cert /etc/elasticsearch/kirk.pem -key /etc/elasticsearch/kirk-key.pem -cd /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/ . Apply configuration from a single file (config.yml) using PEM certificates: ./securityadmin.sh -f ../securityconfig/config.yml -icl -nhnv -cert /etc/elasticsearch/kirk.pem -cacert /etc/elasticsearch/root-ca.pem -h -key /etc/elasticsearch/kirk-key.pem -t config . Apply configuration in securityconfig with keystore and truststore files: ./securityadmin.sh \\ -cd /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/ \\ -ks /path/to/keystore.jks \\ -kspass changeit \\ -ts /path/to/truststore.jks \\ -tspass changeit -nhnv -icl . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/#sample-commands",
    "relUrl": "/docs/security/configuration/security-admin/#sample-commands"
  },"714": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Using securityadmin with keystore and truststore files",
    "content": "You can also use keystore files in JKS format in conjunction with securityadmin.sh: ./securityadmin.sh -cd ../securityconfig -icl -nhnv -ts &lt;path/to/truststore&gt; -tspass &lt;truststore password&gt; -ks &lt;path/to/keystore&gt; -kspass &lt;keystore password&gt; . Use the following options to control the key and truststore settings. | Name | Description | . | -ks | The location of the keystore containing the admin certificate and all intermediate certificates, if any. You can use an absolute or relative path. Relative paths are resolved relative to the execution directory of securityadmin.sh. | . | -kspass | The password for the keystore. | . | -kst | The key store type, either JKS or PKCS#12/PFX. If not specified, the security plugin tries to determine the type from the file extension. | . | -ksalias | The alias of the admin certificate, if any. | . | -ts | The location of the truststore containing the root certificate. You can use an absolute or relative path. Relative paths are resolved relative to the execution directory of securityadmin.sh. | . | -tspass | The password for the truststore. | . | -tst | The truststore type, either JKS or PKCS#12/PFX. If not specified, the security plugin tries to determine the type from the file extension. | . | -tsalias | The alias for the root certificate, if any. | . Elasticsearch settings . If you run a default Elasticsearch installation, which listens on transport port 9300 and uses elasticsearch as a cluster name, you can omit the following settings altogether. Otherwise, specify your Elasticsearch settings by using the following switches. | Name | Description | . | -h | Elasticsearch hostname. Default is localhost. | . | -p | Elasticsearch port. Default is 9300—not the HTTP port. | . | -cn | Cluster name. Default is elasticsearch. | . | -icl | Ignore cluster name. | . | -sniff | Sniff cluster nodes. Sniffing detects available nodes using the Elasticsearch _cluster/state API. | . | -arc,--accept-red-cluster | Execute securityadmin.sh even if the cluster state is red. Default is false, which means the script will not execute on a red cluster. | . Certificate validation settings . Use the following options to control certificate validation. | Name | Description | . | -nhnv | Do not validate hostname. Default is false. | . | -nrhn | Do not resolve hostname. Only relevant if -nhnv is not set. | . | -noopenssl | Do not use OpenSSL, even if available. Default is to use OpenSSL if it is available. | . Configuration files settings . The following switches define which configuration files you want to push to the security plugin. You can either push a single file or specify a directory containing one or more configuration files. | Name | Description | . | -cd | Directory containing multiple security plugin configuration files. | . | -f | Single configuration file. Can’t be used with -cd. | . | -t | File type. | . | -rl | Reload the current configuration and flush the internal cache. | . To upload all configuration files in a directory, use this: ./securityadmin.sh -cd ../securityconfig -ts ... -tspass ... -ks ... -kspass ... If you want to push a single configuration file, use this: ./securityadmin.sh -f ../securityconfig/internal_users.yml -t internalusers \\ -ts ... -tspass ... -ks ... -kspass ... The file type must be one of the following: . | config | roles | rolesmapping | internalusers | actiongroups | . Cipher settings . You probably won’t need to change cipher settings. If you need to, use the following options. | Name | Description | . | -ec | Comma-separated list of enabled TLS ciphers. | . | -ep | Comma-separated list of enabled TLS protocols. | . Backup, restore, and migrate . You can download all current configuration files from your cluster with the following command: ./securityadmin.sh -backup /file/path -ts ... -tspass ... -ks ... -kspass ... This command dumps the current security plugin configuration from your cluster to individual files in the directory you specify. You can then use these files as backups or to load the configuration into a different cluster. This command is useful when moving a proof-of-concept to production: ./securityadmin.sh -backup ~ -icl -nhnv -cacert ../../../config/root-ca.pem -cert ../../../config/kirk.pem -key ../../../config/kirk-key.pem . To upload the dumped files to another cluster: ./securityadmin.sh -h production.example.com -p 9301 -cd /etc/backup/ -ts ... -tspass ... -ks ... -kspass ... To migrate configuration YAML files from the Open Distro for Elasticsearch 0.x.x format to the 1.x.x format: ./securityadmin.sh -migrate ../securityconfig -ts ... -tspass ... -ks ... -kspass ... | Name | Description | . | -backup | Retrieve the current security plugin configuration from a running cluster and dump it to the working directory. | . | -migrate | Migrate configuration YAML files from version 0.x.x to 1.x.x. | . Other options . | Name | Description | . | -dci | Delete the security plugin configuration index and exit. This option is useful if the cluster state is red due to a corrupted security plugin index. | . | -esa | Enable shard allocation and exit. This option is useful if you disabled shard allocation while performing a full cluster restart and need to recreate the security plugin index. | . | -w | Displays information about the used admin certificate. | . | -rl | By default, the security plugin caches authenticated users, along with their roles and permissions, for one hour. This option reloads the current security plugin configuration stored in your cluster, invalidating any cached users, roles, and permissions. | . | -i | The security plugin index name. Default is .opendistro_security. | . | -er | Set explicit number of replicas or auto-expand expression for the opendistro_security index. | . | -era | Enable replica auto-expand. | . | -dra | Disable replica auto-expand. | . | -us | Update the replica settings. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/#using-securityadmin-with-keystore-and-truststore-files",
    "relUrl": "/docs/security/configuration/security-admin/#using-securityadmin-with-keystore-and-truststore-files"
  },"715": {
    "doc": "Apply Changes with securityadmin.sh",
    "title": "Apply Changes with securityadmin.sh",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/security-admin/",
    "relUrl": "/docs/security/configuration/security-admin/"
  },"716": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "securityadmin.sh Troubleshooting",
    "content": "This page includes troubleshooting steps for securityadmin.sh. . | Cluster not reachable . | Check hostname | Check the port | . | None of the configured nodes are available . | Check cluster name | Check hostname verification | Check cluster state | Check the security index name | . | “ERR: DN is not an admin user” | Use the diagnose option | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/#securityadminsh-troubleshooting",
    "relUrl": "/docs/troubleshoot/security-admin/#securityadminsh-troubleshooting"
  },"717": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "Cluster not reachable",
    "content": "If securityadmin.sh can’t reach the cluster, it outputs: . Open Distro Security Admin v6 Will connect to localhost:9300 ERR: Seems there is no elasticsearch running on localhost:9300 - Will exit . Check hostname . By default, securityadmin.sh uses localhost. If your cluster runs on any other host, specify the hostname using the -h option. Check the port . Check that you are running securityadmin.sh against the transport port, not the HTTP port. By default, securityadmin.sh uses 9300. If your cluster runs on a different port, use the -p option to specify the port number. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/#cluster-not-reachable",
    "relUrl": "/docs/troubleshoot/security-admin/#cluster-not-reachable"
  },"718": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "None of the configured nodes are available",
    "content": "If securityadmin.sh can reach the cluster, but can’t update the configuration, it outputs: . Contacting elasticsearch cluster 'elasticsearch' and wait for YELLOW clusterstate ... Cannot retrieve cluster state due to: None of the configured nodes are available: [{#transport#-1}{mr2NlX3XQ3WvtVG0Dv5eHw}{localhost}{127.0.0.1:9300}]. This is not an error, will keep on trying ... * Try running securityadmin.sh.sh with -icl and -nhnv (If thats works you need to check your clustername as well as hostnames in your SSL certificates) * If this is not working, try running securityadmin.sh.sh with --diagnose and see diagnose trace log file) * Add --accept-red-cluster to allow securityadmin.sh to operate on a red cluster. Check cluster name . By default, securityadmin.sh uses elasticsearch as the cluster name. If your cluster has a different name, you can either ignore the name completely using the -icl option or specify the name using the -cn option. Check hostname verification . By default, securityadmin.sh verifies that the hostname in your node’s certificate matches the node’s actual hostname. If this is not the case (e.g. if you’re using the demo certificates), you can disable hostname verification by adding the -nhnv option. Check cluster state . By default, securityadmin.sh only executes if the cluster state is at least yellow. If your cluster state is red, you can still execute securityadmin.sh, but you need to add the -arc option. Check the security index name . By default, the security plugin uses opendistro_security as the name of the configuration index. If you configured a different index name in elasticsearch.yml, specify it using the -i option. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/#none-of-the-configured-nodes-are-available",
    "relUrl": "/docs/troubleshoot/security-admin/#none-of-the-configured-nodes-are-available"
  },"719": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "“ERR: DN is not an admin user”",
    "content": "If the TLS certificate used to start securityadmin.sh isn’t an admin certificate, the script outputs: . Connected as CN=node-0.example.com,OU=SSL,O=Test,L=Test,C=DE ERR: CN=node-0.example.com,OU=SSL,O=Test,L=Test,C=DE is not an admin user . You must use an admin certificate when executing the script. To learn more, see Configure admin certificates. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/#err-dn-is-not-an-admin-user",
    "relUrl": "/docs/troubleshoot/security-admin/#err-dn-is-not-an-admin-user"
  },"720": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "Use the diagnose option",
    "content": "For more information on why securityadmin.sh is not executing, add the --diagnose option: ./securityadmin.sh -diagnose -cd ../securityconfig/ -cacert ... -cert ... -key ... -keypass ... The script prints the location of the generated diagnostic file. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/#use-the-diagnose-option",
    "relUrl": "/docs/troubleshoot/security-admin/#use-the-diagnose-option"
  },"721": {
    "doc": "Troubleshoot securityadmin.sh",
    "title": "Troubleshoot securityadmin.sh",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/security-admin/",
    "relUrl": "/docs/troubleshoot/security-admin/"
  },"722": {
    "doc": "Security Roles",
    "title": "Security roles",
    "content": "If you use the security plugin alongside alerting, you might want to limit certain users to certain permissions. For example, you might want some users to only be able to view and acknowledge alerts, while others can create monitors and destinations. This page contains some sample roles for common use cases. Mix and match these roles to give users the permissions they need to use the alerting feature. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/security-roles/#security-roles",
    "relUrl": "/docs/alerting/security-roles/#security-roles"
  },"723": {
    "doc": "Security Roles",
    "title": "View and acknowledge alerts",
    "content": ". | In Kibana, choose Security, Roles. | Create a new security role named alerting_alerts. | In the Index Permissions tab, choose Add index permissions. | Specify the .opendistro-alerting-alerts index pattern. | Add the crud action group and Save role definition. | Choose Role Mappings. | Map the alerting_alerts role to the desired users or backend roles. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/security-roles/#view-and-acknowledge-alerts",
    "relUrl": "/docs/alerting/security-roles/#view-and-acknowledge-alerts"
  },"724": {
    "doc": "Security Roles",
    "title": "Create, update, and delete monitors and destinations",
    "content": ". | In Kibana, choose Security, Roles. | Create a new security role named alerting_monitors. | In the Index Permissions tab, choose Add index permissions. | Specify the .opendistro-alerting-config index pattern. | Add the crud action group and Save role definition. | Choose Role Mappings. | Map the alerting_monitors role to the desired users or backend roles. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/security-roles/#create-update-and-delete-monitors-and-destinations",
    "relUrl": "/docs/alerting/security-roles/#create-update-and-delete-monitors-and-destinations"
  },"725": {
    "doc": "Security Roles",
    "title": "Read-only",
    "content": ". | In Kibana, choose Security, Roles. | Create a new security role named alerting_read_only. | In the Index Permissions tab, choose Add index permissions. | Specify the .opendistro-alerting-alerts index pattern. | Choose Add index pattern to add a second index pattern. | Specify the .opendistro-alerting-config index pattern. | Choose the read action group and Save role definition. | Choose Role Mappings. | Map the alerting_read_only role to the desired users or backend roles. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/security-roles/#read-only",
    "relUrl": "/docs/alerting/security-roles/#read-only"
  },"726": {
    "doc": "Security Roles",
    "title": "Security Roles",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/security-roles/",
    "relUrl": "/docs/alerting/security-roles/"
  },"727": {
    "doc": "Settings and Statistics",
    "title": "KNN Settings and statistics",
    "content": "The KNN plugin adds several new index settings, cluster settings, and statistics. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/settings/#knn-settings-and-statistics",
    "relUrl": "/docs/knn/settings/#knn-settings-and-statistics"
  },"728": {
    "doc": "Settings and Statistics",
    "title": "Index settings",
    "content": "The default values should work well for most use cases, but you can change these settings when you create the index. | Setting | Default | Description | . | index.knn.algo_param.ef_search | 512 | The size of the dynamic list used during KNN searches. Higher values lead to more accurate, but slower searches. | . | index.knn.algo_param.ef_construction | 512 | The size of the dynamic list used during KNN graph creation. Higher values lead to a more accurate graph, but slower indexing speed. | . | index.knn.algo_param.m | 16 | The number of bidirectional links that the plugin creates for each new element. Increasing and decreasing this value can have a large impact on memory consumption. Keep this value between 2-100. | . | index.knn.space_type | “l2” | The vector space used to calculate the distance between vectors. Currently, the KNN plugin supports the l2 space (Euclidean distance) and cosinesimil space (cosine similarity). For more information on these spaces, refer to the NMSLIB documentation. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/settings/#index-settings",
    "relUrl": "/docs/knn/settings/#index-settings"
  },"729": {
    "doc": "Settings and Statistics",
    "title": "Cluster settings",
    "content": "| Setting | Default | Description | . | knn.algo_param.index_thread_qty | 1 | The number of threads used for graph creation. Keeping this value low reduces the CPU impact of the KNN plugin, but also reduces indexing performance. | . | knn.cache.item.expiry.enabled | false | Whether to remove graphs that have not been accessed for a certain duration from memory. | . | knn.cache.item.expiry.minutes | 3h | If enabled, the idle time before removing a graph from memory. | . | knn.circuit_breaker.unset.percentage | 75.0 | The native memory usage threshold for the circuit breaker. Memory usage must be below this percentage of knn.memory.circuit_breaker.limit for knn.circuit_breaker.triggered to remain false. | . | knn.circuit_breaker.triggered | false | True when memory usage exceeds the knn.circuit_breaker.unset.percentage value. | . | knn.memory.circuit_breaker.limit | 60% | The native memory limit for graphs. At the default value, if a machine has 100 GB of memory and the JVM uses 32 GB, KNN uses 60% of the remaining 68 GB (40.8 GB). If memory usage exceeds this value, KNN removes the least recently used graphs. | . | knn.memory.circuit_breaker.enabled | true | Whether to enable the KNN memory circuit breaker. | . | knn.plugin.enabled | true | Enables or disables the KNN plugin. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/settings/#cluster-settings",
    "relUrl": "/docs/knn/settings/#cluster-settings"
  },"730": {
    "doc": "Settings and Statistics",
    "title": "Statistics",
    "content": "KNN includes statistics that can give you a sense for how the plugin is performing: . GET _opendistro/_knn/stats . You can also filter by node and/or statistic: . GET /_opendistro/_knn/nodeId1,nodeId2/stats/statName1,statName2 . | Statistic | Description | . | totalLoadTime | The time in nanoseconds that KNN has taken to load graphs into the cache. | . | evictionCount | The number of graphs that have been evicted from the cache due to memory constraints or idle time. | . | hitCount | The number of cache hits. A cache hit occurs when a user queries a graph and it is already loaded into memory. | . | cacheCapacityReached | Whether knn.memory.circuit_breaker.limit has been reached. | . | loadSuccessCount | The number of times KNN successfully loaded a graph into the cache. | . | graphMemoryUsage | Current cache size (total size of all graphs in memory) in kilobytes. | . | missCount | The number of cache misses. A cache miss occurs when a user queries a graph and it has not yet been loaded into memory. | . | loadExceptionCount | The number of times an exception occurred when trying to load a graph into the cache. | . | script_compilations | The number of times the KNN script has been compiled. This value should usually be 1 or 0, but if the cache containing the compiled scripts is filled, the KNN script might be recompiled. | . | script_compilation_errors | The number of errors during script compilation. | . | script_query_requests | The number of query requests that use the KNN script. | . | script_query_errors | The number of errors during script queries. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/settings/#statistics",
    "relUrl": "/docs/knn/settings/#statistics"
  },"731": {
    "doc": "Settings and Statistics",
    "title": "Settings and Statistics",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/knn/settings/",
    "relUrl": "/docs/knn/settings/"
  },"732": {
    "doc": "Settings",
    "title": "Settings",
    "content": "The SQL plugin adds a few settings to the standard Elasticsearch cluster settings. Most are dynamic, so you can change the default behavior of the plugin without restarting your cluster. You can update these settings like any other cluster setting: . PUT _cluster/settings { \"transient\" : { \"opendistro.sql.enabled\" : false } } . | Setting | Default | Description | . | opendistro.sql.enabled | True | Change to false to disable the plugin. | . | opendistro.sql.query.slowlog | 2 seconds | Configure the time limit (in seconds) for slow queries. The plugin logs slow queries as Slow query: elapsed=xxx (ms) in elasticsearch.log. | . | opendistro.sql.query.analysis.enabled | True | Enables or disables the query analyzer. Changing this setting to false lets you bypass strict syntactic and semantic analysis. | . | opendistro.sql.query.analysis.semantic.suggestion | False | If enabled, the query analyzer suggests correct field names for quick fixes. | . | opendistro.sql.query.analysis.semantic.threshold | 200 | Because query analysis needs to build semantic context in memory, indices with a large number of fields are be skipped. You can update this setting to apply analysis to smaller or larger indices as needed. | . | opendistro.sql.query.response.format | JDBC | Sets the default response format for queries. The supported formats are JDBC, JSON, CSV, raw, and table. | . | opendistro.sql.cursor.enabled | False | You can enable or disable pagination for all queries that are supported. | . | opendistro.sql.cursor.fetch_size | 1,000 | You can set the default fetch_size for all queries that are supported by pagination. An explicit fetch_size passed in request overrides this value. | . | opendistro.sql.cursor.keep_alive | 1 minute | This value configures how long the cursor context is kept open. Cursor contexts are resource heavy, so we recommend a low value. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/settings/",
    "relUrl": "/docs/sql/settings/"
  },"733": {
    "doc": "Settings",
    "title": "ISM Settings",
    "content": "We don’t recommend changing these settings; the defaults should work well for most use cases. Index State Management (ISM) stores its configuration in the .opendistro-ism-config index. Don’t modify this index without using the ISM API operations. All settings are available using the Elasticsearch _cluster/settings operation. None require a restart, and all can be marked persistent or transient. | Setting | Default | Description | . | opendistro.index_state_management.enabled | True | Specifies whether ISM is enabled or not. | . | opendistro.index_state_management.job_interval | 5 minutes | The interval at which the managed index jobs are run. | . | opendistro.index_state_management.coordinator.sweep_period | 10 minutes | How often the routine background sweep is run. | . | opendistro.index_state_management.coordinator.backoff_millis | 50 milliseconds | The backoff time between retries for failures in the ManagedIndexCoordinator (such as when we update managed indices). | . | opendistro.index_state_management.coordinator.backoff_count | 2 | The count of retries for failures in the ManagedIndexCoordinator. | . | opendistro.index_state_management.history.enabled | True | Specifies whether audit history is enabled or not. The logs from ISM are automatically indexed to a logs document. | . | opendistro.index_state_management.history.max_docs | 2,500,000 | The maximum number of documents before rolling over the audit history index. | . | opendistro.index_state_management.history.max_age | 24 hours | The maximum age before rolling over the audit history index. | . | opendistro.index_state_management.history.rollover_check_period | 8 hours | The time between rollover checks for the audit history index. | . | opendistro.index_state_management.history.rollover_retention_period | 30 days | How long audit history indices are kept. | . | opendistro.index_state_management.allow_list | All actions | List of actions that you can use. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/settings/#ism-settings",
    "relUrl": "/docs/ism/settings/#ism-settings"
  },"734": {
    "doc": "Settings",
    "title": "Audit history indices",
    "content": "If you don’t want to disable ISM audit history or shorten the retention period, you can create an index template to reduce the shard count of the history indices: . PUT _index_template/ism_history_indices { \"index_patterns\": [ \".opendistro-ism-managed-index-history-*\" ], \"settings\": { \"number_of_shards\": 1, \"number_of_replicas\": 0 } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/settings/#audit-history-indices",
    "relUrl": "/docs/ism/settings/#audit-history-indices"
  },"735": {
    "doc": "Settings",
    "title": "Settings",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ism/settings/",
    "relUrl": "/docs/ism/settings/"
  },"736": {
    "doc": "Management",
    "title": "Management",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/settings/",
    "relUrl": "/docs/alerting/settings/"
  },"737": {
    "doc": "Management",
    "title": "Alerting indices",
    "content": "The alerting feature creates several indices and one alias. Don’t delete these or modify their contents without using the alerting APIs. | Index | Purpose | . | .opendistro-alerting-alerts | Stores ongoing alerts. | . | .opendistro-alerting-alert-history-&lt;date&gt; | Stores a history of completed alerts. | . | .opendistro-alerting-config | Stores monitors, triggers, and destinations. Take a snapshot of this index to back up your alerting configuration. | . | .opendistro-alerting-alert-history-write (alias) | Provides a consistent URI for the .opendistro-alerting-alert-history-&lt;date&gt; index. | . All alerting indices are hidden by default. For a summary, make the following request: . GET _cat/indices?expand_wildcards=open,hidden . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/settings/#alerting-indices",
    "relUrl": "/docs/alerting/settings/#alerting-indices"
  },"738": {
    "doc": "Management",
    "title": "Alerting settings",
    "content": "We don’t recommend changing these settings; the defaults should work well for most use cases. All settings are available using the Elasticsearch _cluster/settings API. None require a restart, and all can be marked persistent or transient. | Setting | Default | Description | . | opendistro.scheduled_jobs.enabled | true | Whether the alerting plugin is enabled or not. If disabled, all monitors immediately stop running. | . | opendistro.alerting.index_timeout | 60s | The timeout for creating monitors and destinations using the REST APIs. | . | opendistro.alerting.request_timeout | 10s | The timeout for miscellaneous requests from the plugin. | . | opendistro.alerting.action_throttle_max_value | 24h | The maximum amount of time you can set for action throttling. By default, this value displays as 1440 minutes in Kibana. | . | opendistro.alerting.input_timeout | 30s | How long the monitor can take to issue the search request. | . | opendistro.alerting.bulk_timeout | 120s | How long the monitor can write alerts to the alert index. | . | opendistro.alerting.alert_backoff_count | 2 | The number of retries for writing alerts before the operation fails. | . | opendistro.alerting.alert_backoff_millis | 50ms | The amount of time to wait between retries—increases exponentially after each failed retry. | . | opendistro.alerting.alert_history_rollover_period | 12h | How frequently to check whether the .opendistro-alerting-alert-history-write alias should roll over to a new history index and whether the Alerting plugin should delete any history indices. | . | opendistro.alerting.move_alerts_backoff_millis | 250 | The amount of time to wait between retries—increases exponentially after each failed retry. | . | opendistro.alerting.move_alerts_backoff_count | 3 | The number of retries for moving alerts to a deleted state after their monitor or trigger has been deleted. | . | opendistro.alerting.monitor.max_monitors | 1000 | The maximum number of monitors users can create. | . | opendistro.alerting.alert_history_max_age | 24h | The oldest document the .opendistro-alert-history-&lt;date&gt; index should keep. | . | opendistro.alerting.alert_history_max_docs | 1000 | The maximum number of documents the .opendistro-alert-history-&lt;date&gt; index should keep. | . | opendistro.alerting.alert_history_enabled | true | Whether to create .opendistro-alerting-alert-history-&lt;date&gt; indices. | . | opendistro.alerting.alert_history_retention_period | 30d | The amount of time to keep history indices before automatically deleting them. | . | opendistro.scheduled_jobs.sweeper.period | 5m | The alerting feature uses its “job sweeper” component to periodically check for new or updated jobs. This setting is the rate at which the sweeper checks to see if any jobs (monitors) have changed and need to be rescheduled. | . | opendistro.scheduled_jobs.sweeper.page_size | 100 | The page size for the sweeper. You shouldn’t need to change this value. | . | opendistro.scheduled_jobs.sweeper.backoff_millis | 50ms | The amount of time the sweeper waits between retries—increases exponentially after each failed retry. | . | opendistro.scheduled_jobs.sweeper.retry_count | 3 | The total number of times the sweeper should retry before throwing an error. | . | opendistro.scheduled_jobs.request_timeout | 10s | The timeout for the request that sweeps shards for jobs. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/alerting/settings/#alerting-settings",
    "relUrl": "/docs/alerting/settings/#alerting-settings"
  },"739": {
    "doc": "Settings",
    "title": "Settings",
    "content": "The PPL plugin adds a few settings to the standard Elasticsearch cluster settings. Most are dynamic, so you can change the default behavior of the plugin without restarting your cluster. You can update these settings like any other cluster setting: . PUT _cluster/settings { \"transient\": { \"opendistro\": { \"ppl\": { \"enabled\": \"false\" } } } } . Requests to _opendistro/_ppl include index names in the request body, so they have the same access policy considerations as the bulk, mget, and msearch operations. If you set the rest.action.multi.allow_explicit_index parameter to false, the PPL plugin is disabled. You can specify the settings shown in the following table: . | Setting | Description | Default | . | opendistro.ppl.enabled | Change to false to disable the plugin. | True | . | opendistro.ppl.query.memory_limit | Set heap memory usage limit. If a query crosses this limit, it’s terminated. | 85% | . | opendistro.query.size_limit | Set the maximum number of results that you want to see. This impacts the accuracy of aggregation operations. For example, if you have 1000 documents in an index, by default, only 200 documents are extracted from the index for aggregation. | 200 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/ppl/settings/",
    "relUrl": "/docs/ppl/settings/"
  },"740": {
    "doc": "Take and Restore Snapshots",
    "title": "Take and restore snapshots",
    "content": "Snapshots are backups of a cluster’s indices and state. State includes cluster settings, node information, index settings, and shard allocation. Snapshots have two main uses: . | Recovering from failure . For example, if cluster health goes red, you might restore the red indices from a snapshot. | Migrating from one cluster to another . For example, if you are moving from a proof-of-concept to a production cluster, you might take a snapshot of the former and restore it on the latter. | . | About snapshots | Register repository . | Shared file system | Amazon S3 | . | Take snapshots | Restore snapshots . | Conflicts and compatibility | . | Security plugin considerations | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#take-and-restore-snapshots",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#take-and-restore-snapshots"
  },"741": {
    "doc": "Take and Restore Snapshots",
    "title": "About snapshots",
    "content": "Snapshots are not instantaneous; they take time to complete and do not represent perfect point-in-time views of the cluster. While a snapshot is in-progress, you can still index documents and make other requests to the cluster, but new documents (and updates to existing documents) generally aren’t included in the snapshot. The snapshot includes primary shards as they existed when Elasticsearch initiated the snapshot. Depending on the size of your snapshot thread pool, different shards might be included in the snapshot at slightly different times. Elasticsearch snapshots are incremental, meaning that they only store data that has changed since the last successful snapshot. The difference in disk usage between frequent and infrequent snapshots is often minimal. In other words, taking hourly snapshots for a week (for a total of 168 snapshots) might not use much more disk space than taking a single snapshot at the end of the week. Also, the more frequently you take snapshots, the less time they take to complete. Some Elasticsearch users take snapshots as often as every half hour. If you need to delete a snapshot, be sure to use the Elasticsearch API rather than navigating to the storage location and purging files. Incremental snapshots from a cluster often share a lot of the same data; when you use the API, Elasticsearch only removes data that no other snapshot is using. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#about-snapshots",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#about-snapshots"
  },"742": {
    "doc": "Take and Restore Snapshots",
    "title": "Register repository",
    "content": "Before you can take a snapshot, you have to “register” a snapshot repository. A snapshot repository is really just a storage location: a shared file system, Amazon S3, Hadoop Distributed File System (HDFS), Azure Storage, etc. Shared file system . | To use a shared file system as a snapshot repository, add it to elasticsearch.yml: . path.repo: [\"/mnt/snapshots\"] . On the RPM and Debian installs, you can then mount the file system. If you’re using the Docker install, add the file system to each node in docker-compose.yml before starting the cluster: . volumes: - /Users/jdoe/snapshots:/mnt/snapshots . | Then register the repository using the REST API: . PUT _snapshot/my-fs-repository { \"type\": \"fs\", \"settings\": { \"location\": \"/mnt/snapshots\" } } . If the request is successful, the response from Elasticsearch is minimal: . { \"acknowledged\": true } . | . You probably only need to specify location, but to summarize the options: . | Setting | Description | . | location | The shared file system for snapshots. Required. | . | chunk_size | Breaks large files into chunks during snapshot operations (e.g. 64mb, 1gb), which is important for cloud storage providers and far less important for shared file systems. Default is null (unlimited). Optional. | . | compress | Whether to compress metadata files. This setting does not affect data files, which might already be compressed (depending on your index settings). Default is false. Optional. | . | max_restore_bytes_per_sec | The maximum rate at which snapshots restore. Default is 40 MB per second (40m). Optional. | . | max_snapshot_bytes_per_sec | The maximum rate at which snapshots take. Default is 40 MB per second (40m). Optional. | . | readonly | Whether the repository is read-only. Useful when migrating from one cluster (\"readonly\": false when registering) to another cluster (\"readonly\": true when registering). Optional. | . Amazon S3 . | To use an Amazon S3 bucket as a snapshot repository, install the repository-s3 plugin on all nodes: . sudo ./bin/elasticsearch-plugin install repository-s3 . If you’re using the Docker installation, see Customize the Docker image. Your Dockerfile should look something like this: . FROM amazon/opendistro-for-elasticsearch:1.11.0 ENV AWS_ACCESS_KEY_ID &lt;access-key&gt; ENV AWS_SECRET_ACCESS_KEY &lt;secret-key&gt; # Optional ENV AWS_SESSION_TOKEN &lt;optional-session-token&gt; RUN /usr/share/elasticsearch/bin/elasticsearch-plugin install --batch repository-s3 RUN /usr/share/elasticsearch/bin/elasticsearch-keystore create RUN echo $AWS_ACCESS_KEY_ID | /usr/share/elasticsearch/bin/elasticsearch-keystore add --stdin s3.client.default.access_key RUN echo $AWS_SECRET_ACCESS_KEY | /usr/share/elasticsearch/bin/elasticsearch-keystore add --stdin s3.client.default.secret_key # Optional RUN echo $AWS_SESSION_TOKEN | /usr/share/elasticsearch/bin/elasticsearch-keystore add --stdin s3.client.default.session_token . After the Docker cluster starts, skip to step 7. | Add your AWS access and secret keys to the Elasticsearch keystore: . sudo ./bin/elasticsearch-keystore add s3.client.default.access_key sudo ./bin/elasticsearch-keystore add s3.client.default.secret_key . | (Optional) If you’re using temporary credentials, add your session token: . sudo ./bin/elasticsearch-keystore add s3.client.default.session_token . | (Optional) If you connect to the internet through a proxy, add those credentials: . sudo ./bin/elasticsearch-keystore add s3.client.default.proxy.username sudo ./bin/elasticsearch-keystore add s3.client.default.proxy.password . | (Optional) Add other settings to elasticsearch.yml: . s3.client.default.disable_chunked_encoding: false # Disables chunked encoding for compatibility with some storage services, but you probably don't need to change this value. s3.client.default.endpoint: s3.amazonaws.com # S3 has alternate endpoints, but you probably don't need to change this value. s3.client.default.max_retries: 3 # number of retries if a request fails s3.client.default.path_style_access: false # whether to use the deprecated path-style bucket URLs. # You probably don't need to change this value, but for more information, see https://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html#path-style-access. s3.client.default.protocol: https # http or https s3.client.default.proxy.host: my-proxy-host # the hostname for your proxy server s3.client.default.proxy.port: 8080 # port for your proxy server s3.client.default.read_timeout: 50s # the S3 connection timeout s3.client.default.use_throttle_retries: true # whether the client should wait a progressively longer amount of time (exponential backoff) between each successive retry . | If you changed elasticsearch.yml, you must restart each node in the cluster. Otherwise, you only need to reload secure cluster settings: . POST _nodes/reload_secure_settings . | Create an S3 bucket if you don’t already have one. To take snapshots, you must have permissions to access the bucket. The following IAM policy is an example of those permissions: . { \"Version\": \"2012-10-17\", \"Statement\": [{ \"Action\": [ \"s3:*\" ], \"Effect\": \"Allow\", \"Resource\": [ \"arn:aws:s3:::your-bucket\", \"arn:aws:s3:::your-bucket/*\" ] }] } . | Register the repository using the REST API: . PUT _snapshot/my-s3-repository { \"type\": \"s3\", \"settings\": { \"bucket\": \"my-s3-bucket\", \"base_path\": \"my/snapshot/directory\" } } . | . You probably don’t need to specify anything but bucket and base_path, but to summarize the options: . | Setting | Description | . | base_path | The path within the bucket where you want to store snapshots (e.g. my/snapshot/directory). Optional. If not specified, snapshots are stored in the bucket root. | . | bucket | Name of the S3 bucket. Required. | . | buffer_size | The threshold beyond which chunks (of chunk_size) should be broken into pieces (of buffer_size) and sent to S3 using a different API. Default is the smaller of two values: 100 MB or 5% of the Java heap. Valid values are between 5mb and 5gb. We don’t recommend changing this option. | . | canned_acl | S3 has several canned ACLs that the repository-s3 plugin can add to objects as it creates them in S3. Default is private. Optional. | . | chunk_size | Breaks files into chunks during snapshot operations (e.g. 64mb, 1gb), which is important for cloud storage providers and far less important for shared file systems. Default is 1gb. Optional. | . | client | When specifying client settings (e.g. s3.client.default.access_key), you can use a string other than default (e.g. s3.client.backup-role.access_key). If you used an alternate name, change this value to match. Default and recommended value is default. Optional. | . | compress | Whether to compress metadata files. This setting does not affect data files, which depending on your index settings, might already be compressed. Default is false. Optional. | . | max_restore_bytes_per_sec | The maximum rate at which snapshots restore. Default is 40 MB per second (40m). Optional. | . | max_snapshot_bytes_per_sec | The maximum rate at which snapshots take. Default is 40 MB per second (40m). Optional. | . | readonly | Whether the repository is read-only. Useful when migrating from one cluster (\"readonly\": false when registering) to another cluster (\"readonly\": true when registering). Optional. | . | server_side_encryption | Whether to encrypt snapshot files in the S3 bucket. This setting uses AES-256 with S3-managed keys. See Protecting Data Using Server-Side Encryption. Default is false. Optional. | . | storage_class | Specifies the S3 storage class for the snapshots files. Default is standard. Do not use the glacier and deep_archive storage classes. Optional. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#register-repository",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#register-repository"
  },"743": {
    "doc": "Take and Restore Snapshots",
    "title": "Take snapshots",
    "content": "You specify two pieces of information when you create a snapshot: . | Name of your snapshot repository | Name for the snapshot | . The following snapshot includes all indices and the cluster state: . PUT _snapshot/my-repository/1 . You can also add a request body to include or exclude certain indices or specify some other settings: . PUT _snapshot/my-repository/2 { \"indices\": \"kibana*,my-index*,-my-index-2016\", \"ignore_unavailable\": true, \"include_global_state\": false, \"partial\": false } . | Setting | Description | . | indices | The indices that you want to include in the snapshot. You can use , to create a list of indices, * to specify an index pattern, and - to exclude certain indices. Don’t put spaces between items. Default is all indices. | . | ignore_unavailable | If an index from the indices list doesn’t exist, whether to ignore it rather than fail the snapshot. Default is false. | . | include_global_state | Whether to include cluster state in the snapshot. Default is true. | . | partial | Whether to allow partial snapshots. Default is false, which fails the entire snapshot if one or more shards fails to store. | . If you request the snapshot immediately after taking it, you might see something like: . GET _snapshot/my-repository/2 { \"snapshots\": [{ \"snapshot\": \"2\", \"version\": \"6.5.4\", \"indices\": [ \"kibana_sample_data_ecommerce\", \"my-index\", \"kibana_sample_data_logs\", \"kibana_sample_data_flights\" ], \"include_global_state\": true, \"state\": \"IN_PROGRESS\", ... }] } . Note that the snapshot is still in progress. If you want to wait for the snapshot to finish before continuing, add the wait_for_completion parameter to your request. Snapshots can take a while to complete, though, so consider whether or not this option fits your use case: . PUT _snapshot/my-repository/3?wait_for_completion=true . Snapshots have the following states: . | State | Description | . | SUCCESS | The snapshot successfully stored all shards. | . | IN_PROGRESS | The snapshot is currently running. | . | PARTIAL | At least one shard failed to store successfully. Can only occur if you set partial to true when taking the snapshot. | . | FAILED | The snapshot encountered an error and stored no data. | . | INCOMPATIBLE | The snapshot is incompatible with the version of Elasticsearch running on this cluster. See Conflicts and compatibility. | . You can’t take a snapshot if one is currently in progress. To check: . GET _snapshot/_status . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#take-snapshots",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#take-snapshots"
  },"744": {
    "doc": "Take and Restore Snapshots",
    "title": "Restore snapshots",
    "content": "The first step in restoring a snapshot is retrieving existing snapshots. To see all snapshot repositories: . GET _snapshot/_all . To see all snapshots in a repository: . GET _snapshot/my-repository/_all . Then you can restore a snapshot: . POST _snapshot/my-repository/2/_restore . Just like when taking a snapshot, you can add a request body to include or exclude certain indices or specify some other settings: . POST _snapshot/my-repository/2/_restore { \"indices\": \"kibana*,my-index*\", \"ignore_unavailable\": true, \"include_global_state\": false, \"include_aliases\": false, \"partial\": false, \"rename_pattern\": \"kibana(.+)\", \"rename_replacement\": \"restored-kibana$1\", \"index_settings\": { \"index.blocks.read_only\": false }, \"ignore_index_settings\": [ \"index.refresh_interval\" ] } . | Setting | Description | . | indices | The indices that you want to restore. You can use , to create a list of indices, * to specify an index pattern, and - to exclude certain indices. Don’t put spaces between items. Default is all indices. | . | ignore_unavailable | If an index from the indices list doesn’t exist, whether to ignore it rather than fail the restore operation. Default is false. | . | include_global_state | Whether to restore the cluster state. Default is false. | . | include_aliases | Whether to restore aliases alongside their associated indices. Default is true. | . | partial | Whether to allow the restoration of partial snapshots. Default is false. | . | rename_pattern | If you want to rename indices as you restore them, use this option to specify a regular expression that matches all indices you want to restore. Use capture groups (()) to reuse portions of the index name. | . | rename_replacement | If you want to rename indices as you restore them, use this option to specify the replacement pattern. Use $0 to include the entire matching index name, $1 to include the content of the first capture group, etc. | . | index_settings | If you want to change index settings on restore, specify them here. | . | ignore_index_settings | Rather than explicitly specifying new settings with index_settings, you can ignore certain index settings in the snapshot and use the cluster defaults on restore. | . Conflicts and compatibility . One way to avoid naming conflicts when restoring indices is to use the rename_pattern and rename_replacement options. Then, if necessary, you can use the _reindex API to combine the two. The simpler way is to delete existing indices prior to restoring from a snapshot. You can use the _close API to close existing indices prior to restoring from a snapshot, but the index in the snapshot has to have the same number of shards as the existing index. We recommend ceasing write requests to a cluster before restoring from a snapshot, which helps avoid scenarios such as: . | You delete an index, which also deletes its alias. | A write request to the now-deleted alias creates a new index with the same name as the alias. | The alias from the snapshot fails to restore due to a naming conflict with the new index. | . Snapshots are only forward-compatible, and only by one major version. For example, snapshots taken on a 2.x cluster can’t be restored on a 1.x cluster or a 6.x cluster, but they can be restored on a 2.x or 5.x cluster. If you have an old snapshot, you can sometimes restore it into an intermediate cluster, reindex all indices, take a new snapshot, and repeat until you arrive at your desired version, but you might find it easier to just manually index your data on the new cluster. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#restore-snapshots",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#restore-snapshots"
  },"745": {
    "doc": "Take and Restore Snapshots",
    "title": "Security plugin considerations",
    "content": "If you are using the security plugin, snapshots have some additional restrictions: . | In order to perform snapshot and restore operations, users must have the built-in manage_snapshots role. | You can’t restore snapshots that contain global state or the .opendistro_security index. | . If a snapshot contains global state, you must exclude it when performing the restore. If your snapshot also contains the .opendistro_security index, either exclude it or list all the other indices that you want to include: . POST _snapshot/my-repository/3/_restore { \"indices\": \"-.opendistro_security\", \"include_global_state\": false } . The .opendistro_security index contains sensitive data, so we recommend excluding it when you take a snapshot. If you do need to restore the index from a snapshot, you must include an admin certificate in the request: . curl -k --cert chain.pem --key kirk.key.pem -XPOST 'https://localhost:9200/_snapshot/my-repository/3/_restore?pretty' . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/#security-plugin-considerations",
    "relUrl": "/docs/elasticsearch/snapshot-restore/#security-plugin-considerations"
  },"746": {
    "doc": "Take and Restore Snapshots",
    "title": "Take and Restore Snapshots",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/snapshot-restore/",
    "relUrl": "/docs/elasticsearch/snapshot-restore/"
  },"747": {
    "doc": "Full-Text Search",
    "title": "Full-text search",
    "content": "Use SQL commands for full-text search. The SQL plugin supports a subset of the full-text queries available in Elasticsearch. To learn about full-text queries in Elasticsearch, see Full-text queries. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#full-text-search",
    "relUrl": "/docs/sql/sql-full-text/#full-text-search"
  },"748": {
    "doc": "Full-Text Search",
    "title": "Match",
    "content": "To search for text in a single field, use MATCHQUERY or MATCH_QUERY functions. Pass in your search query and the field name that you want to search against. SELECT account_number, address FROM accounts WHERE MATCH_QUERY(address, 'Holmes') . Alternate syntax: . SELECT account_number, address FROM accounts WHERE address = MATCH_QUERY('Holmes') . | account_number | address | . | 1 | 880 Holmes Lane | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#match",
    "relUrl": "/docs/sql/sql-full-text/#match"
  },"749": {
    "doc": "Full-Text Search",
    "title": "Multi match",
    "content": "To search for text in multiple fields, use MULTI_MATCH, MULTIMATCH, or MULTIMATCHQUERY functions. For example, search for Dale in either the firstname or lastname fields: . SELECT firstname, lastname FROM accounts WHERE MULTI_MATCH('query'='Dale', 'fields'='*name') . | firstname | lastname | . | Dale | Adams | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#multi-match",
    "relUrl": "/docs/sql/sql-full-text/#multi-match"
  },"750": {
    "doc": "Full-Text Search",
    "title": "Query string",
    "content": "To split text based on operators, use the QUERY function. SELECT account_number, address FROM accounts WHERE QUERY('address:Lane OR address:Street') . | account_number | address | . | 1 | 880 Holmes Lane | . | 6 | 671 Bristol Street | . | 13 | 789 Madison Street | . The QUERY function supports logical connectives, wildcard, regex, and proximity search. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#query-string",
    "relUrl": "/docs/sql/sql-full-text/#query-string"
  },"751": {
    "doc": "Full-Text Search",
    "title": "Match phrase",
    "content": "To search for exact phrases, use MATCHPHRASE, MATCH_PHRASE, or MATCHPHRASEQUERY functions. SELECT account_number, address FROM accounts WHERE MATCH_PHRASE(address, '880 Holmes Lane') . | account_number | address | . | 1 | 880 Holmes Lane | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#match-phrase",
    "relUrl": "/docs/sql/sql-full-text/#match-phrase"
  },"752": {
    "doc": "Full-Text Search",
    "title": "Score query",
    "content": "To return a relevance score along with every matching document, use SCORE, SCOREQUERY, or SCORE_QUERY functions. You need to pass in two arguments. The first is the MATCH_QUERY expression. The second is an optional floating point number to boost the score (default value is 1.0). SELECT account_number, address, _score FROM accounts WHERE SCORE(MATCH_QUERY(address, 'Lane'), 0.5) OR SCORE(MATCH_QUERY(address, 'Street'), 100) ORDER BY _score . | account_number | address | score | . | 1 | 880 Holmes Lane | 0.5 | . | 6 | 671 Bristol Street | 100 | . | 13 | 789 Madison Street | 100 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/#score-query",
    "relUrl": "/docs/sql/sql-full-text/#score-query"
  },"753": {
    "doc": "Full-Text Search",
    "title": "Full-Text Search",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/sql-full-text/",
    "relUrl": "/docs/sql/sql-full-text/"
  },"754": {
    "doc": "Audit Log Storage Types",
    "title": "Audit log storage types",
    "content": "Audit logs can take up quite a bit of space, so the security plugin offers several options for storage locations. | Setting | Description | . | debug | Outputs to stdout. Useful for testing and debugging. | . | internal_elasticsearch | Writes to an audit index on the current Elasticsearch cluster. | . | external_elasticsearch | Writes to an audit index on a remote Elasticsearch cluster. | . | webhook | Sends events to an arbitrary HTTP endpoint. | . | log4j | Writes the events to a Log4j logger. You can use any Log4j appender, such as SNMP, JDBC, Cassandra, and Kafka. | . You configure the output location in elasticsearch.yml: . opendistro_security.audit.type: &lt;debug|internal_elasticsearch|external_elasticsearch|webhook|log4j&gt; . external_elasticsearch, webhook, and log4j all have additional configuration options. Details follow. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/storage-types/#audit-log-storage-types",
    "relUrl": "/docs/security/audit-logs/storage-types/#audit-log-storage-types"
  },"755": {
    "doc": "Audit Log Storage Types",
    "title": "External Elasticsearch",
    "content": "The external_elasticsearch storage type requires one or more Elasticsearch endpoints with a host/IP address and port. Optionally, provide the index name and a document type. opendistro_security.audit.type: external_elasticsearch opendistro_security.audit.config.http_endpoints: [&lt;endpoints&gt;] opendistro_security.audit.config.index: &lt;indexname&gt; opendistro_security.audit.config.type: _doc . The security plugin uses the Elasticsearch REST API to send events, just like any other indexing request. For opendistro_security.audit.config.http_endpoints, use a comma-separated list of hosts/IP addresses and the REST port (default 9200). opendistro_security.audit.config.http_endpoints: [192.168.178.1:9200,192.168.178.2:9200] . If you use external_elasticsearch and the remote cluster also uses the security plugin, you must supply some additional parameters for authentication. These parameters depend on which authentication type you configured for the remote cluster. TLS settings . | Name | Data Type | Description | . | opendistro_security.audit.config.enable_ssl | Boolean | If you enabled SSL/TLS on the receiving cluster, set to true. The default is false. | . | opendistro_security.audit.config.verify_hostnames | Boolean | Whether to verify the hostname of the SSL/TLS certificate of the receiving cluster. Default is true. | . | opendistro_security.audit.config.pemtrustedcas_filepath | String | The trusted root certificate of the external Elasticsearch cluster, relative to the config directory. | . | opendistro_security.audit.config.pemtrustedcas_content | String | Instead of specifying the path (opendistro_security.audit.config.pemtrustedcas_filepath), you can configure the Base64-encoded certificate content directly. | . | opendistro_security.audit.config.enable_ssl_client_auth | Boolean | Whether to enable SSL/TLS client authentication. If you set this to true, the audit log module sends the node’s certificate along with the request. The receiving cluster can use this certificate to verify the identity of the caller. | . | opendistro_security.audit.config.pemcert_filepath | String | The path to the TLS certificate to send to the external Elasticsearch cluster, relative to the config directory. | . | opendistro_security.audit.config.pemcert_content | String | Instead of specifying the path (opendistro_security.audit.config.pemcert_filepath), you can configure the Base64-encoded certificate content directly. | . | opendistro_security.audit.config.pemkey_filepath | String | The path to the private key of the TLS certificate to send to the external Elasticsearch cluster, relative to the config directory. | . | opendistro_security.audit.config.pemkey_content | String | Instead of specifying the path (opendistro_security.audit.config.pemkey_filepath), you can configure the Base64-encoded certificate content directly. | . | opendistro_security.audit.config.pemkey_password | String | The password of the private key. | . Basic auth settings . If you enabled HTTP basic authentication on the receiving cluster, use these settings to specify the username and password: . opendistro_security.audit.config.username: &lt;username&gt; opendistro_security.audit.config.password: &lt;password&gt; . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/storage-types/#external-elasticsearch",
    "relUrl": "/docs/security/audit-logs/storage-types/#external-elasticsearch"
  },"756": {
    "doc": "Audit Log Storage Types",
    "title": "Webhook",
    "content": "Use the following keys to configure the webhook storage type. | Name | Data Type | Description | . | opendistro_security.audit.config.webhook.url | String | The HTTP or HTTPS URL to send the logs to. | . | opendistro_security.audit.config.webhook.ssl.verify | Boolean | If true, the TLS certificate provided by the endpoint (if any) will be verified. If set to false, no verification is performed. You can disable this check if you use self-signed certificates. | . | opendistro_security.audit.config.webhook.ssl.pemtrustedcas_filepath | String | The path to the trusted certificate against which the webhook’s TLS certificate is validated. | . | opendistro_security.audit.config.webhook.ssl.pemtrustedcas_content | String | Same as opendistro_security.audit.config.webhook.ssl.pemtrustedcas_content, but you can configure the base 64 encoded certificate content directly. | . | opendistro_security.audit.config.webhook.format | String | The format in which the audit log message is logged, can be one of URL_PARAMETER_GET, URL_PARAMETER_POST, TEXT, JSON, SLACK. See Formats. | . Formats . | Format | Description | . | URL_PARAMETER_GET | Uses HTTP GET to send logs to the webhook URL. All logged information is appended to the URL as request parameters. | . | URL_PARAMETER_POST | Uses HTTP POST to send logs to the webhook URL. All logged information is appended to the URL as request parameters. | . | TEXT | Uses HTTP POST to send logs to the webhook URL. The request body contains the audit log message in plain text format. | . | JSON | Uses HTTP POST to send logs to the webhook URL. The request body contains the audit log message in JSON format. | . | SLACK | Uses HTTP POST to send logs to the webhook URL. The request body contains the audit log message in JSON format suitable for consumption by Slack. The default implementation returns \"text\": \"&lt;AuditMessage#toText&gt;\". | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/storage-types/#webhook",
    "relUrl": "/docs/security/audit-logs/storage-types/#webhook"
  },"757": {
    "doc": "Audit Log Storage Types",
    "title": "Log4j",
    "content": "The log4j storage type lets you specify the name of the logger and log level. opendistro_security.audit.config.log4j.logger_name: audit opendistro_security.audit.config.log4j.level: INFO . By default, the security plugin uses the logger name audit and logs the events on INFO level. Audit events are stored in JSON format. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/storage-types/#log4j",
    "relUrl": "/docs/security/audit-logs/storage-types/#log4j"
  },"758": {
    "doc": "Audit Log Storage Types",
    "title": "Audit Log Storage Types",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/audit-logs/storage-types/",
    "relUrl": "/docs/security/audit-logs/storage-types/"
  },"759": {
    "doc": "Tarball",
    "title": "Tarball",
    "content": "The tarball installation works on Linux systems and provides a self-contained directory with everything you need to run Open Distro for Elasticsearch, including an integrated Java Development Kit (JDK). The tarball is a good option for testing and development, but we recommend Docker or a package manager for production deployments. The tarball supports CentOS 7, Amazon Linux 2, Ubuntu 18.04, and most other Linux distributions. If you have your own Java installation and you set JAVA_HOME in the terminal, macOS works as well. | Download the tarball: . curl https://d3g5vo6xdbdb9a.cloudfront.net/tarball/opendistro-elasticsearch/opendistroforelasticsearch-1.11.0.tar.gz -o opendistroforelasticsearch-1.11.0.tar.gz . | Download the checksum: . curl https://d3g5vo6xdbdb9a.cloudfront.net/tarball/opendistro-elasticsearch/opendistroforelasticsearch-1.11.0.tar.gz.sha512 -o opendistroforelasticsearch-1.11.0.tar.gz.sha512 . | Verify the tarball against the checksum: . shasum -a 512 -c opendistroforelasticsearch-1.11.0.tar.gz.sha512 . On CentOS, you might not have shasum. Install this package: . sudo yum install perl-Digest-SHA . Due to a known issue with the checksum, this step might fail. You can still proceed with the installation. | Extract the TAR file to a directory and change to that directory: . tar -zxf opendistroforelasticsearch-1.11.0.tar.gz cd opendistroforelasticsearch-1.11.0 . | Run Open Distro for Elasticsearch: ./opendistro-tar-install.sh . | Open a second terminal session, and send requests to the server to verify that Open Distro for Elasticsearch is up and running: . curl -XGET https://localhost:9200 -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/plugins?v -u admin:admin --insecure . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/tar/",
    "relUrl": "/docs/install/tar/"
  },"760": {
    "doc": "Tarball",
    "title": "Configuration",
    "content": "You can modify config/elasticsearch.yml or specify environment variables as arguments using -E: ./opendistro-tar-install.sh -Ecluster.name=odfe-cluster -Enode.name=odfe-node1 -Ehttp.host=0.0.0.0 -Ediscovery.type=single-node . For other settings, see Important settings. (Optional) Set up Performance Analyzer . In a tarball installation, Performance Analyzer collects data when it is enabled. But in order to read that data using the REST API on port 9600, you must first manually launch the associated reader agent process: . | Make Performance Analyzer accessible outside of the host machine . cd /usr/share/elasticsearch # navigate to the Elasticsearch home directory cd plugins/opendistro_performance_analyzer/pa_config/ vi performance-analyzer.properties . Uncomment the line #webservice-bind-host and set it to 0.0.0.0: . # ======================== Elasticsearch performance analyzer plugin config ========================= # NOTE: this is an example for Linux. Please modify the config accordingly if you are using it under other OS. # WebService bind host; default to all interfaces webservice-bind-host = 0.0.0.0 # Metrics data location metrics-location = /dev/shm/performanceanalyzer/ # Metrics deletion interval (minutes) for metrics data. # Interval should be between 1 to 60. metrics-deletion-interval = 1 # If set to true, the system cleans up the files behind it. So at any point, we should expect only 2 # metrics-db-file-prefix-path files. If set to false, no files are cleaned up. This can be useful, if you are archiving # the files and wouldn't like for them to be cleaned up. cleanup-metrics-db-files = true # WebService exposed by App's port webservice-listener-port = 9600 # Metric DB File Prefix Path location metrics-db-file-prefix-path = /tmp/metricsdb_ https-enabled = false #Setup the correct path for certificates certificate-file-path = specify_path private-key-file-path = specify_path # Plugin Stats Metadata file name, expected to be in the same location plugin-stats-metadata = plugin-stats-metadata # Agent Stats Metadata file name, expected to be in the same location agent-stats-metadata = agent-stats-metadata . | Make the CLI executable: . sudo chmod +x ./bin/performance-analyzer-agent-cli . | Launch the agent CLI: . ES_HOME=\"$PWD\" ./bin/performance-analyzer-agent-cli . | In a separate window, enable the Performance Analyzer plugin: . curl localhost:9200/_opendistro/_performanceanalyzer/cluster/config -H 'Content-Type: application/json' -d '{\"enabled\": true}' . If you receive the curl: (52) Empty reply from server error, you are likely protecting your cluster with the security plugin and need to provide identity certificates. Modify the following command to use your certificates: . curl -k --cert config/kirk.pem --key config/kirk-key.pem https://localhost:9200/_opendistro/_performanceanalyzer/cluster/config -H 'Content-Type: application/json' -d '{\"enabled\": true}' . | Finally, enable the Root Cause Analyzer (RCA) framework . curl localhost:9200/_opendistro/_performanceanalyzer/cluster/config -H 'Content-Type: application/json' -d '{\"enabled\": true}' . Similar to step 4, if you run into curl: (52) Empty reply from server, run the command below to enable RCA . curl -k --cert config/kirk.pem --key config/kirk-key.pem https://localhost:9200/_opendistro/_performanceanalyzer/rca/cluster/config -H 'Content-Type: application/json' -d '{\"enabled\": true}' . | . (Optional) Removing Performance Analyzer . See Clean up Performance Analyzer files. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/tar/#configuration",
    "relUrl": "/docs/install/tar/#configuration"
  },"761": {
    "doc": "Term-Level Queries",
    "title": "Term-level queries",
    "content": "Elasticsearch supports two types of queries when you search for data: term-level queries and full-text queries. The following table shows the differences between them: . |   | Term-level queries | Full-text queries | . | Description | Term-level queries answer which documents match a query. | Full-text queries answer how well the documents match a query. | . | Analyzer | The search term isn’t analyzed. This means that the term query searches for your search term as it is. | The search term is analyzed by the same analyzer that was used for the specific field of the document at the time it was indexed. This means that your search term goes through the same analysis process that the document’s field did. | . | Relevance | Term-level queries simply return documents that match without sorting them based on the relevance score. They still calculate the relevance score, but this score is the same for all the documents that are returned. | Full-text queries calculate a relevance score for each match and sort the results by decreasing order of relevance. | . | Use Case | Use term-level queries when you want to match exact values such as numbers, dates, tags, and so on, and don’t need the matches to be sorted by relevance. | Use full-text queries to match text fields and sort by relevance after taking into account factors like casing and stemming variants. | . Elasticsearch uses a probabilistic ranking framework called Okapi BM25 to calculate relevance scores. To learn more about Okapi BM25, see Wikipedia. Assume that you have the complete works of Shakespeare indexed in an Elasticsearch cluster. We use a term-level query to search for the phrase “To be, or not to be” in the text_entry field: . GET shakespeare/_search { \"query\": { \"term\": { \"text_entry\": \"To be, or not to be\" } } } . Sample response . { \"took\" : 3, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 0, \"relation\" : \"eq\" }, \"max_score\" : null, \"hits\" : [ ] } } . We don’t get back any matches (hits). This is because the term “To be, or not to be” is searched literally in the inverted index, where only the analyzed values of the text fields are stored. Term-level queries aren’t suited for searching on analyzed text fields because they often yield unexpected results. When working with text data, use term-level queries only for fields mapped as keyword only. Using a full-text query: . GET shakespeare/_search { \"query\": { \"match\": { \"text_entry\": \"To be, or not to be\" } } } . The search query “To be, or not to be” is analyzed and tokenized into an array of tokens just like the text_entry field of the documents. The full-text query performs an intersection of tokens between our search query and the text_entry fields for all the documents, and then sorts the results by relevance scores: . Sample response . { \"took\" : 19, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 10000, \"relation\" : \"gte\" }, \"max_score\" : 17.419369, \"hits\" : [ { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"34229\", \"_score\" : 17.419369, \"_source\" : { \"type\" : \"line\", \"line_id\" : 34230, \"play_name\" : \"Hamlet\", \"speech_number\" : 19, \"line_number\" : \"3.1.64\", \"speaker\" : \"HAMLET\", \"text_entry\" : \"To be, or not to be: that is the question:\" } }, { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"109930\", \"_score\" : 14.883024, \"_source\" : { \"type\" : \"line\", \"line_id\" : 109931, \"play_name\" : \"A Winters Tale\", \"speech_number\" : 23, \"line_number\" : \"4.4.153\", \"speaker\" : \"PERDITA\", \"text_entry\" : \"Not like a corse; or if, not to be buried,\" } }, { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"103117\", \"_score\" : 14.782743, \"_source\" : { \"type\" : \"line\", \"line_id\" : 103118, \"play_name\" : \"Twelfth Night\", \"speech_number\" : 53, \"line_number\" : \"1.3.95\", \"speaker\" : \"SIR ANDREW\", \"text_entry\" : \"will not be seen; or if she be, its four to one\" } } ] } } ... For a list of all full-text queries, see Full-text queries. If you want to query for an exact term like “HAMLET” in the speaker field and don’t need the results to be sorted by relevance scores, a term-level query is more efficient: . GET shakespeare/_search { \"query\": { \"term\": { \"speaker\": \"HAMLET\" } } } . Sample response . { \"took\" : 5, \"timed_out\" : false, \"_shards\" : { \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : { \"value\" : 1582, \"relation\" : \"eq\" }, \"max_score\" : 4.2540946, \"hits\" : [ { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"32700\", \"_score\" : 4.2540946, \"_source\" : { \"type\" : \"line\", \"line_id\" : 32701, \"play_name\" : \"Hamlet\", \"speech_number\" : 9, \"line_number\" : \"1.2.66\", \"speaker\" : \"HAMLET\", \"text_entry\" : \"[Aside] A little more than kin, and less than kind.\" } }, { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"32702\", \"_score\" : 4.2540946, \"_source\" : { \"type\" : \"line\", \"line_id\" : 32703, \"play_name\" : \"Hamlet\", \"speech_number\" : 11, \"line_number\" : \"1.2.68\", \"speaker\" : \"HAMLET\", \"text_entry\" : \"Not so, my lord; I am too much i' the sun.\" } }, { \"_index\" : \"shakespeare\", \"_type\" : \"_doc\", \"_id\" : \"32709\", \"_score\" : 4.2540946, \"_source\" : { \"type\" : \"line\", \"line_id\" : 32710, \"play_name\" : \"Hamlet\", \"speech_number\" : 13, \"line_number\" : \"1.2.75\", \"speaker\" : \"HAMLET\", \"text_entry\" : \"Ay, madam, it is common.\" } } ] } } ... The term-level queries are exact matches. So, if you search for “Hamlet”, you don’t get back any matches, because “HAMLET” is a keyword field and is stored in Elasticsearch literally and not in an analyzed form. The search query “HAMLET” is also searched literally. So, to get a match on this field, we need to enter the exact same characters. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#term-level-queries",
    "relUrl": "/docs/elasticsearch/term/#term-level-queries"
  },"762": {
    "doc": "Term-Level Queries",
    "title": "Term",
    "content": "Use the term query to search for an exact term in a field. GET shakespeare/_search { \"query\": { \"term\": { \"line_id\": { \"value\": \"61809\" } } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#term",
    "relUrl": "/docs/elasticsearch/term/#term"
  },"763": {
    "doc": "Term-Level Queries",
    "title": "Terms",
    "content": "Use the terms query to search for multiple terms in the same field. GET shakespeare/_search { \"query\": { \"terms\": { \"line_id\": [ \"61809\", \"61810\" ] } } } . You get back documents that match any of the terms. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#terms",
    "relUrl": "/docs/elasticsearch/term/#terms"
  },"764": {
    "doc": "Term-Level Queries",
    "title": "IDs",
    "content": "Use the ids query to search for one or more document ID values. GET shakespeare/_search { \"query\": { \"ids\": { \"values\": [ 34229, 91296 ] } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#ids",
    "relUrl": "/docs/elasticsearch/term/#ids"
  },"765": {
    "doc": "Term-Level Queries",
    "title": "Range",
    "content": "Use the range query to search for a range of values in a field. To search for documents where the line_id value is &gt;= 10 and &lt;= 20: . GET shakespeare/_search { \"query\": { \"range\": { \"line_id\": { \"gte\": 10, \"lte\": 20 } } } } . | Parameter | Behavior | . | gte | Greater than or equal to. | . | gt | Greater than. | . | lte | Less than or equal to. | . | lt | Less than. | . Assume that you have a products index and you want to find all the products that were added in the year 2019: . GET products/_search { \"query\": { \"range\": { \"created\": { \"gte\": \"2019/01/01\", \"lte\": \"2019/12/31\" } } } } . Specify relative dates by using basic math expressions. To subtract 1 year and 1 day from the specified date: . GET products/_search { \"query\": { \"range\": { \"created\": { \"gte\": \"2019/01/01||-1y-1d\" } } } } . The first date that we specify is the anchor date or the starting point for the date math. Add two trailing pipe symbols. You could then add one day (+1d) or subtract two weeks (-2w). This math expression is relative to the anchor date that you specify. You could also round off dates by adding a forward slash to the date or time unit. To find products added in the last year and rounded off by month: . GET products/_search { \"query\": { \"range\": { \"created\": { \"gte\": \"now-1y/M\" } } } } . The keyword now refers to the current date and time. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#range",
    "relUrl": "/docs/elasticsearch/term/#range"
  },"766": {
    "doc": "Term-Level Queries",
    "title": "Prefix",
    "content": "Use the prefix query to search for terms that begin with a specific prefix. GET shakespeare/_search { \"query\": { \"prefix\": { \"speaker\": \"KING\" } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#prefix",
    "relUrl": "/docs/elasticsearch/term/#prefix"
  },"767": {
    "doc": "Term-Level Queries",
    "title": "Exists",
    "content": "Use the exists query to search for documents that contain a specific field. GET shakespeare/_search { \"query\": { \"exists\": { \"field\": \"speaker\" } } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#exists",
    "relUrl": "/docs/elasticsearch/term/#exists"
  },"768": {
    "doc": "Term-Level Queries",
    "title": "Wildcards",
    "content": "Use wildcard queries to search for terms that match a wildcard pattern. | Feature | Behavior | . | * | Specifies all valid values. | . | ? | Specifies a single valid value. | . To search for terms that start with H and end with Y: . GET shakespeare/_search { \"query\": { \"wildcard\": { \"speaker\": { \"value\": \"H*Y\" } } } } . If we change * to ?, we get no matches, because ? refers to a single character. Wildcard queries tend to be slow because they need to iterate over a lot of terms. Avoid placing wildcard characters at the beginning of a query because it could be a very expensive operation in terms of both resources and time. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#wildcards",
    "relUrl": "/docs/elasticsearch/term/#wildcards"
  },"769": {
    "doc": "Term-Level Queries",
    "title": "Regex",
    "content": "Use the regex query to search for terms that match a regular expression. This regular expression matches any single uppercase or lowercase letter: . GET shakespeare/_search { \"query\": { \"regexp\": { \"play_name\": \"H[a-zA-Z]+mlet\" } } } . Regular expressions are applied to the terms in the field and not the entire value of the field. The efficiency of your regular expression depends a lot on the patterns you write. Make sure that you write regex queries with either a prefix or suffix to improve performance. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/#regex",
    "relUrl": "/docs/elasticsearch/term/#regex"
  },"770": {
    "doc": "Term-Level Queries",
    "title": "Term-Level Queries",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/term/",
    "relUrl": "/docs/elasticsearch/term/"
  },"771": {
    "doc": "Troubleshoot TLS",
    "title": "TLS troubleshooting",
    "content": "This page includes troubleshooting steps for configuring TLS certificates with the security plugin. . | Validate YAML | View contents of PEM certificates . | Check for special characters and whitespace in DNs | Check certificate IP addresses | Validate certificate chain | Check the configured alias | . | View contents of your keystore and truststore | Check SAN hostnames and IP addresses | Check OID for node certificates | Check EKU field for node certificates | TLS versions | Supported ciphers | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#tls-troubleshooting",
    "relUrl": "/docs/troubleshoot/tls/#tls-troubleshooting"
  },"772": {
    "doc": "Troubleshoot TLS",
    "title": "Validate YAML",
    "content": "elasticsearch.yml and the files in opendistro_security/securityconfig/ are in the YAML format. A linter like YAML Lint can help verify that you don’t have any formatting errors. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#validate-yaml",
    "relUrl": "/docs/troubleshoot/tls/#validate-yaml"
  },"773": {
    "doc": "Troubleshoot TLS",
    "title": "View contents of PEM certificates",
    "content": "You can use OpenSSL to display the content of each PEM certificate: . openssl x509 -subject -nameopt RFC2253 -noout -in node1.pem . Then ensure that the value matches the one in elasticsearch.yml. For more complete information on a certificate: . openssl x509 -in node1.pem -text -noout . Check for special characters and whitespace in DNs . The security plugin uses the string representation of Distinguished Names (RFC1779) when validating node certificates. If parts of your DN contain special characters (e.g. a comma), make sure you escape it in your configuration: . opendistro_security.nodes_dn: - 'CN=node-0.example.com,OU=SSL,O=My\\, Test,L=Test,C=DE' . You can have whitespace within a field, but not between fields. Bad configuration . opendistro_security.nodes_dn: - 'CN=node-0.example.com, OU=SSL,O=My\\, Test, L=Test, C=DE' . Good configuration . opendistro_security.nodes_dn: - 'CN=node-0.example.com,OU=SSL,O=My\\, Test,L=Test,C=DE' . Check certificate IP addresses . Sometimes the IP address in your certificate is not the one communicating with the cluster. This problem can occur if your node has multiple interfaces or is running on a dual stack network (IPv6 and IPv4). If this problem occurs, you might see the following in the node’s Elasticsearch log: . SSL Problem Received fatal alert: certificate_unknown javax.net.ssl.SSLException: Received fatal alert: certificate_unknown . You might also see the following message in your cluster’s master log when the new node tries to join the cluster: . Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 10.0.0.42 found . Check the IP address in the certificate: . IPAddress: 2001:db8:0:1:1.2.3.4 . In this example, the node tries to join the cluster with the IPv4 address of 10.0.0.42, but the certificate contians the IPv6 address of 2001:db8:0:1:1.2.3.4. Validate certificate chain . TLS certificates are organized in a certificate chain. You can check with keytool that the certificate chain is correct by inspecting the owner and the issuer of each certificate. If you used the demo installation script that ships with the security plugin, the chain looks like: . Node certificate . Owner: CN=node-0.example.com, OU=SSL, O=Test, L=Test, C=DE Issuer: CN=Example Com Inc. Signing CA, OU=Example Com Inc. Signing CA, O=Example Com Inc., DC=example, DC=com . Signing certificate . Owner: CN=Example Com Inc. Signing CA, OU=Example Com Inc. Signing CA, O=Example Com Inc., DC=example, DC=com Issuer: CN=Example Com Inc. Root CA, OU=Example Com Inc. Root CA, O=Example Com Inc., DC=example, DC=com . Root certificate . Owner: CN=Example Com Inc. Root CA, OU=Example Com Inc. Root CA, O=Example Com Inc., DC=example, DC=com Issuer: CN=Example Com Inc. Root CA, OU=Example Com Inc. Root CA, O=Example Com Inc., DC=example, DC=com . From the entries, you can see that the root certificate signed the intermediate certificate, which signed the node certificate. The root certificate signed itself, hence the name “self-signed certificate.” If you’re using separate keystore and truststore files, your root CA can most likely in the truststore. Generally, the keystore contains client or node certificate and all intermediate certificates, and the truststore contains the root certificate. Check the configured alias . If you have multiple entries in the keystore and you are using aliases to refer to them, make sure that the configured alias in elasticsearch.yml matches the one in the keystore. If there is only one entry in the keystore, you do not need to configure an alias. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#view-contents-of-pem-certificates",
    "relUrl": "/docs/troubleshoot/tls/#view-contents-of-pem-certificates"
  },"774": {
    "doc": "Troubleshoot TLS",
    "title": "View contents of your keystore and truststore",
    "content": "In order to view information about the certificates stored in your keystore or truststore, use the keytool command like: . keytool -list -v -keystore keystore.jks . keytool prompts for the password of the keystore and lists all entries. For example, you can use this output to check for the correctness of the SAN and EKU settings. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#view-contents-of-your-keystore-and-truststore",
    "relUrl": "/docs/troubleshoot/tls/#view-contents-of-your-keystore-and-truststore"
  },"775": {
    "doc": "Troubleshoot TLS",
    "title": "Check SAN hostnames and IP addresses",
    "content": "The valid hostnames and IP addresses of a TLS certificates are stored as SAN entries. Check that the hostname and IP entries in the SAN section are correct, especially when you use hostname verification: . Certificate[1]: Owner: CN=node-0.example.com, OU=SSL, O=Test, L=Test, C=DE ... Extensions: ... #5: ObjectId: 2.5.29.17 Criticality=false SubjectAlternativeName [ DNSName: node-0.example.com DNSName: localhost IPAddress: 127.0.0.1 ... ] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#check-san-hostnames-and-ip-addresses",
    "relUrl": "/docs/troubleshoot/tls/#check-san-hostnames-and-ip-addresses"
  },"776": {
    "doc": "Troubleshoot TLS",
    "title": "Check OID for node certificates",
    "content": "If you are using OIDs to denote valid node certificates, check that the SAN extension for your node certificate contains the correct OIDName: . Certificate[1]: Owner: CN=node-0.example.com, OU=SSL, O=Test, L=Test, C=DE ... Extensions: ... #5: ObjectId: 2.5.29.17 Criticality=false SubjectAlternativeName [ ... OIDName: 1.2.3.4.5.5 ] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#check-oid-for-node-certificates",
    "relUrl": "/docs/troubleshoot/tls/#check-oid-for-node-certificates"
  },"777": {
    "doc": "Troubleshoot TLS",
    "title": "Check EKU field for node certificates",
    "content": "Node certificates need to have both serverAuth and clientAuth set in the extended key usage field: . #3: ObjectId: 2.5.29.37 Criticality=false ExtendedKeyUsages [ serverAuth clientAuth ] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#check-eku-field-for-node-certificates",
    "relUrl": "/docs/troubleshoot/tls/#check-eku-field-for-node-certificates"
  },"778": {
    "doc": "Troubleshoot TLS",
    "title": "TLS versions",
    "content": "The security plugin disables TLS version 1.0 by default; it is outdated, insecure, and vulnerable. If you need to use TLSv1 and accept the risks, you can enable it in elasticsearch.yml: . opendistro_security.ssl.http.enabled_protocols: - \"TLSv1\" - \"TLSv1.1\" - \"TLSv1.2\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#tls-versions",
    "relUrl": "/docs/troubleshoot/tls/#tls-versions"
  },"779": {
    "doc": "Troubleshoot TLS",
    "title": "Supported ciphers",
    "content": "TLS relies on the server and client negotiating a common cipher suite. Depending on your system, the available ciphers will vary. They depend on the JDK or OpenSSL version you’re using, and whether or not the JCE Unlimited Strength Jurisdiction Policy Files are installed. For legal reasons, the JDK does not include strong ciphers like AES256. In order to use strong ciphers you need to download and install the Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files. If you don’t have them installed, you might see an error message on startup: . [INFO ] AES-256 not supported, max key length for AES is 128 bit. That is not an issue, it just limits possible encryption strength. To enable AES 256 install 'Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files' . The security plugin still works and falls back to weaker cipher suites. The plugin also prints out all available cipher suites during startup: . [INFO ] sslTransportClientProvider: JDK with ciphers [TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_DSS_WITH_AES_128_CBC_SHA256, ...] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/#supported-ciphers",
    "relUrl": "/docs/troubleshoot/tls/#supported-ciphers"
  },"780": {
    "doc": "Troubleshoot TLS",
    "title": "Troubleshoot TLS",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/troubleshoot/tls/",
    "relUrl": "/docs/troubleshoot/tls/"
  },"781": {
    "doc": "TLS Certificates",
    "title": "Configure TLS certificates",
    "content": "TLS is configured in elasticsearch.yml. There are two main configuration sections: the transport layer and the REST layer. TLS is optional for the REST layer and mandatory for the transport layer. You can find an example configuration template with all options on GitHub. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#configure-tls-certificates",
    "relUrl": "/docs/security/configuration/tls/#configure-tls-certificates"
  },"782": {
    "doc": "TLS Certificates",
    "title": "X.509 PEM certificates and PKCS #8 keys",
    "content": "The following tables contain the settings you can use to configure the location of your PEM certificates and private keys. Transport layer TLS . | Name | Description | . | opendistro_security.ssl.transport.pemkey_filepath | Path to the certificate’s key file (PKCS #8), which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.transport.pemkey_password | Key password. Omit this setting if the key has no password. Optional. | . | opendistro_security.ssl.transport.pemcert_filepath | Path to the X.509 node certificate chain (PEM format), which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.transport.pemtrustedcas_filepath | Path to the root CAs (PEM format), which must be under the config directory, specified using a relative path. Required. | . REST layer TLS . | Name | Description | . | opendistro_security.ssl.http.pemkey_filepath | Path to the certificate’s key file (PKCS #8), which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.http.pemkey_password | Key password. Omit this setting if the key has no password. Optional. | . | opendistro_security.ssl.http.pemcert_filepath | Path to the X.509 node certificate chain (PEM format), which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.http.pemtrustedcas_filepath | Path to the root CAs (PEM format), which must be under the config directory, specified using a relative path. Required. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#x509-pem-certificates-and-pkcs-8-keys",
    "relUrl": "/docs/security/configuration/tls/#x509-pem-certificates-and-pkcs-8-keys"
  },"783": {
    "doc": "TLS Certificates",
    "title": "Keystore and truststore files",
    "content": "As an alternative to certificates and private keys in PEM format, you can instead use keystore and truststore files in JKS or PKCS12/PFX format. The following settings configure the location and password of your keystore and truststore files. If you want, you can use different keystore and truststore files for the REST and the transport layer. Transport layer TLS . | Name | Description | . | opendistro_security.ssl.transport.keystore_type | The type of the keystore file, JKS or PKCS12/PFX. Optional. Default is JKS. | . | opendistro_security.ssl.transport.keystore_filepath | Path to the keystore file, which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.transport.keystore_alias: my_alias | Alias name. Optional. Default is the first alias. | . | opendistro_security.ssl.transport.keystore_password | Keystore password. Default is changeit. | . | opendistro_security.ssl.transport.truststore_type | The type of the truststore file, JKS or PKCS12/PFX. Default is JKS. | . | opendistro_security.ssl.transport.truststore_filepath | Path to the truststore file, which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.transport.truststore_alias | Alias name. Optional. Default is all certificates. | . | opendistro_security.ssl.transport.truststore_password | Truststore password. Default is changeit. | . REST layer TLS . | Name | Description | . | opendistro_security.ssl.http.enabled | Whether to enable TLS on the REST layer. If enabled, only HTTPS is allowed. Optional. Default is false. | . | opendistro_security.ssl.http.keystore_type | The type of the keystore file, JKS or PKCS12/PFX. Optional. Default is JKS. | . | opendistro_security.ssl.http.keystore_filepath | Path to the keystore file, which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.http.keystore_alias | Alias name. Optional. Default is the first alias. | . | opendistro_security.ssl.http.keystore_password | Keystore password. Default is changeit. | . | opendistro_security.ssl.http.truststore_type | The type of the truststore file, JKS or PKCS12/PFX. Default is JKS. | . | opendistro_security.ssl.http.truststore_filepath | Path to the truststore file, which must be under the config directory, specified using a relative path. Required. | . | opendistro_security.ssl.http.truststore_alias | Alias name. Optional. Default is all certificates. | . | opendistro_security.ssl.http.truststore_password | Truststore password. Default is changeit. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#keystore-and-truststore-files",
    "relUrl": "/docs/security/configuration/tls/#keystore-and-truststore-files"
  },"784": {
    "doc": "TLS Certificates",
    "title": "Configure node certificates",
    "content": "The security plugin needs to identify inter-cluster requests (i.e. requests between the nodes). The simplest way of configuring node certificates is to list the Distinguished Names (DNs) of these certificates in elasticsearch.yml. All DNs must be included in elasticsearch.yml on all nodes. The security plugin supports wildcards and regular expressions: . opendistro_security.nodes_dn: - 'CN=node.other.com,OU=SSL,O=Test,L=Test,C=DE' - 'CN=*.example.com,OU=SSL,O=Test,L=Test,C=DE' - 'CN=elk-devcluster*' - '/CN=.*regex/' . If your node certificates have an OID identifier in the SAN section, you can omit this configuration. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#configure-node-certificates",
    "relUrl": "/docs/security/configuration/tls/#configure-node-certificates"
  },"785": {
    "doc": "TLS Certificates",
    "title": "Configure admin certificates",
    "content": "Admin certificates are regular client certificates that have elevated rights to perform administrative tasks. You need an admin certificate to change the the security plugin configuration using plugins/opendistro_security/tools/securityadmin.sh or the REST API. Admin certificates are configured in elasticsearch.yml by stating their DN(s): . opendistro_security.authcz.admin_dn: - CN=admin,OU=SSL,O=Test,L=Test,C=DE . For security reasons, you can’t use wildcards or regular expressions here. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#configure-admin-certificates",
    "relUrl": "/docs/security/configuration/tls/#configure-admin-certificates"
  },"786": {
    "doc": "TLS Certificates",
    "title": "(Advanced) OpenSSL",
    "content": "The security plugin supports OpenSSL, but we only recommend it if you use Java 8. If you use Java 11, we recommend the default configuration. To use OpenSSL, you must install OpenSSL, the Apache Portable Runtime, and a Netty version with OpenSSL support matching your platform on all nodes. If OpenSSL is enabled, but for one reason or another the installation does not work, the security plugin falls back to the Java JCE as the security engine. | Name | Description | . | opendistro_security.ssl.transport.enable_openssl_if_available | Enable OpenSSL on the transport layer if available. Optional. Default is true. | . | opendistro_security.ssl.http.enable_openssl_if_available | Enable OpenSSL on the REST layer if available. Optional. Default is true. | . | Download the statically-linked JAR that includes OpenSSL, Apache Portable Runtime, and netty-tcnative for RPM-based distributions or other distributions and place it in plugins/opendistro_security/ on every node. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#advanced-openssl",
    "relUrl": "/docs/security/configuration/tls/#advanced-openssl"
  },"787": {
    "doc": "TLS Certificates",
    "title": "(Advanced) Hostname verification and DNS lookup",
    "content": "In addition to verifying the TLS certificates against the root CA and/or intermediate CA(s), the security plugin can apply additional checks on the transport layer. With enforce_hostname_verification enabled, the security plugin verifies that the hostname of the communication partner matches the hostname in the certificate. The hostname is taken from the subject or SAN entries of your certificate. For example, if the hostname of your node is node-0.example.com, then the hostname in the TLS certificate has to be set to node-0.example.com, as well. Otherwise, errors are thrown: . [ERROR][c.a.o.s.s.t.OpenDistroSecuritySSLNettyTransport] [WX6omJY] SSL Problem No name matching &lt;hostname&gt; found [ERROR][c.a.o.s.s.t.OpenDistroSecuritySSLNettyTransport] [WX6omJY] SSL Problem Received fatal alert: certificate_unknown . In addition, when resolve_hostnames is enabled, the security plugin resolves the (verified) hostname against your DNS. If the hostname does not resolve, errors are thrown: . | Name | Description | . | opendistro_security.ssl.transport.enforce_hostname_verification | Whether to verify hostnames on the transport layer. Optional. Default is true. | . | opendistro_security.ssl.transport.resolve_hostname | Whether to resolve hostnames against DNS on the transport layer. Optional. Default is true. Only works if hostname verification is also enabled. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#advanced-hostname-verification-and-dns-lookup",
    "relUrl": "/docs/security/configuration/tls/#advanced-hostname-verification-and-dns-lookup"
  },"788": {
    "doc": "TLS Certificates",
    "title": "(Advanced) Client authentication",
    "content": "With TLS client authentication enabled, REST clients can send a TLS certificate with the HTTP request to provide identity information to the security plugin. There are three main usage scenarios for TLS client authentication: . | Providing an admin certificate when using the REST management API. | Configuring roles and permissions based on a client certificate. | Providing identity information for tools like Kibana, Logstash, or Beats. | . TLS client authentication has three modes: . | NONE: The security plugin does not accept TLS client certificates. If one is sent, it is discarded. | OPTIONAL: The security plugin accepts TLS client certificates if they are sent, but does not require them. | REQUIRE: The security plugin only accepts REST requests when a valid client TLS certificate is sent. | . For the REST management API, the client authentication modes has to be OPTIONAL at a minimum. You can configure the client authentication mode by using the following setting: . | Name | Description | . | opendistro_security.ssl.http.clientauth_mode | The TLS client authentication mode to use. Can be one of NONE, OPTIONAL (default) or REQUIRE. Optional. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#advanced-client-authentication",
    "relUrl": "/docs/security/configuration/tls/#advanced-client-authentication"
  },"789": {
    "doc": "TLS Certificates",
    "title": "(Advanced) Enabled ciphers and protocols",
    "content": "You can limit the allowed ciphers and TLS protocols for the REST layer. For example, you can only allow strong ciphers and limit the TLS versions to the most recent ones. If this setting is not enabled, the ciphers and TLS versions are negotiated between the browser and the security plugin automatically, which in some cases can lead to a weaker cipher suite being used. You can configure the ciphers and protocols using the following settings. | Name | Description | . | opendistro_security.ssl.http.enabled_ciphers | Array, enabled TLS cipher suites for the REST layer. Only Java format is supported. | . | opendistro_security.ssl.http.enabled_protocols | Array, enabled TLS protocols for the REST layer. Only Java format is supported. | . | opendistro_security.ssl.transport.enabled_ciphers | Array, enabled TLS cipher suites for the transport layer. Only Java format is supported. | . | opendistro_security.ssl.transport.enabled_protocols | Array, enabled TLS protocols for the transport layer. Only Java format is supported. | . Example settings . opendistro_security.ssl.http.enabled_ciphers: - \"TLS_DHE_RSA_WITH_AES_256_CBC_SHA\" - \"TLS_DHE_DSS_WITH_AES_128_CBC_SHA256\" opendistro_security.ssl.http.enabled_protocols: - \"TLSv1.1\" - \"TLSv1.2\" . Because it is insecure, the security plugin disables TLSv1 by default. If you need to use TLSv1 and accept the risks, you can still enable it: . opendistro_security.ssl.http.enabled_protocols: - \"TLSv1\" - \"TLSv1.1\" - \"TLSv1.2\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#advanced-enabled-ciphers-and-protocols",
    "relUrl": "/docs/security/configuration/tls/#advanced-enabled-ciphers-and-protocols"
  },"790": {
    "doc": "TLS Certificates",
    "title": "(Advanced) Disable client initiated renegotiation for Java 8",
    "content": "Set -Djdk.tls.rejectClientInitiatedRenegotiation=true to disable secure client initiated renegotiation, which is enabled by default. This can be set via ES_JAVA_OPTS in config/jvm.options. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/#advanced-disable-client-initiated-renegotiation-for-java-8",
    "relUrl": "/docs/security/configuration/tls/#advanced-disable-client-initiated-renegotiation-for-java-8"
  },"791": {
    "doc": "TLS Certificates",
    "title": "TLS Certificates",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/tls/",
    "relUrl": "/docs/security/configuration/tls/"
  },"792": {
    "doc": "Troubleshooting",
    "title": "Troubleshooting",
    "content": "The SQL plugin is stateless, so troubleshooting is mostly focused on why a particular query fails. The most common error is the dreaded null pointer exception, which can occur during parsing errors or when using the wrong HTTP method (POST vs. GET and vice versa). The POST method and HTTP request body offer the most consistent results: . POST _opendistro/_sql { \"query\": \"SELECT * FROM my-index WHERE ['name.firstname']='saanvi' LIMIT 5\" } . If a query isn’t behaving the way you expect, use the _explain API to see the translated query, which you can then troubleshoot. For most operations, _explain returns Elasticsearch query DSL. For UNION, MINUS, and JOIN, it returns something more akin to a SQL execution plan. Sample request . POST _opendistro/_sql/_explain { \"query\": \"SELECT * FROM my-index LIMIT 50\" } . Sample response . { \"from\": 0, \"size\": 50 } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/troubleshoot/",
    "relUrl": "/docs/sql/troubleshoot/"
  },"793": {
    "doc": "Troubleshooting",
    "title": "Syntax analysis exception",
    "content": "You might receive the following error if the plugin can’t parse your query: . { \"reason\": \"Invalid SQL query\", \"details\": \"Failed to parse query due to offending symbol [:] at: 'SELECT * FROM xxx WHERE xxx:' &lt;--- HERE... More details: Expecting tokens in {&lt;EOF&gt;, 'AND', 'BETWEEN', 'GROUP', 'HAVING', 'IN', 'IS', 'LIKE', 'LIMIT', 'NOT', 'OR', 'ORDER', 'REGEXP', '*', '/', '%', '+', '-', 'DIV', 'MOD', '=', '&gt;', '&lt;', '!', '|', '&amp;', '^', '.', DOT_ID}\", \"type\": \"SyntaxAnalysisException\" } . To resolve this error: . | Check if your syntax follows the MySQL grammar. | If your syntax is correct, disable strict query analysis: . PUT _cluster/settings { \"persistent\" : { \"opendistro.sql.query.analysis.enabled\" : false } } . | Run the query again to see if it works. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/troubleshoot/#syntax-analysis-exception",
    "relUrl": "/docs/sql/troubleshoot/#syntax-analysis-exception"
  },"794": {
    "doc": "Troubleshooting",
    "title": "Index mapping verification exception",
    "content": "If you see the following verification exception: . { \"error\": { \"reason\": \"There was internal problem at backend\", \"details\": \"When using multiple indices, the mappings must be identical.\", \"type\": \"VerificationException\" }, \"status\": 503 } . Make sure the index in your query is not an index pattern and is not an index pattern and doesn’t have multiple types. If these steps don’t work, submit a Github issue here. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/troubleshoot/#index-mapping-verification-exception",
    "relUrl": "/docs/sql/troubleshoot/#index-mapping-verification-exception"
  },"795": {
    "doc": "Supported Units",
    "title": "Supported units",
    "content": "Elasticsearch supports the following units for all REST operations: . | Unit | Description | Example | . | Times | The supported units for time are d for days, h for hours, m for minutes, s for seconds, ms for milliseconds, micros for microseconds, and nanos for nanoseconds. | 5d or 7h | . | Bytes | The supported units for byte size are b for bytes, kb for kibibytes, mb for mebibytes, gb for gibibytes, tb for tebibytes, and pb for pebibytes. Despite the base-10 abbreviations, these units are base-2; 1kb is 1,024 bytes, 1mb is 1,048,576 bytes, etc. | 7kb or 6gb | . | Distances | The supported units for distance are mi for miles, yd for yards, ft for feet, in for inches, km for kilometers, m for meters, cm for centimeters, mm for millimeters, and nmi or NM for nautical miles. | 5mi or 4ft | . | Quantities without units | For large values that don’t have a unit, use k for kilo, m for mega, g for giga, t for tera, and p for peta. | 5k for 5,000 | . To convert output units to human-readable values, see Common REST parameters. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/units/#supported-units",
    "relUrl": "/docs/elasticsearch/units/#supported-units"
  },"796": {
    "doc": "Supported Units",
    "title": "Supported Units",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/units/",
    "relUrl": "/docs/elasticsearch/units/"
  },"797": {
    "doc": "Users and Roles",
    "title": "Users and roles",
    "content": "The security plugin includes an internal user database. Use this database in place of or in addition to an external authentication system such as LDAP or Active Directory. Roles are the core way of controlling access to your cluster. Roles contain any combination of cluster-wide permissions, index-specific permissions, document- and field-level security, and tenants. Then you map users to these roles so that users gain those permissions. Unless you need to create new read-only or hidden users, we highly recommend using Kibana or the REST API to create new users, roles, and role mappings. The .yml files are for initial setup, not ongoing use. . | Create users . | Kibana | internal_users.yml | REST API | . | Create roles . | Kibana | roles.yml | REST API | . | Map users to roles . | Kibana | roles_mapping.yml | REST API | . | Predefined roles | Sample roles . | Set up a read-only user in Kibana | Set up a bulk access role in Kibana | . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#users-and-roles",
    "relUrl": "/docs/security/access-control/users-roles/#users-and-roles"
  },"798": {
    "doc": "Users and Roles",
    "title": "Create users",
    "content": "You can create users using Kibana, internal_users.yml, or the REST API. Kibana . | Choose Security, Internal Users, and Create internal user. | Provide a username and password. The security plugin automatically hashes the password and stores it in the .opendistro_security index. | If desired, specify user attributes. Attributes are optional user properties that you can use for variable substitution in index permissions or document-level security. | Choose Submit. | . internal_users.yml . See YAML files. REST API . See Create user. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#create-users",
    "relUrl": "/docs/security/access-control/users-roles/#create-users"
  },"799": {
    "doc": "Users and Roles",
    "title": "Create roles",
    "content": "Just like users, you can create roles using Kibana, roles.yml, or the REST API. Kibana . | Choose Security, Roles, and Create role. | Provide a name for the role. | Add permissions as desired. For example, you might give a role no cluster permissions, read permissions to two indices, unlimited permissions to a third index, and read permissions to the analysts tenant. | Choose Submit. | . roles.yml . See YAML files. REST API . See Create role. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#create-roles",
    "relUrl": "/docs/security/access-control/users-roles/#create-roles"
  },"800": {
    "doc": "Users and Roles",
    "title": "Map users to roles",
    "content": "After creating roles, you map users (or backend roles) to them. Intuitively, people often think of this process as giving a user one or more roles, but in the security plugin, the process is reversed; you select a role and then map one or more users to it. Just like users and roles, you create role mappings using Kibana, roles_mapping.yml, or the REST API. Kibana . | Choose Security, Roles, and a role. | Choose the Mapped users tab and Manage mapping. | Specify users or external identities (also known as backend roles). | Choose Map. | . roles_mapping.yml . See YAML files. REST API . See Create role mapping. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#map-users-to-roles",
    "relUrl": "/docs/security/access-control/users-roles/#map-users-to-roles"
  },"801": {
    "doc": "Users and Roles",
    "title": "Predefined roles",
    "content": "The security plugin includes several predefined roles that serve as useful defaults. | Role | Description | . | all_access | Grants full access to the cluster: all cluster-wide operations, write to all indices, write to all tenants. | . | kibana_read_only | A special role that prevents users from making changes to visualizations, dashboards, and other Kibana objects. See opendistro_security.readonly_mode.roles in kibana.yml. Pair with the kibana_user role. | . | kibana_user | Grants permissions to use Kibana: cluster-wide searches, index monitoring, and write to various Kibana indices. | . | logstash | Grants permissions for Logstash to interact with the cluster: cluster-wide searches, cluster monitoring, and write to the various Logstash indices. | . | manage_snapshots | Grants permissions to manage snapshot repositories, take snapshots, and restore snapshots. | . | readall | Grants permissions for cluster-wide searches like msearch and search permissions for all indices. | . | readall_and_monitor | Same as readall, but with added cluster monitoring permissions. | . | security_rest_api_access | A special role that allows access to the REST API. See opendistro_security.restapi.roles_enabled in elasticsearch.yml and Access control for the API. | . For more detailed summaries of the permissions for each role, reference their action groups against the descriptions in Default action groups. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#predefined-roles",
    "relUrl": "/docs/security/access-control/users-roles/#predefined-roles"
  },"802": {
    "doc": "Users and Roles",
    "title": "Sample roles",
    "content": "The following examples show how you might set up a read-only and a bulk access role. Set up a read-only user in Kibana . Create a new read_only_index role: . | Open Kibana. | Choose Security, Roles. | Create a new role named read_only_index. | For Cluster permissions, add the cluster_composite_ops_ro action group. | For Index Permissions, add an index pattern. For example, you might specify my-index-*. | For index permissions, add the read action group. | Choose Create. | . Map three roles to the read-only user: . | Choose the Mapped users tab and Manage mapping. | For Internal users, add your read-only user. | Choose Map. | Repeat these steps for the kibana_user and kibana_read_only roles. | . Set up a bulk access role in Kibana . Create a new bulk_access role: . | Open Kibana. | Choose Security, Roles. | Create a new role named bulk_access. | For Cluster permissions, add the cluster_composite_ops action group. | For Index Permissions, add an index pattern. For example, you might specify my-index-*. | For index permissions, add the write action group. | Choose Create. | . Map the role to your user: . | Choose the Mapped users tab and Manage mapping. | For Internal users, add your bulk access user. | Choose Map. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/#sample-roles",
    "relUrl": "/docs/security/access-control/users-roles/#sample-roles"
  },"803": {
    "doc": "Users and Roles",
    "title": "Users and Roles",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/access-control/users-roles/",
    "relUrl": "/docs/security/access-control/users-roles/"
  },"804": {
    "doc": "Search Experience",
    "title": "Search Experience",
    "content": "Expectations from search engines have evolved over the years. Just returning relevant results quickly is no longer enough for most users. Elasticsearch includes many features that enhance the user’s search experience as follows: . | Feature | Description | . | Autocomplete queries | Suggest phrases as the user types. | . | Paginate results | Rather than a single, long list, break search results into pages. | . | Scroll search | Return a large number of results in batches. | . | Sort results | Allow sorting results by different criteria. | . | Highlight query matches | Highlight the search term in the results. | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/",
    "relUrl": "/docs/elasticsearch/ux/"
  },"805": {
    "doc": "Search Experience",
    "title": "Autocomplete queries",
    "content": "Autocomplete shows suggestions to users while they type. For example, if a user types “pop,” Elasticsearch provides suggestions like “popcorn” or “popsicles.” These suggestions preempt your user’s intention and lead them to a possible search term more quickly. Elasticsearch allows you to design autocomplete that updates with each keystroke, provides a few relevant suggestions, and tolerates typos. Implement autocomplete using one of three methods: . | Prefix matching | Edge N-gram matching | Completion suggesters | . These methods are described below. Prefix matching . Prefix matching finds documents that matches the last term in the query string. For example, assume that the user types “qui” into a search UI. To autocomplete this phrase, use the match_phrase_prefix query to search all text_entry fields that begin with the prefix “qui.” To make the word order and relative positions flexible, specify a slop value. To learn about the slop option, see Options. Sample Request . GET shakespeare/_search { \"query\": { \"match_phrase_prefix\": { \"text_entry\": { \"query\": \"qui\", \"slop\": 3 } } } } . Prefix matching doesn’t require any special mappings. It works with your data as-is. However, it’s a fairly resource-intensive operation. A prefix of a could match hundreds of thousands of terms and not be useful to your user. To limit the impact of prefix expansion, set max_expansions to a reasonable number. To learn about the max_expansions option, see Options. Sample Request . GET shakespeare/_search { \"query\": { \"match_phrase_prefix\": { \"text_entry\": { \"query\": \"qui\", \"slop\": 3, \"max_expansions\": 10 } } } } . The ease of implementing query-time autocomplete comes at the cost of performance. When implementing this feature on a large scale, we recommend an index-time solution. With an index-time solution, you might experience slower indexing, but it’s a price you pay only once and not for every query. The edge N-gram and completion suggester methods are index time. Edge N-gram matching . During indexing, edge N-grams chop up a word into a sequence of N characters to support a faster lookup of partial search terms. If you N-gram the word “quick,” the results depend on the value of N. | N | Type | N-gram | . | 1 | Unigram | [ q, u, i, c, k ] | . | 2 | Bigram | [ qu, ui, ic, ck ] | . | 3 | Trigram | [ qui, uic, ick ] | . | 4 | Four-gram | [ quic, uick ] | . | 5 | Five-gram | [ quick ] | . Autocomplete needs only the beginning N-grams of a search phrase, so Elasticsearch uses a special type of N-gram called edge N-gram. Edge N-gramming the word “quick” results in the following: . | q | qu | qui | quic | quick | . This follows the same sequence the user types. To configure a field to use edge N-grams, create an autocomplete analyzer with an edge_ngram filter: . Sample Request . PUT shakespeare { \"mappings\": { \"properties\": { \"text_entry\": { \"type\": \"text\", \"analyzer\": \"autocomplete\" } } }, \"settings\": { \"analysis\": { \"filter\": { \"edge_ngram_filter\": { \"type\": \"edge_ngram\", \"min_gram\": 1, \"max_gram\": 20 } }, \"analyzer\": { \"autocomplete\": { \"type\": \"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"edge_ngram_filter\" ] } } } } } . This example creates the index and instantiates the edge N-gram filter and analyzer. The edge_ngram_filter produces edge N-grams with a minimum N-gram length of 1 (a single letter) and a maximum length of 20. So it offers suggestions for words of up to 20 letters. The autocomplete analyzer tokenizes a string into individual terms, lowercases the terms, and then produces edge N-grams for each term using the edge_ngram_filter. Use the analyze operation to test this analyzer: . POST shakespeare/_analyze { \"analyzer\": \"autocomplete\", \"text\": \"quick\" } . It returns edge N-grams as tokens: . | q | qu | qui | quic | quick | . Use the standard analyzer at search time. Otherwise, the search query splits into edge N-grams and you get results for everything that matches q, u, and i. This is one of the few occasions where you use a different analyzer on the index and query side. Sample Request . GET shakespeare/_search { \"query\": { \"match\": { \"text_entry\": { \"query\": \"qui\", \"analyzer\": \"standard\" } } } } . Sample Response . { \"took\": 5, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 533, \"relation\": \"eq\" }, \"max_score\": 9.712725, \"hits\": [ { \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"22006\", \"_score\": 9.712725, \"_source\": { \"type\": \"line\", \"line_id\": 22007, \"play_name\": \"Antony and Cleopatra\", \"speech_number\": 12, \"line_number\": \"5.2.44\", \"speaker\": \"CLEOPATRA\", \"text_entry\": \"Quick, quick, good hands.\" } }, { \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"54665\", \"_score\": 9.712725, \"_source\": { \"type\": \"line\", \"line_id\": 54666, \"play_name\": \"Loves Labours Lost\", \"speech_number\": 21, \"line_number\": \"5.1.52\", \"speaker\": \"HOLOFERNES\", \"text_entry\": \"Quis, quis, thou consonant?\" } } ] } } . Alternatively, specify the search_analyzer in the mapping itself: . \"mappings\": { \"properties\": { \"text_entry\": { \"type\": \"text\", \"analyzer\": \"autocomplete\", \"search_analyzer\": \"standard\" } } } . Completion suggester . The completion suggester accepts a list of suggestions and builds them into a finite-state transducer (FST), an optimized data structure that’s essentially a graph. This data structure lives in memory and is optimized for fast prefix lookups. To learn more about FSTs, see Wikipedia. As the user types, the completion suggester moves through the FST graph one character at a time along a matching path. After it runs out of user input, it examines the remaining endings to produce a list of suggestions. The completion suggester makes your autocomplete solution as efficient as possible and lets you have explicit control over its suggestions. Use a dedicated field type called completion, which stores the FST-like data structures in the index: . PUT shakespeare { \"mappings\": { \"properties\": { \"text_entry\": { \"type\": \"completion\" } } } } . To get back suggestions, use the search endpoint with the suggest parameter: . GET shakespeare/_search { \"suggest\": { \"autocomplete\": { \"prefix\": \"To be\", \"completion\": { \"field\": \"text_entry\" } } } } . The phrase “to be” is prefix matched with the FST of the text_entry field. Sample Response . { \"took\": 9, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] }, \"suggest\": { \"text_entry\": [ { \"text\": \"To be\", \"offset\": 0, \"length\": 5, \"options\": [ { \"text\": \"To be a comrade with the wolf and owl,--\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"50652\", \"_score\": 1, \"_source\": { \"type\": \"line\", \"line_id\": 50653, \"play_name\": \"King Lear\", \"speech_number\": 68, \"line_number\": \"2.4.230\", \"speaker\": \"KING LEAR\", \"text_entry\": \"To be a comrade with the wolf and owl,--\" } }, { \"text\": \"To be a make-peace shall become my age:\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"78566\", \"_score\": 1, \"_source\": { \"type\": \"line\", \"line_id\": 78567, \"play_name\": \"Richard II\", \"speech_number\": 20, \"line_number\": \"1.1.160\", \"speaker\": \"JOHN OF GAUNT\", \"text_entry\": \"To be a make-peace shall become my age:\" } } ] } ] } } . To specify the number of suggestions that you want to return, use the size parameter: . GET shakespeare/_search { \"suggest\": { \"autocomplete\": { \"prefix\": \"To m\", \"completion\": { \"field\": \"text_entry\", \"size\": 3 } } } } . Sample Response . { \"took\": 3, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] }, \"suggest\": { \"text_entry\": [ { \"text\": \"To m\", \"offset\": 0, \"length\": 5, \"options\": [ { \"text\": \"To make a bastard and a slave of me!\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"5369\", \"_score\": 4, \"_source\": { \"type\": \"line\", \"line_id\": 5370, \"play_name\": \"Henry VI Part 1\", \"speech_number\": 2, \"line_number\": \"4.5.15\", \"speaker\": \"JOHN TALBOT\", \"text_entry\": \"To make a bastard and a slave of me!\" } }, { \"text\": \"To make a bloody supper in the Tower.\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"12504\", \"_score\": 4, \"_source\": { \"type\": \"line\", \"line_id\": 12505, \"play_name\": \"Henry VI Part 3\", \"speech_number\": 40, \"line_number\": \"5.5.85\", \"speaker\": \"CLARENCE\", \"text_entry\": \"To make a bloody supper in the Tower.\" } } ] } ] } } . The suggest parameter finds suggestions using only prefix matching. For example, you don’t get back “To be, or not to be,” which you might want as a suggestion. To work around this issue, manually add curated suggestions and add weights to prioritize your suggestions. Index a document with an input suggestion and assign a weight: . PUT shakespeare/_doc/1 { \"text\": \"To m\", \"text_entry\": { \"input\": [ \"To be, or not to be: that is the question:\" ], \"weight\": 10 } } . Perform the same search as before: . GET shakespeare/_search { \"suggest\": { \"autocomplete\": { \"prefix\": \"To m\", \"completion\": { \"field\": \"text_entry\", \"size\": 3 } } } } . You see the indexed document as the first result: . { \"took\": 1021, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] }, \"suggest\": { \"autocomplete\": [ { \"text\": \"To m\", \"offset\": 0, \"length\": 5, \"options\": [ { \"text\": \"To be, or not to be: that is the question:\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"1\", \"_score\": 30, \"_source\": { \"text\": \"To me\", \"text_entry\": { \"input\": [ \"To be, or not to be: that is the question:\" ], \"weight\": 10 } } }, { \"text\": \"To make a bastard and a slave of me!\", \"_index\": \"shakespeare\", \"_type\": \"_doc\", \"_id\": \"5369\", \"_score\": 4, \"_source\": { \"type\": \"line\", \"line_id\": 5370, \"play_name\": \"Henry VI Part 1\", \"speech_number\": 2, \"line_number\": \"4.5.15\", \"speaker\": \"JOHN TALBOT\", \"text_entry\": \"To make a bastard and a slave of me!\" } } ] } ] } } . Use the term suggester to suggest corrected spellings for individual words. The term suggester uses an edit distance to compute suggestions. Edit distance is the number of characters that need to be changed for a term to match. In this example, the user misspells a search term: . GET shakespeare/_search { \"suggest\": { \"spell-check\": { \"text\": \"lief\", \"term\": { \"field\": \"text_entry\" } } } } . The term suggester returns a list of corrections: . { \"took\": 48, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] }, \"suggest\": { \"spell-check\": [ { \"text\": \"lief\", \"offset\": 0, \"length\": 4, \"options\": [ { \"text\": \"lifes\", \"score\": 0.8, \"freq\": 21 }, { \"text\": \"life\", \"score\": 0.75, \"freq\": 805 }, { \"text\": \"lives\", \"score\": 0.6, \"freq\": 187 }, { \"text\": \"liege\", \"score\": 0.6, \"freq\": 138 }, { \"text\": \"lived\", \"score\": 0.6, \"freq\": 80 } ] } ] } } . The higher the score, the better the suggestion is. The frequency represents the number of times the term appears in the documents of that index. To implement a “Did you mean suggestion?” feature, use a phrase suggester. The phrase suggester is similar to the term suggester, except that it uses N-gram language models to suggest whole phrases instead of individual words. Create a custom analyzer called trigram that uses a shingle filter. This filter is similar to the edge_ngram filter, but it applies to words instead of letters: . PUT shakespeare { \"settings\": { \"index\": { \"analysis\": { \"analyzer\": { \"trigram\": { \"type\": \"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"shingle\" ] } }, \"filter\": { \"shingle\": { \"type\": \"shingle\", \"min_shingle_size\": 2, \"max_shingle_size\": 3 } } } } }, \"mappings\": { \"properties\": { \"text_entry\": { \"type\": \"text\", \"fields\": { \"trigram\": { \"type\": \"text\", \"analyzer\": \"trigram\" } } } } } } . This example includes as incorrect phrase: . POST shakespeare/_search { \"suggest\": { \"text\": \"That the qution\", \"simple_phrase\": { \"phrase\": { \"field\": \"text_entry.trigram\" } } } } . You get back the corrected phrase: . { \"took\": 3, \"timed_out\": false, \"_shards\": { \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": { \"value\": 0, \"relation\": \"eq\" }, \"max_score\": null, \"hits\": [] }, \"suggest\": { \"simple_phrase\": [ { \"text\": \"That the qution\", \"offset\": 0, \"length\": 18, \"options\": [ { \"text\": \"that is the question\", \"score\": 0.0015543294 } ] } ] } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/#autocomplete-queries",
    "relUrl": "/docs/elasticsearch/ux/#autocomplete-queries"
  },"806": {
    "doc": "Search Experience",
    "title": "Paginate results",
    "content": "The from and size parameters return results to your users one page at a time. The from parameter is the document number that you want to start showing the results from. The size parameter is the number of results that you want to show. Together, they let you return a subset of the search results. For example, if the value of size is 10 and the value of from is 0, you see the first 10 results. If you change the value of from to 10, you see the next 10 results (because the results are zero-indexed). So, if you want to see results starting from result 11, from must be 10. GET shakespeare/_search { \"from\": 0, \"size\": 10, \"query\": { \"match\": { \"play_name\": \"Hamlet\" } } } . To calculate the from parameter relative to the page number: . from = size * (page_number - 1) . Each time the user chooses the next page of the results, your application needs to make the same search query with an incremented from value. You can also specify the from and size parameters in the search URI: . GET shakespeare/_search?from=0&amp;size=10 . If you only specify the size parameter, the from parameter defaults to 0. Querying for pages deep in your results can have a significant performance impact, so Elasticsearch limits this approach to 10,000 results. The from and size parameters are stateless, so the results are based on the latest available data. This can cause inconsistent pagination. For example, assume a user stays on the first page of the results for a minute and then navigates to the second page; in that time, a new document is indexed in the background which is relevant enough to show up on the first page. In this scenario, the last result of the first page is pushed to the second page, so the user ends up seeing a result on the second page that they already saw on the first page. Use the scroll operation for consistent pagination. The scroll operation keeps a search context open for a certain period of time. Any data changes do not affect the results during this time. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/#paginate-results",
    "relUrl": "/docs/elasticsearch/ux/#paginate-results"
  },"807": {
    "doc": "Search Experience",
    "title": "Scroll search",
    "content": "The from and size parameters allow you to paginate your search results, but with a limit of 10,000 results at a time. If you need to request massive volumes of data from, for example, a machine learning job, use the scroll operation instead. The scroll operation allows you to request an unlimited number of results. To use the scroll operation, add a scroll parameter to the request header with a search context to tell Elasticsearch how long you need to keep scrolling. This search context needs to be long enough to process a single batch of results. To set the number of results that you want returned for each batch, use the size parameter: . GET shakespeare/_search?scroll=10m { \"size\": 10000 } . Elasticsearch caches the results and returns a scroll ID to access them in batches: . \"_scroll_id\" : \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAUWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ==\" . Pass this scroll ID to the scroll operation to get back the next batch of results: . GET _search/scroll { \"scroll\": \"10m\", \"scroll_id\": \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAUWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ==\" } . Using this scroll ID, you get results in batches of 10,000 as long as the search context is still open. Typically, the scroll ID does not change between requests, but it can change, so make sure to always use the latest scroll ID. If you don’t send the next scroll request within the set search context, the scroll operation does not return any results. If you expect billions of results, use a sliced scroll. Slicing allows you to perform multiple scroll operations for the same request, but in parallel. Set the ID and the maximum number of slices for the scroll: . GET shakespeare/_search?scroll=10m { \"slice\": { \"id\": 0, \"max\": 10 }, \"query\": { \"match_all\": {} } } . With a single scroll ID, you get back 10 results. You can have up to 10 IDs. Perform the same command with ID equal to 1: . GET shakespeare/_search?scroll=10m { \"slice\": { \"id\": 1, \"max\": 10 }, \"query\": { \"match_all\": {} } } . Close the search context when you’re done scrolling, because it continues to consume computing resources until the timeout: . DELETE _search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAAcWdmpUZDhnRFBUcWFtV21nMmFwUGJEQQ== . Sample Response . { \"succeeded\": true, \"num_freed\": 1 } . To close all open scroll contexts: . DELETE _search/scroll/_all . The scroll operation corresponds to a specific timestamp. It does not consider documents added after that timestamp as potential results. Because open search contexts consume a lot of memory, we suggest you do not use the scroll operation for frequent user queries that don’t need the search context open. Instead, use the sort parameter with the search_after parameter to scroll responses for user queries. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/#scroll-search",
    "relUrl": "/docs/elasticsearch/ux/#scroll-search"
  },"808": {
    "doc": "Search Experience",
    "title": "Sort results",
    "content": "Sorting allows your users to sort the results in a way that’s most meaningful to them. By default, full-text queries sort results by the relevance score. You can choose to sort the results by any field value in either ascending or descending order. For example, to sort results by descending order of a line_id value: . GET shakespeare/_search { \"query\": { \"term\": { \"play_name\": { \"value\": \"Henry IV\" } } }, \"sort\": [ { \"line_id\": { \"order\": \"desc\" } } ] } . The sort parameter is an array, so you can specify multiple field values in the order of their priority. If you have two fields with the same value for line_id, Elasticsearch uses speech_number, which is the second option for sorting. GET shakespeare/_search { \"query\": { \"term\": { \"play_name\": { \"value\": \"Henry IV\" } } }, \"sort\": [ { \"line_id\": { \"order\": \"desc\" } }, { \"speech_number\": { \"order\": \"desc\" } } ] } . You can continue to sort by any number of field values to get the results in just the right order. It doesn’t have to be a numerical value, you can also sort by date or timestamp fields: . \"sort\": [ { \"date\": { \"order\": \"desc\" } } ] . For numeric fields that contain an array of numbers, you can sort by avg, sum, and median modes: . \"sort\": [ { \"price\": { \"order\": \"asc\", \"mode\": \"avg\" } } ] . To sort by the minimum or maximum values, use the min or max modes. These modes work for both numeric and string data types. A text field that’s analyzed cannot be used to sort documents, because the inverted index only contains the individual tokenized terms and not the entire string. So, you cannot sort by the play_name, for example. One workaround is map a raw version of the text field as a keyword type, so it won’t be analyzed and you have a copy of the full original version for sorting purposes. GET shakespeare/_search { \"query\": { \"term\": { \"play_name\": { \"value\": \"Henry IV\" } } }, \"sort\": [ { \"play_name.keyword\": { \"order\": \"desc\" } } ] } . You get back results sorted by the play_name field in alphabetic order. Use sort with search_after parameter for more efficient scrolling. You get back results after the values you specify in the search_after array. Make sure you have the same number of values in the search_after array as in the sort array, also ordered in the same way. In this case, you get back results after line_id = 3202 and speech_number = 8. GET shakespeare/_search { \"query\": { \"term\": { \"play_name\": { \"value\": \"Henry IV\" } } }, \"sort\": [ { \"line_id\": { \"order\": \"desc\" } }, { \"speech_number\": { \"order\": \"desc\" } } ], \"search_after\": [ \"3202\", \"8\" ] } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/#sort-results",
    "relUrl": "/docs/elasticsearch/ux/#sort-results"
  },"809": {
    "doc": "Search Experience",
    "title": "Highlight query matches",
    "content": "Highlighting emphasizes the search term(s) in the results. To highlight the search terms, add a highlight parameter outside of the query block: . GET shakespeare/_search { \"query\": { \"match\": { \"text_entry\": \"life\" } }, \"highlight\": { \"fields\": { \"text_entry\": {} } } } . For each document in the results, you get back a highlight object that shows your search term wrapped in an em tag: . \"highlight\": { \"text_entry\": [ \"my &lt;em&gt;life&lt;/em&gt;, except my &lt;em&gt;life&lt;/em&gt;.\" ] } . Design your application code to parse the results from the highlight object and perform some action on the search terms, such as changing their color, bolding, italicizing, and so on. To change the default em tags, use the pretag and posttag parameters: . GET shakespeare/_search?format=yaml { \"query\": { \"match\": { \"play_name\": \"Henry IV\" } }, \"highlight\": { \"pre_tags\": [ \"&lt;strong&gt;\" ], \"post_tags\": [ \"&lt;/strong&gt;\" ], \"fields\": { \"play_name\": {} } } } . The highlight parameter highlights the original terms even when using synonyms or stemming for the search itself. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/elasticsearch/ux/#highlight-query-matches",
    "relUrl": "/docs/elasticsearch/ux/#highlight-query-matches"
  },"810": {
    "doc": "Version History",
    "title": "Version history",
    "content": "| Open Distro for Elasticsearch version | Release highlights | Release date | Elasticsearch version | . | 1.11.0 | Adds Piped Processing Language (PPL) for exploring data, high cardinality support to Anomaly Detection, custom scoring for KNN, and security supporting to the alerting plugin. Query Workbench replaces SQL Workbench in this version. | 27 October 2020 | 7.9.1 | . | 1.10.1 | Completely revamps the security user interface in Kibana, adds new email destination to the alerting plugin, adds sample detectors to Anomaly Detection, bumps Elasticsearch version. | 30 September 2020 | 7.9.1 | . | 1.9.0 | Adds Root Cause Analysis, new Anomaly Detection actions, and a new Index State Management action. | 9 July 2020 | 7.8.0 | . | 1.8.0 | Adds snapshot operation to Index State Management, a new count aggregation to Anomaly Detection, and cosine similarity to KNN. Also bumps Elasticsearch version. | 2 June 2020 | 7.7.0 | . | 1.7.0 | Adds numerous new SQL operations, SQL user interface for Kibana, SQL CLI, Anomaly Detection plugin, and Anomaly Detection user interface for Kibana. | 13 May 2020 | 7.6.1 | . | 1.6.0 | Optimizes security for a faster version of the implied permission type, adds memoization of results for batch requests, implements lazy loading for k-NN efSearch parameter, adds the KNN plugin to the RPM and Debian installs, improves exception handling and report date handling using standard formats for the SQL plugin, and bumps Elasticsearch version. | 02 April 2020 | 7.6.1 | . | 1.4.0 | Adds the KNN plugin for Elasticsearch to the Docker image, adds account management to the security plugin API and Kibana, and bumps Elasticsearch version. | 10 February 2020 | 7.4.2 | . | 1.3.0 | Adds Index State Management plugins for Elasticsearch and Kibana and bumps Elasticsearch version. | 17 December 2019 | 7.3.2 | . | 1.2.1 | Bumps Elasticsearch version. | 4 November 2019 | 7.2.1 | . | 1.2.0 | Bumps Elasticsearch version. | 19 September 2019 | 7.2.0 | . | 1.1.0 | Bumps Elasticsearch version. | 30 July 2019 | 7.1.1 | . | 1.0.2 | Fixes an action group bug in the security plugin. | 23 July 2019 | 7.0.1 | . | 1.0.1 | Fixes backend role bugs in the security plugin. | 12 July 2019 | 7.0.1 | . | 1.0.0 | Adds action throttling to the alerting plugin and bumps Elasticsearch to a new major version. See Upgrade to 1.x.x for breaking changes. | 28 June 2019 | 7.0.1 | . | 0.10.0 | Support for older Elasticsearch version. | 7 August 2019 | 6.8.1 | . | 0.9.0 | Bumps Elasticsearch version. | 1 May 2019 | 6.7.1 | . | 0.8.0 | Bumps Elasticsearch version. | 5 April 2019 | 6.6.2 | . | 0.7.1 | Fixes Kibana multi-tenancy. | 29 March 2019 | 6.5.4 | . | 0.7.0 | Initial release. | 11 March 2019 | 6.5.4 | . For detailed release notes, see these GitHub repositories: . | Open Distro for Elasticsearch | Security | Alerting | SQL | Index State Management | Performance Analyzer | KNN | Anomaly Detection | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/version-history/#version-history",
    "relUrl": "/version-history/#version-history"
  },"811": {
    "doc": "Version History",
    "title": "Version History",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/version-history/",
    "relUrl": "/version-history/"
  },"812": {
    "doc": "Window Functions",
    "title": "Window Functions",
    "content": "A window function performs a calculation across a frame of data rows around the current row and finds a result for each row. PARTITION BY and ORDER BY define the frame of data over which the calculation is made. You can use window functions in the following three categories: . | Aggregate Functions: COUNT(), MIN(), MAX(), AVG(), and SUM(). | Ranking Functions: ROW_NUMBER(), RANK(), DENSE_RANK(), PERCENT_RANK(), and NTILE(). | Analytic Functions: CUME_DIST(), LAG(), and LEAD(). | . The syntax of a window function is as follows: . function_name (expression [, expression...]) OVER ( PARTITION BY expression [, expression...] ORDER BY expression [ASC | DESC] [, ...] ) . The PARTITION BY and ORDER BY clauses are optional. To use window functions, enable the new SQL engine: . PUT _cluster/settings { \"persistent\": { \"opendistro.sql.engine.new.enabled\" : \"true\" } } . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/window/",
    "relUrl": "/docs/sql/window/"
  },"813": {
    "doc": "Window Functions",
    "title": "Ranking functions",
    "content": "Ranking functions assign an incremental ranking value to each row in the frame. The increase in the ranking value depends on how the ranking function is implemented. The ranking value is mostly determined by the field values in the ORDER BY clause. If the PARTITION BY clause is also present, the ranking function resets its state, while maintaining the incremental ranking value. If you use the ranking function without the ORDER BY clause, the result is undetermined. Without the ORDER BY clause, ROW_NUMBER assigns a random number to each data row while RANK and DENSE_RANK assign a ranking value of 1 to each data row. RANK . The RANK function assigns a ranking value to each row of a result set. It assigns the same ranking value for the same field values specified in the ORDER BY list. SELECT gender, RANK() OVER ( ORDER BY gender DESC ) AS rnk FROM accounts; . | gender | rank | . | M | 1 | . | M | 1 | . | M | 1 | . | F | 4 | . In this case, the next few ranks are skipped depending on the number of ties that occur. ROW_NUMBER . ROW_NUMBER assigns a number to each data row of the result set sequentially. The row number increases by 1 regardless of the fields specified in the ORDER BY list. SELECT gender, balance, ROW_NUMBER() OVER ( PARTITION BY gender ORDER BY balance ) AS num FROM accounts; . | gender | balance | num | . | F | 32838 | 1 | . | M | 4180 | 1 | . | M | 5686 | 2 | . | M | 39225 | 3 | . DENSE_RANK . Similar to the RANK function, DENSE_RANK also assigns a ranking value to each row but without any gaps between the ranking values. SELECT gender, DENSE_RANK() OVER ( ORDER BY gender DESC ) AS rnk FROM accounts; . | gender | rank | . | M | 1 | . | M | 1 | . | M | 1 | . | F | 2 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/window/#ranking-functions",
    "relUrl": "/docs/sql/window/#ranking-functions"
  },"814": {
    "doc": "Windows",
    "title": "Windows",
    "content": "Like the tarball installation, the Windows installation of Open Distro for Elasticsearch is a good option for testing and development, but we recommend Docker or a package manager for production deployments. We test on Windows 10 and Windows Server 2019, but other versions might work. As an alternative, try Ubuntu for Windows 10, which you can use to install Debian packages. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/",
    "relUrl": "/docs/install/windows/"
  },"815": {
    "doc": "Windows",
    "title": "ZIP install",
    "content": ". | Download the ZIP file. | Extract the file to a directory, and open that directory at the command prompt. | Run Open Distro for Elasticsearch: .\\bin\\elasticsearch.bat . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/#zip-install",
    "relUrl": "/docs/install/windows/#zip-install"
  },"816": {
    "doc": "Windows",
    "title": "EXE install",
    "content": ". | Install Java 11. | Download the EXE file, run it, and click through the steps. | Open the command prompt and navigate to the Open Distro for Elasticsearch install directory. | Run Open Distro for Elasticsearch: .\\bin\\elasticsearch.bat . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/#exe-install",
    "relUrl": "/docs/install/windows/#exe-install"
  },"817": {
    "doc": "Windows",
    "title": "Install as a Windows service",
    "content": "Installing Open Distro for Elasticsearch as a Windows service lets it run in the background and makes it easier to monitor. You can also configure the service to start automatically after a reboot. | Open the command prompt and navigate to the Open Distro for Elasticsearch install directory. | Set the JAVA_HOME environment variable: . set JAVA_HOME=C:\\path\\to\\jdk . | (Optional) Set the ES_START_TYPE environment variable if you want Open Distro for Elasticsearch to start automatically when Windows starts: . set ES_START_TYPE=auto . | Install the service: .\\bin\\elasticsearch-service.bat install . | (Optional) Open the service manager UI to make additional configuration changes: .\\bin\\elasticsearch-service.bat manager . | Start the service: .\\bin\\elasticsearch-service.bat start . | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/#install-as-a-windows-service",
    "relUrl": "/docs/install/windows/#install-as-a-windows-service"
  },"818": {
    "doc": "Windows",
    "title": "Verify the install",
    "content": "After you start Open Distro for Elasticsearch, open a new command prompt window. Then send requests to the server to verify that it is up and running: . curl -XGET https://localhost:9200 -u admin:admin --insecure curl -XGET https://localhost:9200/_cat/plugins?v -u admin:admin --insecure . You must have curl installed for these commands to work. Alternatives include Invoke-RestMethod (only PowerShell 6 and later support the -SkipCertificateCheck flag) and Postman. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/#verify-the-install",
    "relUrl": "/docs/install/windows/#verify-the-install"
  },"819": {
    "doc": "Windows",
    "title": "Configuration",
    "content": "You can modify config\\elasticsearch.yml or specify environment variables as arguments using -E: .\\bin\\elasticsearch.bat -Ecluster.name=odfe-cluster -Enode.name=odfe-node1 -Ehttp.host=0.0.0.0 -Ediscovery.type=single-node . For other settings, see Important settings. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/install/windows/#configuration",
    "relUrl": "/docs/install/windows/#configuration"
  },"820": {
    "doc": "Workbench",
    "title": "Workbench",
    "content": "Use the SQL workbench to easily run on-demand SQL queries, translate SQL into its REST equivalent, and view and save results as text, JSON, JDBC, or CSV. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/workbench/",
    "relUrl": "/docs/sql/workbench/"
  },"821": {
    "doc": "Workbench",
    "title": "Quick start",
    "content": "To get started with SQL Workbench, choose Dev Tools in Kibana and use the bulk operation to index some sample data: . PUT accounts/_bulk?refresh {\"index\":{\"_id\":\"1\"}} {\"account_number\":1,\"balance\":39225,\"firstname\":\"Amber\",\"lastname\":\"Duke\",\"age\":32,\"gender\":\"M\",\"address\":\"880 Holmes Lane\",\"employer\":\"Pyrami\",\"email\":\"amberduke@pyrami.com\",\"city\":\"Brogan\",\"state\":\"IL\"} {\"index\":{\"_id\":\"6\"}} {\"account_number\":6,\"balance\":5686,\"firstname\":\"Hattie\",\"lastname\":\"Bond\",\"age\":36,\"gender\":\"M\",\"address\":\"671 Bristol Street\",\"employer\":\"Netagy\",\"email\":\"hattiebond@netagy.com\",\"city\":\"Dante\",\"state\":\"TN\"} {\"index\":{\"_id\":\"13\"}} {\"account_number\":13,\"balance\":32838,\"firstname\":\"Nanette\",\"lastname\":\"Bates\",\"age\":28,\"gender\":\"F\",\"address\":\"789 Madison Street\",\"employer\":\"Quility\",\"email\":\"nanettebates@quility.com\",\"city\":\"Nogal\",\"state\":\"VA\"} {\"index\":{\"_id\":\"18\"}} {\"account_number\":18,\"balance\":4180,\"firstname\":\"Dale\",\"lastname\":\"Adams\",\"age\":33,\"gender\":\"M\",\"address\":\"467 Hutchinson Court\",\"email\":\"daleadams@boink.com\",\"city\":\"Orick\",\"state\":\"MD\"} . Then return to SQL Workbench. List indices . To list all your indices: . SHOW TABLES LIKE % . | id | TABLE_NAME | . | 0 | accounts | . Read data . After you index a document, retrieve it using the following SQL expression: . SELECT * FROM accounts WHERE _id = 1 . | id | account_number | firstname | gender | city | balance | employer | state | email | address | lastname | age | . | 0 | 1 | Amber | M | Brogan | 39225 | Pyrami | IL | amberduke@pyrami.com | 880 Holmes Lane | Duke | 32 | . Delete data . To delete a document from an index, use the DELETE clause: . DELETE FROM accounts WHERE _id = 0 . | id | deleted_rows | . | 0 | 1 | . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/sql/workbench/#quick-start",
    "relUrl": "/docs/sql/workbench/#quick-start"
  },"822": {
    "doc": "YAML Files",
    "title": "YAML files",
    "content": "Before running securityadmin.sh to load the settings into the .opendistro_security index, configure the YAML files in plugins/opendistro_security/securityconfig. You might want to back up these files so that you can reuse them on other clusters. The best use of these YAML files is to configure reserved and hidden resources, such as the admin and kibanaserver users. You might find it easier to create other users, roles, mappings, action groups, and tenants using Kibana or the REST API. ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#yaml-files",
    "relUrl": "/docs/security/configuration/yaml/#yaml-files"
  },"823": {
    "doc": "YAML Files",
    "title": "internal_users.yml",
    "content": "This file contains any initial users that you want to add to the security plugin’s internal user database. The file format requires a hashed password. To generate one, run plugins/opendistro_security/tools/hash.sh -p &lt;new-password&gt;. If you decide to keep any of the demo users, change their passwords. --- # This is the internal user database # The hash value is a bcrypt hash and can be generated with plugin/tools/hash.sh _meta: type: \"internalusers\" config_version: 2 # Define your internal users here new-user: hash: \"$2y$12$88IFVl6IfIwCFh5aQYfOmuXVL9j2hz/GusQb35o.4sdTDAEMTOD.K\" reserved: false hidden: false opendistro_security_roles: - \"some-security-role\" backend_roles: - \"some-backend-role\" attributes: attribute1: \"value1\" static: false ## Demo users admin: hash: \"$2a$12$VcCDgh2NDk07JGN0rjGbM.Ad41qVR/YFJcgHp0UGns5JDymv..TOG\" reserved: true backend_roles: - \"admin\" description: \"Demo admin user\" kibanaserver: hash: \"$2a$12$4AcgAt3xwOWadA5s5blL6ev39OXDNhmOesEoo33eZtrq2N0YrU3H.\" reserved: true description: \"Demo kibanaserver user\" kibanaro: hash: \"$2a$12$JJSXNfTowz7Uu5ttXfeYpeYE0arACvcwlPBStB1F.MI7f0U9Z4DGC\" reserved: false backend_roles: - \"kibanauser\" - \"readall\" attributes: attribute1: \"value1\" attribute2: \"value2\" attribute3: \"value3\" description: \"Demo kibanaro user\" logstash: hash: \"$2a$12$u1ShR4l4uBS3Uv59Pa2y5.1uQuZBrZtmNfqB3iM/.jL0XoV9sghS2\" reserved: false backend_roles: - \"logstash\" description: \"Demo logstash user\" readall: hash: \"$2a$12$ae4ycwzwvLtZxwZ82RmiEunBbIPiAmGZduBAjKN0TXdwQFtCwARz2\" reserved: false backend_roles: - \"readall\" description: \"Demo readall user\" snapshotrestore: hash: \"$2y$12$DpwmetHKwgYnorbgdvORCenv4NAK8cPUg8AI6pxLCuWf/ALc0.v7W\" reserved: false backend_roles: - \"snapshotrestore\" description: \"Demo snapshotrestore user\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#internal_usersyml",
    "relUrl": "/docs/security/configuration/yaml/#internal_usersyml"
  },"824": {
    "doc": "YAML Files",
    "title": "roles.yml",
    "content": "This file contains any initial roles that you want to add to the security plugin. Aside from some metadata, the default file is empty, because the security plugin has a number of static roles that it adds automatically. --- complex-role: reserved: false hidden: false cluster_permissions: - \"read\" - \"cluster:monitor/nodes/stats\" - \"cluster:monitor/task/get\" index_permissions: - index_patterns: - \"kibana_sample_data_*\" dls: \"{\\\"match\\\": {\\\"FlightDelay\\\": true}}\" fls: - \"~FlightNum\" masked_fields: - \"Carrier\" allowed_actions: - \"read\" tenant_permissions: - tenant_patterns: - \"analyst_*\" allowed_actions: - \"kibana_all_write\" static: false _meta: type: \"roles\" config_version: 2 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#rolesyml",
    "relUrl": "/docs/security/configuration/yaml/#rolesyml"
  },"825": {
    "doc": "YAML Files",
    "title": "roles_mapping.yml",
    "content": "--- manage_snapshots: reserved: true hidden: false backend_roles: - \"snapshotrestore\" hosts: [] users: [] and_backend_roles: [] logstash: reserved: false hidden: false backend_roles: - \"logstash\" hosts: [] users: [] and_backend_roles: [] own_index: reserved: false hidden: false backend_roles: [] hosts: [] users: - \"*\" and_backend_roles: [] description: \"Allow full access to an index named like the username\" kibana_user: reserved: false hidden: false backend_roles: - \"kibanauser\" hosts: [] users: [] and_backend_roles: [] description: \"Maps kibanauser to kibana_user\" complex-role: reserved: false hidden: false backend_roles: - \"ldap-analyst\" hosts: [] users: - \"new-user\" and_backend_roles: [] _meta: type: \"rolesmapping\" config_version: 2 all_access: reserved: true hidden: false backend_roles: - \"admin\" hosts: [] users: [] and_backend_roles: [] description: \"Maps admin to all_access\" readall: reserved: true hidden: false backend_roles: - \"readall\" hosts: [] users: [] and_backend_roles: [] kibana_server: reserved: true hidden: false backend_roles: [] hosts: [] users: - \"kibanaserver\" and_backend_roles: [] . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#roles_mappingyml",
    "relUrl": "/docs/security/configuration/yaml/#roles_mappingyml"
  },"826": {
    "doc": "YAML Files",
    "title": "action_groups.yml",
    "content": "This file contains any initial action groups that you want to add to the security plugin. Aside from some metadata, the default file is empty, because the security plugin has a number of static action groups that it adds automatically. These static action groups cover a wide variety of use cases and are a great way to get started with the plugin. --- my-action-group: reserved: false hidden: false allowed_actions: - \"indices:data/write/index*\" - \"indices:data/write/update*\" - \"indices:admin/mapping/put\" - \"indices:data/write/bulk*\" - \"read\" - \"write\" static: false _meta: type: \"actiongroups\" config_version: 2 . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#action_groupsyml",
    "relUrl": "/docs/security/configuration/yaml/#action_groupsyml"
  },"827": {
    "doc": "YAML Files",
    "title": "tenants.yml",
    "content": "--- _meta: type: \"tenants\" config_version: 2 admin_tenant: reserved: false description: \"Demo tenant for admin user\" . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#tenantsyml",
    "relUrl": "/docs/security/configuration/yaml/#tenantsyml"
  },"828": {
    "doc": "YAML Files",
    "title": "nodes_dn.yml",
    "content": "--- _meta: type: \"nodesdn\" config_version: 2 # Define nodesdn mapping name and corresponding values # cluster1: # nodes_dn: # - CN=*.example.com . ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/#nodes_dnyml",
    "relUrl": "/docs/security/configuration/yaml/#nodes_dnyml"
  },"829": {
    "doc": "YAML Files",
    "title": "YAML Files",
    "content": " ",
    "url": "https://opendistro.github.io/for-elasticsearch-docs/old/1.11.0/docs/security/configuration/yaml/",
    "relUrl": "/docs/security/configuration/yaml/"
  }
}
